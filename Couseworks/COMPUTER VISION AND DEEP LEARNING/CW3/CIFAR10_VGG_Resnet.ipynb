{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "CIFAR10_VGG_Resnet.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09f49cce26484aa0b9081a07e6b28b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cc9285d5b72647928df997e72e3db7f8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_83cf1798cd964d97bd9753f0b1e08110",
              "IPY_MODEL_c23373de742b42bfbc2383d2dad37000"
            ]
          }
        },
        "cc9285d5b72647928df997e72e3db7f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83cf1798cd964d97bd9753f0b1e08110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d08f2edcfe45428384b92af656c1c20b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e546610156b45a89c01f8b93666b20c"
          }
        },
        "c23373de742b42bfbc2383d2dad37000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e3480b9517d446e9a9245fd73e917164",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:02&lt;00:00, 69040138.98it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f11cc7651dcf4cabb9ae607a9ee2b52f"
          }
        },
        "d08f2edcfe45428384b92af656c1c20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e546610156b45a89c01f8b93666b20c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3480b9517d446e9a9245fd73e917164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f11cc7651dcf4cabb9ae607a9ee2b52f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTVbLfh0NGhc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import copy\n",
        "from collections import namedtuple\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.optim.lr_scheduler import StepLR, _LRScheduler\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3VnC7UzqbLj"
      },
      "source": [
        "# Load CIFAR10 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHJfzTq9NGhx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "09f49cce26484aa0b9081a07e6b28b01",
            "cc9285d5b72647928df997e72e3db7f8",
            "83cf1798cd964d97bd9753f0b1e08110",
            "c23373de742b42bfbc2383d2dad37000",
            "d08f2edcfe45428384b92af656c1c20b",
            "4e546610156b45a89c01f8b93666b20c",
            "e3480b9517d446e9a9245fd73e917164",
            "f11cc7651dcf4cabb9ae607a9ee2b52f"
          ]
        },
        "outputId": "202d19b3-8c74-4158-9f95-7d7b0d78965c"
      },
      "source": [
        "# using pretrained means to normalize the dataset\n",
        "pretrained_means = [0.4914, 0.4822, 0.4465]\n",
        "pretrained_stds= [0.247, 0.243, 0.261]\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# define tranforms on the training set\n",
        "# include resizing and horizontal flip\n",
        "transform = transforms.Compose([transforms.Resize((32,32)),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean = pretrained_means,\n",
        "                                                     std = pretrained_stds)])\n",
        "# load the data\n",
        "train = datasets.CIFAR10(root='./data', train=True, download=True, transform = transform)\n",
        "test = datasets.CIFAR10(root='./data', train=False, download=True, transform = transform)\n",
        "\n",
        "# percentage of the training data to be used in training\n",
        "TRAIN_VAL_RATIO = 0.90\n",
        "\n",
        "n_train_examples = int(len(train) * TRAIN_VAL_RATIO)\n",
        "n_valid_examples = len(train) - n_train_examples\n",
        "\n",
        "train, val = torch.utils.data.random_split(train, [n_train_examples, n_valid_examples])\n",
        "\n",
        "# applying the transform on validation set\n",
        "val = copy.deepcopy(val)\n",
        "val.dataset.transform = transform\n",
        "\n",
        "# defining appropriate dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val, batch_size = BATCH_SIZE, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle=False)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09f49cce26484aa0b9081a07e6b28b01",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n5Pl8TOqi2m"
      },
      "source": [
        "# Utils Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvNjnxR8ZbBm"
      },
      "source": [
        "def calculate_accuracy(y_pred, y):\n",
        "    '''get model accuracy'''\n",
        "    p = y_pred.argmax(1, keepdim = True)\n",
        "    acc = p.eq(y.view_as(p)).sum().float() / y.shape[0]\n",
        "    return acc\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, device):\n",
        "    '''\n",
        "    function to be called for training and collect \n",
        "    model loss and model accuracy\n",
        "    and perform a training step\n",
        "\n",
        "    iterator: DataLoader Object\n",
        "    optimizer: Optimizer type\n",
        "    criterion: loss type\n",
        "    '''\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set to training mode\n",
        "    model.train()\n",
        "    \n",
        "    for (x, y) in iterator:\n",
        "        \n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x)\n",
        "        \n",
        "        loss = criterion(y_pred, y)\n",
        "        \n",
        "        acc = calculate_accuracy(y_pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # update loss and accuracy values\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion, device):\n",
        "    '''\n",
        "    function to be called for evaluating and collect \n",
        "    model val loss and model val accuracy\n",
        "\n",
        "    iterator: DataLoader Object\n",
        "    optimizer: Optimizer type\n",
        "    criterion: loss type\n",
        "    '''\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for (x, y) in iterator:\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            y_pred = model(x)\n",
        "            loss = criterion(y_pred, y)\n",
        "            acc = calculate_accuracy(y_pred, y)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGYf6Hj-NGhy"
      },
      "source": [
        "class LRFinder:\n",
        "    def __init__(self, model, optimizer, criterion, device):\n",
        "        \n",
        "        self.optimizer = optimizer\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.device = device\n",
        "        \n",
        "        torch.save(model.state_dict(), 'init_params.pt')\n",
        "\n",
        "    def range_test(self, iterator, end_lr = 10, num_iter = 100, smooth_f = 0.05, diverge_th = 5):\n",
        "        \n",
        "        lrs = []\n",
        "        losses = []\n",
        "        best_loss = float('inf')\n",
        "\n",
        "        lr_scheduler = ExponentialLR(self.optimizer, end_lr, num_iter)\n",
        "        \n",
        "        iterator = IteratorWrapper(iterator)\n",
        "        \n",
        "        for iteration in range(num_iter):\n",
        "\n",
        "            loss = self._train_batch(iterator)\n",
        "\n",
        "            #update lr\n",
        "            lr_scheduler.step()\n",
        "            \n",
        "            lrs.append(lr_scheduler.get_lr()[0])\n",
        "\n",
        "            if iteration > 0:\n",
        "                loss = smooth_f * loss + (1 - smooth_f) * losses[-1]\n",
        "                \n",
        "            if loss < best_loss:\n",
        "                best_loss = loss\n",
        "\n",
        "            losses.append(loss)\n",
        "            \n",
        "            if loss > diverge_th * best_loss:\n",
        "                print(\"Stopping early, the loss has diverged\")\n",
        "                break\n",
        "                       \n",
        "        #reset model to initial parameters\n",
        "        self.model.load_state_dict(torch.load('init_params.pt'))\n",
        "                    \n",
        "        return lrs, losses\n",
        "\n",
        "    def _train_batch(self, iterator):\n",
        "        \n",
        "        self.model.train()\n",
        "        \n",
        "        self.optimizer.zero_grad()\n",
        "        \n",
        "        x, y = iterator.get_batch()\n",
        "        \n",
        "        x = x.to(self.device)\n",
        "        y = y.to(self.device)\n",
        "        \n",
        "        #y_pred, _ = self.model(x) original\n",
        "        y_pred = self.model(x)\n",
        "\n",
        "                \n",
        "        loss = self.criterion(y_pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        self.optimizer.step()\n",
        "        \n",
        "        return loss.item()\n",
        "\n",
        "class ExponentialLR(_LRScheduler):\n",
        "    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
        "        self.end_lr = end_lr\n",
        "        self.num_iter = num_iter\n",
        "        super(ExponentialLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        curr_iter = self.last_epoch + 1\n",
        "        r = curr_iter / self.num_iter\n",
        "        return [base_lr * (self.end_lr / base_lr) ** r for base_lr in self.base_lrs]\n",
        "\n",
        "class IteratorWrapper:\n",
        "    def __init__(self, iterator):\n",
        "        self.iterator = iterator\n",
        "        self._iterator = iter(iterator)\n",
        "\n",
        "    def __next__(self):\n",
        "        try:\n",
        "            inputs, labels = next(self._iterator)\n",
        "        except StopIteration:\n",
        "            self._iterator = iter(self.iterator)\n",
        "            inputs, labels, *_ = next(self._iterator)\n",
        "\n",
        "        return inputs, labels\n",
        "\n",
        "    def get_batch(self):\n",
        "        return next(self)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhY2jAiXNGhz"
      },
      "source": [
        "def plot_lr_finder(lrs, losses, skip_start = 5, skip_end = 5):\n",
        "    \n",
        "    if skip_end == 0:\n",
        "        lrs = lrs[skip_start:]\n",
        "        losses = losses[skip_start:]\n",
        "    else:\n",
        "        lrs = lrs[skip_start:-skip_end]\n",
        "        losses = losses[skip_start:-skip_end]\n",
        "    \n",
        "    fig = plt.figure(figsize = (16,8))\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "    ax.plot(lrs, losses)\n",
        "    ax.set_xscale('log')\n",
        "    ax.set_xlabel('Learning rate')\n",
        "    ax.set_ylabel('Loss')\n",
        "    ax.grid(True, 'both', 'x')\n",
        "    plt.show()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB6Wf6R3NGh0"
      },
      "source": [
        "def get_preds(model, iterator):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for (x, y) in iterator:\n",
        "\n",
        "            x = x.to(device)\n",
        "\n",
        "            y_pred = model(x)\n",
        "\n",
        "            y_prob = F.softmax(y_pred, dim = -1)\n",
        "            top_pred = y_prob.argmax(1, keepdim = True)\n",
        "\n",
        "            images.append(x.cpu())\n",
        "            labels.append(y.cpu())\n",
        "            probs.append(y_prob.cpu())\n",
        "\n",
        "    images = torch.cat(images, dim = 0)\n",
        "    labels = torch.cat(labels, dim = 0)\n",
        "    probs = torch.cat(probs, dim = 0)\n",
        "\n",
        "    return images, labels, probs"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCZXnTXkNGh0"
      },
      "source": [
        "def plot_confusion_matrix(labels, pred_labels, classes):\n",
        "    \n",
        "    fig = plt.figure(figsize = (10, 10));\n",
        "    ax = fig.add_subplot(1, 1, 1);\n",
        "    cm = confusion_matrix(labels, pred_labels);\n",
        "    cm = ConfusionMatrixDisplay(cm, classes);\n",
        "    cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)\n",
        "    plt.xticks(rotation = 20)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngBsGGFfNGh1"
      },
      "source": [
        "def labels_accuracy(y, y_pred):\n",
        "    crr = 0\n",
        "    for i in range(len(y)):\n",
        "        if y[i] == y_pred[i]:\n",
        "            crr += 1\n",
        "    return crr/len(y)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNdDgRBHNGh1"
      },
      "source": [
        "def normalize_image(image):\n",
        "    image_min = image.min()\n",
        "    image_max = image.max()\n",
        "    image.clamp_(min = image_min, max = image_max)\n",
        "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
        "    return image\n",
        "\n",
        "def plot_images(images, labels, classes, normalize = False):\n",
        "\n",
        "    n_images = len(images)\n",
        "\n",
        "    rows = int(np.sqrt(n_images))\n",
        "    cols = int(np.sqrt(n_images))\n",
        "\n",
        "    fig = plt.figure(figsize = (10, 10))\n",
        "\n",
        "    for i in range(rows*cols):\n",
        "\n",
        "        ax = fig.add_subplot(rows, cols, i+1)\n",
        "        \n",
        "        image = images[i]\n",
        "\n",
        "        if normalize:\n",
        "            image = normalize_image(image)\n",
        "\n",
        "        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
        "        ax.set_title(classes[labels[i]])\n",
        "        ax.axis('off')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP83y2Z4NGh2"
      },
      "source": [
        "def show_incorrect_preds(incorrect, classes, n_images, normalize = False):\n",
        "\n",
        "    rows = 1 \n",
        "    cols = n_images  \n",
        "\n",
        "    fig = plt.figure(figsize = (10, 10))\n",
        "    fig.tight_layout()\n",
        "    for i in range(cols):\n",
        "\n",
        "        ax = fig.add_subplot(rows, cols, i+1)\n",
        "        \n",
        "        image, true_label, probs = incorrect[i]\n",
        "        image = image[0]\n",
        "        true_prob = probs[true_label]\n",
        "        incorrect_prob, incorrect_label = torch.max(probs, dim = 0)\n",
        "        true_class = classes[true_label][0]\n",
        "        incorrect_class = classes[incorrect_label][0]\n",
        "\n",
        "        if normalize:\n",
        "            image = normalize_image(image)\n",
        "\n",
        "        ax.imshow(image.cpu().numpy())\n",
        "        ax.set_title(f'true class: {true_class}\\n' \\\n",
        "                     f'pred class: {incorrect_class}')\n",
        "        ax.axis('off')\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A63CFXWxNGh2"
      },
      "source": [
        "# VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roYgAiN4NGh2"
      },
      "source": [
        "class VGG(nn.Module):\n",
        "    def __init__(self, features, output_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.features = features\n",
        "        \n",
        "        #self.avgpool = nn.AdaptiveAvgPool2d(7)\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 , 128),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, output_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        #x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.classifier(h)\n",
        "        return x#, h"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rwnj81QNGh3"
      },
      "source": [
        "def get_vgg_layers(config, batch_norm):\n",
        "    \n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "    \n",
        "    for c in config:\n",
        "        assert c == 'M' or isinstance(c, int)\n",
        "        if c == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size = 2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, c, kernel_size = 3, padding = 1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(c), nn.ReLU(inplace = True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace = True)]\n",
        "            in_channels = c\n",
        "            \n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vtIJ1jwNGh3"
      },
      "source": [
        "vgg11_config = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
        "\n",
        "vgg13_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
        "\n",
        "vgg16_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
        "\n",
        "vgg19_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixwfkWKwNGh3"
      },
      "source": [
        "vgg13_layers = get_vgg_layers(vgg13_config, batch_norm = True)\n",
        "vgg16_layers = get_vgg_layers(vgg16_config, batch_norm = True)\n",
        "vgg19_layers = get_vgg_layers(vgg19_config, batch_norm = True)\n",
        "\n",
        "#vgg16_layers"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-qlMtXPXlp_"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgN9V4AMNGh4"
      },
      "source": [
        "OUTPUT_DIM = 10\n",
        "\n",
        "#model_VGG13 = VGG(vgg13_layers, OUTPUT_DIM)\n",
        "model_VGG16 = VGG(vgg16_layers, OUTPUT_DIM)\n",
        "#model_VGG19 = VGG(vgg19_layers, OUTPUT_DIM)\n",
        "\n",
        "#print(model_VGG16)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b32d_8tuNGh4"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_VGG16 = model_VGG16.to(device)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UylbpHxPNGh4"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "#summary(model_VGG16.to(device), (3, 32, 32))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT_pH7ZHNGh4"
      },
      "source": [
        "### Find best LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_3LdNnkNGh5"
      },
      "source": [
        "START_LR = 1e-7\n",
        "\n",
        "optimizer = optim.SGD(model_VGG16.parameters(), momentum=0.9, lr = START_LR)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_VGG16 = model_VGG16.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv3S-_hQNGh5"
      },
      "source": [
        "END_LR = 10\n",
        "NUM_ITER = 100\n",
        "\n",
        "lr_finder = LRFinder(model_VGG16, optimizer, criterion, device)\n",
        "lrs, losses = lr_finder.range_test(train_loader, END_LR, NUM_ITER)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgE8FFKzNGh6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "c292791f-f758-4d23-c763-2bd6badf39e9"
      },
      "source": [
        "plot_lr_finder(lrs, losses, skip_start = 10, skip_end = 20)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebx6UcABNGh6"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LZVpslENGh6"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)\n",
        "optimizer = torch.optim.SGD(model_VGG16.parameters(), lr = 0.01, momentum=0.9, weight_decay=0.0001)\n",
        "# scheduler for VGG\n",
        "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[10], last_epoch= -1)\n",
        "# scheduler for ResNet\n",
        "##scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[100, 150], last_epoch= -1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxBQwyGINGh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5583f6c1-13fe-4754-9171-2badfe44bd61"
      },
      "source": [
        "\n",
        "\n",
        "EPOCHS = 100\n",
        "train_loss_list_VGG16 = []\n",
        "train_acc_list_VGG16 = []\n",
        "\n",
        "val_loss_list_VGG16 = []\n",
        "val_acc_list_VGG16 = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model_VGG16, train_loader, optimizer, criterion, device)\n",
        "    #optimizer.step()\n",
        "    val_loss, val_acc = evaluate(model_VGG16, val_loader, criterion, device)\n",
        "    end_time = time.time()\n",
        "\n",
        "    train_loss_list_VGG16.append(train_loss)\n",
        "    train_acc_list_VGG16.append(train_acc)\n",
        "    val_loss_list_VGG16.append(val_loss)\n",
        "    val_acc_list_VGG16.append(val_acc)\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 2m 57s\n",
            "\tTrain Loss: 1.393 | Train Acc: 48.97%\n",
            "\t Val. Loss: 1.129 |  Val. Acc: 60.96%\n",
            "Epoch: 02 | Epoch Time: 2m 55s\n",
            "\tTrain Loss: 0.901 | Train Acc: 68.88%\n",
            "\t Val. Loss: 0.832 |  Val. Acc: 70.90%\n",
            "Epoch: 03 | Epoch Time: 2m 55s\n",
            "\tTrain Loss: 0.699 | Train Acc: 76.75%\n",
            "\t Val. Loss: 0.755 |  Val. Acc: 74.63%\n",
            "Epoch: 04 | Epoch Time: 2m 56s\n",
            "\tTrain Loss: 0.582 | Train Acc: 80.59%\n",
            "\t Val. Loss: 0.637 |  Val. Acc: 78.63%\n",
            "Epoch: 05 | Epoch Time: 2m 56s\n",
            "\tTrain Loss: 0.491 | Train Acc: 83.80%\n",
            "\t Val. Loss: 0.823 |  Val. Acc: 74.30%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMGEvkCnNGh7"
      },
      "source": [
        "images, labels, probs = get_preds(model_VGG16, test_loader)\n",
        "pred_labels = torch.argmax(probs, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ195jESNGh7"
      },
      "source": [
        "classes = test.classes\n",
        "\n",
        "plot_confusion_matrix(labels, pred_labels, classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mSlRO_NNGh7"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_loss_list_VGG16, label = 'training loss')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_loss_list_VGG16, label = 'validation loss')\n",
        "plt.legend()\n",
        "plt.title('VGG16 , Cross Entropy Loss across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzVMwPvfNGh8"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_acc_list_VGG16, label = 'training accuracy')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list_VGG16, label = 'validation accuracy')\n",
        "plt.legend()\n",
        "plt.title('VGG16 , Accuracy across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XbngY-ZNGh8"
      },
      "source": [
        "labels_accuracy(labels.numpy(), pred_labels.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gjyNig8NGh8"
      },
      "source": [
        "correct_pred = torch.eq(labels, pred_labels)\n",
        "incorrect_examples = []\n",
        "\n",
        "for image, label, prob, correct in zip(images, labels, probs, correct_pred):\n",
        "    if not correct:\n",
        "        incorrect_examples.append((image, label, prob))\n",
        "\n",
        "incorrect_examples.sort(reverse = True, key = lambda x: torch.max(x[2], dim = 0).values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxIl-ZiCNGh8"
      },
      "source": [
        "show_incorrect_preds(incorrect_examples, classes, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-WxjGaQZE-g"
      },
      "source": [
        "## VGG13"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQhT-pzvZT8l"
      },
      "source": [
        "OUTPUT_DIM = 10\n",
        "\n",
        "model_VGG13 = VGG(vgg13_layers, OUTPUT_DIM)\n",
        "#model_VGG16 = VGG(vgg16_layers, OUTPUT_DIM)\n",
        "#model_VGG19 = VGG(vgg19_layers, OUTPUT_DIM)\n",
        "\n",
        "#print(model_VGG16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apML1RxFZUFC"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_VGG16 = model_VGG16.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wqKF_VFZUI-"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "#summary(model_VGG13.to(device), (3, 32, 32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtM6OCjQZ0JL"
      },
      "source": [
        "### Find Best LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWr4AD0KZxuA"
      },
      "source": [
        "START_LR = 1e-7\n",
        "\n",
        "optimizer = optim.SGD(model_VGG13.parameters(), momentum=0.9, lr = START_LR)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_VGG13 = model_VGG13.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGeTPEzCZUNE"
      },
      "source": [
        "END_LR = 10\n",
        "NUM_ITER = 100\n",
        "\n",
        "lr_finder = LRFinder(model_VGG13, optimizer, criterion, device)\n",
        "lrs, losses = lr_finder.range_test(train_loader, END_LR, NUM_ITER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrRigXcBZUQj"
      },
      "source": [
        "plot_lr_finder(lrs, losses, skip_start = 10, skip_end = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_8S3cs5Z57C"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CIHO9aLZ8v1"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)\n",
        "optimizer = torch.optim.SGD(model_VGG13.parameters(), lr = 0.01, momentum=0.9, weight_decay=0.0001)\n",
        "# scheduler for VGG\n",
        "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[10], last_epoch= -1)\n",
        "# scheduler for ResNet\n",
        "##scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[100, 150], last_epoch= -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MadAWnGZZ9CZ"
      },
      "source": [
        "EPOCHS = 100\n",
        "train_loss_list_VGG13 = []\n",
        "train_acc_list_VGG13 = []\n",
        "\n",
        "val_loss_list_VGG13 = []\n",
        "val_acc_list_VGG13 = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model_VGG13, train_loader, optimizer, criterion, device)\n",
        "    #optimizer.step()\n",
        "    val_loss, val_acc = evaluate(model_VGG13, val_loader, criterion, device)\n",
        "    end_time = time.time()\n",
        "\n",
        "    train_loss_list_VGG13.append(train_loss)\n",
        "    train_acc_list_VGG13.append(train_acc)\n",
        "    val_loss_list_VGG13.append(val_loss)\n",
        "    val_acc_list_VGG13.append(val_acc)\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-XcLq0VZ9Fq"
      },
      "source": [
        "images, labels, probs = get_preds(model_VGG13, test_loader)\n",
        "pred_labels = torch.argmax(probs, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhWb1E_iZ9Jt"
      },
      "source": [
        "classes = test.classes\n",
        "\n",
        "plot_confusion_matrix(labels, pred_labels, classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-5UlfFmakFs"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_loss_list_VGG13, label = 'training loss')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_loss_list_VGG13, label = 'validation loss')\n",
        "plt.legend()\n",
        "plt.title('VGG13 , Cross Entropy Loss across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMk-l3zoakJi"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_acc_list_VGG13, label = 'training accuracy')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list_VGG13, label = 'validation accuracy')\n",
        "plt.legend()\n",
        "plt.title('VGG13 , Accuracy across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KVlOWprakNh"
      },
      "source": [
        "labels_accuracy(labels.numpy(), pred_labels.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr09EIXbau8P"
      },
      "source": [
        "correct_pred = torch.eq(labels, pred_labels)\n",
        "incorrect_examples = []\n",
        "\n",
        "for image, label, prob, correct in zip(images, labels, probs, correct_pred):\n",
        "    if not correct:\n",
        "        incorrect_examples.append((image, label, prob))\n",
        "\n",
        "incorrect_examples.sort(reverse = True, key = lambda x: torch.max(x[2], dim = 0).values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6GZ4R5YavBW"
      },
      "source": [
        "show_incorrect_preds(incorrect_examples, classes, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyXeMzFFNGh9"
      },
      "source": [
        "# Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXsXOCbKNGh9"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, config, output_dim):\n",
        "        super().__init__()\n",
        "                \n",
        "        block, n_blocks, channels = config\n",
        "        self.in_channels = channels[0]\n",
        "            \n",
        "        assert len(n_blocks) == len(channels) == 4\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "        \n",
        "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
        "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride = 2)\n",
        "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride = 2)\n",
        "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride = 2)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "        \n",
        "    def get_resnet_layer(self, block, n_blocks, channels, stride = 1):\n",
        "    \n",
        "        layers = []\n",
        "        \n",
        "        if self.in_channels != block.expansion * channels:\n",
        "            downsample = True\n",
        "        else:\n",
        "            downsample = False\n",
        "        \n",
        "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "        \n",
        "        for i in range(1, n_blocks):\n",
        "            layers.append(block(block.expansion * channels, channels))\n",
        "\n",
        "        self.in_channels = block.expansion * channels\n",
        "            \n",
        "        return nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.fc(h)\n",
        "        \n",
        "        return x#, h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rq-aAoLNGh-"
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    \n",
        "    expansion = 1\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "                \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        \n",
        "        \n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = stride, bias = False)\n",
        "            bn = nn.BatchNorm2d(out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "        \n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        i = x\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        \n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        \n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "                        \n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjsXRXyqNGh-"
      },
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    \n",
        "    expansion = 4\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "    \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = stride, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(out_channels, self.expansion * out_channels, kernel_size = 1, stride = 1, bias = False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        \n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size = 1, stride = stride, bias = False)\n",
        "            bn = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "            \n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        i = x\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        \n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        \n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "                \n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "            \n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "    \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33NV7-K9NGh_"
      },
      "source": [
        "class CIFARResNet(nn.Module):\n",
        "    def __init__(self, config, output_dim):\n",
        "        super().__init__()\n",
        "                \n",
        "        block, layers, channels = config\n",
        "        self.in_channels = channels[0]\n",
        "            \n",
        "        assert len(layers) == len(channels) == 3\n",
        "        assert all([i == j*2 for i, j in zip(channels[1:], channels[:-1])])\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        \n",
        "        self.layer1 = self.get_resnet_layer(block, layers[0], channels[0])\n",
        "        self.layer2 = self.get_resnet_layer(block, layers[1], channels[1], stride = 2)\n",
        "        self.layer3 = self.get_resnet_layer(block, layers[2], channels[2], stride = 2)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "        \n",
        "    def get_resnet_layer(self, block, n_blocks, channels, stride = 1):\n",
        "    \n",
        "        layers = []\n",
        "        \n",
        "        if self.in_channels != channels:\n",
        "            downsample = True\n",
        "        else:\n",
        "            downsample = False\n",
        "        \n",
        "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "        \n",
        "        for i in range(1, n_blocks):\n",
        "            layers.append(block(channels, channels))\n",
        "\n",
        "        self.in_channels = channels\n",
        "            \n",
        "        return nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        \n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.fc(h)\n",
        "        \n",
        "        return x#, h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr1Rur5FNGh_"
      },
      "source": [
        "class Identity(nn.Module):\n",
        "    def __init__(self, f):\n",
        "        super().__init__()\n",
        "        self.f = f\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.f(x)\n",
        "        \n",
        "\n",
        "class CIFARBasicBlock(nn.Module):\n",
        "        \n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "                \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3,stride = stride, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3,stride = 1, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "                \n",
        "        \n",
        "        if downsample:\n",
        "            identity_fn = lambda x : F.pad(x[:, :, ::2, ::2], [0, 0, 0, 0, in_channels // 2, in_channels // 2])\n",
        "            downsample = Identity(identity_fn)\n",
        "        else:\n",
        "            downsample = None\n",
        "        \n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        i = x\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        \n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        \n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "                                \n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-437eRMNGiA"
      },
      "source": [
        "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSm1QogWNGiA"
      },
      "source": [
        "resnet18_config = ResNetConfig (block = BasicBlock, n_blocks = [2,2,2,2], channels = [64, 128, 256, 512])\n",
        "resnet34_config = ResNetConfig (block = BasicBlock, n_blocks = [3,4,6,3], channels = [64, 128, 256, 512])\n",
        "\n",
        "resnet50_config = ResNetConfig (block = Bottleneck,n_blocks = [3, 4, 6, 3], channels = [64, 128, 256, 512])\n",
        "\n",
        "cifar_resnet20_config = ResNetConfig (block = CIFARBasicBlock, n_blocks = [3, 3, 3], channels = [16, 32, 64])\n",
        "cifar_resnet32_config = ResNetConfig (block = CIFARBasicBlock, n_blocks = [5, 5, 5], channels = [16, 32, 64])\n",
        "cifar_resnet44_config = ResNetConfig (block = CIFARBasicBlock, n_blocks = [7, 7, 7], channels = [16, 32, 64])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuzwVBeddSSc"
      },
      "source": [
        "## Resnet44"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EQgZ20xdFnX"
      },
      "source": [
        "#model_Resnet20 = CIFARResNet(cifar_resnet20_config,10)\n",
        "model_Resnet44 = CIFARResNet(cifar_resnet44_config,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evxXMykRNGiA"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_Resnet44 = model_Resnet44.to(device)\n",
        "#model_Resnet44"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW9PTpw_NGiA"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "#summary(model_Resnet44.to(device), (3, 32, 32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDR2AysFNGiB"
      },
      "source": [
        "### Find Best LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAy0CQpmNGiB"
      },
      "source": [
        "START_LR = 1e-7\n",
        "\n",
        "optimizer = optim.SGD(model_Resnet44.parameters(), momentum=0.9, lr = START_LR)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_Resnet44 = model_Resnet44.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGjOXDleNGiB"
      },
      "source": [
        "END_LR = 10\n",
        "NUM_ITER = 100\n",
        "\n",
        "lr_finder = LRFinder(model_Resnet44, optimizer, criterion, device)\n",
        "lrs, losses = lr_finder.range_test(train_loader, END_LR, NUM_ITER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5jwaA2BNGiB"
      },
      "source": [
        "plot_lr_finder(lrs, losses, skip_start = 10, skip_end = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5_bJdtCNGiB"
      },
      "source": [
        "###  Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFzCvHxbNGiB"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)\n",
        "optimizer = torch.optim.SGD(model_Resnet44.parameters(), momentum=0.1, lr = 0.01, weight_decay=0.0001)\n",
        "# scheduler for VGG\n",
        "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[10], last_epoch= -1)\n",
        "# scheduler for ResNet\n",
        "##scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[100, 150], last_epoch= -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7TW-cshNGiC"
      },
      "source": [
        "EPOCHS = 100\n",
        "train_loss_list_Resnet44 = []\n",
        "train_acc_list_Resnet44 = []\n",
        "\n",
        "val_loss_list_Resnet44 = []\n",
        "val_acc_list_Resnet44 = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model_Resnet44, train_loader, optimizer, criterion, device)\n",
        "    #optimizer.step()\n",
        "    val_loss, val_acc = evaluate(model_Resnet44, val_loader, criterion, device)\n",
        "    end_time = time.time()\n",
        "\n",
        "    train_loss_list_Resnet44.append(train_loss)\n",
        "    train_acc_list_Resnet44.append(train_acc)\n",
        "    val_loss_list_Resnet44.append(val_loss)\n",
        "    val_acc_list_Resnet44.append(val_acc)\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "551DHVHBNGiC"
      },
      "source": [
        "images, labels, probs = get_preds(model_Resnet44, test_loader)\n",
        "pred_labels = torch.argmax(probs, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gE-3T5LNGiC"
      },
      "source": [
        "classes = test.classes\n",
        "\n",
        "plot_confusion_matrix(labels, pred_labels, classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuS3aqYhNGiC"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_loss_list_Resnet44, label = 'training loss')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_loss_list_Resnet44, label = 'validation loss')\n",
        "plt.legend()\n",
        "plt.title('Resnet44 , Cross Entropy Loss across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQrl83ozNGiD"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_acc_list_Resnet44, label = 'training accuracy')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list_Resnet44, label = 'validation accuracy')\n",
        "plt.legend()\n",
        "plt.title('Resnet44 , Accuracy across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlbmARlRNGiD"
      },
      "source": [
        "labels_accuracy(labels.numpy(), pred_labels.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKie_zDyNGiD"
      },
      "source": [
        "correct_pred = torch.eq(labels, pred_labels)\n",
        "incorrect_examples = []\n",
        "\n",
        "for image, label, prob, correct in zip(images, labels, probs, correct_pred):\n",
        "    if not correct:\n",
        "        incorrect_examples.append((image, label, prob))\n",
        "\n",
        "incorrect_examples.sort(reverse = True, key = lambda x: torch.max(x[2], dim = 0).values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omdMieN5NGiD"
      },
      "source": [
        "show_incorrect_preds(incorrect_examples, classes, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrQU_FDPea7Z"
      },
      "source": [
        "## Resnet20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG3HZWIqefG8"
      },
      "source": [
        "model_Resnet20 = CIFARResNet(cifar_resnet20_config,10)\n",
        "#model_Resnet44 = CIFARResNet(cifar_resnet44_config,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGhI1yGDefPI"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_Resnet20 = model_Resnet20.to(device)\n",
        "#model_Resnet44"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIjPfFRcefSY"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "#summary(model_Resnet20.to(device), (3, 32, 32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq7GLjwEe-JD"
      },
      "source": [
        "### Find Best LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7hS5x63efVt"
      },
      "source": [
        "START_LR = 1e-7\n",
        "\n",
        "optimizer = optim.SGD(model_Resnet20.parameters(), momentum=0.9, lr = START_LR)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_Resnet20 = model_Resnet20.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIHgUmnEfHnT"
      },
      "source": [
        "END_LR = 10\n",
        "NUM_ITER = 100\n",
        "\n",
        "lr_finder = LRFinder(model_Resnet20, optimizer, criterion, device)\n",
        "lrs, losses = lr_finder.range_test(train_loader, END_LR, NUM_ITER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJXRFY_zefYq"
      },
      "source": [
        "plot_lr_finder(lrs, losses, skip_start = 10, skip_end = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHmXAgcifEsO"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7UgYaTyjp-P"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)\n",
        "optimizer = torch.optim.SGD(model_Resnet20.parameters(), momentum=0.1, lr = 0.01, weight_decay=0.0001)\n",
        "# scheduler for VGG\n",
        "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[10], last_epoch= -1)\n",
        "# scheduler for ResNet\n",
        "##scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[100, 150], last_epoch= -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzb2KITVeaFx"
      },
      "source": [
        "EPOCHS = 100\n",
        "train_loss_list_Resnet20 = []\n",
        "train_acc_list_Resnet20 = []\n",
        "\n",
        "val_loss_list_Resnet20 = []\n",
        "val_acc_list_Resnet20 = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model_Resnet20, train_loader, optimizer, criterion, device)\n",
        "    #optimizer.step()\n",
        "    val_loss, val_acc = evaluate(model_Resnet20, val_loader, criterion, device)\n",
        "    end_time = time.time()\n",
        "\n",
        "    train_loss_list_Resnet20.append(train_loss)\n",
        "    train_acc_list_Resnet20.append(train_acc)\n",
        "    val_loss_list_Resnet20.append(val_loss)\n",
        "    val_acc_list_Resnet20.append(val_acc)\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZN4gMldfRKD"
      },
      "source": [
        "images, labels, probs = get_preds(model_Resnet20, test_loader)\n",
        "pred_labels = torch.argmax(probs, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9d2hRgPfRNf"
      },
      "source": [
        "classes = test.classes\n",
        "\n",
        "plot_confusion_matrix(labels, pred_labels, classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfD7tH7-fRQd"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_loss_list_Resnet20, label = 'training loss')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_loss_list_Resnet20, label = 'validation loss')\n",
        "plt.legend()\n",
        "plt.title('Resnet20 , Cross Entropy Loss across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G54Ljk-4fRZy"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_acc_list_Resnet20, label = 'training accuracy')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list_Resnet20, label = 'validation accuracy')\n",
        "plt.legend()\n",
        "plt.title('Resnet20 , Accuracy across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyrcpuGafaSl"
      },
      "source": [
        "labels_accuracy(labels.numpy(), pred_labels.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbPFcFkHfaYD"
      },
      "source": [
        "correct_pred = torch.eq(labels, pred_labels)\n",
        "incorrect_examples = []\n",
        "\n",
        "for image, label, prob, correct in zip(images, labels, probs, correct_pred):\n",
        "    if not correct:\n",
        "        incorrect_examples.append((image, label, prob))\n",
        "\n",
        "incorrect_examples.sort(reverse = True, key = lambda x: torch.max(x[2], dim = 0).values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L7kHdohflFI"
      },
      "source": [
        "show_incorrect_preds(incorrect_examples, classes, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXl7qDk9NGiD"
      },
      "source": [
        "# Comparing Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b6Tp3GYNGiD"
      },
      "source": [
        "import seaborn as sns\n",
        "with sns.color_palette(\"husl\"):\n",
        "  \n",
        "    #sns.lineplot([i for i in range(1,EPOCHS + 1)], train_acc_list, label = 'Training Accuracy')\n",
        "    sns.lineplot([i for i in range(1,EPOCHS + 1)], val_acc_list_Resnet20, label = 'ResNet-20')\n",
        "    plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list_Resnet44, label = 'ResNet-44')\n",
        "    plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list_VGG16, label = 'VGG-16')\n",
        "    plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list_VGG13, label = 'VGG-13')\n",
        "    plt.legend()\n",
        "    plt.title('Validation Accuracy on CIFAR10')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}