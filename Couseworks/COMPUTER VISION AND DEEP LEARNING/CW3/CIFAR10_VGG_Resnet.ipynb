{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "CIFAR10_VGG_Resnet.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7a375d7eeea8464dbf04b8ebc65fb301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f707991e225c48d39c1678e2b2ddc496",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fa73a512872445a08a33ec20de9b517a",
              "IPY_MODEL_8db9734748e345a49227b29e551892b2"
            ]
          }
        },
        "f707991e225c48d39c1678e2b2ddc496": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa73a512872445a08a33ec20de9b517a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a7ce946f95d44a8eb53bc92c9922c498",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c43036202558419cac153b149278e1b0"
          }
        },
        "8db9734748e345a49227b29e551892b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7ce41e7374f94510acd3fe83d6dccc82",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:27&lt;00:00, 6311106.00it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aeab7390aaaa47d5a77ace6ee03cf6bd"
          }
        },
        "a7ce946f95d44a8eb53bc92c9922c498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c43036202558419cac153b149278e1b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ce41e7374f94510acd3fe83d6dccc82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aeab7390aaaa47d5a77ace6ee03cf6bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTVbLfh0NGhc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "import copy\n",
        "from collections import namedtuple\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.optim.lr_scheduler import StepLR, _LRScheduler\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3VnC7UzqbLj"
      },
      "source": [
        "# Load CIFAR10 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHJfzTq9NGhx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "7a375d7eeea8464dbf04b8ebc65fb301",
            "f707991e225c48d39c1678e2b2ddc496",
            "fa73a512872445a08a33ec20de9b517a",
            "8db9734748e345a49227b29e551892b2",
            "a7ce946f95d44a8eb53bc92c9922c498",
            "c43036202558419cac153b149278e1b0",
            "7ce41e7374f94510acd3fe83d6dccc82",
            "aeab7390aaaa47d5a77ace6ee03cf6bd"
          ]
        },
        "outputId": "6428af59-822a-440b-fbd5-64b8b57cbb90"
      },
      "source": [
        "# using pretrained means to normalize the dataset\n",
        "pretrained_means = [0.4914, 0.4822, 0.4465]\n",
        "pretrained_stds= [0.247, 0.243, 0.261]\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# define tranforms on the training set\n",
        "# include resizing and horizontal flip\n",
        "transform = transforms.Compose([transforms.Resize((32,32)),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean = pretrained_means,\n",
        "                                                     std = pretrained_stds)])\n",
        "# load the data\n",
        "train = datasets.CIFAR10(root='./data', train=True, download=True, transform = transform)\n",
        "test = datasets.CIFAR10(root='./data', train=False, download=True, transform = transform)\n",
        "\n",
        "# percentage of the training data to be used in training\n",
        "TRAIN_VAL_RATIO = 0.90\n",
        "\n",
        "n_train_examples = int(len(train) * TRAIN_VAL_RATIO)\n",
        "n_valid_examples = len(train) - n_train_examples\n",
        "\n",
        "train, val = torch.utils.data.random_split(train, [n_train_examples, n_valid_examples])\n",
        "\n",
        "# applying the transform on validation set\n",
        "val = copy.deepcopy(val)\n",
        "val.dataset.transform = transform\n",
        "\n",
        "# defining appropriate dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val, batch_size = BATCH_SIZE, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle=False)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a375d7eeea8464dbf04b8ebc65fb301",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n5Pl8TOqi2m"
      },
      "source": [
        "# Utils Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvNjnxR8ZbBm"
      },
      "source": [
        "def calculate_accuracy(y_pred, y):\n",
        "    '''get model accuracy'''\n",
        "    p = y_pred.argmax(1, keepdim = True)\n",
        "    acc = p.eq(y.view_as(p)).sum().float() / y.shape[0]\n",
        "    return acc\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, device):\n",
        "    '''\n",
        "    function to be called for training and collect \n",
        "    model loss and model accuracy\n",
        "    and perform a training step\n",
        "\n",
        "    iterator: DataLoader Object\n",
        "    optimizer: Optimizer type\n",
        "    criterion: loss type\n",
        "    '''\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set to training mode\n",
        "    model.train()\n",
        "    \n",
        "    for (x, y) in iterator:\n",
        "        \n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x)\n",
        "        \n",
        "        loss = criterion(y_pred, y)\n",
        "        \n",
        "        acc = calculate_accuracy(y_pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # update loss and accuracy values\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion, device):\n",
        "    '''\n",
        "    function to be called for evaluating and collect \n",
        "    model val loss and model val accuracy\n",
        "\n",
        "    iterator: DataLoader Object\n",
        "    optimizer: Optimizer type\n",
        "    criterion: loss type\n",
        "    '''\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for (x, y) in iterator:\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            y_pred = model(x)\n",
        "            loss = criterion(y_pred, y)\n",
        "            acc = calculate_accuracy(y_pred, y)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGYf6Hj-NGhy"
      },
      "source": [
        "class LRFinder:\n",
        "    def __init__(self, model, optimizer, criterion, device):\n",
        "        \n",
        "        self.optimizer = optimizer\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.device = device\n",
        "        \n",
        "        torch.save(model.state_dict(), 'init_params.pt')\n",
        "\n",
        "    def range_test(self, iterator, end_lr = 10, num_iter = 100, smooth_f = 0.05, diverge_th = 5):\n",
        "        \n",
        "        lrs = []\n",
        "        losses = []\n",
        "        best_loss = float('inf')\n",
        "\n",
        "        lr_scheduler = ExponentialLR(self.optimizer, end_lr, num_iter)\n",
        "        \n",
        "        iterator = IteratorWrapper(iterator)\n",
        "        \n",
        "        for iteration in range(num_iter):\n",
        "\n",
        "            loss = self._train_batch(iterator)\n",
        "\n",
        "            #update lr\n",
        "            lr_scheduler.step()\n",
        "            \n",
        "            lrs.append(lr_scheduler.get_lr()[0])\n",
        "\n",
        "            if iteration > 0:\n",
        "                loss = smooth_f * loss + (1 - smooth_f) * losses[-1]\n",
        "                \n",
        "            if loss < best_loss:\n",
        "                best_loss = loss\n",
        "\n",
        "            losses.append(loss)\n",
        "            \n",
        "            if loss > diverge_th * best_loss:\n",
        "                print(\"Stopping early, the loss has diverged\")\n",
        "                break\n",
        "                       \n",
        "        #reset model to initial parameters\n",
        "        self.model.load_state_dict(torch.load('init_params.pt'))\n",
        "                    \n",
        "        return lrs, losses\n",
        "\n",
        "    def _train_batch(self, iterator):\n",
        "        \n",
        "        self.model.train()\n",
        "        \n",
        "        self.optimizer.zero_grad()\n",
        "        \n",
        "        x, y = iterator.get_batch()\n",
        "        \n",
        "        x = x.to(self.device)\n",
        "        y = y.to(self.device)\n",
        "        \n",
        "        #y_pred, _ = self.model(x) original\n",
        "        y_pred = self.model(x)\n",
        "\n",
        "                \n",
        "        loss = self.criterion(y_pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        self.optimizer.step()\n",
        "        \n",
        "        return loss.item()\n",
        "\n",
        "class ExponentialLR(_LRScheduler):\n",
        "    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
        "        self.end_lr = end_lr\n",
        "        self.num_iter = num_iter\n",
        "        super(ExponentialLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        curr_iter = self.last_epoch + 1\n",
        "        r = curr_iter / self.num_iter\n",
        "        return [base_lr * (self.end_lr / base_lr) ** r for base_lr in self.base_lrs]\n",
        "\n",
        "class IteratorWrapper:\n",
        "    def __init__(self, iterator):\n",
        "        self.iterator = iterator\n",
        "        self._iterator = iter(iterator)\n",
        "\n",
        "    def __next__(self):\n",
        "        try:\n",
        "            inputs, labels = next(self._iterator)\n",
        "        except StopIteration:\n",
        "            self._iterator = iter(self.iterator)\n",
        "            inputs, labels, *_ = next(self._iterator)\n",
        "\n",
        "        return inputs, labels\n",
        "\n",
        "    def get_batch(self):\n",
        "        return next(self)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhY2jAiXNGhz"
      },
      "source": [
        "def plot_lr_finder(lrs, losses, skip_start = 5, skip_end = 5):\n",
        "    \n",
        "    if skip_end == 0:\n",
        "        lrs = lrs[skip_start:]\n",
        "        losses = losses[skip_start:]\n",
        "    else:\n",
        "        lrs = lrs[skip_start:-skip_end]\n",
        "        losses = losses[skip_start:-skip_end]\n",
        "    \n",
        "    fig = plt.figure(figsize = (16,8))\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "    ax.plot(lrs, losses)\n",
        "    ax.set_xscale('log')\n",
        "    ax.set_xlabel('Learning rate')\n",
        "    ax.set_ylabel('Loss')\n",
        "    ax.grid(True, 'both', 'x')\n",
        "    plt.show()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB6Wf6R3NGh0"
      },
      "source": [
        "def get_preds(model, iterator):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for (x, y) in iterator:\n",
        "\n",
        "            x = x.to(device)\n",
        "\n",
        "            y_pred = model(x)\n",
        "\n",
        "            y_prob = F.softmax(y_pred, dim = -1)\n",
        "            top_pred = y_prob.argmax(1, keepdim = True)\n",
        "\n",
        "            images.append(x.cpu())\n",
        "            labels.append(y.cpu())\n",
        "            probs.append(y_prob.cpu())\n",
        "\n",
        "    images = torch.cat(images, dim = 0)\n",
        "    labels = torch.cat(labels, dim = 0)\n",
        "    probs = torch.cat(probs, dim = 0)\n",
        "\n",
        "    return images, labels, probs"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCZXnTXkNGh0"
      },
      "source": [
        "def plot_confusion_matrix(labels, pred_labels, classes):\n",
        "    \n",
        "    fig = plt.figure(figsize = (10, 10));\n",
        "    ax = fig.add_subplot(1, 1, 1);\n",
        "    cm = confusion_matrix(labels, pred_labels);\n",
        "    cm = ConfusionMatrixDisplay(cm, classes);\n",
        "    cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)\n",
        "    plt.xticks(rotation = 20)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngBsGGFfNGh1"
      },
      "source": [
        "def labels_accuracy(y, y_pred):\n",
        "    crr = 0\n",
        "    for i in range(len(y)):\n",
        "        if y[i] == y_pred[i]:\n",
        "            crr += 1\n",
        "    return crr/len(y)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNdDgRBHNGh1"
      },
      "source": [
        "def normalize_image(image):\n",
        "    image_min = image.min()\n",
        "    image_max = image.max()\n",
        "    image.clamp_(min = image_min, max = image_max)\n",
        "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
        "    return image\n",
        "\n",
        "def plot_images(images, labels, classes, normalize = False):\n",
        "\n",
        "    n_images = len(images)\n",
        "\n",
        "    rows = int(np.sqrt(n_images))\n",
        "    cols = int(np.sqrt(n_images))\n",
        "\n",
        "    fig = plt.figure(figsize = (10, 10))\n",
        "\n",
        "    for i in range(rows*cols):\n",
        "\n",
        "        ax = fig.add_subplot(rows, cols, i+1)\n",
        "        \n",
        "        image = images[i]\n",
        "\n",
        "        if normalize:\n",
        "            image = normalize_image(image)\n",
        "\n",
        "        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
        "        ax.set_title(classes[labels[i]])\n",
        "        ax.axis('off')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP83y2Z4NGh2"
      },
      "source": [
        "def show_incorrect_preds(incorrect, classes, n_images, normalize = False):\n",
        "\n",
        "    rows = 1 \n",
        "    cols = n_images  \n",
        "\n",
        "    fig = plt.figure(figsize = (10, 10))\n",
        "    fig.tight_layout()\n",
        "    for i in range(cols):\n",
        "\n",
        "        ax = fig.add_subplot(rows, cols, i+1)\n",
        "        \n",
        "        image, true_label, probs = incorrect[i]\n",
        "        image = image[0]\n",
        "        true_prob = probs[true_label]\n",
        "        incorrect_prob, incorrect_label = torch.max(probs, dim = 0)\n",
        "        true_class = classes[true_label][0]\n",
        "        incorrect_class = classes[incorrect_label][0]\n",
        "\n",
        "        if normalize:\n",
        "            image = normalize_image(image)\n",
        "\n",
        "        ax.imshow(image.cpu().numpy())\n",
        "        ax.set_title(f'true class: {true_class}\\n' \\\n",
        "                     f'pred class: {incorrect_class}')\n",
        "        ax.axis('off')\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A63CFXWxNGh2"
      },
      "source": [
        "# VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roYgAiN4NGh2"
      },
      "source": [
        "class VGG(nn.Module):\n",
        "    def __init__(self, features, output_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.features = features\n",
        "        \n",
        "        #self.avgpool = nn.AdaptiveAvgPool2d(7)\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 , 128),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, output_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        #x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.classifier(h)\n",
        "        return x#, h"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rwnj81QNGh3"
      },
      "source": [
        "def get_vgg_layers(config, batch_norm):\n",
        "    \n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "    \n",
        "    for c in config:\n",
        "        assert c == 'M' or isinstance(c, int)\n",
        "        if c == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size = 2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, c, kernel_size = 3, padding = 1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(c), nn.ReLU(inplace = True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace = True)]\n",
        "            in_channels = c\n",
        "            \n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vtIJ1jwNGh3"
      },
      "source": [
        "vgg11_config = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
        "\n",
        "vgg13_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
        "\n",
        "vgg16_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
        "\n",
        "vgg19_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixwfkWKwNGh3"
      },
      "source": [
        "vgg13_layers = get_vgg_layers(vgg13_config, batch_norm = True)\n",
        "vgg16_layers = get_vgg_layers(vgg16_config, batch_norm = True)\n",
        "vgg19_layers = get_vgg_layers(vgg19_config, batch_norm = True)\n",
        "\n",
        "#vgg16_layers"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-qlMtXPXlp_"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgN9V4AMNGh4"
      },
      "source": [
        "OUTPUT_DIM = 10\n",
        "\n",
        "#model_VGG13 = VGG(vgg13_layers, OUTPUT_DIM)\n",
        "model_VGG16 = VGG(vgg16_layers, OUTPUT_DIM)\n",
        "#model_VGG19 = VGG(vgg19_layers, OUTPUT_DIM)\n",
        "\n",
        "#print(model_VGG16)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b32d_8tuNGh4"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_VGG16 = model_VGG16.to(device)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UylbpHxPNGh4"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "#summary(model_VGG16.to(device), (3, 32, 32))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT_pH7ZHNGh4"
      },
      "source": [
        "### Find best LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_3LdNnkNGh5"
      },
      "source": [
        "START_LR = 1e-7\n",
        "\n",
        "optimizer = optim.SGD(model_VGG16.parameters(), momentum=0.9, lr = START_LR)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_VGG16 = model_VGG16.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv3S-_hQNGh5"
      },
      "source": [
        "END_LR = 10\n",
        "NUM_ITER = 100\n",
        "\n",
        "lr_finder = LRFinder(model_VGG16, optimizer, criterion, device)\n",
        "lrs, losses = lr_finder.range_test(train_loader, END_LR, NUM_ITER)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgE8FFKzNGh6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "38321cb0-04cb-40a2-dcdd-e246ed88c606"
      },
      "source": [
        "plot_lr_finder(lrs, losses, skip_start = 10, skip_end = 20)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebx6UcABNGh6"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LZVpslENGh6"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)\n",
        "optimizer = torch.optim.SGD(model_VGG16.parameters(), lr = 0.01, momentum=0.9, weight_decay=0.0001)\n",
        "# scheduler for VGG\n",
        "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[10], last_epoch= -1)\n",
        "# scheduler for ResNet\n",
        "##scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[100, 150], last_epoch= -1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxBQwyGINGh6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "8adbbbed-b374-4813-9ed0-2b9b05b5cd1f"
      },
      "source": [
        "EPOCHS = 50\n",
        "train_loss_list_VGG16 = []\n",
        "train_acc_list_VGG16 = []\n",
        "\n",
        "val_loss_list_VGG16 = []\n",
        "val_acc_list_VGG16 = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model_VGG16, train_loader, optimizer, criterion, device)\n",
        "    #optimizer.step()\n",
        "    val_loss, val_acc = evaluate(model_VGG16, val_loader, criterion, device)\n",
        "    end_time = time.time()\n",
        "\n",
        "    train_loss_list_VGG16.append(train_loss)\n",
        "    train_acc_list_VGG16.append(train_acc)\n",
        "    val_loss_list_VGG16.append(val_loss)\n",
        "    val_acc_list_VGG16.append(val_acc)\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    ct = datetime.datetime.now()\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s, | Timestamp: {ct}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')\n",
        "    \n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-164001ac9bd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mepoch_mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_secs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s, | Timestamp: {ct}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMGEvkCnNGh7"
      },
      "source": [
        "images, labels, probs = get_preds(model_VGG16, test_loader)\n",
        "pred_labels = torch.argmax(probs, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ195jESNGh7"
      },
      "source": [
        "classes = test.classes\n",
        "\n",
        "plot_confusion_matrix(labels, pred_labels, classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mSlRO_NNGh7"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_loss_list_VGG16, label = 'training loss')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_loss_list_VGG16, label = 'validation loss')\n",
        "plt.legend()\n",
        "plt.title('VGG16 , Cross Entropy Loss across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzVMwPvfNGh8"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_acc_list_VGG16, label = 'training accuracy')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list_VGG16, label = 'validation accuracy')\n",
        "plt.legend()\n",
        "plt.title('VGG16 , Accuracy across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XbngY-ZNGh8"
      },
      "source": [
        "labels_accuracy(labels.numpy(), pred_labels.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gjyNig8NGh8"
      },
      "source": [
        "correct_pred = torch.eq(labels, pred_labels)\n",
        "incorrect_examples = []\n",
        "\n",
        "for image, label, prob, correct in zip(images, labels, probs, correct_pred):\n",
        "    if not correct:\n",
        "        incorrect_examples.append((image, label, prob))\n",
        "\n",
        "incorrect_examples.sort(reverse = True, key = lambda x: torch.max(x[2], dim = 0).values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxIl-ZiCNGh8"
      },
      "source": [
        "show_incorrect_preds(incorrect_examples, classes, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-WxjGaQZE-g"
      },
      "source": [
        "## VGG13"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQhT-pzvZT8l"
      },
      "source": [
        "OUTPUT_DIM = 10\n",
        "\n",
        "model_VGG13 = VGG(vgg13_layers, OUTPUT_DIM)\n",
        "#model_VGG16 = VGG(vgg16_layers, OUTPUT_DIM)\n",
        "#model_VGG19 = VGG(vgg19_layers, OUTPUT_DIM)\n",
        "\n",
        "#print(model_VGG16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apML1RxFZUFC"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_VGG16 = model_VGG16.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wqKF_VFZUI-"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "#summary(model_VGG13.to(device), (3, 32, 32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtM6OCjQZ0JL"
      },
      "source": [
        "### Find Best LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWr4AD0KZxuA"
      },
      "source": [
        "START_LR = 1e-7\n",
        "\n",
        "optimizer = optim.SGD(model_VGG13.parameters(), momentum=0.9, lr = START_LR)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_VGG13 = model_VGG13.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGeTPEzCZUNE"
      },
      "source": [
        "END_LR = 10\n",
        "NUM_ITER = 100\n",
        "\n",
        "lr_finder = LRFinder(model_VGG13, optimizer, criterion, device)\n",
        "lrs, losses = lr_finder.range_test(train_loader, END_LR, NUM_ITER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrRigXcBZUQj"
      },
      "source": [
        "plot_lr_finder(lrs, losses, skip_start = 10, skip_end = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_8S3cs5Z57C"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CIHO9aLZ8v1"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)\n",
        "optimizer = torch.optim.SGD(model_VGG13.parameters(), lr = 0.01, momentum=0.9, weight_decay=0.0001)\n",
        "# scheduler for VGG\n",
        "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[10], last_epoch= -1)\n",
        "# scheduler for ResNet\n",
        "##scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[100, 150], last_epoch= -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MadAWnGZZ9CZ"
      },
      "source": [
        "EPOCHS = 50\n",
        "train_loss_list_VGG13 = []\n",
        "train_acc_list_VGG13 = []\n",
        "\n",
        "val_loss_list_VGG13 = []\n",
        "val_acc_list_VGG13 = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model_VGG13, train_loader, optimizer, criterion, device)\n",
        "    #optimizer.step()\n",
        "    val_loss, val_acc = evaluate(model_VGG13, val_loader, criterion, device)\n",
        "    end_time = time.time()\n",
        "\n",
        "    train_loss_list_VGG13.append(train_loss)\n",
        "    train_acc_list_VGG13.append(train_acc)\n",
        "    val_loss_list_VGG13.append(val_loss)\n",
        "    val_acc_list_VGG13.append(val_acc)\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    ct = datetime.datetime.now()\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s, | Timestamp: {ct}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-XcLq0VZ9Fq"
      },
      "source": [
        "images, labels, probs = get_preds(model_VGG13, test_loader)\n",
        "pred_labels = torch.argmax(probs, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhWb1E_iZ9Jt"
      },
      "source": [
        "classes = test.classes\n",
        "\n",
        "plot_confusion_matrix(labels, pred_labels, classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-5UlfFmakFs"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_loss_list_VGG13, label = 'training loss')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_loss_list_VGG13, label = 'validation loss')\n",
        "plt.legend()\n",
        "plt.title('VGG13 , Cross Entropy Loss across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMk-l3zoakJi"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_acc_list_VGG13, label = 'training accuracy')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list_VGG13, label = 'validation accuracy')\n",
        "plt.legend()\n",
        "plt.title('VGG13 , Accuracy across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KVlOWprakNh"
      },
      "source": [
        "labels_accuracy(labels.numpy(), pred_labels.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr09EIXbau8P"
      },
      "source": [
        "correct_pred = torch.eq(labels, pred_labels)\n",
        "incorrect_examples = []\n",
        "\n",
        "for image, label, prob, correct in zip(images, labels, probs, correct_pred):\n",
        "    if not correct:\n",
        "        incorrect_examples.append((image, label, prob))\n",
        "\n",
        "incorrect_examples.sort(reverse = True, key = lambda x: torch.max(x[2], dim = 0).values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6GZ4R5YavBW"
      },
      "source": [
        "show_incorrect_preds(incorrect_examples, classes, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyXeMzFFNGh9"
      },
      "source": [
        "# Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXsXOCbKNGh9"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, config, output_dim):\n",
        "        super().__init__()\n",
        "                \n",
        "        block, n_blocks, channels = config\n",
        "        self.in_channels = channels[0]\n",
        "            \n",
        "        assert len(n_blocks) == len(channels) == 4\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "        \n",
        "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
        "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride = 2)\n",
        "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride = 2)\n",
        "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride = 2)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "        \n",
        "    def get_resnet_layer(self, block, n_blocks, channels, stride = 1):\n",
        "    \n",
        "        layers = []\n",
        "        \n",
        "        if self.in_channels != block.expansion * channels:\n",
        "            downsample = True\n",
        "        else:\n",
        "            downsample = False\n",
        "        \n",
        "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "        \n",
        "        for i in range(1, n_blocks):\n",
        "            layers.append(block(block.expansion * channels, channels))\n",
        "\n",
        "        self.in_channels = block.expansion * channels\n",
        "            \n",
        "        return nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.fc(h)\n",
        "        \n",
        "        return x#, h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rq-aAoLNGh-"
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    \n",
        "    expansion = 1\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "                \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        \n",
        "        \n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = stride, bias = False)\n",
        "            bn = nn.BatchNorm2d(out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "        \n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        i = x\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        \n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        \n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "                        \n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjsXRXyqNGh-"
      },
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    \n",
        "    expansion = 4\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "    \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = stride, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(out_channels, self.expansion * out_channels, kernel_size = 1, stride = 1, bias = False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        \n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size = 1, stride = stride, bias = False)\n",
        "            bn = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "            \n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        i = x\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        \n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        \n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "                \n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "            \n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "    \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33NV7-K9NGh_"
      },
      "source": [
        "class CIFARResNet(nn.Module):\n",
        "    def __init__(self, config, output_dim):\n",
        "        super().__init__()\n",
        "                \n",
        "        block, layers, channels = config\n",
        "        self.in_channels = channels[0]\n",
        "            \n",
        "        assert len(layers) == len(channels) == 3\n",
        "        assert all([i == j*2 for i, j in zip(channels[1:], channels[:-1])])\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        \n",
        "        self.layer1 = self.get_resnet_layer(block, layers[0], channels[0])\n",
        "        self.layer2 = self.get_resnet_layer(block, layers[1], channels[1], stride = 2)\n",
        "        self.layer3 = self.get_resnet_layer(block, layers[2], channels[2], stride = 2)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "        \n",
        "    def get_resnet_layer(self, block, n_blocks, channels, stride = 1):\n",
        "    \n",
        "        layers = []\n",
        "        \n",
        "        if self.in_channels != channels:\n",
        "            downsample = True\n",
        "        else:\n",
        "            downsample = False\n",
        "        \n",
        "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "        \n",
        "        for i in range(1, n_blocks):\n",
        "            layers.append(block(channels, channels))\n",
        "\n",
        "        self.in_channels = channels\n",
        "            \n",
        "        return nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        \n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.fc(h)\n",
        "        \n",
        "        return x#, h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr1Rur5FNGh_"
      },
      "source": [
        "class Identity(nn.Module):\n",
        "    def __init__(self, f):\n",
        "        super().__init__()\n",
        "        self.f = f\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.f(x)\n",
        "        \n",
        "\n",
        "class CIFARBasicBlock(nn.Module):\n",
        "        \n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "                \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3,stride = stride, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3,stride = 1, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "                \n",
        "        \n",
        "        if downsample:\n",
        "            identity_fn = lambda x : F.pad(x[:, :, ::2, ::2], [0, 0, 0, 0, in_channels // 2, in_channels // 2])\n",
        "            downsample = Identity(identity_fn)\n",
        "        else:\n",
        "            downsample = None\n",
        "        \n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        i = x\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        \n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        \n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "                                \n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-437eRMNGiA"
      },
      "source": [
        "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSm1QogWNGiA"
      },
      "source": [
        "resnet18_config = ResNetConfig (block = BasicBlock, n_blocks = [2,2,2,2], channels = [64, 128, 256, 512])\n",
        "resnet34_config = ResNetConfig (block = BasicBlock, n_blocks = [3,4,6,3], channels = [64, 128, 256, 512])\n",
        "\n",
        "resnet50_config = ResNetConfig (block = Bottleneck,n_blocks = [3, 4, 6, 3], channels = [64, 128, 256, 512])\n",
        "\n",
        "cifar_resnet20_config = ResNetConfig (block = CIFARBasicBlock, n_blocks = [3, 3, 3], channels = [16, 32, 64])\n",
        "cifar_resnet32_config = ResNetConfig (block = CIFARBasicBlock, n_blocks = [5, 5, 5], channels = [16, 32, 64])\n",
        "cifar_resnet44_config = ResNetConfig (block = CIFARBasicBlock, n_blocks = [7, 7, 7], channels = [16, 32, 64])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuzwVBeddSSc"
      },
      "source": [
        "## Resnet44"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EQgZ20xdFnX"
      },
      "source": [
        "#model_Resnet20 = CIFARResNet(cifar_resnet20_config,10)\n",
        "model_Resnet44 = CIFARResNet(cifar_resnet44_config,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evxXMykRNGiA"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_Resnet44 = model_Resnet44.to(device)\n",
        "#model_Resnet44"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW9PTpw_NGiA"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "#summary(model_Resnet44.to(device), (3, 32, 32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDR2AysFNGiB"
      },
      "source": [
        "### Find Best LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAy0CQpmNGiB"
      },
      "source": [
        "START_LR = 1e-7\n",
        "\n",
        "optimizer = optim.SGD(model_Resnet44.parameters(), momentum=0.9, lr = START_LR)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_Resnet44 = model_Resnet44.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGjOXDleNGiB"
      },
      "source": [
        "END_LR = 10\n",
        "NUM_ITER = 100\n",
        "\n",
        "lr_finder = LRFinder(model_Resnet44, optimizer, criterion, device)\n",
        "lrs, losses = lr_finder.range_test(train_loader, END_LR, NUM_ITER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5jwaA2BNGiB"
      },
      "source": [
        "plot_lr_finder(lrs, losses, skip_start = 10, skip_end = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5_bJdtCNGiB"
      },
      "source": [
        "###  Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFzCvHxbNGiB"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)\n",
        "optimizer = torch.optim.SGD(model_Resnet44.parameters(), momentum=0.1, lr = 0.01, weight_decay=0.0001)\n",
        "# scheduler for VGG\n",
        "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[10], last_epoch= -1)\n",
        "# scheduler for ResNet\n",
        "##scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[100, 150], last_epoch= -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7TW-cshNGiC"
      },
      "source": [
        "EPOCHS = 50\n",
        "train_loss_list_Resnet44 = []\n",
        "train_acc_list_Resnet44 = []\n",
        "\n",
        "val_loss_list_Resnet44 = []\n",
        "val_acc_list_Resnet44 = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model_Resnet44, train_loader, optimizer, criterion, device)\n",
        "    #optimizer.step()\n",
        "    val_loss, val_acc = evaluate(model_Resnet44, val_loader, criterion, device)\n",
        "    end_time = time.time()\n",
        "\n",
        "    train_loss_list_Resnet44.append(train_loss)\n",
        "    train_acc_list_Resnet44.append(train_acc)\n",
        "    val_loss_list_Resnet44.append(val_loss)\n",
        "    val_acc_list_Resnet44.append(val_acc)\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    ct = datetime.datetime.now()\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s, | Timestamp: {ct}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "551DHVHBNGiC"
      },
      "source": [
        "images, labels, probs = get_preds(model_Resnet44, test_loader)\n",
        "pred_labels = torch.argmax(probs, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gE-3T5LNGiC"
      },
      "source": [
        "classes = test.classes\n",
        "\n",
        "plot_confusion_matrix(labels, pred_labels, classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuS3aqYhNGiC"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_loss_list_Resnet44, label = 'training loss')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_loss_list_Resnet44, label = 'validation loss')\n",
        "plt.legend()\n",
        "plt.title('Resnet44 , Cross Entropy Loss across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQrl83ozNGiD"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_acc_list_Resnet44, label = 'training accuracy')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list_Resnet44, label = 'validation accuracy')\n",
        "plt.legend()\n",
        "plt.title('Resnet44 , Accuracy across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlbmARlRNGiD"
      },
      "source": [
        "labels_accuracy(labels.numpy(), pred_labels.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKie_zDyNGiD"
      },
      "source": [
        "correct_pred = torch.eq(labels, pred_labels)\n",
        "incorrect_examples = []\n",
        "\n",
        "for image, label, prob, correct in zip(images, labels, probs, correct_pred):\n",
        "    if not correct:\n",
        "        incorrect_examples.append((image, label, prob))\n",
        "\n",
        "incorrect_examples.sort(reverse = True, key = lambda x: torch.max(x[2], dim = 0).values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omdMieN5NGiD"
      },
      "source": [
        "show_incorrect_preds(incorrect_examples, classes, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrQU_FDPea7Z"
      },
      "source": [
        "## Resnet20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG3HZWIqefG8"
      },
      "source": [
        "model_Resnet20 = CIFARResNet(cifar_resnet20_config,10)\n",
        "#model_Resnet44 = CIFARResNet(cifar_resnet44_config,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGhI1yGDefPI"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_Resnet20 = model_Resnet20.to(device)\n",
        "#model_Resnet44"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIjPfFRcefSY"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "#summary(model_Resnet20.to(device), (3, 32, 32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq7GLjwEe-JD"
      },
      "source": [
        "### Find Best LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7hS5x63efVt"
      },
      "source": [
        "START_LR = 1e-7\n",
        "\n",
        "optimizer = optim.SGD(model_Resnet20.parameters(), momentum=0.9, lr = START_LR)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_Resnet20 = model_Resnet20.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIHgUmnEfHnT"
      },
      "source": [
        "END_LR = 10\n",
        "NUM_ITER = 100\n",
        "\n",
        "lr_finder = LRFinder(model_Resnet20, optimizer, criterion, device)\n",
        "lrs, losses = lr_finder.range_test(train_loader, END_LR, NUM_ITER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJXRFY_zefYq"
      },
      "source": [
        "plot_lr_finder(lrs, losses, skip_start = 10, skip_end = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHmXAgcifEsO"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7UgYaTyjp-P"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)\n",
        "optimizer = torch.optim.SGD(model_Resnet20.parameters(), momentum=0.1, lr = 0.01, weight_decay=0.0001)\n",
        "# scheduler for VGG\n",
        "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[10], last_epoch= -1)\n",
        "# scheduler for ResNet\n",
        "##scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[100, 150], last_epoch= -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzb2KITVeaFx"
      },
      "source": [
        "EPOCHS = 50\n",
        "train_loss_list_Resnet20 = []\n",
        "train_acc_list_Resnet20 = []\n",
        "\n",
        "val_loss_list_Resnet20 = []\n",
        "val_acc_list_Resnet20 = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model_Resnet20, train_loader, optimizer, criterion, device)\n",
        "    #optimizer.step()\n",
        "    val_loss, val_acc = evaluate(model_Resnet20, val_loader, criterion, device)\n",
        "    end_time = time.time()\n",
        "\n",
        "    train_loss_list_Resnet20.append(train_loss)\n",
        "    train_acc_list_Resnet20.append(train_acc)\n",
        "    val_loss_list_Resnet20.append(val_loss)\n",
        "    val_acc_list_Resnet20.append(val_acc)\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    ct = datetime.datetime.now()\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s, | Timestamp: {ct}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZN4gMldfRKD"
      },
      "source": [
        "images, labels, probs = get_preds(model_Resnet20, test_loader)\n",
        "pred_labels = torch.argmax(probs, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9d2hRgPfRNf"
      },
      "source": [
        "classes = test.classes\n",
        "\n",
        "plot_confusion_matrix(labels, pred_labels, classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfD7tH7-fRQd"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_loss_list_Resnet20, label = 'training loss')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_loss_list_Resnet20, label = 'validation loss')\n",
        "plt.legend()\n",
        "plt.title('Resnet20 , Cross Entropy Loss across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G54Ljk-4fRZy"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_acc_list_Resnet20, label = 'training accuracy')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list_Resnet20, label = 'validation accuracy')\n",
        "plt.legend()\n",
        "plt.title('Resnet20 , Accuracy across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyrcpuGafaSl"
      },
      "source": [
        "labels_accuracy(labels.numpy(), pred_labels.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbPFcFkHfaYD"
      },
      "source": [
        "correct_pred = torch.eq(labels, pred_labels)\n",
        "incorrect_examples = []\n",
        "\n",
        "for image, label, prob, correct in zip(images, labels, probs, correct_pred):\n",
        "    if not correct:\n",
        "        incorrect_examples.append((image, label, prob))\n",
        "\n",
        "incorrect_examples.sort(reverse = True, key = lambda x: torch.max(x[2], dim = 0).values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L7kHdohflFI"
      },
      "source": [
        "show_incorrect_preds(incorrect_examples, classes, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXl7qDk9NGiD"
      },
      "source": [
        "# Comparing Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b6Tp3GYNGiD"
      },
      "source": [
        "import seaborn as sns\n",
        "with sns.color_palette(\"husl\"):\n",
        "  \n",
        "    #sns.lineplot([i for i in range(1,EPOCHS + 1)], train_acc_list, label = 'Training Accuracy')\n",
        "    sns.lineplot([i for i in range(1,EPOCHS + 1)], val_acc_list_Resnet20, label = 'ResNet-20')\n",
        "    plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list_Resnet44, label = 'ResNet-44')\n",
        "    plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list_VGG16, label = 'VGG-16')\n",
        "    plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list_VGG13, label = 'VGG-13')\n",
        "    plt.legend()\n",
        "    plt.title('Validation Accuracy on CIFAR10')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}