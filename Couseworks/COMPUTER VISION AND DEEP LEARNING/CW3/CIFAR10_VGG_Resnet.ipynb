{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "CIFAR10_VGG_Resnet.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTVbLfh0NGhc",
        "outputId": "aca3b61e-d1a4-4e3a-b603-8571c0090989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import copy\n",
        "from collections import namedtuple\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.optim.lr_scheduler import StepLR, _LRScheduler\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a8eb3c132a54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: KeyboardInterrupt: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHJfzTq9NGhx"
      },
      "source": [
        "# using pretrained means to normalize the dataset\n",
        "pretrained_means = [0.4914, 0.4822, 0.4465]\n",
        "pretrained_stds= [0.247, 0.243, 0.261]\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# define tranforms on the training set\n",
        "# include resizing and horizontal flip\n",
        "transform = transforms.Compose([transforms.Resize((32,32)),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean = pretrained_means,\n",
        "                                                     std = pretrained_stds)])\n",
        "# load the data\n",
        "train = datasets.CIFAR10(root='./data', train=True, download=True, transform = transform)\n",
        "test = datasets.CIFAR10(root='./data', train=False, download=True, transform = transform)\n",
        "\n",
        "# percentage of the training data to be used in training\n",
        "TRAIN_VAL_RATIO = 0.90\n",
        "\n",
        "n_train_examples = int(len(train) * TRAIN_VAL_RATIO)\n",
        "n_valid_examples = len(train) - n_train_examples\n",
        "\n",
        "train, val = torch.utils.data.random_split(train, [n_train_examples, n_valid_examples])\n",
        "\n",
        "# applying the transform on validation set\n",
        "val = copy.deepcopy(val)\n",
        "val.dataset.transform = transform\n",
        "\n",
        "# defining appropriate dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val, batch_size = BATCH_SIZE, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvNjnxR8ZbBm"
      },
      "source": [
        "def calculate_accuracy(y_pred, y):\n",
        "    '''get model accuracy'''\n",
        "    p = y_pred.argmax(1, keepdim = True)\n",
        "    acc = p.eq(y.view_as(p)).sum().float() / y.shape[0]\n",
        "    return acc\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, device):\n",
        "    '''\n",
        "    function to be called for training and collect \n",
        "    model loss and model accuracy\n",
        "    and perform a training step\n",
        "\n",
        "    iterator: DataLoader Object\n",
        "    optimizer: Optimizer type\n",
        "    criterion: loss type\n",
        "    '''\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set to training mode\n",
        "    model.train()\n",
        "    \n",
        "    for (x, y) in iterator:\n",
        "        \n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x)\n",
        "        \n",
        "        loss = criterion(y_pred, y)\n",
        "        \n",
        "        acc = calculate_accuracy(y_pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # update loss and accuracy values\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion, device):\n",
        "    '''\n",
        "    function to be called for evaluating and collect \n",
        "    model val loss and model val accuracy\n",
        "\n",
        "    iterator: DataLoader Object\n",
        "    optimizer: Optimizer type\n",
        "    criterion: loss type\n",
        "    '''\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for (x, y) in iterator:\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            y_pred = model(x)\n",
        "            loss = criterion(y_pred, y)\n",
        "            acc = calculate_accuracy(y_pred, y)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGYf6Hj-NGhy"
      },
      "source": [
        "class LRFinder:\n",
        "    def __init__(self, model, optimizer, criterion, device):\n",
        "        \n",
        "        self.optimizer = optimizer\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.device = device\n",
        "        \n",
        "        torch.save(model.state_dict(), 'init_params.pt')\n",
        "\n",
        "    def range_test(self, iterator, end_lr = 10, num_iter = 100, smooth_f = 0.05, diverge_th = 5):\n",
        "        \n",
        "        lrs = []\n",
        "        losses = []\n",
        "        best_loss = float('inf')\n",
        "\n",
        "        lr_scheduler = ExponentialLR(self.optimizer, end_lr, num_iter)\n",
        "        \n",
        "        iterator = IteratorWrapper(iterator)\n",
        "        \n",
        "        for iteration in range(num_iter):\n",
        "\n",
        "            loss = self._train_batch(iterator)\n",
        "\n",
        "            #update lr\n",
        "            lr_scheduler.step()\n",
        "            \n",
        "            lrs.append(lr_scheduler.get_lr()[0])\n",
        "\n",
        "            if iteration > 0:\n",
        "                loss = smooth_f * loss + (1 - smooth_f) * losses[-1]\n",
        "                \n",
        "            if loss < best_loss:\n",
        "                best_loss = loss\n",
        "\n",
        "            losses.append(loss)\n",
        "            \n",
        "            if loss > diverge_th * best_loss:\n",
        "                print(\"Stopping early, the loss has diverged\")\n",
        "                break\n",
        "                       \n",
        "        #reset model to initial parameters\n",
        "        model.load_state_dict(torch.load('init_params.pt'))\n",
        "                    \n",
        "        return lrs, losses\n",
        "\n",
        "    def _train_batch(self, iterator):\n",
        "        \n",
        "        self.model.train()\n",
        "        \n",
        "        self.optimizer.zero_grad()\n",
        "        \n",
        "        x, y = iterator.get_batch()\n",
        "        \n",
        "        x = x.to(self.device)\n",
        "        y = y.to(self.device)\n",
        "        \n",
        "        #y_pred, _ = self.model(x) original\n",
        "        y_pred = self.model(x)\n",
        "\n",
        "                \n",
        "        loss = self.criterion(y_pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        self.optimizer.step()\n",
        "        \n",
        "        return loss.item()\n",
        "\n",
        "class ExponentialLR(_LRScheduler):\n",
        "    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
        "        self.end_lr = end_lr\n",
        "        self.num_iter = num_iter\n",
        "        super(ExponentialLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        curr_iter = self.last_epoch + 1\n",
        "        r = curr_iter / self.num_iter\n",
        "        return [base_lr * (self.end_lr / base_lr) ** r for base_lr in self.base_lrs]\n",
        "\n",
        "class IteratorWrapper:\n",
        "    def __init__(self, iterator):\n",
        "        self.iterator = iterator\n",
        "        self._iterator = iter(iterator)\n",
        "\n",
        "    def __next__(self):\n",
        "        try:\n",
        "            inputs, labels = next(self._iterator)\n",
        "        except StopIteration:\n",
        "            self._iterator = iter(self.iterator)\n",
        "            inputs, labels, *_ = next(self._iterator)\n",
        "\n",
        "        return inputs, labels\n",
        "\n",
        "    def get_batch(self):\n",
        "        return next(self)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhY2jAiXNGhz"
      },
      "source": [
        "def plot_lr_finder(lrs, losses, skip_start = 5, skip_end = 5):\n",
        "    \n",
        "    if skip_end == 0:\n",
        "        lrs = lrs[skip_start:]\n",
        "        losses = losses[skip_start:]\n",
        "    else:\n",
        "        lrs = lrs[skip_start:-skip_end]\n",
        "        losses = losses[skip_start:-skip_end]\n",
        "    \n",
        "    fig = plt.figure(figsize = (16,8))\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "    ax.plot(lrs, losses)\n",
        "    ax.set_xscale('log')\n",
        "    ax.set_xlabel('Learning rate')\n",
        "    ax.set_ylabel('Loss')\n",
        "    ax.grid(True, 'both', 'x')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB6Wf6R3NGh0"
      },
      "source": [
        "def get_preds(model, iterator):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for (x, y) in iterator:\n",
        "\n",
        "            x = x.to(device)\n",
        "\n",
        "            y_pred = model(x)\n",
        "\n",
        "            y_prob = F.softmax(y_pred, dim = -1)\n",
        "            top_pred = y_prob.argmax(1, keepdim = True)\n",
        "\n",
        "            images.append(x.cpu())\n",
        "            labels.append(y.cpu())\n",
        "            probs.append(y_prob.cpu())\n",
        "\n",
        "    images = torch.cat(images, dim = 0)\n",
        "    labels = torch.cat(labels, dim = 0)\n",
        "    probs = torch.cat(probs, dim = 0)\n",
        "\n",
        "    return images, labels, probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCZXnTXkNGh0"
      },
      "source": [
        "def plot_confusion_matrix(labels, pred_labels, classes):\n",
        "    \n",
        "    fig = plt.figure(figsize = (10, 10));\n",
        "    ax = fig.add_subplot(1, 1, 1);\n",
        "    cm = confusion_matrix(labels, pred_labels);\n",
        "    cm = ConfusionMatrixDisplay(cm, classes);\n",
        "    cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)\n",
        "    plt.xticks(rotation = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngBsGGFfNGh1"
      },
      "source": [
        "def labels_accuracy(y, y_pred):\n",
        "    crr = 0\n",
        "    for i in range(len(y)):\n",
        "        if y[i] == y_pred[i]:\n",
        "            crr += 1\n",
        "    return crr/len(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNdDgRBHNGh1"
      },
      "source": [
        "def normalize_image(image):\n",
        "    image_min = image.min()\n",
        "    image_max = image.max()\n",
        "    image.clamp_(min = image_min, max = image_max)\n",
        "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
        "    return image\n",
        "\n",
        "def plot_images(images, labels, classes, normalize = False):\n",
        "\n",
        "    n_images = len(images)\n",
        "\n",
        "    rows = int(np.sqrt(n_images))\n",
        "    cols = int(np.sqrt(n_images))\n",
        "\n",
        "    fig = plt.figure(figsize = (10, 10))\n",
        "\n",
        "    for i in range(rows*cols):\n",
        "\n",
        "        ax = fig.add_subplot(rows, cols, i+1)\n",
        "        \n",
        "        image = images[i]\n",
        "\n",
        "        if normalize:\n",
        "            image = normalize_image(image)\n",
        "\n",
        "        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
        "        ax.set_title(classes[labels[i]])\n",
        "        ax.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP83y2Z4NGh2"
      },
      "source": [
        "def show_incorrect_preds(incorrect, classes, n_images, normalize = False):\n",
        "\n",
        "    rows = 1 \n",
        "    cols = n_images  \n",
        "\n",
        "    fig = plt.figure(figsize = (10, 10))\n",
        "    fig.tight_layout()\n",
        "    for i in range(cols):\n",
        "\n",
        "        ax = fig.add_subplot(rows, cols, i+1)\n",
        "        \n",
        "        image, true_label, probs = incorrect[i]\n",
        "        image = image[0]\n",
        "        true_prob = probs[true_label]\n",
        "        incorrect_prob, incorrect_label = torch.max(probs, dim = 0)\n",
        "        true_class = classes[true_label][0]\n",
        "        incorrect_class = classes[incorrect_label][0]\n",
        "\n",
        "        if normalize:\n",
        "            image = normalize_image(image)\n",
        "\n",
        "        ax.imshow(image.cpu().numpy())\n",
        "        ax.set_title(f'true class: {true_class}\\n' \\\n",
        "                     f'pred class: {incorrect_class}')\n",
        "        ax.axis('off')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A63CFXWxNGh2"
      },
      "source": [
        "# VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roYgAiN4NGh2"
      },
      "source": [
        "class VGG(nn.Module):\n",
        "    def __init__(self, features, output_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.features = features\n",
        "        \n",
        "        #self.avgpool = nn.AdaptiveAvgPool2d(7)\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 , 128),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, output_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        #x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.classifier(h)\n",
        "        return x#, h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rwnj81QNGh3"
      },
      "source": [
        "def get_vgg_layers(config, batch_norm):\n",
        "    \n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "    \n",
        "    for c in config:\n",
        "        assert c == 'M' or isinstance(c, int)\n",
        "        if c == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size = 2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, c, kernel_size = 3, padding = 1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(c), nn.ReLU(inplace = True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace = True)]\n",
        "            in_channels = c\n",
        "            \n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vtIJ1jwNGh3"
      },
      "source": [
        "vgg11_config = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
        "\n",
        "vgg13_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
        "\n",
        "vgg16_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
        "\n",
        "vgg19_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixwfkWKwNGh3"
      },
      "source": [
        "vgg13_layers = get_vgg_layers(vgg13_config, batch_norm = True)\n",
        "vgg16_layers = get_vgg_layers(vgg16_config, batch_norm = True)\n",
        "vgg19_layers = get_vgg_layers(vgg19_config, batch_norm = True)\n",
        "\n",
        "#vgg16_layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-qlMtXPXlp_"
      },
      "source": [
        "## VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgN9V4AMNGh4"
      },
      "source": [
        "OUTPUT_DIM = 10\n",
        "\n",
        "#model_VGG13 = VGG(vgg13_layers, OUTPUT_DIM)\n",
        "model_VGG16 = VGG(vgg16_layers, OUTPUT_DIM)\n",
        "#model_VGG19 = VGG(vgg19_layers, OUTPUT_DIM)\n",
        "\n",
        "#print(model_VGG16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b32d_8tuNGh4"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_VGG16 = model_VGG16.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UylbpHxPNGh4"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "#summary(model_VGG16.to(device), (3, 32, 32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT_pH7ZHNGh4"
      },
      "source": [
        "### Finding best LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_3LdNnkNGh5"
      },
      "source": [
        "START_LR = 1e-7\n",
        "\n",
        "optimizer = optim.Adam(model_VGG16.parameters(), lr = START_LR)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_VGG16 = model_VGG16.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv3S-_hQNGh5"
      },
      "source": [
        "END_LR = 10\n",
        "NUM_ITER = 100\n",
        "\n",
        "lr_finder = LRFinder(model_VGG16, optimizer, criterion, device)\n",
        "lrs, losses = lr_finder.range_test(train_loader, END_LR, NUM_ITER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgE8FFKzNGh6"
      },
      "source": [
        "plot_lr_finder(lrs, losses, skip_start = 10, skip_end = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebx6UcABNGh6"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LZVpslENGh6"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)\n",
        "optimizer = torch.optim.SGD(model_VGG16.parameters(), lr = 0.01, momentum=0.9, weight_decay=0.0001)\n",
        "# scheduler for VGG\n",
        "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[10], last_epoch= -1)\n",
        "# scheduler for ResNet\n",
        "##scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[100, 150], last_epoch= -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxBQwyGINGh6"
      },
      "source": [
        "\n",
        "\n",
        "EPOCHS = 150\n",
        "train_loss_list_VGG16 = []\n",
        "train_acc_list_VGG16 = []\n",
        "\n",
        "val_loss_list_VGG16 = []\n",
        "val_acc_list_VGG16 = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model_VGG16, train_loader, optimizer, criterion, device)\n",
        "    #optimizer.step()\n",
        "    val_loss, val_acc = evaluate(model_VGG16, val_loader, criterion, device)\n",
        "    end_time = time.time()\n",
        "\n",
        "    train_loss_list_VGG16.append(train_loss)\n",
        "    train_acc_list_VGG16.append(train_acc)\n",
        "    val_loss_list_VGG16.append(val_loss)\n",
        "    val_acc_list_VGG16.append(val_acc)\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMGEvkCnNGh7"
      },
      "source": [
        "images, labels, probs = get_preds(model_VGG16, test_loader)\n",
        "pred_labels = torch.argmax(probs, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ195jESNGh7"
      },
      "source": [
        "classes = test.classes\n",
        "\n",
        "plot_confusion_matrix(labels, pred_labels, classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mSlRO_NNGh7"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_loss_list_VGG16, label = 'training loss')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_loss_list_VGG16, label = 'validation loss')\n",
        "plt.legend()\n",
        "plt.title('VGG16 , Cross Entropy Loss across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzVMwPvfNGh8"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_acc_list, label = 'training accuracy')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list, label = 'validation accuracy')\n",
        "plt.legend()\n",
        "plt.title('VGG16 , Accuracy across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XbngY-ZNGh8"
      },
      "source": [
        "labels_accuracy(labels.numpy(), pred_labels.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gjyNig8NGh8"
      },
      "source": [
        "correct_pred = torch.eq(labels, pred_labels)\n",
        "incorrect_examples = []\n",
        "\n",
        "for image, label, prob, correct in zip(images, labels, probs, correct_pred):\n",
        "    if not correct:\n",
        "        incorrect_examples.append((image, label, prob))\n",
        "\n",
        "incorrect_examples.sort(reverse = True, key = lambda x: torch.max(x[2], dim = 0).values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxIl-ZiCNGh8"
      },
      "source": [
        "show_incorrect_preds(incorrect_examples, classes, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-WxjGaQZE-g"
      },
      "source": [
        "## VGG13"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQhT-pzvZT8l"
      },
      "source": [
        "OUTPUT_DIM = 10\n",
        "\n",
        "model_VGG13 = VGG(vgg13_layers, OUTPUT_DIM)\n",
        "#model_VGG16 = VGG(vgg16_layers, OUTPUT_DIM)\n",
        "#model_VGG19 = VGG(vgg19_layers, OUTPUT_DIM)\n",
        "\n",
        "#print(model_VGG16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apML1RxFZUFC"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_VGG16 = model_VGG16.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wqKF_VFZUI-"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "#summary(model_VGG13.to(device), (3, 32, 32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtM6OCjQZ0JL"
      },
      "source": [
        "### Find Best LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWr4AD0KZxuA"
      },
      "source": [
        "START_LR = 1e-7\n",
        "\n",
        "optimizer = optim.Adam(model_VGG13.parameters(), lr = START_LR)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_VGG13 = model_VGG13.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGeTPEzCZUNE"
      },
      "source": [
        "END_LR = 10\n",
        "NUM_ITER = 100\n",
        "\n",
        "lr_finder = LRFinder(model_VGG13, optimizer, criterion, device)\n",
        "lrs, losses = lr_finder.range_test(train_loader, END_LR, NUM_ITER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrRigXcBZUQj"
      },
      "source": [
        "plot_lr_finder(lrs, losses, skip_start = 10, skip_end = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_8S3cs5Z57C"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CIHO9aLZ8v1"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)\n",
        "optimizer = torch.optim.SGD(model_VGG13.parameters(), lr = 0.01, momentum=0.9, weight_decay=0.0001)\n",
        "# scheduler for VGG\n",
        "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[10], last_epoch= -1)\n",
        "# scheduler for ResNet\n",
        "##scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[100, 150], last_epoch= -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MadAWnGZZ9CZ"
      },
      "source": [
        "EPOCHS = 150\n",
        "train_loss_list_VGG13 = []\n",
        "train_acc_list_VGG13 = []\n",
        "\n",
        "val_loss_list_VGG13 = []\n",
        "val_acc_list_VGG13 = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model_VGG13, train_loader, optimizer, criterion, device)\n",
        "    #optimizer.step()\n",
        "    val_loss, val_acc = evaluate(model_VGG13, val_loader, criterion, device)\n",
        "    end_time = time.time()\n",
        "\n",
        "    train_loss_list_VGG13.append(train_loss)\n",
        "    train_acc_list_VGG13.append(train_acc)\n",
        "    val_loss_list_VGG13.append(val_loss)\n",
        "    val_acc_list_VGG13.append(val_acc)\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-XcLq0VZ9Fq"
      },
      "source": [
        "images, labels, probs = get_preds(model_VGG13, test_loader)\n",
        "pred_labels = torch.argmax(probs, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhWb1E_iZ9Jt"
      },
      "source": [
        "classes = test.classes\n",
        "\n",
        "plot_confusion_matrix(labels, pred_labels, classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-5UlfFmakFs"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_loss_list_VGG13, label = 'training loss')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_loss_list_VGG13, label = 'validation loss')\n",
        "plt.legend()\n",
        "plt.title('VGG13 , Cross Entropy Loss across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMk-l3zoakJi"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_acc_list_VGG13, label = 'training accuracy')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list_VGG13, label = 'validation accuracy')\n",
        "plt.legend()\n",
        "plt.title('VGG13 , Accuracy across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KVlOWprakNh"
      },
      "source": [
        "labels_accuracy(labels.numpy(), pred_labels.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr09EIXbau8P"
      },
      "source": [
        "correct_pred = torch.eq(labels, pred_labels)\n",
        "incorrect_examples = []\n",
        "\n",
        "for image, label, prob, correct in zip(images, labels, probs, correct_pred):\n",
        "    if not correct:\n",
        "        incorrect_examples.append((image, label, prob))\n",
        "\n",
        "incorrect_examples.sort(reverse = True, key = lambda x: torch.max(x[2], dim = 0).values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6GZ4R5YavBW"
      },
      "source": [
        "show_incorrect_preds(incorrect_examples, classes, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyXeMzFFNGh9"
      },
      "source": [
        "# Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXsXOCbKNGh9"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, config, output_dim):\n",
        "        super().__init__()\n",
        "                \n",
        "        block, n_blocks, channels = config\n",
        "        self.in_channels = channels[0]\n",
        "            \n",
        "        assert len(n_blocks) == len(channels) == 4\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "        \n",
        "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
        "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride = 2)\n",
        "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride = 2)\n",
        "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride = 2)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "        \n",
        "    def get_resnet_layer(self, block, n_blocks, channels, stride = 1):\n",
        "    \n",
        "        layers = []\n",
        "        \n",
        "        if self.in_channels != block.expansion * channels:\n",
        "            downsample = True\n",
        "        else:\n",
        "            downsample = False\n",
        "        \n",
        "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "        \n",
        "        for i in range(1, n_blocks):\n",
        "            layers.append(block(block.expansion * channels, channels))\n",
        "\n",
        "        self.in_channels = block.expansion * channels\n",
        "            \n",
        "        return nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.fc(h)\n",
        "        \n",
        "        return x#, h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rq-aAoLNGh-"
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    \n",
        "    expansion = 1\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "                \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        \n",
        "        \n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = stride, bias = False)\n",
        "            bn = nn.BatchNorm2d(out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "        \n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        i = x\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        \n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        \n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "                        \n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjsXRXyqNGh-"
      },
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    \n",
        "    expansion = 4\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "    \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = stride, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(out_channels, self.expansion * out_channels, kernel_size = 1, stride = 1, bias = False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        \n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size = 1, stride = stride, bias = False)\n",
        "            bn = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "            \n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        i = x\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        \n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        \n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "                \n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "            \n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "    \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33NV7-K9NGh_"
      },
      "source": [
        "class CIFARResNet(nn.Module):\n",
        "    def __init__(self, config, output_dim):\n",
        "        super().__init__()\n",
        "                \n",
        "        block, layers, channels = config\n",
        "        self.in_channels = channels[0]\n",
        "            \n",
        "        assert len(layers) == len(channels) == 3\n",
        "        assert all([i == j*2 for i, j in zip(channels[1:], channels[:-1])])\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        \n",
        "        self.layer1 = self.get_resnet_layer(block, layers[0], channels[0])\n",
        "        self.layer2 = self.get_resnet_layer(block, layers[1], channels[1], stride = 2)\n",
        "        self.layer3 = self.get_resnet_layer(block, layers[2], channels[2], stride = 2)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "        \n",
        "    def get_resnet_layer(self, block, n_blocks, channels, stride = 1):\n",
        "    \n",
        "        layers = []\n",
        "        \n",
        "        if self.in_channels != channels:\n",
        "            downsample = True\n",
        "        else:\n",
        "            downsample = False\n",
        "        \n",
        "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "        \n",
        "        for i in range(1, n_blocks):\n",
        "            layers.append(block(channels, channels))\n",
        "\n",
        "        self.in_channels = channels\n",
        "            \n",
        "        return nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        \n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.fc(h)\n",
        "        \n",
        "        return x#, h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr1Rur5FNGh_"
      },
      "source": [
        "class Identity(nn.Module):\n",
        "    def __init__(self, f):\n",
        "        super().__init__()\n",
        "        self.f = f\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.f(x)\n",
        "        \n",
        "\n",
        "class CIFARBasicBlock(nn.Module):\n",
        "        \n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "                \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3,stride = stride, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3,stride = 1, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "                \n",
        "        \n",
        "        if downsample:\n",
        "            identity_fn = lambda x : F.pad(x[:, :, ::2, ::2], [0, 0, 0, 0, in_channels // 2, in_channels // 2])\n",
        "            downsample = Identity(identity_fn)\n",
        "        else:\n",
        "            downsample = None\n",
        "        \n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        i = x\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        \n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        \n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "                                \n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-437eRMNGiA"
      },
      "source": [
        "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSm1QogWNGiA"
      },
      "source": [
        "resnet18_config = ResNetConfig (block = BasicBlock, n_blocks = [2,2,2,2], channels = [64, 128, 256, 512])\n",
        "resnet34_config = ResNetConfig (block = BasicBlock, n_blocks = [3,4,6,3], channels = [64, 128, 256, 512])\n",
        "\n",
        "resnet50_config = ResNetConfig (block = Bottleneck,n_blocks = [3, 4, 6, 3], channels = [64, 128, 256, 512])\n",
        "\n",
        "cifar_resnet20_config = ResNetConfig (block = CIFARBasicBlock, n_blocks = [3, 3, 3], channels = [16, 32, 64])\n",
        "cifar_resnet32_config = ResNetConfig (block = CIFARBasicBlock, n_blocks = [5, 5, 5], channels = [16, 32, 64])\n",
        "cifar_resnet44_config = ResNetConfig (block = CIFARBasicBlock, n_blocks = [7, 7, 7], channels = [16, 32, 64])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuzwVBeddSSc"
      },
      "source": [
        "## Resnet44"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EQgZ20xdFnX"
      },
      "source": [
        "#model_Resnet20 = CIFARResNet(cifar_resnet20_config,10)\n",
        "model_Resnet44 = CIFARResNet(cifar_resnet44_config,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evxXMykRNGiA"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_Resnet44 = model_Resnet44.to(device)\n",
        "#model_Resnet44"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW9PTpw_NGiA"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "#summary(model_Resnet44.to(device), (3, 32, 32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDR2AysFNGiB"
      },
      "source": [
        "### Fiding best LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAy0CQpmNGiB"
      },
      "source": [
        "START_LR = 1e-7\n",
        "\n",
        "optimizer = optim.SGD(model_Resnet44.parameters(), momentum=0.9, lr = START_LR)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_Resnet44 = model_Resnet44.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGjOXDleNGiB"
      },
      "source": [
        "END_LR = 10\n",
        "NUM_ITER = 100\n",
        "\n",
        "lr_finder = LRFinder(model_Resnet44, optimizer, criterion, device)\n",
        "lrs, losses = lr_finder.range_test(train_loader, END_LR, NUM_ITER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5jwaA2BNGiB"
      },
      "source": [
        "plot_lr_finder(lrs, losses, skip_start = 10, skip_end = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5_bJdtCNGiB"
      },
      "source": [
        "###  Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFzCvHxbNGiB"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)\n",
        "optimizer = torch.optim.SGD(model_Resnet44.parameters(), momentum=0.1, lr = 0.1, weight_decay=0.0001)\n",
        "# scheduler for VGG\n",
        "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[10], last_epoch= -1)\n",
        "# scheduler for ResNet\n",
        "##scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[100, 150], last_epoch= -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7TW-cshNGiC"
      },
      "source": [
        "EPOCHS = 150\n",
        "train_loss_list_Resnet44 = []\n",
        "train_acc_list_Resnet44 = []\n",
        "\n",
        "val_loss_list_Resnet44 = []\n",
        "val_acc_list_Resnet44 = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model_Resnet44, train_loader, optimizer, criterion, device)\n",
        "    #optimizer.step()\n",
        "    val_loss, val_acc = evaluate(model_Resnet44, val_loader, criterion, device)\n",
        "    end_time = time.time()\n",
        "\n",
        "    train_loss_list_Resnet44.append(train_loss)\n",
        "    train_acc_list_Resnet44.append(train_acc)\n",
        "    val_loss_list_Resnet44.append(val_loss)\n",
        "    val_acc_list_Resnet44.append(val_acc)\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "551DHVHBNGiC"
      },
      "source": [
        "images, labels, probs = get_preds(model_Resnet44, test_loader)\n",
        "pred_labels = torch.argmax(probs, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gE-3T5LNGiC"
      },
      "source": [
        "classes = test.classes\n",
        "\n",
        "plot_confusion_matrix(labels, pred_labels, classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuS3aqYhNGiC"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_loss_list_Resnet44, label = 'training loss')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_loss_list_Resnet44, label = 'validation loss')\n",
        "plt.legend()\n",
        "plt.title('Resnet44 , Cross Entropy Loss across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQrl83ozNGiD"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_acc_list_Resnet44, label = 'training accuracy')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list_Resnet44, label = 'validation accuracy')\n",
        "plt.legend()\n",
        "plt.title('Resnet44 , Accuracy across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlbmARlRNGiD"
      },
      "source": [
        "labels_accuracy(labels.numpy(), pred_labels.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKie_zDyNGiD"
      },
      "source": [
        "correct_pred = torch.eq(labels, pred_labels)\n",
        "incorrect_examples = []\n",
        "\n",
        "for image, label, prob, correct in zip(images, labels, probs, correct_pred):\n",
        "    if not correct:\n",
        "        incorrect_examples.append((image, label, prob))\n",
        "\n",
        "incorrect_examples.sort(reverse = True, key = lambda x: torch.max(x[2], dim = 0).values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omdMieN5NGiD"
      },
      "source": [
        "show_incorrect_preds(incorrect_examples, classes, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrQU_FDPea7Z"
      },
      "source": [
        "## Resnet20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG3HZWIqefG8"
      },
      "source": [
        "model_Resnet20 = CIFARResNet(cifar_resnet20_config,10)\n",
        "#model_Resnet44 = CIFARResNet(cifar_resnet44_config,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGhI1yGDefPI"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_Resnet20 = model_Resnet20.to(device)\n",
        "#model_Resnet44"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIjPfFRcefSY"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "#summary(model_Resnet20.to(device), (3, 32, 32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq7GLjwEe-JD"
      },
      "source": [
        "### Find Best LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7hS5x63efVt"
      },
      "source": [
        "START_LR = 1e-7\n",
        "\n",
        "optimizer = optim.SGD(model_Resnet20.parameters(), momentum=0.9, lr = START_LR)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_Resnet20 = model_Resnet20.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIHgUmnEfHnT"
      },
      "source": [
        "END_LR = 10\n",
        "NUM_ITER = 100\n",
        "\n",
        "lr_finder = LRFinder(model_Resnet20, optimizer, criterion, device)\n",
        "lrs, losses = lr_finder.range_test(train_loader, END_LR, NUM_ITER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJXRFY_zefYq"
      },
      "source": [
        "plot_lr_finder(lrs, losses, skip_start = 10, skip_end = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHmXAgcifEsO"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7UgYaTyjp-P"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)\n",
        "optimizer = torch.optim.SGD(model_Resnet20.parameters(), momentum=0.1, lr = 0.1, weight_decay=0.0001)\n",
        "# scheduler for VGG\n",
        "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[10], last_epoch= -1)\n",
        "# scheduler for ResNet\n",
        "##scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[100, 150], last_epoch= -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzb2KITVeaFx"
      },
      "source": [
        "EPOCHS = 150\n",
        "train_loss_list_Resnet20 = []\n",
        "train_acc_list_Resnet20 = []\n",
        "\n",
        "val_loss_list_Resnet20 = []\n",
        "val_acc_list_Resnet20 = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model_Resnet20, train_loader, optimizer, criterion, device)\n",
        "    #optimizer.step()\n",
        "    val_loss, val_acc = evaluate(model_Resnet20, val_loader, criterion, device)\n",
        "    end_time = time.time()\n",
        "\n",
        "    train_loss_list_Resnet20.append(train_loss)\n",
        "    train_acc_list_Resnet20.append(train_acc)\n",
        "    val_loss_list_Resnet20.append(val_loss)\n",
        "    val_acc_list_Resnet20.append(val_acc)\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZN4gMldfRKD"
      },
      "source": [
        "images, labels, probs = get_preds(model_Resnet20, test_loader)\n",
        "pred_labels = torch.argmax(probs, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9d2hRgPfRNf"
      },
      "source": [
        "classes = test.classes\n",
        "\n",
        "plot_confusion_matrix(labels, pred_labels, classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfD7tH7-fRQd"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_loss_list_Resnet20, label = 'training loss')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_loss_list_Resnet20, label = 'validation loss')\n",
        "plt.legend()\n",
        "plt.title('Resnet20 , Cross Entropy Loss across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G54Ljk-4fRZy"
      },
      "source": [
        "plt.plot([i for i in range(1,EPOCHS + 1)], train_acc_list_Resnet20, label = 'training accuracy')\n",
        "plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list_Resnet20, label = 'validation accuracy')\n",
        "plt.legend()\n",
        "plt.title('Resnet20 , Accuracy across Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyrcpuGafaSl"
      },
      "source": [
        "labels_accuracy(labels.numpy(), pred_labels.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbPFcFkHfaYD"
      },
      "source": [
        "correct_pred = torch.eq(labels, pred_labels)\n",
        "incorrect_examples = []\n",
        "\n",
        "for image, label, prob, correct in zip(images, labels, probs, correct_pred):\n",
        "    if not correct:\n",
        "        incorrect_examples.append((image, label, prob))\n",
        "\n",
        "incorrect_examples.sort(reverse = True, key = lambda x: torch.max(x[2], dim = 0).values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L7kHdohflFI"
      },
      "source": [
        "show_incorrect_preds(incorrect_examples, classes, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXl7qDk9NGiD"
      },
      "source": [
        "# Comparing Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b6Tp3GYNGiD"
      },
      "source": [
        "import seaborn as sns\n",
        "with sns.color_palette(\"husl\"):\n",
        "  \n",
        "    #sns.lineplot([i for i in range(1,EPOCHS + 1)], train_acc_list, label = 'Training Accuracy')\n",
        "    sns.lineplot([i for i in range(1,EPOCHS + 1)], val_acc_list_Resnet20, label = 'ResNet-20')\n",
        "    plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list_Resnet44, label = 'ResNet-44')\n",
        "    plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list_VGG16, label = 'VGG-16')\n",
        "    plt.plot([i for i in range(1,EPOCHS + 1)], val_acc_list_VGG13, label = 'VGG-13')\n",
        "    plt.legend()\n",
        "    plt.title('Validation Accuracy on CIFAR10')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}