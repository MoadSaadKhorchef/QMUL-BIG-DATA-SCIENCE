{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Moad Saad Khorchef<br>\n",
    "## ID: 200934655\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Solution \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDjUBw3eIfrK",
    "outputId": "611c3087-6754-4b1f-ea93-18b1e5baea0e"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys, re, pickle, glob\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import soundfile\n",
    "\n",
    "\n",
    "#from IPython.display import Audio\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2FyOgx_rtiU"
   },
   "source": [
    "### Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tfBxTkiCI3be"
   },
   "outputs": [],
   "source": [
    "def feature_chromagram(waveform, sample_rate):\n",
    "    # STFT computed here explicitly; mel spectrogram and MFCC functions do this under the hood\n",
    "    stft_spectrogram=np.abs(librosa.stft(waveform))\n",
    "    # Produce the chromagram for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
    "    chromagram=np.mean(librosa.feature.chroma_stft(S=stft_spectrogram, sr=sample_rate,hop_length=512,n_fft=2048).T,axis=0)\n",
    "    return chromagram\n",
    "\n",
    "def feature_melspectrogram(waveform, sample_rate):\n",
    "    # Produce the mel spectrogram for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
    "    # Using 8khz as upper frequency bound should be enough for most speech classification tasks\n",
    "    melspectrogram=np.mean(librosa.feature.melspectrogram(y=waveform, sr=sample_rate, n_mels=128, fmax=sample_rate, hop_length=512,n_fft=2048).T,axis=0) ###\n",
    "    return melspectrogram\n",
    "\n",
    "def feature_mfcc(waveform, sample_rate):\n",
    "    # Compute the MFCCs for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
    "    # 40 filterbanks = 40 coefficients\n",
    "    mfc_coefficients=np.mean(librosa.feature.mfcc(y=waveform, sr=sample_rate, n_mfcc=40).T, axis=0) \n",
    "    return mfc_coefficients\n",
    "\n",
    "\n",
    "\n",
    "def getPitch(x,fs,winLen=0.02):\n",
    "  #winLen = 0.02 \n",
    "    p = winLen*fs\n",
    "    frame_length = int(2**int(p-1).bit_length())\n",
    "    hop_length = frame_length//2\n",
    "    f0, voiced_flag, voiced_probs = librosa.pyin(y=x, fmin=80, fmax=450, sr=fs, frame_length=frame_length,hop_length=hop_length)\n",
    "    return f0,voiced_flag\n",
    "\n",
    "\n",
    "\n",
    "def get_features(file):\n",
    "    # load an individual soundfile\n",
    "     with soundfile.SoundFile(file) as audio:\n",
    "        waveform = audio.read(dtype=\"float32\")\n",
    "        sample_rate = audio.samplerate\n",
    "        # compute features of soundfile\n",
    "        chromagram = feature_chromagram(waveform, sample_rate)\n",
    "        melspectrogram = feature_melspectrogram(waveform, sample_rate)\n",
    "        mfc_coefficients = feature_mfcc(waveform, sample_rate)\n",
    "\n",
    "        # my added features\n",
    "        #######\n",
    "        y = waveform\n",
    "        sr = sample_rate\n",
    "        stft_=np.abs(librosa.stft(waveform))\n",
    "\n",
    "        cent = np.mean( librosa.feature.spectral_centroid(y=y, sr=sr,hop_length=512,n_fft=2048).T, axis=0)\n",
    "        contrast = np.mean( librosa.feature.spectral_contrast(S=stft_, sr=sr,hop_length=512,n_fft=2048).T, axis=0)\n",
    "        #tonnetz = np.mean( librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sample_rate ,hop_length=512).T,axis=0)#\n",
    "        rms = np.mean( librosa.feature.rms(y=y,frame_length=2048 ,hop_length=512).T, axis=0)\n",
    "        spec_bw = np.mean( librosa.feature.spectral_bandwidth(y=y, sr=sr ,n_fft=2048, hop_length=512).T, axis=0)\n",
    "        rolloff = np.mean( librosa.feature.spectral_rolloff(y=y, sr=sr ,n_fft=2048, hop_length=512).T, axis=0)\n",
    "        zcr = np.mean( librosa.feature.zero_crossing_rate(y, frame_length=2048, hop_length=512).T, axis=0) \n",
    "        #######\n",
    "\n",
    "        feature_matrix=np.array([])\n",
    "        # use np.hstack to stack our feature arrays horizontally to create a feature matrix\n",
    "        feature_matrix = np.hstack((chromagram, melspectrogram, mfc_coefficients , cent, contrast, rms, spec_bw, rolloff, zcr))\n",
    "        \n",
    "        return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "s58-kfhrJALL"
   },
   "outputs": [],
   "source": [
    "#import os, glob\n",
    "\n",
    "#def load_data():\n",
    "#    X,y=[],[]\n",
    "#    count = 0\n",
    "#    for file in glob.glob('/content/drive/MyDrive/Data/MLEnd/training/*/*.wav'):\n",
    "#        file_name=os.path.basename(file)\n",
    "#        fileID = file.split('/')[-1]\n",
    "#        features = get_features(file)\n",
    "#        X.append(features)\n",
    "       # y.append(emotion)\n",
    "#        count += 1\n",
    "        # '\\r' + end='' results in printing over same line\n",
    "#        print('\\r' + f' Processed {count}/{20000} audio samples',end=' ')\n",
    "    # Return arrays to plug into sklearn's cross-validation algorithms\n",
    "#    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NSQvdCnFL0yT"
   },
   "outputs": [],
   "source": [
    "def getXy(files,labels_file,scale_audio=False, onlySingleDigit=False):\n",
    "    X,y =[],[]\n",
    "    for file in tqdm(files):\n",
    "        file = file.replace(\"\\\\\", \"/\")\n",
    "        fileID = file.split(\"/\")[-1]\n",
    "        #print(fileID)\n",
    "        yi = list(labels_file[labels_file['File ID']==fileID]['digit_label'])[0]\n",
    "        label = list(labels_file[labels_file['File ID']==fileID]['intonation'])[0]\n",
    "        if onlySingleDigit and yi>9:\n",
    "            continue\n",
    "        else:\n",
    "            fs = None # if None, fs would be 22050\n",
    "            x, fs = librosa.load(file,sr=fs)\n",
    "            if scale_audio: x = x/np.max(np.abs(x))\n",
    "            f0, voiced_flag = getPitch(x,fs,winLen=0.02)\n",
    "\n",
    "            power = np.sum(x**2)/len(x)\n",
    "            pitch_mean = np.nanmean(f0) if np.mean(np.isnan(f0))<1 else 0\n",
    "            pitch_std  = np.nanstd(f0) if np.mean(np.isnan(f0))<1 else 0\n",
    "            voiced_fr = np.mean(voiced_flag)\n",
    "\n",
    "            #added \n",
    "            features = get_features(file)\n",
    "\n",
    "            #xi = [power,pitch_mean,pitch_std,voiced_fr]\n",
    "\n",
    "            xi = np.hstack((power,pitch_mean,pitch_std,voiced_fr,features))\n",
    "\n",
    "            X.append(xi)\n",
    "            y.append(label)\n",
    "    return np.array(X),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File ID</th>\n",
       "      <th>digit_label</th>\n",
       "      <th>participant</th>\n",
       "      <th>intonation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000000.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>S73</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000001.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>S88</td>\n",
       "      <td>excited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000002.wav</td>\n",
       "      <td>70</td>\n",
       "      <td>S5</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000003.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>S85</td>\n",
       "      <td>bored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000004.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>S30</td>\n",
       "      <td>excited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0019995.wav</td>\n",
       "      <td>90</td>\n",
       "      <td>S163</td>\n",
       "      <td>excited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0019996.wav</td>\n",
       "      <td>10</td>\n",
       "      <td>S99</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0019997.wav</td>\n",
       "      <td>90</td>\n",
       "      <td>S46</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0019998.wav</td>\n",
       "      <td>19</td>\n",
       "      <td>S13</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0019999.wav</td>\n",
       "      <td>20</td>\n",
       "      <td>S101</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           File ID  digit_label participant intonation\n",
       "0      0000000.wav            4         S73   question\n",
       "1      0000001.wav            2         S88    excited\n",
       "2      0000002.wav           70          S5    neutral\n",
       "3      0000003.wav            2         S85      bored\n",
       "4      0000004.wav            4         S30    excited\n",
       "...            ...          ...         ...        ...\n",
       "19995  0019995.wav           90        S163    excited\n",
       "19996  0019996.wav           10         S99   question\n",
       "19997  0019997.wav           90         S46   question\n",
       "19998  0019998.wav           19         S13    neutral\n",
       "19999  0019999.wav           20        S101    neutral\n",
       "\n",
       "[20000 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('./Data/MLEnd/trainingMLEnd.csv')\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cSRor5BeKNj-",
    "outputId": "49085e8b-3127-46b6-cc3d-b7384876e54c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/6000 [00:00<?, ?it/s]C:\\Users\\Moad\\anaconda3\\lib\\site-packages\\librosa\\filters.py:238: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 6000/6000 [14:54<00:00,  6.70it/s]\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(\"./Data/MLEnd/training/Training/*.wav\" )\n",
    "\n",
    "\n",
    "X,y = getXy(files[:6000],labels_file=labels,scale_audio=True, onlySingleDigit=True)\n",
    "\n",
    "#a,b = getXy(files[:1000],labels_file=labels,scale_audio=True, onlySingleDigit=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('./Data/MLEnd/training/Training/*.wav')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5l2dL0wJaSpV"
   },
   "outputs": [],
   "source": [
    "#print('The shape of X is', a.shape) \n",
    "#print('The shape of y is', b.shape)\n",
    "#print('The labels vector is', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6x4I-Y-QAb9",
    "outputId": "6f4974a6-a3b1-4add-dcc5-26e8cbf248af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is (1949, 196)\n",
      "The shape of y is (1949,)\n"
     ]
    }
   ],
   "source": [
    "print('The shape of X is', X.shape) \n",
    "print('The shape of y is', y.shape)\n",
    "#print('The labels vector is', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kki0oC8OrjGu"
   },
   "source": [
    "### Best Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0g0wTYEkf1Uy",
    "outputId": "1f5af75e-5ddc-42cd-f0c5-f44a4402a087"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1949, 190)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif#\n",
    "\n",
    "#X.shape\n",
    "X_new = SelectKBest(mutual_info_classif, k=190).fit_transform(X, y)\n",
    "#X_new = SelectKBest(mutual_info_classif, k=150).fit_transform(a, b)\n",
    "\n",
    "X_new.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "wxHZ2cWnR0kU",
    "outputId": "07fc174f-180a-45fc-a500-8d5d3c4d9210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Audio samples represented: 1949\n",
      "Numerical features extracted per sample: 190\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010129</td>\n",
       "      <td>208.882834</td>\n",
       "      <td>118.829623</td>\n",
       "      <td>0.215278</td>\n",
       "      <td>0.753131</td>\n",
       "      <td>0.766886</td>\n",
       "      <td>0.749057</td>\n",
       "      <td>0.671027</td>\n",
       "      <td>0.634170</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>...</td>\n",
       "      <td>12.066502</td>\n",
       "      <td>13.726420</td>\n",
       "      <td>15.600197</td>\n",
       "      <td>15.085901</td>\n",
       "      <td>15.386061</td>\n",
       "      <td>19.041806</td>\n",
       "      <td>0.009657</td>\n",
       "      <td>2197.995732</td>\n",
       "      <td>4693.939209</td>\n",
       "      <td>0.159003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035339</td>\n",
       "      <td>157.289085</td>\n",
       "      <td>31.784415</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.583537</td>\n",
       "      <td>0.643321</td>\n",
       "      <td>0.677088</td>\n",
       "      <td>0.669812</td>\n",
       "      <td>0.709702</td>\n",
       "      <td>0.740893</td>\n",
       "      <td>...</td>\n",
       "      <td>13.944263</td>\n",
       "      <td>15.772536</td>\n",
       "      <td>16.208509</td>\n",
       "      <td>17.446751</td>\n",
       "      <td>17.795718</td>\n",
       "      <td>27.592407</td>\n",
       "      <td>0.031027</td>\n",
       "      <td>2434.352641</td>\n",
       "      <td>5335.701069</td>\n",
       "      <td>0.155646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013676</td>\n",
       "      <td>134.964540</td>\n",
       "      <td>4.520547</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>0.677341</td>\n",
       "      <td>0.748570</td>\n",
       "      <td>0.695867</td>\n",
       "      <td>0.597716</td>\n",
       "      <td>0.595714</td>\n",
       "      <td>0.726472</td>\n",
       "      <td>...</td>\n",
       "      <td>12.323731</td>\n",
       "      <td>16.377326</td>\n",
       "      <td>15.793714</td>\n",
       "      <td>20.858538</td>\n",
       "      <td>21.230001</td>\n",
       "      <td>19.016606</td>\n",
       "      <td>0.031680</td>\n",
       "      <td>1446.833328</td>\n",
       "      <td>1627.869907</td>\n",
       "      <td>0.027166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.052517</td>\n",
       "      <td>181.944641</td>\n",
       "      <td>40.719889</td>\n",
       "      <td>0.494253</td>\n",
       "      <td>0.569682</td>\n",
       "      <td>0.537822</td>\n",
       "      <td>0.540425</td>\n",
       "      <td>0.537556</td>\n",
       "      <td>0.533592</td>\n",
       "      <td>0.509157</td>\n",
       "      <td>...</td>\n",
       "      <td>15.977014</td>\n",
       "      <td>20.075173</td>\n",
       "      <td>18.970150</td>\n",
       "      <td>17.982028</td>\n",
       "      <td>19.588298</td>\n",
       "      <td>25.813768</td>\n",
       "      <td>0.078083</td>\n",
       "      <td>1994.697128</td>\n",
       "      <td>3658.686967</td>\n",
       "      <td>0.105957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027461</td>\n",
       "      <td>109.742686</td>\n",
       "      <td>18.208426</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.704168</td>\n",
       "      <td>0.769274</td>\n",
       "      <td>0.750523</td>\n",
       "      <td>0.715473</td>\n",
       "      <td>0.715584</td>\n",
       "      <td>0.750014</td>\n",
       "      <td>...</td>\n",
       "      <td>11.006136</td>\n",
       "      <td>14.597893</td>\n",
       "      <td>15.629837</td>\n",
       "      <td>15.968503</td>\n",
       "      <td>17.372982</td>\n",
       "      <td>28.002703</td>\n",
       "      <td>0.073354</td>\n",
       "      <td>1915.549197</td>\n",
       "      <td>4090.016602</td>\n",
       "      <td>0.118665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>0.012427</td>\n",
       "      <td>218.320824</td>\n",
       "      <td>74.117411</td>\n",
       "      <td>0.215190</td>\n",
       "      <td>0.671424</td>\n",
       "      <td>0.675539</td>\n",
       "      <td>0.718936</td>\n",
       "      <td>0.770489</td>\n",
       "      <td>0.783567</td>\n",
       "      <td>0.700486</td>\n",
       "      <td>...</td>\n",
       "      <td>13.106332</td>\n",
       "      <td>14.723138</td>\n",
       "      <td>14.927029</td>\n",
       "      <td>16.610873</td>\n",
       "      <td>16.490449</td>\n",
       "      <td>22.097368</td>\n",
       "      <td>0.038017</td>\n",
       "      <td>2287.243290</td>\n",
       "      <td>5410.558000</td>\n",
       "      <td>0.220672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>0.019418</td>\n",
       "      <td>244.020822</td>\n",
       "      <td>69.803627</td>\n",
       "      <td>0.337349</td>\n",
       "      <td>0.687252</td>\n",
       "      <td>0.701269</td>\n",
       "      <td>0.734410</td>\n",
       "      <td>0.739803</td>\n",
       "      <td>0.626294</td>\n",
       "      <td>0.625772</td>\n",
       "      <td>...</td>\n",
       "      <td>15.619662</td>\n",
       "      <td>16.779178</td>\n",
       "      <td>16.662217</td>\n",
       "      <td>16.648297</td>\n",
       "      <td>15.834053</td>\n",
       "      <td>25.801179</td>\n",
       "      <td>0.064158</td>\n",
       "      <td>2398.899065</td>\n",
       "      <td>4433.504918</td>\n",
       "      <td>0.065118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>0.055544</td>\n",
       "      <td>205.535959</td>\n",
       "      <td>44.520564</td>\n",
       "      <td>0.508065</td>\n",
       "      <td>0.500811</td>\n",
       "      <td>0.442746</td>\n",
       "      <td>0.422549</td>\n",
       "      <td>0.392942</td>\n",
       "      <td>0.397227</td>\n",
       "      <td>0.447477</td>\n",
       "      <td>...</td>\n",
       "      <td>18.152734</td>\n",
       "      <td>22.305314</td>\n",
       "      <td>22.854587</td>\n",
       "      <td>25.405481</td>\n",
       "      <td>27.847928</td>\n",
       "      <td>33.575963</td>\n",
       "      <td>0.165468</td>\n",
       "      <td>1813.729011</td>\n",
       "      <td>3224.423513</td>\n",
       "      <td>0.081496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>0.022832</td>\n",
       "      <td>270.207906</td>\n",
       "      <td>77.876257</td>\n",
       "      <td>0.302632</td>\n",
       "      <td>0.584216</td>\n",
       "      <td>0.621987</td>\n",
       "      <td>0.611628</td>\n",
       "      <td>0.667121</td>\n",
       "      <td>0.762832</td>\n",
       "      <td>0.667282</td>\n",
       "      <td>...</td>\n",
       "      <td>16.730680</td>\n",
       "      <td>18.322132</td>\n",
       "      <td>17.769921</td>\n",
       "      <td>18.166319</td>\n",
       "      <td>21.190978</td>\n",
       "      <td>22.895909</td>\n",
       "      <td>0.025193</td>\n",
       "      <td>2193.073818</td>\n",
       "      <td>5535.166530</td>\n",
       "      <td>0.206826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>0.022271</td>\n",
       "      <td>209.188324</td>\n",
       "      <td>17.903261</td>\n",
       "      <td>0.186813</td>\n",
       "      <td>0.698230</td>\n",
       "      <td>0.691233</td>\n",
       "      <td>0.631692</td>\n",
       "      <td>0.642415</td>\n",
       "      <td>0.635447</td>\n",
       "      <td>0.615306</td>\n",
       "      <td>...</td>\n",
       "      <td>13.454528</td>\n",
       "      <td>18.725646</td>\n",
       "      <td>14.281809</td>\n",
       "      <td>16.210192</td>\n",
       "      <td>17.468596</td>\n",
       "      <td>23.073855</td>\n",
       "      <td>0.014502</td>\n",
       "      <td>2548.469437</td>\n",
       "      <td>5033.620287</td>\n",
       "      <td>0.096754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1949 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1           2         3         4         5    \\\n",
       "0     0.010129  208.882834  118.829623  0.215278  0.753131  0.766886   \n",
       "1     0.035339  157.289085   31.784415  0.293333  0.583537  0.643321   \n",
       "2     0.013676  134.964540    4.520547  0.084507  0.677341  0.748570   \n",
       "3     0.052517  181.944641   40.719889  0.494253  0.569682  0.537822   \n",
       "4     0.027461  109.742686   18.208426  0.120000  0.704168  0.769274   \n",
       "...        ...         ...         ...       ...       ...       ...   \n",
       "1944  0.012427  218.320824   74.117411  0.215190  0.671424  0.675539   \n",
       "1945  0.019418  244.020822   69.803627  0.337349  0.687252  0.701269   \n",
       "1946  0.055544  205.535959   44.520564  0.508065  0.500811  0.442746   \n",
       "1947  0.022832  270.207906   77.876257  0.302632  0.584216  0.621987   \n",
       "1948  0.022271  209.188324   17.903261  0.186813  0.698230  0.691233   \n",
       "\n",
       "           6         7         8         9    ...        180        181  \\\n",
       "0     0.749057  0.671027  0.634170  0.670543  ...  12.066502  13.726420   \n",
       "1     0.677088  0.669812  0.709702  0.740893  ...  13.944263  15.772536   \n",
       "2     0.695867  0.597716  0.595714  0.726472  ...  12.323731  16.377326   \n",
       "3     0.540425  0.537556  0.533592  0.509157  ...  15.977014  20.075173   \n",
       "4     0.750523  0.715473  0.715584  0.750014  ...  11.006136  14.597893   \n",
       "...        ...       ...       ...       ...  ...        ...        ...   \n",
       "1944  0.718936  0.770489  0.783567  0.700486  ...  13.106332  14.723138   \n",
       "1945  0.734410  0.739803  0.626294  0.625772  ...  15.619662  16.779178   \n",
       "1946  0.422549  0.392942  0.397227  0.447477  ...  18.152734  22.305314   \n",
       "1947  0.611628  0.667121  0.762832  0.667282  ...  16.730680  18.322132   \n",
       "1948  0.631692  0.642415  0.635447  0.615306  ...  13.454528  18.725646   \n",
       "\n",
       "            182        183        184        185       186          187  \\\n",
       "0     15.600197  15.085901  15.386061  19.041806  0.009657  2197.995732   \n",
       "1     16.208509  17.446751  17.795718  27.592407  0.031027  2434.352641   \n",
       "2     15.793714  20.858538  21.230001  19.016606  0.031680  1446.833328   \n",
       "3     18.970150  17.982028  19.588298  25.813768  0.078083  1994.697128   \n",
       "4     15.629837  15.968503  17.372982  28.002703  0.073354  1915.549197   \n",
       "...         ...        ...        ...        ...       ...          ...   \n",
       "1944  14.927029  16.610873  16.490449  22.097368  0.038017  2287.243290   \n",
       "1945  16.662217  16.648297  15.834053  25.801179  0.064158  2398.899065   \n",
       "1946  22.854587  25.405481  27.847928  33.575963  0.165468  1813.729011   \n",
       "1947  17.769921  18.166319  21.190978  22.895909  0.025193  2193.073818   \n",
       "1948  14.281809  16.210192  17.468596  23.073855  0.014502  2548.469437   \n",
       "\n",
       "              188       189  \n",
       "0     4693.939209  0.159003  \n",
       "1     5335.701069  0.155646  \n",
       "2     1627.869907  0.027166  \n",
       "3     3658.686967  0.105957  \n",
       "4     4090.016602  0.118665  \n",
       "...           ...       ...  \n",
       "1944  5410.558000  0.220672  \n",
       "1945  4433.504918  0.065118  \n",
       "1946  3224.423513  0.081496  \n",
       "1947  5535.166530  0.206826  \n",
       "1948  5033.620287  0.096754  \n",
       "\n",
       "[1949 rows x 190 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'\\nAudio samples represented: {X_new.shape[0]}')\n",
    "print(f'Numerical features extracted per sample: {X_new.shape[1]}')\n",
    "features_df = pd.DataFrame(X_new) # make it pretty for display\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptP8E8J5q2Ej"
   },
   "source": [
    "### Class Balance Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a34-98ZEnYlK",
    "outputId": "5763ef92-9261-4cae-e379-de885d603803"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bored', 'excited', 'neutral', 'question'], dtype='<U8')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intonation_list = np.unique(y)\n",
    "intonation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "XGpvh4EjnEmT",
    "outputId": "c0518534-3c93-467e-e0a8-19d8f4a0e3f1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2520x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot emotions\n",
    "plt.figure(figsize=(35,4))\n",
    "plt.subplot(1,3,1)\n",
    "#np.unique returns ordered list of unique elements and count of each element\n",
    "intonation_list, count = np.unique(y, return_counts=True)\n",
    "plt.bar(x=range(4), height=count)\n",
    "plt.xticks(ticks=range(4), labels = [intonation for intonation in intonation_list],fontsize=10)\n",
    "plt.xlabel('intonation')\n",
    "plt.tick_params(labelsize=16)\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wTIPPs_antQR",
    "outputId": "9280e681-847c-4f65-a124-0cffd081cc7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# If nan sample, remove them\n",
    "if np.sum(np.isnan(X)):\n",
    "    idx = np.isnan(X).sum(1)>0\n",
    "    X = X[~idx]\n",
    "    y = y[~idx]\n",
    "print(np.sum(np.isnan(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYyyMvBJq9T7"
   },
   "source": [
    "### Normalising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "epVppsnHo7NR"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# keep our unscaled features just in case we need to process them alternatively\n",
    "#features_scaled = X\n",
    "#features_scaled = a\n",
    "features_scaled = X_new\n",
    "features_scaled = scaler.fit_transform(features_scaled)\n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "# keep our unscaled features just in case we need to process them alternatively\n",
    "#features_minmax = features\n",
    "#features_minmax = scaler.fit_transform(features_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "gGD6HgWLEgeD",
    "outputId": "89a866ca-d465-468c-c5fb-79e8d048f2a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.842976</td>\n",
       "      <td>0.400776</td>\n",
       "      <td>3.385139</td>\n",
       "      <td>-0.579043</td>\n",
       "      <td>0.799140</td>\n",
       "      <td>1.027576</td>\n",
       "      <td>0.857193</td>\n",
       "      <td>0.111030</td>\n",
       "      <td>-0.139985</td>\n",
       "      <td>0.260398</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.232015</td>\n",
       "      <td>-1.458734</td>\n",
       "      <td>-0.386383</td>\n",
       "      <td>-1.335666</td>\n",
       "      <td>-1.373209</td>\n",
       "      <td>-1.175288</td>\n",
       "      <td>-0.711562</td>\n",
       "      <td>-0.066101</td>\n",
       "      <td>-0.012779</td>\n",
       "      <td>0.290658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.876839</td>\n",
       "      <td>-0.247284</td>\n",
       "      <td>0.142631</td>\n",
       "      <td>-0.091997</td>\n",
       "      <td>-0.860901</td>\n",
       "      <td>-0.174619</td>\n",
       "      <td>0.164147</td>\n",
       "      <td>0.099436</td>\n",
       "      <td>0.549521</td>\n",
       "      <td>0.899578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.398668</td>\n",
       "      <td>-0.524623</td>\n",
       "      <td>-0.095913</td>\n",
       "      <td>-0.112957</td>\n",
       "      <td>-0.236553</td>\n",
       "      <td>0.978520</td>\n",
       "      <td>0.038124</td>\n",
       "      <td>0.557227</td>\n",
       "      <td>0.458210</td>\n",
       "      <td>0.248346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.600979</td>\n",
       "      <td>-0.527699</td>\n",
       "      <td>-0.872971</td>\n",
       "      <td>-1.395019</td>\n",
       "      <td>0.057287</td>\n",
       "      <td>0.849369</td>\n",
       "      <td>0.344986</td>\n",
       "      <td>-0.588274</td>\n",
       "      <td>-0.491041</td>\n",
       "      <td>0.768550</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.117857</td>\n",
       "      <td>-0.248518</td>\n",
       "      <td>-0.293978</td>\n",
       "      <td>1.654044</td>\n",
       "      <td>1.383427</td>\n",
       "      <td>-1.181635</td>\n",
       "      <td>0.061036</td>\n",
       "      <td>-2.047093</td>\n",
       "      <td>-2.262965</td>\n",
       "      <td>-1.370896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.048664</td>\n",
       "      <td>0.062410</td>\n",
       "      <td>0.475485</td>\n",
       "      <td>1.161689</td>\n",
       "      <td>-0.996521</td>\n",
       "      <td>-1.201049</td>\n",
       "      <td>-1.151872</td>\n",
       "      <td>-1.162142</td>\n",
       "      <td>-1.058135</td>\n",
       "      <td>-1.205914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503463</td>\n",
       "      <td>1.439656</td>\n",
       "      <td>1.222777</td>\n",
       "      <td>0.164269</td>\n",
       "      <td>0.609022</td>\n",
       "      <td>0.530499</td>\n",
       "      <td>1.688916</td>\n",
       "      <td>-0.602248</td>\n",
       "      <td>-0.772550</td>\n",
       "      <td>-0.377887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.339394</td>\n",
       "      <td>-0.844506</td>\n",
       "      <td>-0.363086</td>\n",
       "      <td>-1.173552</td>\n",
       "      <td>0.319872</td>\n",
       "      <td>1.050802</td>\n",
       "      <td>0.871304</td>\n",
       "      <td>0.534995</td>\n",
       "      <td>0.603220</td>\n",
       "      <td>0.982447</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.702604</td>\n",
       "      <td>-1.060881</td>\n",
       "      <td>-0.372230</td>\n",
       "      <td>-0.878557</td>\n",
       "      <td>-0.435961</td>\n",
       "      <td>1.081869</td>\n",
       "      <td>1.522988</td>\n",
       "      <td>-0.810979</td>\n",
       "      <td>-0.455997</td>\n",
       "      <td>-0.217723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>-0.686187</td>\n",
       "      <td>0.519325</td>\n",
       "      <td>1.719571</td>\n",
       "      <td>-0.579592</td>\n",
       "      <td>-0.000634</td>\n",
       "      <td>0.138839</td>\n",
       "      <td>0.567138</td>\n",
       "      <td>1.059792</td>\n",
       "      <td>1.223815</td>\n",
       "      <td>0.532453</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.770540</td>\n",
       "      <td>-1.003703</td>\n",
       "      <td>-0.707822</td>\n",
       "      <td>-0.545867</td>\n",
       "      <td>-0.852259</td>\n",
       "      <td>-0.405623</td>\n",
       "      <td>0.283348</td>\n",
       "      <td>0.169265</td>\n",
       "      <td>0.513147</td>\n",
       "      <td>1.067873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>-0.209269</td>\n",
       "      <td>0.842139</td>\n",
       "      <td>1.558879</td>\n",
       "      <td>0.182652</td>\n",
       "      <td>0.154298</td>\n",
       "      <td>0.389172</td>\n",
       "      <td>0.716143</td>\n",
       "      <td>0.767077</td>\n",
       "      <td>-0.211884</td>\n",
       "      <td>-0.146379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344871</td>\n",
       "      <td>-0.065061</td>\n",
       "      <td>0.120734</td>\n",
       "      <td>-0.526485</td>\n",
       "      <td>-1.161887</td>\n",
       "      <td>0.527328</td>\n",
       "      <td>1.200383</td>\n",
       "      <td>0.463728</td>\n",
       "      <td>-0.203912</td>\n",
       "      <td>-0.892584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>2.255192</td>\n",
       "      <td>0.358737</td>\n",
       "      <td>0.617064</td>\n",
       "      <td>1.247870</td>\n",
       "      <td>-1.670651</td>\n",
       "      <td>-2.126057</td>\n",
       "      <td>-2.286985</td>\n",
       "      <td>-2.541593</td>\n",
       "      <td>-2.302972</td>\n",
       "      <td>-1.766326</td>\n",
       "      <td>...</td>\n",
       "      <td>1.469044</td>\n",
       "      <td>2.457780</td>\n",
       "      <td>3.077604</td>\n",
       "      <td>4.008954</td>\n",
       "      <td>4.505159</td>\n",
       "      <td>2.485716</td>\n",
       "      <td>4.754478</td>\n",
       "      <td>-1.079503</td>\n",
       "      <td>-1.091256</td>\n",
       "      <td>-0.686173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>0.023606</td>\n",
       "      <td>1.171070</td>\n",
       "      <td>1.859592</td>\n",
       "      <td>-0.033978</td>\n",
       "      <td>-0.854261</td>\n",
       "      <td>-0.382188</td>\n",
       "      <td>-0.466211</td>\n",
       "      <td>0.073773</td>\n",
       "      <td>1.034530</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.837939</td>\n",
       "      <td>0.639342</td>\n",
       "      <td>0.649665</td>\n",
       "      <td>0.259715</td>\n",
       "      <td>1.365020</td>\n",
       "      <td>-0.204479</td>\n",
       "      <td>-0.166559</td>\n",
       "      <td>-0.079082</td>\n",
       "      <td>0.604597</td>\n",
       "      <td>0.893364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>-0.014666</td>\n",
       "      <td>0.404614</td>\n",
       "      <td>-0.374453</td>\n",
       "      <td>-0.756655</td>\n",
       "      <td>0.261750</td>\n",
       "      <td>0.291526</td>\n",
       "      <td>-0.272998</td>\n",
       "      <td>-0.161894</td>\n",
       "      <td>-0.128327</td>\n",
       "      <td>-0.241474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.616012</td>\n",
       "      <td>0.823558</td>\n",
       "      <td>-1.015916</td>\n",
       "      <td>-0.753383</td>\n",
       "      <td>-0.390859</td>\n",
       "      <td>-0.159656</td>\n",
       "      <td>-0.541590</td>\n",
       "      <td>0.858180</td>\n",
       "      <td>0.236513</td>\n",
       "      <td>-0.493873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1949 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -0.842976  0.400776  3.385139 -0.579043  0.799140  1.027576  0.857193   \n",
       "1     0.876839 -0.247284  0.142631 -0.091997 -0.860901 -0.174619  0.164147   \n",
       "2    -0.600979 -0.527699 -0.872971 -1.395019  0.057287  0.849369  0.344986   \n",
       "3     2.048664  0.062410  0.475485  1.161689 -0.996521 -1.201049 -1.151872   \n",
       "4     0.339394 -0.844506 -0.363086 -1.173552  0.319872  1.050802  0.871304   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1944 -0.686187  0.519325  1.719571 -0.579592 -0.000634  0.138839  0.567138   \n",
       "1945 -0.209269  0.842139  1.558879  0.182652  0.154298  0.389172  0.716143   \n",
       "1946  2.255192  0.358737  0.617064  1.247870 -1.670651 -2.126057 -2.286985   \n",
       "1947  0.023606  1.171070  1.859592 -0.033978 -0.854261 -0.382188 -0.466211   \n",
       "1948 -0.014666  0.404614 -0.374453 -0.756655  0.261750  0.291526 -0.272998   \n",
       "\n",
       "           7         8         9    ...       180       181       182  \\\n",
       "0     0.111030 -0.139985  0.260398  ... -1.232015 -1.458734 -0.386383   \n",
       "1     0.099436  0.549521  0.899578  ... -0.398668 -0.524623 -0.095913   \n",
       "2    -0.588274 -0.491041  0.768550  ... -1.117857 -0.248518 -0.293978   \n",
       "3    -1.162142 -1.058135 -1.205914  ...  0.503463  1.439656  1.222777   \n",
       "4     0.534995  0.603220  0.982447  ... -1.702604 -1.060881 -0.372230   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1944  1.059792  1.223815  0.532453  ... -0.770540 -1.003703 -0.707822   \n",
       "1945  0.767077 -0.211884 -0.146379  ...  0.344871 -0.065061  0.120734   \n",
       "1946 -2.541593 -2.302972 -1.766326  ...  1.469044  2.457780  3.077604   \n",
       "1947  0.073773  1.034530  0.230769  ...  0.837939  0.639342  0.649665   \n",
       "1948 -0.161894 -0.128327 -0.241474  ... -0.616012  0.823558 -1.015916   \n",
       "\n",
       "           183       184       185       186       187       188       189  \n",
       "0    -1.335666 -1.373209 -1.175288 -0.711562 -0.066101 -0.012779  0.290658  \n",
       "1    -0.112957 -0.236553  0.978520  0.038124  0.557227  0.458210  0.248346  \n",
       "2     1.654044  1.383427 -1.181635  0.061036 -2.047093 -2.262965 -1.370896  \n",
       "3     0.164269  0.609022  0.530499  1.688916 -0.602248 -0.772550 -0.377887  \n",
       "4    -0.878557 -0.435961  1.081869  1.522988 -0.810979 -0.455997 -0.217723  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1944 -0.545867 -0.852259 -0.405623  0.283348  0.169265  0.513147  1.067873  \n",
       "1945 -0.526485 -1.161887  0.527328  1.200383  0.463728 -0.203912 -0.892584  \n",
       "1946  4.008954  4.505159  2.485716  4.754478 -1.079503 -1.091256 -0.686173  \n",
       "1947  0.259715  1.365020 -0.204479 -0.166559 -0.079082  0.604597  0.893364  \n",
       "1948 -0.753383 -0.390859 -0.159656 -0.541590  0.858180  0.236513 -0.493873  \n",
       "\n",
       "[1949 rows x 190 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_scaled_df = pd.DataFrame(features_scaled) # make it pretty for display\n",
    "features_scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1rZFd-brPRB"
   },
   "source": [
    "### Dataset Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Ux_q_akgryM1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "############# Unscaled test/train set #############\n",
    "#X_train, X_val, y_train, y_val = train_test_split(\n",
    "#    X, \n",
    "#    y, \n",
    "#    test_size=0.2, \n",
    "#    stratify=y\n",
    "#)\n",
    "\n",
    "############ Standard Scaled test/train set ###########\n",
    "# The labels/classes (y_train, y_test) never change, keep old values \n",
    "X_train_scaled, X_test_scaled, y_train, y_val = train_test_split(\n",
    "    features_scaled, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAa3LbhCqTBB"
   },
   "source": [
    "## Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "Jr7sG7UJuDkm",
    "outputId": "1c33fd69-9438-4a72-c9b0-7485d377b4c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moad\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>62.31%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>60.26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC RBF kernel</td>\n",
       "      <td>58.21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>50.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>48.72%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>43.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>35.64%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Classifier Accuracy Score\n",
       "3         RandomForestClassifier         62.31%\n",
       "0           KNeighborsClassifier         60.26%\n",
       "1                 SVC RBF kernel         58.21%\n",
       "4             AdaBoostClassifier         50.00%\n",
       "2         DecisionTreeClassifier         48.72%\n",
       "6  QuadraticDiscriminantAnalysis         43.59%\n",
       "5                     GaussianNB         35.64%"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "X_train_scaled, X_val_scaled, y_train, y_val = train_test_split(\n",
    "    features_scaled, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "classification_models = [\n",
    "    KNeighborsClassifier(),#(3),\n",
    "    #SVC(kernel='linear'),#, C=0.025),\n",
    "    SVC(kernel='rbf'),\n",
    "    DecisionTreeClassifier(),#max_depth=5),\n",
    "    RandomForestClassifier(),#max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "scores = []\n",
    "for model in classification_models:\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    score = model.score(X_val_scaled, y_val)\n",
    "    model_name = type(model).__name__\n",
    "    if model_name=='SVC' and model.kernel=='rbf': model_name+=' RBF kernel'\n",
    "    scores.append((model_name,(f'{100*score:.2f}%')))\n",
    "    \n",
    "# Make it pretty\n",
    "scores_df = pd.DataFrame(scores,columns=['Classifier','Accuracy Score'])\n",
    "scores_df.sort_values(by='Accuracy Score',axis=0,ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuVhMIirqkKZ"
   },
   "source": [
    "### GridSearchCV SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-fImyTfKunFO",
    "outputId": "43661f32-0d30-4f77-feaf-cc48c83650d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......................... C=1, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......................... C=1, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=1, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=1, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=1, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=1, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   0.6s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   0.6s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=1, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=2, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=2, gamma=1, kernel=rbf, total=   0.9s\n",
      "[CV] C=2, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=2, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=2, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=2, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=2, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=2, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=2, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=2, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=2, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=2, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=2, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=2, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=2, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=2, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=2, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=2, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=2, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=2, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=2, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=2, gamma=0.01, kernel=rbf, total=   0.6s\n",
      "[CV] C=2, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=2, gamma=0.01, kernel=rbf, total=   0.6s\n",
      "[CV] C=2, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=2, gamma=0.01, kernel=rbf, total=   0.6s\n",
      "[CV] C=2, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=2, gamma=0.01, kernel=rbf, total=   0.6s\n",
      "[CV] C=2, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=2, gamma=0.01, kernel=rbf, total=   0.6s\n",
      "[CV] C=3, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=3, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=3, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=3, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=3, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=3, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=3, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=3, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=3, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=3, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=3, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=3, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=3, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=3, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=3, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=3, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=3, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=3, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=3, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=3, gamma=0.1, kernel=rbf, total=   0.7s\n",
      "[CV] C=3, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=3, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=3, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=3, gamma=0.01, kernel=rbf, total=   0.6s\n",
      "[CV] C=3, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=3, gamma=0.01, kernel=rbf, total=   0.6s\n",
      "[CV] C=3, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=3, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=3, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=3, gamma=0.01, kernel=rbf, total=   0.8s\n",
      "[CV] C=4, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=4, gamma=1, kernel=rbf, total=   0.9s\n",
      "[CV] C=4, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=4, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=4, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=4, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=4, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=4, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=4, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=4, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=4, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=4, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=4, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=4, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=4, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=4, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=4, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=4, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=4, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=4, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=4, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=4, gamma=0.01, kernel=rbf, total=   0.6s\n",
      "[CV] C=4, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=4, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=4, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=4, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=4, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=4, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=4, gamma=0.01, kernel=rbf .....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=4, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=5, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=5, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=5, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=5, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=5, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=5, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=5, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=5, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=5, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=5, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=5, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=5, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=5, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=5, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=5, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=5, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=5, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=5, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=5, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=5, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=5, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=5, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=5, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=5, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=5, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=5, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=5, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=5, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=5, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=5, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=6, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=6, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=6, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=6, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=6, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=6, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=6, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=6, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=6, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=6, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=6, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=6, gamma=0.1, kernel=rbf, total=   0.7s\n",
      "[CV] C=6, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=6, gamma=0.1, kernel=rbf, total=   0.7s\n",
      "[CV] C=6, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=6, gamma=0.1, kernel=rbf, total=   0.7s\n",
      "[CV] C=6, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=6, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=6, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=6, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=6, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=6, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=6, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=6, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=6, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=6, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=6, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=6, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=6, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=6, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=7, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=7, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=7, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=7, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=7, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=7, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=7, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=7, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=7, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=7, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=7, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=7, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=7, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=7, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=7, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=7, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=7, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=7, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=7, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=7, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=7, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=7, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=7, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=7, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=7, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=7, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=7, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=7, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=7, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=7, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=8, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=8, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=8, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=8, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=8, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=8, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=8, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=8, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=8, gamma=1, kernel=rbf ........................................\n",
      "[CV] ......................... C=8, gamma=1, kernel=rbf, total=   0.8s\n",
      "[CV] C=8, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=8, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=8, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=8, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=8, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=8, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=8, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=8, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=8, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] ....................... C=8, gamma=0.1, kernel=rbf, total=   0.8s\n",
      "[CV] C=8, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=8, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=8, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=8, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=8, gamma=0.01, kernel=rbf .....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=8, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=8, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=8, gamma=0.01, kernel=rbf, total=   0.7s\n",
      "[CV] C=8, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ...................... C=8, gamma=0.01, kernel=rbf, total=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 8, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "SVC(C=8, gamma=0.01)\n",
      "Test dataset accuracy of best hyperparameter setting: 0.6897435897435897.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "param_grid = { 'C':[1,2,3,4,5,6,7,8],'kernel':['rbf'],'gamma': [ 1, 0.1, 0.01 ]}\n",
    "\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2, cv= 5)\n",
    "grid.fit(X_train_scaled,y_train)\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)\n",
    "print('Test dataset accuracy of best hyperparameter setting: {0}.'.format(grid.score(X_val_scaled, y_val)))\n",
    "\n",
    "#grid_predictions = grid.predict(X_val)\n",
    "#print(confusion_matrix(y_val,grid_predictions))\n",
    "#print(classification_report(y_val,grid_predictions))#Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0iIpQWCZqtbr"
   },
   "source": [
    "### GridSearchCV RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4BEBZ28IxrQ6",
    "outputId": "3ab39022-1459-490c-b018-15fe22ff94de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5791738807815979\n",
      "{'max_features': 'sqrt', 'n_estimators': 200}\n",
      "RandomForestClassifier(max_features='sqrt', n_estimators=200, n_jobs=-1,\n",
      "                       oob_score=True)\n",
      "Test dataset accuracy (random forest classifier): 0.6384615384615384.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, oob_score = True) \n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [200,250,280,300,350],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)\n",
    "print('Test dataset accuracy (random forest classifier): {0}.'.format(grid.score(X_val_scaled, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-IfmUSUUPi-"
   },
   "source": [
    "## Advanced Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN implementaion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tried to classify numeral unsuccessfully using pytorch RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom dataloader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data,label ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): path to csv file\n",
    "            height (int): image height\n",
    "            width (int): image width\n",
    "            transform: pytorch transforms for transforms and tensor conversion\n",
    "        \"\"\"\n",
    "        self.datas = torch.tensor(data,dtype=torch.float)\n",
    "        self.labels = torch.tensor(label,dtype=torch.long) \n",
    "        self.length = len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        a = self.datas[index]\n",
    "        b = self.labels[index]\n",
    "\n",
    "        return (a, b)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('X.npy')\n",
    "y = np.load('y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6533, 1, 40)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = X.reshape(6533,1,40 )\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "customData = CustomDataset( X1,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = customData, batch_size=1, shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = customData, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-5.3418e+02,  6.2225e+01,  2.0558e+01,  2.2183e+01,  2.5795e+01,\n",
      "           1.2348e+01,  7.7691e+00,  8.5875e+00,  4.3267e+00,  3.1053e+00,\n",
      "           2.1343e+00, -2.7397e+00, -3.7493e+00, -1.2565e+00, -4.9067e-01,\n",
      "           1.7763e-01,  5.0912e-01, -3.9038e-01,  9.1733e-01,  3.4233e+00,\n",
      "           3.0662e+00,  1.9561e+00,  2.3518e+00,  1.4118e+00, -1.0623e+00,\n",
      "          -2.0780e+00, -1.7906e+00, -1.4467e+00, -1.0500e+00, -1.2150e+00,\n",
      "          -1.5825e+00, -9.7320e-01, -1.3722e-01,  1.4873e-01,  3.2827e-01,\n",
      "           3.0418e-01,  5.9946e-02, -1.8714e-01, -8.4638e-01, -1.6225e+00]]])\n",
      "torch.Size([1, 1, 40])\n",
      "lol\n",
      "tensor([4])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for data,label in train_loader:\n",
    "    print(data)\n",
    "    print(data.shape)\n",
    "    print('lol')\n",
    "    print(label)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_dim=hidden_dim\n",
    "\n",
    "        # define an RNN with specified parameters\n",
    "        # batch_first means that the first dim of the input and output will be the batch_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)\n",
    "        \n",
    "        # last, fully-connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "        self.ls = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # x (batch_size, seq_length, input_size)\n",
    "        # hidden (n_layers, batch_size, hidden_dim)\n",
    "        # r_out (batch_size, time_step, hidden_size)\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # get RNN outputs\n",
    "        r_out, hidden = self.rnn(x, hidden)\n",
    "        # shape output to be (batch_size*seq_length, hidden_dim)\n",
    "        r_out = r_out.view(-1, self.hidden_dim)  \n",
    "        \n",
    "        # get final output \n",
    "        output = self.ls(self.fc(r_out))\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 40 \n",
    "output_size = 10\n",
    "hidden_dim = 256\n",
    "n_layers = 3\n",
    "rnn = RNN(input_size, output_size, hidden_dim, n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (rnn): RNN(40, 256, num_layers=3, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (ls): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_on_gpu=torch.cuda.is_available()\n",
    "if train_on_gpu:\n",
    "    rnn.cuda()\n",
    "rnn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the RNN\n",
    "def train(rnn, n_steps, print_every):\n",
    "    \n",
    "    # initialize the hidden state\n",
    "         \n",
    "    hidden = None \n",
    "    for data, label in train_loader:\n",
    "            \n",
    "        inputs = data\n",
    "        labels = label       \n",
    "        \n",
    "#         # defining the training data \n",
    "#         time_steps = np.linspace(step * np.pi, (step+1)*np.pi, seq_length + 1)\n",
    "#         data = np.sin(time_steps)\n",
    "#         data.resize((seq_length + 1, 1)) # input_size=1\n",
    "\n",
    "#         x = data[:-1]\n",
    "#         y = data[1:]\n",
    "        \n",
    "        # convert data into Tensors\n",
    "#         x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension\n",
    "#         y_tensor = torch.Tensor(y)\n",
    "\n",
    "        inputs = inputs#.unsqueeze(0)\n",
    "        \n",
    "        print(inputs.shape)\n",
    "        \n",
    "        if True:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "#         print(inputs)\n",
    "#         print(inputs.shape)\n",
    "#         print(labels.shape)\n",
    "\n",
    "            \n",
    "        \n",
    "        # outputs from the rnn\n",
    "        prediction, hidden = rnn(inputs, hidden)\n",
    "\n",
    "        \n",
    "#         print(\"yes\")\n",
    "        ## Representing Memory ##\n",
    "        # make a new variable for hidden and detach the hidden state from its history\n",
    "        # this way, we don't backpropagate through the entire history\n",
    "        hidden = hidden.data\n",
    "\n",
    "#         print(prediction)\n",
    "#         print(labels.unsqueeze(0))\n",
    "        # calculate the loss\n",
    "        \n",
    "        print(prediction)\n",
    "        print(labels)\n",
    "        \n",
    "        loss = criterion(prediction, labels)\n",
    "        \n",
    "                \n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        # perform backprop and update weights\n",
    "        loss.backward()\n",
    "               \n",
    "#         rnn.to(\"cpu\")\n",
    "        \n",
    "        optimizer.step()\n",
    "       \n",
    "               \n",
    "        # display loss and predictions\n",
    "                \n",
    "        print('Loss: ', loss.item())\n",
    "#         plt.plot(time_steps[1:], x, 'r.') # input\n",
    "#         plt.plot(time_steps[1:], prediction.data.numpy().flatten(), 'b.') # predictions\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    return rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4502, -2.1462, -2.2434, -2.4633, -2.2896, -2.2039, -2.2474, -2.3628,\n",
      "         -2.1812, -2.5117]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.289579391479492\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8502, -3.4522, -3.0067, -3.2595, -0.5192, -3.2235, -3.3929, -2.9086,\n",
      "         -3.3285, -2.7519]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.0067389011383057\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2307, -6.5855, -0.0238, -5.6007, -8.3608, -5.8805, -5.8269, -5.7966,\n",
      "         -5.4454, -5.7547]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.023820992559194565\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.2947e+00, -7.4205e+00, -8.3279e-03, -6.4084e+00, -9.9224e+00,\n",
      "         -6.9620e+00, -7.1857e+00, -6.6501e+00, -6.5865e+00, -6.9683e+00]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.922446250915527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1931, -5.7223, -0.0362, -5.6574, -5.3308, -5.8637, -5.3045, -5.2132,\n",
      "         -5.3053, -5.5942]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.036234039813280106\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8942, -5.5150, -0.0572, -5.6528, -3.9938, -5.6704, -5.0594, -5.0014,\n",
      "         -5.2124, -5.3262]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.515012264251709\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3796, -1.8699, -0.4740, -4.5360, -2.2154, -4.1021, -3.8863, -3.7445,\n",
      "         -4.2421, -4.1394]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.536027431488037\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2022, -0.5915, -2.0266, -2.3997, -1.8971, -4.4113, -4.3023, -4.4759,\n",
      "         -4.6876, -4.3635]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.302254676818848\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7280, -0.7703, -3.8526, -1.2590, -2.1329, -5.3135, -2.4522, -5.5607,\n",
      "         -5.6171, -5.0925]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.092512607574463\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6562, -1.4363, -5.1151, -0.9637, -2.2640, -6.4753, -1.4561, -6.4106,\n",
      "         -6.5633, -3.5226]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.522556781768799\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5820, -2.3282, -6.3033, -1.2916, -2.7390, -7.3922, -0.9692, -7.2828,\n",
      "         -7.4152, -1.7228]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.303309917449951\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.7027, -3.4314, -6.6144, -1.9935, -3.3454, -8.5502, -1.2792, -8.4007,\n",
      "         -8.5282, -0.6626]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.550196647644043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.7503, -4.2663, -6.8978, -2.6664, -3.8012, -7.4010, -1.9355, -9.3530,\n",
      "         -9.3260, -0.2906]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.801204204559326\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.4617, -4.6239, -6.8440, -2.9736, -2.8011, -6.0958, -2.3167, -9.9121,\n",
      "         -9.7988, -0.2533]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.91208553314209\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.7370, -4.7445, -6.4732, -3.0685, -1.7602, -4.7027, -2.4202, -8.2616,\n",
      "         -9.9959, -0.3961]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.39613771438598633\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.2298,  -5.1079,  -6.3821,  -3.4517,  -1.2246,  -3.6981,  -2.8571,\n",
      "          -7.0130, -10.4202,  -0.5387]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.10790491104126\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.5207,  -4.3643,  -6.1433,  -3.6781,  -0.8486,  -2.6615,  -3.1596,\n",
      "          -5.7260, -10.6495,  -0.8765]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.8764677047729492\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.9001,  -3.8149,  -6.0430,  -4.0267,  -0.9895,  -1.9266,  -3.5977,\n",
      "          -4.6769, -10.9728,  -0.9073]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.9072830677032471\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.3731,  -3.4621,  -6.0815,  -4.4916,  -1.5469,  -1.5780,  -4.1553,\n",
      "          -3.8640, -11.3949,  -0.6948]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.4621450901031494\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.7155,  -2.4200,  -6.0302,  -4.8393,  -2.1379,  -1.4388,  -4.5923,\n",
      "          -3.0645, -11.6911,  -0.7158]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.7157653570175171\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.2366,  -1.7456,  -6.1948,  -5.3741,  -2.9820,  -1.8157,  -5.2112,\n",
      "          -2.6084, -12.1701,  -0.6420]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.81569242477417\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.8105,  -1.3595,  -6.4457,  -5.9660,  -3.8923,  -1.3867,  -5.8805,\n",
      "          -2.3912, -12.7058,  -0.9823]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.8922839164733887\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.2645,  -1.1281,  -6.6068,  -6.4392,  -3.8429,  -1.1805,  -6.4247,\n",
      "          -2.2478, -13.1250,  -1.4372]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.1804925203323364\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.8943,  -1.3690,  -6.9709,  -7.0885,  -4.0300,  -0.6334,  -7.1386,\n",
      "          -2.4756, -13.7232,  -2.2037]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.138585090637207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.2882,  -1.5908,  -7.1235,  -7.5010,  -4.0339,  -0.4446,  -6.6015,\n",
      "          -2.6166, -14.0883,  -2.7860]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.501034736633301\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.3023,  -1.5941,  -6.9185,  -6.5409,  -3.7061,  -0.4537,  -5.7688,\n",
      "          -2.4994, -14.0762,  -3.0082]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.0082104206085205\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.0505,  -1.4780,  -6.4677,  -5.4027,  -3.1613,  -0.6607,  -4.7485,\n",
      "          -2.2399, -13.8004,  -2.3878]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.239860773086548\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.9451,  -1.6596,  -6.1823,  -4.4940,  -2.8216,  -1.3284,  -3.9510,\n",
      "          -1.1479, -13.6732,  -1.9981]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.493998050689697\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.0463,  -2.1595,  -6.1212,  -3.1669,  -2.7557,  -2.3202,  -3.4403,\n",
      "          -0.6943, -13.7547,  -1.9173]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.320235252380371\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.1383,  -2.6992,  -6.0670,  -1.9918,  -2.7453,  -2.5241,  -3.0058,\n",
      "          -0.7883, -13.8287,  -1.9275]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  14.138328552246094\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.6104,  -3.2384,  -6.0171,  -1.0324,  -2.7845,  -2.7617,  -2.6561,\n",
      "          -1.2941, -13.8936,  -2.0185]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.656148910522461\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.4115,  -3.9524,  -6.1668,  -0.6542,  -3.0630,  -3.2149,  -1.7861,\n",
      "          -2.1981, -14.1460,  -2.3720]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.0630416870117188\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.3372,  -4.6354,  -6.3229,  -0.7535,  -2.6294,  -3.6736,  -1.1576,\n",
      "          -3.1433, -14.3938,  -2.7671]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.7671103477478027\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.2957,  -5.2022,  -6.4036,  -1.1451,  -2.2244,  -4.0464,  -0.7984,\n",
      "          -3.9827, -14.5566,  -2.5226]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2.522555351257324\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.2767,  -5.6524,  -6.4082,  -1.6727,  -1.8657,  -4.3281,  -0.7856,\n",
      "          -4.6949, -14.6345,  -1.7495]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  8.276700973510742\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4699,  -6.0135,  -6.3621,  -2.2451,  -1.6035,  -4.5424,  -1.0933,\n",
      "          -5.3008, -14.6537,  -1.0894]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.0893592834472656\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1320,  -6.6499,  -6.6273,  -3.1544,  -1.8225,  -5.0511,  -1.9460,\n",
      "          -6.1633, -14.9770,  -0.4528]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.132018566131592\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2999,  -7.2647,  -6.9042,  -4.0503,  -2.1785,  -5.5532,  -2.8720,\n",
      "          -6.9849, -15.3055,  -0.2621]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.984899520874023\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5678,  -7.7262,  -7.0585,  -4.7811,  -2.4905,  -5.9145,  -3.6629,\n",
      "          -6.6935, -15.5058,  -0.4015]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.781094074249268\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4780,  -8.4275,  -7.4805,  -4.9493,  -3.1192,  -6.5262,  -4.6851,\n",
      "          -6.7102, -15.9690,  -1.1519]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.1519434452056885\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2590,  -9.2104,  -8.0095,  -5.2520,  -3.8704,  -7.2286,  -5.7678,\n",
      "          -6.8709, -16.5351,  -1.6259]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  9.210386276245117\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2473,  -8.6369,  -7.9897,  -5.0297,  -4.0689,  -7.3667,  -6.2540,\n",
      "          -6.5164, -16.5485,  -1.6562]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.516354084014893\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3769,  -7.6495,  -7.5062,  -4.3668,  -3.7975,  -7.0272,  -6.2324,\n",
      "          -4.9714, -16.0952,  -1.3165]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.649529933929443\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7304,  -5.8380,  -6.8160,  -3.5229,  -3.3183,  -6.4684,  -5.9631,\n",
      "          -3.3199, -15.4323,  -0.8959]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.9630866050720215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4118,  -4.2173,  -6.2195,  -2.8230,  -2.9547,  -6.0018,  -4.9120,\n",
      "          -1.8617, -14.8730,  -0.7705]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.911951065063477\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4526,  -3.0179,  -5.9579,  -2.5722,  -2.9950,  -5.8983,  -3.5262,\n",
      "          -0.8851, -14.6975,  -1.2337]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.5721864700317383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7950,  -2.2943,  -6.0296,  -1.9196,  -3.3237,  -6.0681,  -2.6342,\n",
      "          -0.7187, -14.7846,  -2.0391]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.0391483306884766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1201,  -1.7982,  -6.1845,  -1.5213,  -3.7398,  -6.3113,  -1.9640,\n",
      "          -1.0486, -14.9506,  -2.3899]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.389859676361084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.3803,  -1.5217,  -6.3784,  -1.3724,  -4.1892,  -6.5849,  -1.5111,\n",
      "          -1.6759, -15.1526,  -2.2985]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.189199924468994\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.5075,  -1.4145,  -6.5369,  -1.4059,  -3.7899,  -6.8152,  -1.2471,\n",
      "          -2.3747, -15.3166,  -2.2467]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.3747384548187256\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4868,  -1.4538,  -6.6368,  -1.5728,  -3.3991,  -6.9799,  -1.1792,\n",
      "          -2.2482, -15.4201,  -2.2081]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.1792497634887695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.5127,  -1.8005,  -6.8648,  -2.0146,  -3.2063,  -7.2661,  -0.7557,\n",
      "          -2.3489, -15.6499,  -2.3654]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  15.649924278259277\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.3183,  -2.1134,  -6.9464,  -2.3892,  -2.9369,  -7.4002,  -0.5926,\n",
      "          -2.3865, -13.8790,  -2.4306]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.9464216232299805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.8323,  -2.2714,  -5.8777,  -2.5809,  -2.5172,  -7.3047,  -0.6245,\n",
      "          -2.2736, -12.0523,  -2.3181]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  12.052338600158691\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.1113,  -2.3058,  -4.7215,  -2.6248,  -2.0137,  -7.0306,  -0.8383,\n",
      "          -2.0628,  -9.3264,  -2.0800]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.7215471267700195\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.3135,  -2.3627,  -2.8626,  -2.6692,  -1.6148,  -6.7312,  -1.2776,\n",
      "          -1.9191,  -6.7995,  -1.8791]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.669179916381836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.7112,  -2.7016,  -1.4377,  -2.2235,  -1.6306,  -6.6746,  -2.0827,\n",
      "          -2.1178,  -4.7205,  -1.9928]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.6305506229400635\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.5322,  -3.5219,  -0.8131,  -2.3583,  -1.4680,  -7.0842,  -3.3610,\n",
      "          -2.8531,  -3.3049,  -2.6297]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.5218982696533203\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.3386,  -3.5829,  -0.6985,  -2.6117,  -1.5649,  -7.5178,  -4.6072,\n",
      "          -3.6276,  -2.1315,  -3.3082]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.582909345626831\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.0255,  -2.9344,  -0.9737,  -2.8514,  -1.7743,  -7.8669,  -5.7006,\n",
      "          -4.3070,  -1.1897,  -3.8993]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  14.02552604675293\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.7912,  -2.3385,  -1.4920,  -3.0675,  -2.0550,  -8.1393,  -6.6506,\n",
      "          -4.8898,  -0.7286,  -4.4023]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.3384647369384766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.5051,  -1.1517,  -2.0748,  -3.2255,  -2.3389,  -8.3134,  -7.4404,\n",
      "          -5.3515,  -0.8958,  -4.7922]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.2254927158355713\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.4002,  -0.4501,  -2.8629,  -2.8347,  -2.8291,  -8.6262,  -8.3122,\n",
      "          -5.9291,  -1.7179,  -5.3054]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.626241683959961\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.2931,  -0.2468,  -3.6148,  -2.5106,  -3.3106,  -8.0327,  -9.0917,\n",
      "          -6.4433,  -2.6757,  -5.7622]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.032740592956543\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.8261,  -0.2775,  -4.0375,  -1.9067,  -3.5021,  -6.3366,  -9.4710,\n",
      "          -6.5377,  -3.2240,  -5.8422]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.336637020111084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.1299,  -0.5216,  -4.1772,  -1.1963,  -3.4452,  -3.8715,  -9.5463,\n",
      "          -6.3471,  -3.4836,  -5.6477]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.5215730667114258\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.8228,  -0.7385,  -4.5516,  -1.0994,  -3.6473,  -2.0280,  -9.8958,\n",
      "          -6.5040,  -4.1223,  -5.7634]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.7384971380233765\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.9543,  -1.0115,  -5.3103,  -1.6666,  -4.2624,  -0.8681, -10.6226,\n",
      "          -7.0575,  -5.1326,  -6.2803]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  11.954307556152344\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.4939,  -1.6719,  -6.1848,  -2.5023,  -5.0138,  -0.3311, -11.4616,\n",
      "          -7.7405,  -6.2367,  -6.9325]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.184848308563232\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.8542,  -2.1688,  -5.9152,  -3.0972,  -5.4803,  -0.1842, -12.0043,\n",
      "          -8.1406,  -7.0228,  -7.3021]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  10.85418701171875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.0744,  -2.2461,  -5.1857,  -3.2220,  -5.4893,  -0.1711, -12.0054,\n",
      "          -8.0130,  -7.2831,  -7.2185]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.185667991638184\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0182,  -1.9364,  -3.3414,  -2.9165,  -5.0570,  -0.2793, -11.5542,\n",
      "          -7.4462,  -7.0702,  -6.6995]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.070170879364014\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0466,  -1.5794,  -1.5671,  -2.5136,  -4.4737,  -0.7364, -11.0150,\n",
      "          -6.8033,  -5.5060,  -6.0350]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.5670688152313232\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1786,  -2.3038,  -0.3135,  -3.1242,  -4.8689,  -2.3748, -11.4404,\n",
      "          -7.1357,  -5.0070,  -6.3481]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.868945121765137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7595,  -3.3820,  -0.1115,  -4.0675,  -4.7591,  -4.2785, -12.1820,\n",
      "          -7.7937,  -4.9185,  -6.9889]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.11147049069404602\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6084,  -4.5922,  -0.0615,  -5.1463,  -4.8772,  -6.2237, -13.0648,\n",
      "          -8.6010,  -5.0577,  -7.7810]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.877203941345215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8855,  -5.0892,  -0.1093,  -5.5218,  -3.6410,  -7.3815, -13.2583,\n",
      "          -8.7266,  -4.5845,  -7.8924]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.892448425292969\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8457,  -5.1266,  -0.3722,  -5.4430,  -2.1426,  -8.0193, -13.0213,\n",
      "          -8.4322,  -3.7392,  -6.9625]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.443027019500732\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0665,  -5.2751,  -1.3242,  -4.6942,  -1.1234,  -8.7413, -12.9504,\n",
      "          -8.3392,  -3.0381,  -6.2061]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  12.950410842895508\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0634,  -5.7648,  -2.5568,  -4.4110,  -0.6860,  -9.7088, -12.4153,\n",
      "          -8.5448,  -2.8944,  -5.9061]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.556755542755127\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2186,  -6.0986,  -2.9193,  -4.0519,  -0.5787, -10.4733, -11.8185,\n",
      "          -8.6191,  -2.7194,  -5.5243]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  10.473336219787598\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2935,  -6.1072,  -2.9880,  -3.4444,  -0.6207, -10.1616, -10.9826,\n",
      "          -8.3913,  -2.3459,  -4.8855]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.2934792041778564\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8289,  -6.1457,  -3.1128,  -2.9478,  -1.0937,  -9.9085, -10.2546,\n",
      "          -8.2142,  -2.1537,  -4.3408]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.145701885223389\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6460, -5.4084, -3.1603, -2.4433, -1.6788, -9.5841, -9.5001, -7.9590,\n",
      "         -2.0269, -3.7606]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.58408260345459\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7158, -4.5869, -3.0752, -1.8970, -2.1935, -8.4727, -8.6601, -7.5715,\n",
      "         -1.9170, -3.0931]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.571485996246338\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0241, -3.7357, -2.9152, -1.4050, -2.6310, -7.3521, -7.7854, -6.2079,\n",
      "         -1.8841, -2.4034]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.6309545040130615\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6008, -3.0156, -2.8415, -1.1856, -2.3355, -6.3727, -7.0283, -5.0094,\n",
      "         -2.0758, -1.8718]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.075822114944458\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4667, -2.5917, -3.0093, -1.4191, -2.3348, -5.6813, -6.5379, -4.1249,\n",
      "         -1.4041, -1.6844]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.404142141342163\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8190, -2.7645, -3.7000, -2.3236, -2.9115, -5.5626, -6.6000, -3.8437,\n",
      "         -0.5213, -2.1401]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.52131187915802\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8658, -3.7704, -5.1483, -4.0252, -4.2804, -6.2635, -7.4632, -4.4146,\n",
      "         -0.1167, -3.4351]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.4632368087768555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0685, -4.0447, -5.8111, -4.9273, -4.8778, -6.2470, -6.8144, -4.2903,\n",
      "         -0.0744, -3.9763]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.814405918121338\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.3670, -3.5144, -5.6223, -4.9589, -4.6335, -5.4426, -4.7280, -3.3996,\n",
      "         -0.1305, -3.6878]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.367015838623047\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4190, -2.6039, -5.0025, -4.5417, -3.9684, -4.2660, -2.3947, -2.1732,\n",
      "         -0.4799, -2.9918]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.603930711746216\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1488, -1.7342, -5.0330, -4.7593, -3.9677, -3.7975, -0.9397, -1.7569,\n",
      "         -1.8914, -2.9820]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.9676883220672607\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4971, -1.6603, -5.6564, -5.5544, -3.8234, -3.9804, -0.5203, -2.1343,\n",
      "         -3.8893, -3.5983]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.823354959487915\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6967, -1.6084, -6.1064, -6.1603, -2.8987, -4.0425, -0.4844, -2.4710,\n",
      "         -5.5985, -4.0579]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.48439669609069824\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0954, -1.9177, -6.7324, -6.9276, -2.3187, -4.3282, -0.3820, -3.0731,\n",
      "         -7.3656, -4.7026]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.927576541900635\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.1630, -2.0061, -7.0059, -6.5323, -1.5714, -4.3024, -0.5113, -3.3684,\n",
      "         -8.6715, -4.9985]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.532288551330566\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0717, -2.0271, -7.1010, -5.2945, -0.8939, -4.1357, -0.9144, -3.5156,\n",
      "         -9.7002, -5.1177]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.027118682861328\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0557,  -1.5174,  -7.2536,  -4.2443,  -0.6463,  -4.0624,  -1.6353,\n",
      "          -3.7434, -10.6970,  -5.2958]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.697006225585938\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.9535,  -1.1188,  -7.3038,  -3.2166,  -0.7127,  -3.9201,  -2.3411,\n",
      "          -3.8841, -10.6124,  -5.3719]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.303796768188477\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.7477,  -0.8694,  -6.5205,  -2.2034,  -1.0079,  -3.6918,  -2.9364,\n",
      "          -3.9174, -10.4218,  -5.3299]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.6918251514434814\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.5449,  -0.9137,  -5.7953,  -1.3539,  -1.5159,  -2.7818,  -3.4965,\n",
      "          -3.9495, -10.2318,  -5.2778]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.277790069580078\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4181,  -1.2827,  -5.1971,  -0.8409,  -2.1873,  -2.0581,  -4.0815,\n",
      "          -4.0531, -10.1156,  -4.6063]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.8408645391464233\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.7436,  -2.2443,  -5.0988,  -0.3892,  -3.3139,  -1.9336,  -5.0621,\n",
      "          -4.6029, -10.4494,  -4.4446]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.9336333274841309\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0182,  -3.1663,  -4.9936,  -0.4808,  -4.3386,  -1.2166,  -5.9332,\n",
      "          -5.0895, -10.7307,  -4.2857]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.933225154876709\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.1305,  -3.8925,  -4.7665,  -0.8870,  -5.1381,  -0.6405,  -5.8388,\n",
      "          -5.3988, -10.8482,  -4.0145]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.6405317783355713\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.6320,  -4.9629,  -4.9668,  -1.9560,  -6.2648,  -0.1954,  -6.1549,\n",
      "          -6.0826, -11.3539,  -4.1812]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.632012367248535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0511,  -5.6642,  -4.8813,  -2.7556,  -7.0136,  -0.1022,  -6.1706,\n",
      "          -6.4317, -11.5396,  -4.0709]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.755567789077759\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.0639,  -5.8384,  -4.3472,  -2.3237,  -7.2290,  -0.1643,  -5.7239,\n",
      "          -6.2865, -11.2451,  -3.5206]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.7239460945129395\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7984,  -5.6235,  -3.4992,  -1.6293,  -7.0497,  -0.3943,  -4.2403,\n",
      "          -5.7825, -10.6042,  -2.6691]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.60416030883789\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6328, -5.4041, -2.7274, -1.1162, -6.8607, -1.0012, -2.8813, -5.3024,\n",
      "         -9.1508, -1.9207]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.1161876916885376\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1125, -5.7221, -2.5917, -0.6820, -7.2037, -2.2972, -2.2060, -5.3865,\n",
      "         -8.3498, -1.8609]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.6820458173751831\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1355, -6.4705, -2.9840, -0.3985, -7.9730, -3.9929, -2.1338, -5.9259,\n",
      "         -8.0843, -2.3763]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.1338047981262207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0895, -7.0475, -3.2762, -0.5251, -8.5681, -5.4373, -1.3578, -6.3155,\n",
      "         -7.7436, -2.8078]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.5251082181930542\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3080, -7.7939, -3.7932, -0.5766, -9.3303, -6.9703, -1.0645, -6.8937,\n",
      "         -7.6600, -3.4653]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.793936729431152\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2774, -7.5024, -4.0207, -0.7637, -9.7624, -8.0998, -0.7891, -7.1604,\n",
      "         -7.3277, -3.8253]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.762392044067383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0257, -6.9853, -3.9862, -1.0041, -9.1532, -8.8672, -0.6098, -7.1483,\n",
      "         -6.7739, -3.9125]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.985278606414795\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5705, -5.5796, -3.7029, -1.2096, -8.3362, -9.2947, -0.5636, -6.8716,\n",
      "         -6.0078, -3.7396]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.5635845065116882\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3965, -4.4876, -3.6424, -1.7789, -7.7742, -9.8576, -0.3944, -6.7986,\n",
      "         -5.4938, -3.7772]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.3943589925765991\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5457,  -3.7418,  -3.8424,  -2.6454,  -7.5007, -10.6008,  -0.2465,\n",
      "          -6.9669,  -5.2669,  -4.0626]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.266940593719482\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3977,  -2.7361,  -3.6889,  -3.1290,  -6.9034, -10.9221,  -0.3090,\n",
      "          -6.7740,  -3.8870,  -3.9815]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  6.903388977050781\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1421,  -1.6774,  -3.3766,  -3.4031,  -5.4546, -11.0191,  -0.6671,\n",
      "          -6.4049,  -2.4633,  -3.7291]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.6773784160614014\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5022,  -0.6703,  -3.6168,  -4.1701,  -4.6438, -11.6024,  -1.8296,\n",
      "          -6.5686,  -1.7449,  -4.0146]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.6438188552856445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2064,  -0.4292,  -4.1669,  -5.1860,  -3.5472, -12.4413,  -3.3008,\n",
      "          -7.0297,  -1.5572,  -4.5977]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.5571866035461426\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9857,  -0.7691,  -4.7858,  -6.2178,  -2.6860, -13.3090,  -4.7652,\n",
      "          -7.5569,  -0.8553,  -5.2419]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.217793941497803\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6749,  -1.3599,  -5.3214,  -6.4082,  -1.9261, -14.0628,  -6.0641,\n",
      "          -8.0034,  -0.5516,  -5.7975]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.797530651092529\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1654,  -1.9273,  -5.6693,  -6.4413,  -1.2046, -14.6039,  -7.0996,\n",
      "          -8.2673,  -0.6191,  -5.4263]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.2045766115188599\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.9156,  -2.8410,  -6.2886,  -6.7745,  -0.3712, -15.3951,  -8.3381,\n",
      "          -8.8082,  -1.4226,  -5.3962]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.338082313537598\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6110,  -3.7217,  -6.8650,  -7.0916,  -0.1354, -16.1253,  -8.7770,\n",
      "          -9.3124,  -2.3598,  -5.3875]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  16.125301361083984\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.7919,  -4.0855,  -6.9380,  -6.9300,  -0.0900, -15.6479,  -8.7250,\n",
      "          -9.3194,  -2.8353,  -4.9343]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.7250394821167\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4046,  -3.8741,  -6.4531,  -6.2330,  -0.1150, -14.6647,  -7.4640,\n",
      "          -8.7741,  -2.7615,  -3.9784]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.9783897399902344\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6656,  -3.3070,  -5.6257,  -5.2141,  -0.3268, -13.3859,  -5.9343,\n",
      "          -7.8911,  -2.3565,  -2.0258]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.214117050170898\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.2740,  -3.0932,  -5.1543,  -3.8769,  -1.2515, -12.5035,  -4.8271,\n",
      "          -7.3669,  -2.3421,  -0.6308]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.3420584201812744\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4772,  -3.4843,  -5.2857,  -3.2357,  -2.8251, -12.2589,  -4.3846,\n",
      "          -7.4466,  -2.1388,  -0.3139]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.2357466220855713\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5572,  -3.7519,  -5.3015,  -1.9089,  -4.1789, -11.9307,  -3.8861,\n",
      "          -7.4121,  -1.9433,  -0.4467]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.178864479064941\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6579,  -4.0353,  -5.3451,  -0.8377,  -4.7590, -11.6593,  -3.4747,\n",
      "          -7.4068,  -1.9078,  -1.0419]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.657947063446045\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1132,  -4.4982,  -5.5827,  -0.3654,  -5.4830, -11.6083,  -3.3183,\n",
      "          -7.5969,  -2.1907,  -2.0213]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.582744121551514\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4689,  -4.7672,  -4.8359,  -0.2605,  -5.9828, -11.4053,  -3.0447,\n",
      "          -7.6123,  -2.3804,  -2.8429]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.767230033874512\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5591,  -3.9816,  -3.8301,  -0.3467,  -6.0987, -10.8846,  -2.4928,\n",
      "          -7.2895,  -2.2900,  -3.2892]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.34672942757606506\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9496,  -3.4732,  -3.1277,  -0.4155,  -6.3935, -10.6026,  -2.2395,\n",
      "          -7.1871,  -2.4800,  -3.9076]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.1871337890625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2448,  -2.8374,  -2.3306,  -0.7177,  -6.4627, -10.1498,  -1.8860,\n",
      "          -5.8132,  -2.5224,  -4.2825]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.282473564147949\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7260, -2.3323, -1.7185, -1.3404, -6.5546, -9.7691, -1.7000, -4.6037,\n",
      "         -2.6553, -3.9421]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.9420523643493652\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5161, -2.0518, -1.4207, -2.1838, -6.7464, -9.5329, -1.7664, -3.6297,\n",
      "         -2.9414, -3.0731]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.0731167793273926\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6207, -1.9969, -1.4583, -3.1288, -7.0284, -9.4276, -2.0532, -2.8868,\n",
      "         -3.3518, -1.7720]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.1287622451782227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0746, -2.2346, -1.8751, -3.5273, -7.4753, -9.5242, -2.5933, -2.4689,\n",
      "         -3.9433, -0.9035]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.475349426269531\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6951, -2.6287, -2.4814, -4.0103, -7.3217, -9.7151, -3.2371, -2.2885,\n",
      "         -4.5976, -0.4992]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.597555160522461\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1647, -2.8875, -2.9496, -4.3100, -7.0347, -9.7390, -3.6977, -2.0895,\n",
      "         -4.2245, -0.3972]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.0895421504974365\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6141, -3.1498, -3.4050, -4.5787, -6.7651, -9.7496, -4.1203, -0.9863,\n",
      "         -3.8885, -0.7427]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.1498396396636963\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1237, -2.7954, -3.9244, -4.9086, -6.6028, -9.8397, -4.5938, -0.4714,\n",
      "         -3.6821, -1.4493]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.4713588058948517\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1387,  -3.0589,  -4.9509,  -5.7523,  -6.9978, -10.4618,  -5.5696,\n",
      "          -0.1589,  -4.0572,  -2.7836]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.057171821594238\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4644,  -2.7337,  -5.2878,  -5.9203,  -6.7591, -10.4277,  -5.8575,\n",
      "          -0.1764,  -3.0273,  -3.4338]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.464427471160889\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4046, -1.9761, -5.0865, -5.5641, -6.0345, -9.8870, -5.6097, -0.4990,\n",
      "         -1.6261, -3.5329]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.4990067481994629\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9224, -1.8548, -5.3748, -5.7098, -5.8464, -9.8636, -5.8534, -0.8684,\n",
      "         -0.9838, -4.1067]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.8547656536102295\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5624, -1.2187, -5.6978, -5.9023, -5.7373, -9.9012, -6.1343, -1.6630,\n",
      "         -0.7640, -4.6949]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.13432502746582\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2104, -0.8011, -5.9416, -6.0273, -5.5901, -9.8844, -5.6296, -2.5118,\n",
      "         -0.8875, -5.1815]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.8011204600334167\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2110,  -0.3284,  -6.4483,  -6.4260,  -5.7439, -10.1535,  -5.4605,\n",
      "          -3.6410,  -1.6096,  -5.9090]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.6096372604370117\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1646,  -0.3245,  -6.8258,  -6.7059,  -5.8037, -10.3152,  -5.2295,\n",
      "          -4.6050,  -1.5481,  -6.4865]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.705915451049805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7908,  -0.4479,  -6.7998,  -5.9183,  -5.4917, -10.0933,  -4.6567,\n",
      "          -5.1173,  -1.2912,  -6.6410]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.491708755493164\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2458, -0.7292, -6.5170, -4.9487, -4.2842, -9.6327, -3.8860, -5.3257,\n",
      "         -1.0145, -6.5214]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.9486541748046875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7405, -1.2016, -6.1589, -3.3235, -3.0990, -9.1128, -3.1007, -5.4146,\n",
      "         -0.9436, -6.3102]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.323502540588379\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6320, -2.0262, -6.0338, -1.4466, -2.2557, -8.8398, -2.6204, -5.6957,\n",
      "         -1.3784, -6.3173]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.620366096496582\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3490, -3.5063, -6.5692, -0.5530, -2.2115, -9.2397, -2.1832, -6.5992,\n",
      "         -2.6132, -6.9712]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.5530171394348145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7872,  -5.5715,  -7.7621,  -0.1825,  -2.9544, -10.3091,  -2.5767,\n",
      "          -8.1246,  -4.4939,  -8.2706]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.18246155977249146\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4294,  -7.7627,  -9.1635,  -0.0636,  -3.9846, -11.5986,  -3.3099,\n",
      "          -9.8261,  -6.5248,  -9.7679]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.826132774353027\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.3805,  -9.2059,  -9.8933,  -0.0472,  -4.3919, -12.2273,  -3.4622,\n",
      "          -9.8572,  -7.8241, -10.5842]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.462226390838623\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.7066,  -9.9751, -10.0183,  -0.1130,  -4.2341, -12.2610,  -2.3996,\n",
      "          -9.3512,  -8.4635, -10.7874]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  9.975086212158203\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6760,  -9.6542,  -9.8050,  -0.4045,  -3.7754, -11.9652,  -1.1776,\n",
      "          -8.5682,  -8.7149, -10.6446]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.568177223205566\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.7659,  -9.4811,  -9.7289,  -1.1948,  -3.4935, -11.8145,  -0.4086,\n",
      "          -7.0752,  -9.0584, -10.6321]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.075232028961182\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8514,  -9.3281,  -9.6635,  -2.0989,  -3.2633, -11.6818,  -0.1860,\n",
      "          -4.8906,  -9.3720, -10.6242]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  11.681835174560547\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6067,  -8.8671,  -9.2817,  -2.6686,  -2.7592, -10.4742,  -0.2339,\n",
      "          -2.6019,  -9.3324, -10.2942]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.6018776893615723\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.9864,  -9.0505,  -9.5365,  -3.8259,  -2.9477,  -9.9834,  -1.4084,\n",
      "          -0.3857,  -9.8961, -10.5957]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  9.896087646484375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.3727, -10.2588, -10.8093,  -5.9271,  -4.1973, -10.5830,  -3.6768,\n",
      "          -0.0443, -10.6541, -11.9106]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.04431624710559845\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.9319e+00, -1.1657e+01, -1.2266e+01, -8.1331e+00, -5.6433e+00,\n",
      "         -1.1432e+01, -6.0493e+00, -6.2970e-03, -1.1646e+01, -1.3405e+01]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  11.43162727355957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0501e+01, -1.2081e+01, -1.2742e+01, -9.2864e+00, -6.1127e+00,\n",
      "         -1.0619e+01, -7.3543e+00, -3.0213e-03, -1.1703e+01, -1.3916e+01]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  11.702515602111816\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0200e+01, -1.1649e+01, -1.2358e+01, -9.5131e+00, -5.7236e+00,\n",
      "         -9.0719e+00, -7.7185e+00, -3.9986e-03, -1.0180e+01, -1.3562e+01]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.723583698272705\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.1732, -10.5034, -11.2550,  -8.9623,  -3.9261,  -6.9192,  -7.2920,\n",
      "          -0.0222,  -8.0498, -12.4876]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.919164657592773\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.7064,  -8.9296,  -9.7199,  -7.9254,  -1.7774,  -3.7196,  -6.3677,\n",
      "          -0.2229,  -5.5873, -10.9778]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.925384998321533\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0193,  -8.1455,  -8.9706,  -6.9886,  -0.5923,  -1.4857,  -6.1711,\n",
      "          -1.6195,  -4.0037, -10.2513]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.970617294311523\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.3785,  -8.4166,  -8.3861,  -7.1223,  -0.8872,  -0.6182,  -6.9738,\n",
      "          -4.0073,  -3.5672, -10.5743]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.5671746730804443\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.8102,  -8.7684,  -7.9654,  -7.3503,  -1.5456,  -0.3490,  -7.8060,\n",
      "          -6.2836,  -2.5567, -10.9727]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  10.972688674926758\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.9986,  -8.8843,  -7.3843,  -7.3549,  -2.0859,  -0.4294,  -8.3558,\n",
      "          -8.1381,  -1.5023, -10.4118]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.138142585754395\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.1013, -8.9214, -6.7925, -7.2917, -2.5924, -0.9093, -8.7845, -8.9583,\n",
      "         -0.6544, -9.8377]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.921360969543457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.1857, -8.2531, -6.2508, -7.2265, -3.0931, -1.6258, -9.1631, -9.6902,\n",
      "         -0.2818, -9.3110]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.2818010747432709\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.5949,  -7.9830,  -6.0963,  -7.5009,  -3.9097,  -2.7484,  -9.8377,\n",
      "         -10.6837,  -0.0917,  -9.1684]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  9.837688446044922\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4142,  -7.1891,  -5.4086,  -7.1988,  -4.1107,  -3.2583,  -9.1973,\n",
      "         -11.0304,  -0.0633,  -8.4895]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  9.197253227233887\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.6239,  -5.8456,  -4.1645,  -6.2990,  -3.6761,  -3.1193,  -7.3190,\n",
      "         -10.7158,  -0.0961,  -7.2493]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.16446590423584\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.5284,  -4.2523,  -1.8080,  -5.1056,  -2.9193,  -2.6439,  -5.2416,\n",
      "         -10.0493,  -0.3847,  -5.7480]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.528439521789551\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.2563,  -3.4429,  -0.4447,  -4.6509,  -2.8930,  -2.8858,  -3.9887,\n",
      "         -10.0664,  -1.7383,  -5.0137]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.988654136657715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5846,  -3.2068,  -0.2553,  -4.7186,  -3.3805,  -3.6174,  -2.6838,\n",
      "         -10.5539,  -3.5573,  -4.8279]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.718615531921387\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7845,  -2.8191,  -0.5487,  -3.9429,  -3.6416,  -4.0945,  -1.3490,\n",
      "         -10.7906,  -5.0165,  -4.4628]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.094462871551514\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2849,  -2.7136,  -1.5019,  -3.4571,  -4.0980,  -3.9994,  -0.5232,\n",
      "         -11.2063,  -6.5403,  -4.3437]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.343735694885254\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0043,  -2.8015,  -2.6862,  -3.1750,  -4.6578,  -4.0629,  -0.3187,\n",
      "         -11.7176,  -8.0528,  -3.6613]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.0629143714904785\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5858,  -2.7137,  -3.6025,  -2.7368,  -4.9594,  -3.2090,  -0.4137,\n",
      "         -11.9685,  -9.2076,  -2.8535]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  11.968465805053711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1391,  -2.5436,  -4.3147,  -2.2451,  -5.0984,  -2.3292,  -0.8001,\n",
      "         -11.2972, -10.1117,  -2.0283]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.3292179107666016\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1081,  -2.7102,  -5.2325,  -2.1338,  -5.4920,  -1.1718,  -1.7091,\n",
      "         -10.9551, -11.1915,  -1.6436]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.1337926387786865\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5390,  -3.2554,  -6.4124,  -1.8174,  -6.1972,  -0.6959,  -2.9965,\n",
      "         -10.9932, -12.5129,  -1.7852]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  10.993173599243164\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9505,  -3.7248,  -7.4283,  -1.5863,  -6.7846,  -0.5728,  -4.1412,\n",
      "         -10.2440, -13.6551,  -1.9860]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.9859607219696045\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2795,  -4.0750,  -8.2548,  -1.4192,  -7.2248,  -0.7706,  -5.0942,\n",
      "          -9.4771, -14.5951,  -1.4544]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.279493570327759\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6256,  -4.3206,  -8.9182,  -1.3423,  -7.5398,  -1.1917,  -5.8755,\n",
      "          -8.7022, -15.3607,  -1.0621]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.702211380004883\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0204,  -4.4714,  -9.4364,  -1.3615,  -7.7439,  -1.7043,  -6.5021,\n",
      "          -7.2095, -15.9711,  -0.8794]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.7042620182037354\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5903,  -4.6118,  -9.9001,  -1.5409,  -7.9243,  -1.5880,  -7.0644,\n",
      "          -5.8588, -16.5179,  -1.0118]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.59029221534729\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7085,  -4.9497, -10.5226,  -2.0458,  -8.2915,  -1.8297,  -7.7765,\n",
      "          -4.8459, -17.2153,  -1.5983]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.598341703414917\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4763,  -5.3809, -11.2055,  -2.7064,  -8.7440,  -2.2808,  -8.5404,\n",
      "          -4.0586, -17.9657,  -1.6729]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  17.965747833251953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5042,  -5.4615, -11.5098,  -3.0343,  -8.8405,  -2.4475,  -8.9181,\n",
      "          -3.0490, -17.5899,  -1.5633]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  17.589859008789062\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7921,  -5.2768, -11.5239,  -3.1010,  -8.6672,  -2.3981,  -8.9984,\n",
      "          -1.9126, -16.2780,  -1.3544]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.354400396347046\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6803,  -5.3541, -11.7768,  -3.4311,  -8.7512,  -2.6578,  -9.3112,\n",
      "          -1.2374, -15.3344,  -0.8768]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.2374423742294312\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0620,  -5.8473, -12.4250,  -4.1700,  -9.2470,  -3.3613, -10.0134,\n",
      "          -0.5316, -14.9027,  -1.1635]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.1635072231292725\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4882,  -6.4333, -13.1487,  -4.9859,  -9.8333,  -4.1596, -10.7860,\n",
      "          -0.4722, -14.6520,  -1.0760]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  14.651966094970703\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4568,  -6.6350, -13.4735,  -5.3983, -10.0341,  -4.5628, -11.1548,\n",
      "          -0.5493, -13.3997,  -0.9111]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  11.1548490524292\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.0032,  -6.4868, -13.4354,  -5.4423,  -9.8841,  -4.6028, -10.4740,\n",
      "          -0.7072, -11.9384,  -0.7163]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.602755546569824\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.1964,  -6.0521, -13.0989,  -5.1827,  -9.4467,  -3.6402,  -9.5576,\n",
      "          -0.9031, -10.3177,  -0.5830]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.317718505859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.0904,  -5.3795, -12.5131,  -4.6702,  -8.7700,  -2.5078,  -8.4486,\n",
      "          -1.0888,  -7.8900,  -0.5710]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.448593139648438\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8385,  -4.6178, -11.8263,  -4.0557,  -8.0012,  -1.3851,  -6.6244,\n",
      "          -1.3400,  -5.5413,  -0.7937]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.3399608135223389\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8760,  -4.2002, -11.4688,  -3.7750,  -7.5699,  -0.8107,  -5.2414,\n",
      "          -1.2884,  -3.6869,  -1.5695]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.875997066497803\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1178,  -3.9115, -11.2230,  -3.6139,  -7.2580,  -0.6822,  -4.0738,\n",
      "          -1.5162,  -2.1083,  -2.4913]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.4912569522857666\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6216,  -3.8489, -11.1840,  -3.6695,  -7.1599,  -1.1025,  -3.2146,\n",
      "          -2.0619,  -0.9532,  -2.8534]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.21462082862854\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4795,  -4.1059, -11.4460,  -4.0340,  -7.3691,  -2.0109,  -2.1062,\n",
      "          -2.9431,  -0.4847,  -3.5174]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.1061973571777344\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6380,  -4.6273, -11.9594,  -4.6519,  -7.8353,  -3.2014,  -0.8179,\n",
      "          -4.0533,  -0.7785,  -4.4140]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.83528995513916\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0890,  -5.4047, -12.7222,  -5.5154,  -7.8015,  -4.6038,  -0.2516,\n",
      "          -5.3671,  -1.6678,  -5.5310]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.603759765625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3517,  -5.9601, -13.2608,  -6.1477,  -7.6218,  -5.0210,  -0.1119,\n",
      "          -6.4063,  -2.4538,  -6.3921]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.02099609375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1167,  -5.9870, -13.2706,  -6.2435,  -6.9839,  -4.2434,  -0.0966,\n",
      "          -6.8690,  -2.7478,  -6.6940]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.693965911865234\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4085,  -5.5118, -12.7781,  -5.8298,  -5.9076,  -3.0503,  -0.1637,\n",
      "          -6.7858,  -2.5571,  -5.7709]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.050320625305176\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6369,  -4.9429, -12.1905,  -5.3154,  -4.7953,  -1.1960,  -0.6149,\n",
      "          -6.5683,  -2.2970,  -4.7969]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.6148700714111328\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6708,  -5.1422, -12.3673,  -5.5616,  -4.5050,  -0.4362,  -1.4339,\n",
      "          -7.0802,  -2.8410,  -4.6309]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  12.367288589477539\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7395,  -5.3420, -11.6424,  -5.8020,  -4.2672,  -0.2074,  -2.3396,\n",
      "          -7.5581,  -3.3892,  -4.5034]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.558139324188232\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4617,  -5.1655, -10.6279,  -5.6603,  -3.7027,  -0.1865,  -2.8576,\n",
      "          -6.9000,  -3.5474,  -4.0355]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.899986267089844\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8369, -4.6087, -9.3106, -5.1330, -2.8105, -0.3126, -2.9597, -5.2011,\n",
      "         -3.3089, -3.2237]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.9597268104553223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2145, -4.0035, -8.0115, -4.5506, -1.9413, -0.7909, -2.3326, -3.5615,\n",
      "         -3.0093, -2.4085]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.941260814666748\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1983, -3.9202, -7.2881, -4.4809, -0.9570, -1.9653, -2.2767, -2.5509,\n",
      "         -3.2231, -2.1845]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.956977367401123\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0256, -4.6038, -7.3793, -5.1691, -0.3524, -3.8599, -3.0347, -2.4384,\n",
      "         -4.1879, -2.8046]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.37925386428833\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7067, -5.1198, -6.4814, -5.6854, -0.2370, -5.4745, -3.6405, -2.2910,\n",
      "         -4.9608, -3.2981]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.119750022888184\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9289, -4.4014, -5.2586, -5.7393, -0.3108, -6.5197, -3.7896, -1.8166,\n",
      "         -5.2490, -3.3552]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.78964900970459\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8634, -3.4794, -3.8765, -5.5067, -0.6327, -7.1801, -3.0216, -1.2226,\n",
      "         -5.2293, -3.1480]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.506678104400635\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8221, -2.6704, -2.6470, -4.6055, -1.3088, -7.7753, -2.3585, -0.8985,\n",
      "         -5.2144, -2.9903]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.35845947265625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0462, -2.2361, -1.8430, -4.0411, -2.3577, -8.5541, -1.4384, -1.1414,\n",
      "         -5.4465, -3.1255]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.046186447143555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5949, -2.1429, -1.4751, -3.7593, -3.5885, -9.4721, -0.9732, -1.8056,\n",
      "         -5.8742, -3.4939]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.805645227432251\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3034,  -2.2419,  -1.4403,  -3.6126,  -4.8107, -10.3915,  -0.8834,\n",
      "          -1.8946,  -6.3534,  -3.9393]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.810705661773682\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9141,  -2.2558,  -1.4631,  -3.3404,  -5.0185, -11.0623,  -0.9040,\n",
      "          -1.9236,  -6.6284,  -4.1962]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.628360271453857\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4518,  -2.1914,  -1.5325,  -2.9606,  -5.0517, -11.5084,  -1.0180,\n",
      "          -1.8955,  -5.9891,  -4.2798]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.1914262771606445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1267,  -1.4618,  -1.8044,  -2.6697,  -5.1018, -11.9262,  -1.3631,\n",
      "          -1.9934,  -5.4296,  -4.3806]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.3630520105361938\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0802,  -1.1246,  -2.3385,  -2.5969,  -5.2922, -12.4440,  -1.3473,\n",
      "          -2.3205,  -5.0690,  -4.6213]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.3473052978515625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2402,  -1.1635,  -2.9979,  -2.6746,  -5.5584, -13.0019,  -0.9645,\n",
      "          -2.7771,  -4.8390,  -4.9364]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.2401857376098633\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6121,  -1.4478,  -3.6448,  -2.8002,  -5.8083, -13.5120,  -0.8641,\n",
      "          -3.2409,  -4.6442,  -5.2327]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.8002169132232666\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1828,  -1.8487,  -4.2143,  -2.2214,  -5.9983, -13.9346,  -0.9986,\n",
      "          -3.6499,  -4.4380,  -5.4663]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.998330116271973\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9801,  -2.2482,  -4.6570,  -1.6908,  -5.3614, -14.2314,  -1.2647,\n",
      "          -3.9534,  -4.1762,  -5.5956]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  14.231352806091309\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0106,  -2.5760,  -4.9504,  -1.2269,  -4.6756, -13.7075,  -1.5658,\n",
      "          -4.1264,  -3.8367,  -5.6004]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.0106325149536133\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7012,  -3.1454,  -5.4359,  -1.2287,  -4.2781, -13.4494,  -2.1819,\n",
      "          -4.5086,  -3.7609,  -5.8218]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  13.449400901794434\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6373,  -3.4781,  -5.6633,  -1.2212,  -3.7151, -12.3417,  -2.5935,\n",
      "          -4.6469,  -3.4951,  -5.8090]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.646892070770264\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7708,  -3.5406,  -5.6097,  -1.1594,  -2.9632, -11.0807,  -2.7499,\n",
      "          -3.7933,  -3.0161,  -5.5379]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.5405619144439697\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1591, -2.7164, -5.4394, -1.1982, -2.1975, -9.8178, -2.8056, -2.9142,\n",
      "         -2.4951, -5.1709]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.197476387023926\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0108, -2.2592, -5.5250, -1.6798, -1.1026, -8.9140, -3.1293, -2.3957,\n",
      "         -2.3220, -5.0793]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.010819911956787\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3468, -2.2404, -5.9186, -2.5578, -0.6698, -8.4115, -3.7614, -2.3067,\n",
      "         -2.5519, -5.3140]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.6697801947593689\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1028, -2.6783, -6.6484, -3.7767, -0.3012, -8.3307, -4.7188, -2.6711,\n",
      "         -3.1900, -5.9016]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2.6782867908477783\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6016, -2.1426, -7.0870, -4.6714, -0.2862, -8.0371, -5.3669, -2.8292,\n",
      "         -3.5756, -6.2128]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.8291821479797363\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8067, -1.4813, -7.2154, -5.2170, -0.5418, -7.5044, -5.6866, -2.0297,\n",
      "         -3.6764, -6.2269]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.504415988922119\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9587, -1.0078, -7.2801, -5.6613, -1.1318, -6.3117, -5.9253, -1.3514,\n",
      "         -3.7347, -6.1894]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.311728000640869\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1372, -0.8861, -7.3642, -6.0896, -1.9169, -4.6175, -6.1674, -0.9517,\n",
      "         -3.8304, -6.1822]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.8304479122161865\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2347, -1.0146, -7.3636, -6.4004, -2.6522, -3.0187, -6.3100, -0.7927,\n",
      "         -3.1091, -6.1001]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.309979438781738\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2941, -1.3663, -7.3227, -6.6410, -3.3248, -1.5682, -5.7634, -0.9338,\n",
      "         -2.4509, -5.9869]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.641035079956055\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6016, -2.1202, -7.5287, -6.3907, -4.1994, -0.6411, -5.5146, -1.5849,\n",
      "         -2.1640, -6.1289]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.6411029100418091\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5667, -3.5712, -8.3942, -6.8453, -5.6781, -0.1735, -5.9719, -2.9984,\n",
      "         -2.6705, -6.9378]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.971915245056152\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2159, -4.6770, -8.9505, -7.0315, -6.7897, -0.0909, -5.5370, -4.0847,\n",
      "         -2.9547, -7.4435]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.950456619262695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2871, -5.1655, -8.0153, -6.6839, -7.2770, -0.1005, -4.6311, -4.5606,\n",
      "         -2.7341, -7.3841]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.015325546264648\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8669, -5.1244, -5.8099, -5.8852, -7.2310, -0.2054, -3.3340, -4.5112,\n",
      "         -2.0981, -6.8448]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.12436056137085\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2815, -4.1154, -3.6147, -4.9581, -6.9813, -0.6076, -1.9781, -4.2656,\n",
      "         -1.4083, -6.1504]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.4082989692687988\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3339, -3.7936, -2.2347, -4.7027, -7.3326, -1.8907, -1.4190, -4.6300,\n",
      "         -0.7963, -6.1017]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.702674865722656\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6846, -3.8193, -1.3827, -4.0751, -7.9485, -3.4437, -1.3700, -5.2588,\n",
      "         -0.8833, -6.3578]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.684609889984131\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1610, -3.8658, -0.8400, -3.5257, -8.5099, -4.8724, -1.5034, -5.8166,\n",
      "         -1.2817, -6.5954]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.160965919494629\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7557, -3.8099, -0.6534, -2.9437, -8.9046, -6.0476, -1.6242, -6.2629,\n",
      "         -1.7214, -6.7003]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.8098671436309814\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3704, -2.8837, -0.7978, -2.3114, -9.1185, -6.9705, -1.7319, -6.4968,\n",
      "         -2.1172, -6.6530]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.311429500579834\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4151, -2.3063, -1.5446, -1.3319, -9.5272, -8.0191, -2.1575, -6.9245,\n",
      "         -2.7801, -6.8270]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.1574807167053223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1065,  -2.2093,  -2.7565,  -0.9830, -10.2441,  -9.3134,  -2.3272,\n",
      "          -7.6591,  -3.7727,  -7.3330]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.756455421447754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0783,  -2.1770,  -2.9867,  -0.9043, -10.8625, -10.4524,  -2.5140,\n",
      "          -8.2938,  -4.6570,  -7.7616]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.078315019607544\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6433,  -2.3686,  -3.3733,  -1.2529, -11.5548, -11.6144,  -2.8685,\n",
      "          -9.0010,  -5.5964,  -8.2831]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.368556022644043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5762,  -1.7512,  -3.6374,  -1.6533, -12.0646, -12.5477,  -3.1098,\n",
      "          -9.5243,  -6.3317,  -8.6391]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.5761522054672241\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4137,  -1.5834,  -4.1570,  -2.4071, -12.7825, -13.6476,  -3.6141,\n",
      "         -10.2545,  -7.2544,  -9.2184]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.5834472179412842\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7539,  -0.7867,  -4.5781,  -3.0890, -13.3686, -14.5783,  -4.0247,\n",
      "         -10.8517,  -8.0258,  -9.6796]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.0889780521392822\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4116,  -0.3761,  -4.9326,  -3.0025, -13.8629, -15.3833,  -4.3722,\n",
      "         -11.3560,  -8.6873, -10.0613]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  11.35599136352539\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9452,  -0.2599,  -5.0001,  -2.7005, -14.0500, -15.8505,  -4.4350,\n",
      "         -10.8155,  -9.0254, -10.1468]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  9.025436401367188\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1374,  -0.3158,  -4.6608,  -2.0690, -13.8126, -15.8658,  -4.0932,\n",
      "          -9.9219,  -8.1696,  -9.8179]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  15.865822792053223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1055,  -0.5921,  -4.0614,  -1.2860, -13.2966, -14.9224,  -3.4938,\n",
      "          -8.8141,  -7.0960,  -9.2192]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  9.219210624694824\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1231,  -1.1856,  -3.4824,  -0.7197, -12.7772, -14.0167,  -2.9185,\n",
      "          -7.7608,  -6.0741,  -7.8505]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  14.016653060913086\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2160,  -1.9465,  -2.9660,  -0.5163, -12.2755, -12.4916,  -2.3931,\n",
      "          -6.7639,  -5.1122,  -6.5485]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.3931174278259277\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3884,  -2.7519,  -2.5491,  -0.7371, -11.8168, -11.0903,  -1.3255,\n",
      "          -5.8515,  -4.2391,  -5.3467]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.2391157150268555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7484,  -3.6116,  -2.3729,  -1.4139, -11.5504, -10.0256,  -0.6940,\n",
      "          -5.2000,  -2.8829,  -4.4679]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.7484054565429688\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4676,  -4.5739,  -2.4650,  -2.3604, -11.4775,  -9.2327,  -0.6134,\n",
      "          -4.7839,  -1.8689,  -3.8516]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.8689141273498535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6124,  -5.7782,  -2.9536,  -3.6086, -11.7407,  -8.8467,  -1.2166,\n",
      "          -4.7438,  -0.6675,  -3.6414]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.64143443107605\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1051,  -7.1687,  -3.7434,  -5.0553, -12.2802,  -8.8009,  -2.2523,\n",
      "          -5.0163,  -0.2703,  -3.0109]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.252284526824951\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3914,  -8.2284,  -4.2823,  -6.1697, -12.5720,  -8.5649,  -2.4173,\n",
      "          -5.0723,  -0.2839,  -2.2856]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  12.571992874145508\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3534,  -8.8605,  -4.4570,  -6.8523, -11.7634,  -8.0284,  -2.2991,\n",
      "          -4.8038,  -0.5219,  -1.3865]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  11.763374328613281\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2821,  -9.3648,  -4.5593,  -7.4029, -10.2423,  -7.4791,  -2.1909,\n",
      "          -4.5020,  -1.0990,  -0.7040]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.559340476989746\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2201, -9.7912, -3.7385, -7.8713, -8.8422, -6.9556, -2.1364, -4.2096,\n",
      "         -1.8313, -0.4438]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.44381213188171387\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5115, -10.4900,  -3.3338,  -8.6083,  -7.8940,  -6.7984,  -2.4772,\n",
      "          -4.2715,  -2.9219,  -0.2472]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  10.489998817443848\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4087, -9.9921, -2.6103, -8.8827, -6.6489, -6.2671, -2.4481, -3.9476,\n",
      "         -3.5542, -0.2802]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.4481005668640137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1071, -9.3070, -1.7875, -8.8940, -5.2909, -5.5530, -1.6017, -3.4340,\n",
      "         -3.9090, -0.6446]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.4339914321899414\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0024, -8.8194, -1.3256, -9.0344, -4.2001, -5.0417, -1.0973, -2.3777,\n",
      "         -4.3737, -1.4969]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.034414291381836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1022, -8.5328, -1.3001, -8.6067, -3.3807, -4.7380, -1.0089, -1.6478,\n",
      "         -4.9550, -2.5872]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.738014221191406\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2448, -8.2896, -1.5361, -8.2364, -2.6824, -3.8309, -1.1772, -1.1496,\n",
      "         -5.4995, -3.6425]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.5360560417175293\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5671, -8.2317, -1.2122, -8.0637, -2.2650, -3.1884, -1.6868, -1.0999,\n",
      "         -6.1546, -4.7752]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.06372356414795\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7963, -8.0945, -1.0988, -7.1307, -1.8815, -2.5510, -2.1796, -1.2202,\n",
      "         -6.6619, -5.7179]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.09454345703125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9173, -7.1401, -1.1870, -6.1855, -1.5458, -1.9235, -2.5920, -1.4459,\n",
      "         -7.0158, -6.4661]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.1869741678237915\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2535, -6.4904, -0.8664, -5.5450, -1.6137, -1.6647, -3.2223, -2.0365,\n",
      "         -7.5460, -7.3523]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.352262496948242\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4323, -5.7694, -0.8101, -4.8339, -1.6886, -1.4206, -3.6801, -2.5310,\n",
      "         -7.8882, -7.2507]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.888205528259277\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4064, -4.9244, -0.9500, -4.0011, -1.6981, -1.1635, -3.9120, -2.8397,\n",
      "         -7.2646, -6.9624]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.406390190124512\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4167, -4.0225, -1.2666, -3.1178, -1.6994, -0.9939, -3.9888, -3.0171,\n",
      "         -6.5576, -6.5580]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.557620048522949\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4899, -3.1608, -1.7347, -2.2908, -1.7769, -1.0245, -4.0083, -3.1523,\n",
      "         -5.1425, -6.1327]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.142518997192383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7994, -2.4913, -2.3864, -1.6928, -2.0508, -1.3661, -4.1140, -3.3830,\n",
      "         -3.2478, -5.8271]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.827143669128418\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5322, -2.1664, -3.2718, -1.5012, -2.6128, -2.0608, -4.4376, -3.8344,\n",
      "         -1.7847, -5.0236]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.166423797607422\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8511, -1.6096, -4.4832, -1.8660, -3.5549, -3.1516, -5.1168, -4.6377,\n",
      "         -0.9659, -4.6839]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.8511455059051514\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6908, -1.4994, -5.8303, -2.5495, -4.6712, -4.4087, -5.9782, -5.6144,\n",
      "         -0.7469, -4.6295]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.4993515014648438\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7807, -0.9235, -7.1298, -3.3034, -5.7671, -5.6326, -6.8388, -6.5801,\n",
      "         -0.9722, -4.6699]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.632574081420898\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8975, -0.5915, -8.1988, -3.9057, -6.6541, -5.9669, -7.5119, -7.3484,\n",
      "         -1.3426, -4.6099]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.198753356933594\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9014, -0.4707, -8.0625, -4.2378, -7.2294, -6.0447, -7.8938, -7.8162,\n",
      "         -1.6378, -4.3380]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.237820148468018\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7353, -0.5206, -7.6467, -3.5486, -7.4556, -5.8232, -7.9452, -7.9452,\n",
      "         -1.7497, -3.8095]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.823246955871582\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4870, -0.7472, -7.0276, -2.7028, -7.4153, -4.7250, -7.7471, -7.8171,\n",
      "         -1.7305, -3.1051]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.4869877099990845\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8209, -1.4838, -6.6641, -2.1814, -7.5734, -3.9345, -7.7628, -7.8958,\n",
      "         -2.0341, -2.6980]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.69800066947937\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7243, -2.4524, -6.4795, -1.9333, -7.8584, -3.3767, -7.9192, -8.1092,\n",
      "         -2.5437, -1.7762]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.858366012573242\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0337, -3.3877, -6.3144, -1.8122, -7.3522, -2.8964, -8.0606, -8.3018,\n",
      "         -3.0598, -1.0727]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.0336552858352661\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0055, -4.4736, -6.3853, -2.0371, -7.1145, -2.7181, -8.4065, -8.6939,\n",
      "         -3.7772, -0.9149]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.9149300456047058\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4523, -5.6355, -6.6254, -2.5072, -7.0755, -2.7757, -8.8931, -9.2223,\n",
      "         -4.6151, -0.5004]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.625431060791016\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8271, -6.4678, -5.7699, -2.7710, -6.8230, -2.6510, -9.1140, -9.4807,\n",
      "         -5.1598, -0.3649]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.771038055419922\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0109, -6.9343, -4.7163, -2.0621, -6.3111, -2.3006, -9.0282, -9.4288,\n",
      "         -5.3702, -0.4746]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.311141490936279\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1120, -7.1823, -3.6005, -1.3392, -4.9279, -1.8779, -8.7775, -9.2086,\n",
      "         -5.3898, -0.8582]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.389753341674805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3486, -7.4530, -2.6647, -0.9196, -3.7329, -1.6456, -8.5983, -9.0569,\n",
      "         -4.7355, -1.5620]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.598289489746094\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6914, -7.7492, -1.9329, -0.8747, -2.7253, -1.6166, -7.8252, -8.9717,\n",
      "         -4.2036, -2.4026]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.6913974285125732\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3142, -8.0887, -1.4706, -1.2003, -1.9386, -1.7954, -7.2006, -8.9673,\n",
      "         -3.8069, -3.2996]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.2002884149551392\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2519, -8.5931, -1.4511, -1.1987, -1.5370, -2.2659, -6.8360, -9.1614,\n",
      "         -3.6633, -4.3337]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.161385536193848\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1780, -8.9451, -1.5338, -1.3064, -1.2358, -2.6567, -6.4051, -8.4569,\n",
      "         -3.4494, -5.1729]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.945127487182617\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0703, -8.4014, -1.6625, -1.4610, -1.0528, -2.9234, -5.8849, -7.6890,\n",
      "         -3.1468, -5.8009]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.662454605102539\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1287, -7.9646, -1.1341, -1.8169, -1.2067, -3.2533, -5.4710, -7.0504,\n",
      "         -2.9585, -6.4227]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.2067018747329712\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4089, -7.7019, -1.0653, -2.3830, -0.9449, -3.7077, -5.2315, -6.6062,\n",
      "         -2.9572, -7.1154]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.231529235839844\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5583, -7.2890, -1.1222, -2.7821, -0.8269, -3.9576, -4.1832, -6.0303,\n",
      "         -2.8175, -7.5641]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2.558319091796875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8341, -6.8026, -1.3374, -3.0711, -0.9362, -4.0812, -3.1335, -5.3983,\n",
      "         -2.6205, -7.8545]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.936221718788147\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5376, -6.5927, -1.9835, -3.5923, -0.8037, -4.4318, -2.4438, -5.0599,\n",
      "         -2.7237, -8.3443]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.059871196746826\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3601, -6.3210, -2.6004, -3.9983, -0.9376, -4.6726, -1.7966, -3.9087,\n",
      "         -2.7814, -8.7027]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.998310089111328\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3629, -6.0335, -3.1765, -3.6261, -1.3079, -4.8522, -1.2800, -2.8425,\n",
      "         -2.8349, -8.9821]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.280046820640564\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8712, -6.0756, -4.0313, -3.6088, -2.1441, -5.3190, -0.6366, -2.2260,\n",
      "         -3.2258, -9.5336]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.075579643249512\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4959,  -5.4344,  -4.8596,  -3.6546,  -3.0283,  -5.7855,  -0.4522,\n",
      "          -1.7965,  -3.6498, -10.0732]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.45224717259407043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3807,  -5.1146,  -5.8681,  -3.9693,  -4.1170,  -6.4633,  -0.3004,\n",
      "          -1.7937,  -4.3062, -10.8148]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.380725145339966\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0963,  -4.5243,  -6.4734,  -3.9599,  -4.8044,  -6.7690,  -0.3497,\n",
      "          -1.6144,  -4.6015, -11.1770]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.6143841743469238\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8398,  -3.9637,  -6.9841,  -3.9286,  -5.3941,  -7.0091,  -0.8220,\n",
      "          -0.8006,  -4.8389, -11.4673]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.98412561416626\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6627,  -3.4796,  -6.5937,  -3.9218,  -5.9366,  -7.2337,  -1.5435,\n",
      "          -0.4232,  -5.0663, -11.7364]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  11.736405372619629\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3422,  -2.8489,  -6.0261,  -3.7130,  -6.2109,  -7.2198,  -2.1176,\n",
      "          -0.3715,  -5.0591, -11.0082]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  11.008179664611816\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8452, -2.0376, -5.2313, -3.2570, -6.1746, -6.9227, -2.4293, -0.5655,\n",
      "         -4.7723, -9.3321]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.257026195526123\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5008, -1.3788, -4.4961, -2.1457, -6.1203, -6.6323, -2.7452, -1.1466,\n",
      "         -4.4967, -7.7979]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.496133327484131\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5437, -1.1441, -3.1803, -1.4005, -6.2471, -6.5456, -3.2465, -2.0851,\n",
      "         -4.4307, -6.5892]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.430727005004883\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8740, -1.2866, -2.1491, -1.0231, -6.4828, -6.5883, -3.8442, -3.1456,\n",
      "         -3.7620, -5.6205]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.1491074562072754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6181, -1.9407, -0.8188, -1.2600, -7.0192, -6.9505, -4.7201, -4.4573,\n",
      "         -3.4991, -5.0726]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.457259654998779\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6580, -2.9462, -0.3014, -1.9843, -7.8138, -7.5879, -5.8258, -5.1917,\n",
      "         -3.5946, -4.8936]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.30135712027549744\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0838, -4.3590, -0.0871, -3.2021, -8.9979, -8.6305, -7.2922, -6.3254,\n",
      "         -4.1685, -5.2053]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.168511867523193\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.7910, -5.0588, -0.0789, -3.7455, -9.4823, -8.9873, -8.0314, -6.7657,\n",
      "         -3.3874, -4.9073]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.078935906291008\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.5149,  -5.7783,  -0.0930,  -4.3360, -10.0029,  -9.3928,  -8.7818,\n",
      "          -7.2473,  -2.7917,  -4.7279]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.336032867431641\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5825, -5.8430, -0.2638, -3.5861, -9.8860, -9.1723, -8.8722, -7.0959,\n",
      "         -1.7136, -3.9867]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.87222671508789\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5026, -5.7616, -0.8908, -2.7877, -9.6388, -8.8316, -8.1451, -6.8180,\n",
      "         -0.7325, -3.1906]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.7876667976379395\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7065, -5.9652, -2.0584, -1.6922, -9.6906, -8.7993, -7.7645, -6.8430,\n",
      "         -0.4770, -2.7787]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.965207099914551\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.9532, -5.4743, -3.2754, -0.8955, -9.7993, -8.8322, -7.4836, -6.9283,\n",
      "         -0.7633, -2.5163]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.83216381072998\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.1795, -5.0380, -4.4062, -0.4668, -9.9004, -8.1678, -7.2338, -7.0090,\n",
      "         -1.3640, -2.3441]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.466795951128006\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.7493,  -5.0147,  -5.8007,  -0.1859, -10.3569,  -7.9344,  -7.3743,\n",
      "          -7.4476,  -2.4571,  -2.6269]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.374311447143555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.8945,  -4.6296,  -6.6913,  -0.1442, -10.3994,  -7.3552,  -6.4734,\n",
      "          -7.4746,  -3.1363,  -2.5680]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.629589557647705\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5619, -3.1000, -7.0314, -0.2385, -9.9740, -6.3698, -5.1985, -7.0356,\n",
      "         -3.3166, -2.1095]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.099970579147339\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.2603, -1.0401, -7.3366, -0.8565, -9.5884, -5.4805, -4.0507, -6.6384,\n",
      "         -3.5036, -1.7866]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.336592197418213\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.7844,  -0.2362,  -7.5958,  -2.4973, -10.0362,  -5.4772,  -3.8229,\n",
      "          -7.0767,  -4.4898,  -2.4188]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.07673454284668\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.2757,  -0.1054,  -7.8483,  -4.0513, -10.4584,  -5.4955,  -3.6506,\n",
      "          -6.7299,  -5.4054,  -3.0752]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.458423614501953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.2049, -0.1185, -7.5623, -4.9502, -9.5500, -5.0011, -2.9987, -5.9043,\n",
      "         -5.7203, -3.1884]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.188446521759033\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.7207, -0.3350, -6.8844, -5.3448, -8.3106, -4.1395, -2.0238, -4.7415,\n",
      "         -5.5860, -2.1403]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.1402599811553955\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5492, -1.2928, -6.5387, -5.9684, -7.4581, -3.6387, -1.4979, -3.9646,\n",
      "         -5.7323, -0.8023]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.8023242950439453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.4047, -3.3579, -7.2379, -7.5421, -7.6998, -4.2156, -2.1835, -4.2884,\n",
      "         -6.8764, -0.1971]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.542105197906494\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.0055, -5.0734, -7.6982, -8.0994, -7.7473, -4.5754, -2.7063, -4.4203,\n",
      "         -7.7378, -0.1022]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.7378058433532715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.9737, -6.0508, -7.5400, -8.0286, -7.2171, -4.3337, -2.6490, -3.9749,\n",
      "         -7.2031, -0.1137]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.20311164855957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.4034, -6.3917, -6.8561, -7.4232, -6.1979, -3.5833, -2.1032, -3.0460,\n",
      "         -5.4592, -0.2322]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.459200859069824\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.6634, -6.4742, -6.0143, -6.6519, -5.0547, -2.7007, -1.4673, -2.0193,\n",
      "         -2.9590, -0.6821]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.700692892074585\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5146, -7.0675, -5.7754, -6.4752, -4.5469, -1.7647, -1.5673, -1.7140,\n",
      "         -1.2603, -1.9676]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.567280650138855\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.0813, -8.3033, -6.2629, -7.0175, -4.7980, -1.7427, -1.8252, -2.2784,\n",
      "         -0.6348, -3.9277]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.017475605010986\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.5682, -9.3933, -6.6797, -6.8009, -5.0065, -1.8228, -2.1417, -2.8421,\n",
      "         -0.4309, -5.6847]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.1417160034179688\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.8139, -10.1826,  -6.8631,  -6.4131,  -5.0065,  -1.8164,  -1.6461,\n",
      "          -3.2021,  -0.5217,  -7.0777]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  8.813905715942383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.9915, -10.6802,  -6.8154,  -5.8509,  -4.7979,  -1.7122,  -1.1144,\n",
      "          -3.3443,  -0.8136,  -8.1201]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.815402030944824\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.1413, -11.0196,  -5.8568,  -5.2367,  -4.5071,  -1.6374,  -0.7457,\n",
      "          -3.3907,  -1.2828,  -8.9508]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.236737251281738\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.2526, -11.2024,  -4.8720,  -3.8902,  -4.1306,  -1.5853,  -0.6075,\n",
      "          -3.3357,  -1.7799,  -9.5767]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.3356828689575195\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3501, -11.2640,  -3.8872,  -2.5872,  -3.7008,  -1.5811,  -0.7426,\n",
      "          -2.4390,  -2.2452, -10.0378]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.5871572494506836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7870, -11.5651,  -3.2617,  -1.0435,  -3.5785,  -1.9699,  -1.4267,\n",
      "          -1.9440,  -2.9864, -10.6998]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.2616710662841797\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8539, -12.3663,  -2.4667,  -0.4397,  -4.0208,  -2.9665,  -2.7603,\n",
      "          -2.1542,  -4.2424, -11.8498]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  11.849753379821777\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.9057, -13.1495,  -1.8754,  -0.3560,  -4.4937,  -3.9286,  -4.0097,\n",
      "          -2.4615,  -5.4014, -12.1679]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.905703544616699\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9410, -13.6206,  -1.2328,  -0.5356,  -4.6945,  -4.5915,  -4.9402,\n",
      "          -2.5855,  -6.2361, -12.2429]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.591460704803467\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9596, -13.9172,  -0.7607,  -0.9609,  -4.7548,  -4.3544,  -5.6559,\n",
      "          -2.6276,  -6.8619, -12.1825]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  13.917174339294434\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0183, -13.3677,  -0.6120,  -1.4999,  -4.7165,  -4.0503,  -6.2038,\n",
      "          -2.6220,  -7.3272, -12.0285]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.6219980716705322\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2603, -12.8526,  -0.8922,  -2.1149,  -4.6693,  -3.7687,  -6.6790,\n",
      "          -1.8849,  -7.7271, -11.8698]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.66926383972168\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8631, -12.4384,  -1.5215,  -2.8002,  -3.8926,  -3.5815,  -7.1585,\n",
      "          -1.3876,  -8.1382, -11.7769]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.8002099990844727\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8420, -12.0516,  -2.2495,  -2.7743,  -3.1952,  -3.4191,  -7.5777,\n",
      "          -1.1182,  -8.4954, -11.6797]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.495429992675781\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0227, -11.5463,  -2.8335,  -2.6359,  -2.4425,  -3.1395,  -7.7994,\n",
      "          -0.9706,  -7.9405, -11.4355]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  11.435503005981445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3497, -10.9585,  -3.2747,  -2.4265,  -1.7009,  -2.7861,  -7.8672,\n",
      "          -0.9963,  -7.3081, -10.3582]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.7009003162384033\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1296, -10.7000,  -3.9739,  -2.5681,  -0.6630,  -2.7831,  -8.1997,\n",
      "          -1.5740,  -7.0099,  -9.6585]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  10.699956893920898\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0840, -9.9092, -4.7726, -2.9002, -0.2898, -2.9779, -8.6529, -2.4071,\n",
      "         -6.8949, -9.1810]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.9002175331115723\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7117, -8.9259, -5.2287, -2.3004, -0.2717, -2.9196, -8.7909, -2.9567,\n",
      "         -6.5214, -8.4801]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.480109214782715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9347, -7.6765, -5.2811, -1.4632, -0.4834, -2.5427, -8.5523, -3.1292,\n",
      "         -5.8227, -6.7705]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.1291606426239014\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1059, -6.5046, -5.2864, -0.8168, -1.1019, -2.2137, -8.2914, -2.5016,\n",
      "         -5.1490, -5.1842]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.291366577148438\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3379, -5.5134, -5.3593, -0.5924, -1.9791, -2.0600, -7.4433, -2.0626,\n",
      "         -4.6100, -3.8225]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.5923505425453186\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8857, -4.9509, -5.7569, -0.4206, -3.2048, -2.3417, -7.0073, -2.0920,\n",
      "         -4.4591, -2.9389]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.950860500335693\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2177, -3.5750, -5.9506, -0.5340, -4.1743, -2.4976, -6.4472, -2.0451,\n",
      "         -4.1635, -2.0133]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.447224140167236\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4827, -2.3146, -6.0860, -0.9831, -5.0172, -2.6572, -5.2358, -2.0630,\n",
      "         -3.8694, -1.2359]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.9831269979476929\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0325, -1.5573, -6.5185, -1.2807, -6.0914, -3.1603, -4.4556, -2.4842,\n",
      "         -3.9270, -1.0550]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.055030107498169\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8048, -1.3005, -7.1844, -2.0070, -7.3364, -3.9193, -4.0350, -3.2027,\n",
      "         -4.2681, -0.6962]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.6961506605148315\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.8396, -1.6022, -8.1230, -3.0883, -8.7969, -4.9557, -4.0055, -4.2194,\n",
      "         -4.9234, -0.3497]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.3497341275215149\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.0890,  -2.3350,  -9.2856,  -4.4095, -10.4298,  -6.2114,  -4.3076,\n",
      "          -5.4636,  -5.8359,  -0.1414]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  9.285626411437988\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.7377,  -2.5873,  -9.0462,  -5.1308, -11.4241,  -6.8671,  -4.1115,\n",
      "          -6.1107,  -6.1829,  -0.1087]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.111483097076416\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.7894,  -2.3356,  -8.2973,  -5.2518, -11.7871,  -6.9258,  -2.7472,\n",
      "          -6.1626,  -5.9641,  -0.1888]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.3356494903564453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.7100,  -1.3398,  -7.4965,  -5.2384, -11.9884,  -6.8534,  -1.4346,\n",
      "          -6.0851,  -5.6427,  -0.7193]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.642733573913574\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.9958,  -0.9867,  -7.1325,  -5.5871, -12.5271,  -7.1462,  -0.7694,\n",
      "          -6.3742,  -4.9856,  -1.8973]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.146238803863525\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.3261,  -1.0074,  -6.8775,  -5.9765, -13.0853,  -6.7549,  -0.5551,\n",
      "          -6.7088,  -4.4708,  -3.1376]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.754947662353516\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.3870,  -1.0492,  -6.4106,  -6.0918, -13.3509,  -5.4525,  -0.5106,\n",
      "          -6.7747,  -3.7778,  -4.0493]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.5106432437896729\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.5805,  -1.4747,  -6.1292,  -6.3355, -13.7286,  -4.4200,  -0.3410,\n",
      "          -6.9735,  -3.3085,  -5.0219]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.335515022277832\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.4856,  -1.7054,  -5.5185,  -5.5762, -13.7460,  -3.1705,  -0.3710,\n",
      "          -6.8930,  -2.6068,  -5.6169]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  13.746048927307129\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.2127,  -1.8529,  -4.7872,  -4.7113, -12.7913,  -1.8950,  -0.6662,\n",
      "          -6.6338,  -1.8450,  -5.9636]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.633774280548096\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.0705,  -2.2396,  -4.3123,  -4.0789, -12.0786,  -1.0058,  -1.3953,\n",
      "          -5.7234,  -1.4078,  -6.3956]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  12.078557968139648\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.0956,  -2.8177,  -4.0484,  -3.6734, -10.8218,  -0.6227,  -2.3701,\n",
      "          -5.0586,  -1.3468,  -6.9393]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  10.095555305480957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.1474, -3.2554, -3.6988, -3.1988, -9.5631, -0.5394, -3.1848, -4.3383,\n",
      "         -1.3568, -7.3040]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.304035186767578\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.0565, -3.4413, -3.1677, -2.5619, -8.1923, -0.6471, -3.7104, -3.4629,\n",
      "         -1.3187, -6.6827]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.4412689208984375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.9575, -2.7982, -2.6075, -1.9235, -6.8408, -1.0027, -4.0843, -2.5820,\n",
      "         -1.3648, -6.0075]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.7981534004211426\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1069, -1.6964, -2.3026, -1.5853, -5.7627, -1.7248, -4.5718, -1.9863,\n",
      "         -1.7332, -5.5400]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.5399580001831055\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5524, -1.0433, -2.3204, -1.6281, -5.0037, -2.7137, -5.2284, -1.7664,\n",
      "         -2.4055, -4.6293]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.228363037109375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1054, -0.7540, -2.4672, -1.8481, -4.3744, -3.7023, -5.2023, -1.7513,\n",
      "         -3.1277, -3.8650]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.202260971069336\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5935, -0.7117, -2.5554, -2.0381, -3.7028, -4.4968, -4.4088, -1.7590,\n",
      "         -3.6966, -3.0766]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.408843517303467\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0313, -0.9100, -2.5898, -2.1876, -3.0074, -5.1116, -2.9436, -1.7911,\n",
      "         -4.1184, -2.2893]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.118409156799316\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6186, -1.4506, -2.7618, -2.4767, -2.4981, -5.7488, -1.7363, -2.0292,\n",
      "         -3.8499, -1.7303]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.7302567958831787\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6792, -2.5126, -3.3790, -3.2038, -2.5134, -6.7352, -1.1738, -2.7565,\n",
      "         -4.0332, -1.0601]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.679215908050537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0635, -3.6750, -4.1117, -4.0345, -2.7388, -7.7732, -1.0185, -3.6098,\n",
      "         -4.3595, -0.8491]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.0184667110443115\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7203, -4.9130, -4.9580, -4.9676, -3.1652, -8.8813, -0.6345, -4.5725,\n",
      "         -4.8353, -1.1333]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.835275173187256\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3201, -5.8874, -5.5800, -5.6667, -3.4361, -9.7336, -0.4908, -5.3017,\n",
      "         -4.3955, -1.4696]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.301748752593994\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8124,  -6.5371,  -5.9135,  -6.0688,  -3.4753, -10.2714,  -0.5320,\n",
      "          -4.9504,  -3.7778,  -1.7044]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  10.27135944366455\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2980, -6.9286, -6.0210, -6.2375, -3.3398, -9.8350, -0.7567, -4.4440,\n",
      "         -3.0425, -1.8489]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.3398451805114746\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0128, -7.2285, -6.0664, -6.3374, -2.4109, -9.3882, -1.2107, -3.9431,\n",
      "         -2.3611, -2.0367]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.036670684814453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1605, -7.5964, -6.2063, -6.5256, -1.7409, -9.0826, -1.9105, -3.6039,\n",
      "         -1.9132, -1.6907]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.9104962348937988\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6419, -8.0114, -6.4171, -6.7793, -1.3577, -8.8903, -2.0677, -3.4025,\n",
      "         -1.7010, -1.5915]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.417112350463867\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1714, -8.3174, -5.7093, -6.9405, -1.1460, -8.6489, -2.2232, -3.1789,\n",
      "         -1.5756, -1.5770]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.171433925628662\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8732, -8.5670, -5.0476, -7.0601, -1.1781, -8.4050, -2.4073, -2.9836,\n",
      "         -1.5883, -1.6828]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.6828094720840454\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7601, -8.8188, -4.4833, -7.1951, -1.4749, -8.2120, -2.6585, -2.8740,\n",
      "         -1.7767, -1.2345]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.195113182067871\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7260, -8.9690, -3.9074, -6.5590, -1.8449, -7.9615, -2.8537, -2.7429,\n",
      "         -1.9942, -0.9576]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.853689432144165\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7725, -9.0320, -3.3325, -5.9142, -2.2298, -7.6635, -2.3451, -2.6029,\n",
      "         -2.2181, -0.9043]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.2180933952331543\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9451, -9.0766, -2.8320, -5.3227, -2.6489, -7.3831, -1.9365, -2.5229,\n",
      "         -1.7524, -1.1270]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.6489315032958984\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2415, -9.1373, -2.4505, -4.8133, -2.3179, -7.1511, -1.6824, -2.5346,\n",
      "         -1.4802, -1.5744]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.5743945837020874\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6868, -9.2806, -2.2674, -4.4482, -2.1848, -7.0311, -1.6626, -2.6962,\n",
      "         -1.4902, -1.5109]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.510910153388977\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2450, -9.5092, -2.2885, -4.2266, -2.2521, -7.0230, -1.8675, -2.9947,\n",
      "         -1.7640, -1.0135]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.28851056098938\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8343, -9.7684, -1.6164, -4.0901, -2.4481, -7.0696, -2.2060, -3.3566,\n",
      "         -2.1897, -0.8706]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.35659122467041\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3472, -9.9656, -1.1393, -3.9420, -2.6559, -7.0757, -2.5464, -2.8867,\n",
      "         -2.6192, -0.9956]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.9420039653778076\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7403, -10.0632,  -0.8955,  -3.0623,  -2.8180,  -7.0016,  -2.8241,\n",
      "          -2.4269,  -2.9797,  -1.2840]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.8240976333618164\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0407, -10.0899,  -0.9535,  -2.2401,  -2.9497,  -6.8742,  -2.4009,\n",
      "          -2.0206,  -3.2808,  -1.6742]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.9496536254882812\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3347, -10.1318,  -1.3425,  -1.5896,  -2.3481,  -6.7780,  -2.0962,\n",
      "          -1.7768,  -3.5977,  -2.1736]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.5976967811584473\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6690, -10.2348,  -1.9744,  -1.2084,  -1.9456,  -6.7573,  -1.9668,\n",
      "          -1.7556,  -3.2336,  -2.7679]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.2335901260375977\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.0150, -10.3693,  -2.7006,  -1.1111,  -1.7358,  -6.7813,  -1.9830,\n",
      "          -1.9145,  -2.2542,  -3.3888]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.9829820394515991\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4360, -10.5978,  -3.5179,  -1.3560,  -1.7913,  -6.9108,  -1.5464,\n",
      "          -2.2813,  -1.5550,  -4.0790]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.5550155639648438\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.1368, -11.1237,  -4.5993,  -2.0732,  -2.2915,  -7.3484,  -1.6113,\n",
      "          -3.0127,  -0.6807,  -5.0329]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.291508197784424\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.9150, -11.7436,  -5.7281,  -2.9516,  -2.1929,  -7.8890,  -1.9454,\n",
      "          -3.8566,  -0.4069,  -6.0430]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.40692245960235596\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.8993, -12.5848,  -7.0307,  -4.0617,  -2.4731,  -8.6592,  -2.6220,\n",
      "          -4.9165,  -0.2027,  -7.2377]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.659202575683594\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.3587, -12.9152,  -7.7777,  -4.6463,  -2.3632,  -8.1884,  -2.8512,\n",
      "          -5.4498,  -0.1827,  -7.8870]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  9.35865592956543\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4426, -12.7327,  -7.9709,  -4.6994,  -1.8570,  -7.2840,  -2.6152,\n",
      "          -5.4535,  -0.2801,  -7.9922]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.2800655663013458\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.7518, -12.7028,  -8.2800,  -4.8882,  -1.6568,  -6.6041,  -2.5849,\n",
      "          -5.5949,  -0.3281,  -8.2219]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  12.70284366607666\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.7698, -11.5861,  -8.1989,  -4.7037,  -1.2649,  -5.6325,  -2.2470,\n",
      "          -5.3655,  -0.5226,  -8.0693]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.365478992462158\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6863, -10.3803,  -7.9266,  -4.3443,  -0.9319,  -4.5602,  -1.8121,\n",
      "          -4.1727,  -0.9167,  -7.7325]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.732526779174805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6301, -9.2108, -7.5989, -3.9467, -0.8548, -3.5187, -1.4445, -3.0272,\n",
      "         -1.4710, -6.6465]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.518744468688965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7539, -8.2244, -7.3713, -3.6692, -1.1821, -1.9379, -1.3350, -2.1005,\n",
      "         -2.2003, -5.7361]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.2244234085083\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2947, -6.9254, -7.4772, -3.7472, -2.0249, -0.9299, -1.7192, -1.6728,\n",
      "         -3.2464, -5.2283]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.294717788696289\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3437, -6.0267, -7.8444, -4.1051, -3.1582, -0.5847, -2.4543, -1.7073,\n",
      "         -4.4881, -5.0457]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.488142490386963\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5209, -5.1717, -8.1288, -4.3923, -4.1658, -0.6377, -3.1263, -1.8354,\n",
      "         -4.8539, -4.8388]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.171665191650391\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8893, -3.6179, -8.3098, -4.5843, -5.0104, -0.9978, -3.6854, -2.0019,\n",
      "         -5.1135, -4.5824]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.0018765926361084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7611, -2.3294, -8.5656, -4.8569, -5.8693, -1.6847, -4.2982, -1.5625,\n",
      "         -5.4441, -4.4510]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.444140911102295\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0688, -1.2674, -8.8250, -5.1367, -6.6743, -2.4684, -4.8881, -1.3605,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -5.0713, -4.3695]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.3605118989944458\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9812, -0.8609, -9.4050, -5.7390, -7.7467, -3.5829, -5.7708, -0.9443,\n",
      "         -5.0858, -4.6510]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.746707916259766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8648, -0.7465, -9.8727, -6.2290, -7.8772, -4.5527, -6.5133, -0.8201,\n",
      "         -5.0481, -4.8564]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  9.872686386108398\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4423, -0.7199, -9.1859, -6.4052, -7.7283, -5.1677, -6.9167, -0.7868,\n",
      "         -4.7519, -4.7802]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  9.18591022491455\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6677, -0.7250, -7.4249, -6.2430, -7.2723, -5.4040, -6.9587, -0.7904,\n",
      "         -4.1688, -4.3954]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.168817520141602\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6158, -0.8012, -5.5616, -5.8214, -6.5852, -5.3436, -6.7204, -0.8702,\n",
      "         -2.6817, -3.7806]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.7805593013763428\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5663, -1.1663, -3.8602, -5.4182, -5.9416, -5.2672, -6.4811, -1.2419,\n",
      "         -1.3639, -2.5144]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.418190956115723\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9060, -2.0792, -2.7048, -4.7189, -5.7240, -5.5625, -6.6267, -2.1617,\n",
      "         -0.7161, -1.7908]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.0791547298431396\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4717, -2.5113, -1.9617, -4.3374, -5.7728, -6.0739, -7.0013, -3.3226,\n",
      "         -0.7175, -1.4988]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.5112743377685547\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9783, -2.2332, -1.3967, -3.9898, -5.8063, -6.5235, -7.3265, -4.3841,\n",
      "         -1.0470, -1.3806]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.326460361480713\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3783, -1.9964, -1.0322, -3.6271, -5.7764, -6.8673, -6.8929, -5.2880,\n",
      "         -1.5264, -1.3893]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.776400566101074\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6364, -1.7735, -0.8955, -3.2126, -4.8721, -7.0717, -6.3967, -6.0003,\n",
      "         -2.0040, -1.4670]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.003999710083008\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8070, -1.6285, -1.0480, -2.8023, -3.9981, -7.1914, -5.8855, -6.5792,\n",
      "         -1.7646, -1.6351]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.806970596313477\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0027, -1.5247, -1.3642, -2.3622, -3.1115, -7.1868, -5.3136, -6.9888,\n",
      "         -1.5549, -1.8113]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.5247465372085571\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4377, -1.0295, -2.0159, -2.1862, -2.5014, -7.3374, -4.9557, -7.5128,\n",
      "         -1.6671, -2.2400]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.501382827758789\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0820, -0.9807, -2.8578, -2.2503, -1.3926, -7.6170, -4.7812, -8.1289,\n",
      "         -2.0433, -2.8453]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.250279426574707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9735, -1.4009, -3.8622, -1.8789, -0.7835, -8.0671, -4.8274, -8.8821,\n",
      "         -2.6704, -3.6297]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.629739284515381\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8804, -1.9431, -4.7736, -1.6403, -0.5772, -8.4618, -4.8631, -9.5498,\n",
      "         -3.2727, -3.6354]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.9431324005126953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6977,  -1.7087,  -5.4856,  -1.4453,  -0.7079,  -8.7011,  -4.7841,\n",
      "         -10.0351,  -3.7255,  -3.5426]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.485635757446289\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3607,  -1.4322,  -5.1024,  -1.2421,  -1.0104,  -8.7237,  -4.5251,\n",
      "         -10.2791,  -3.9571,  -3.2862]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.2861695289611816\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0111,  -1.2764,  -4.6865,  -1.1866,  -1.4861,  -8.6686,  -4.2235,\n",
      "         -10.4236,  -4.1038,  -2.3061]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.668550491333008\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7207,  -1.3162,  -4.3021,  -1.3340,  -2.0709,  -7.8543,  -3.9442,\n",
      "         -10.5365,  -4.2302,  -1.4755]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.334019660949707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7126,  -1.7391,  -4.1642,  -1.1465,  -2.8920,  -7.3182,  -3.9030,\n",
      "         -10.8355,  -4.5517,  -1.0853]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.892036199569702\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7111,  -2.1937,  -4.0020,  -1.1496,  -2.8546,  -6.7847,  -3.8285,\n",
      "         -11.0542,  -4.7980,  -0.9206]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.7979912757873535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6033,  -2.5190,  -3.7077,  -1.2112,  -2.7014,  -6.1413,  -3.6127,\n",
      "         -11.0878,  -4.1617,  -0.8887]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.141347885131836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4084,  -2.7082,  -3.3018,  -1.3143,  -2.4535,  -4.6646,  -3.2753,\n",
      "         -10.9571,  -3.4382,  -0.9874]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.301831007003784\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2916,  -2.9079,  -2.1243,  -1.5774,  -2.2775,  -3.3225,  -2.9786,\n",
      "         -10.8209,  -2.7904,  -1.3191]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.907853126525879\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4629,  -2.6061,  -1.3516,  -2.1490,  -2.3871,  -2.3296,  -2.9354,\n",
      "         -10.8880,  -2.4393,  -1.9952]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.3516348600387573\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2247,  -2.9206,  -0.5856,  -3.2802,  -3.0904,  -2.0415,  -3.4666,\n",
      "         -11.4826,  -2.7183,  -3.2341]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.0903844833374023\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9995,  -3.2962,  -0.4097,  -4.3803,  -3.0512,  -1.9330,  -4.0207,\n",
      "         -12.0725,  -3.0703,  -4.4324]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.4096549451351166\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.9763,  -3.9238,  -0.2397,  -5.6432,  -3.3147,  -2.2063,  -4.7951,\n",
      "         -12.8670,  -3.6830,  -5.7835]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.9238154888153076\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4060,  -3.3442,  -0.2759,  -6.3273,  -3.1232,  -2.0782,  -5.0419,\n",
      "         -13.1263,  -3.7962,  -6.5467]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.405979156494141\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5379,  -2.4431,  -0.5190,  -6.5414,  -2.5807,  -1.6530,  -4.8652,\n",
      "         -12.9565,  -3.5105,  -6.8318]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.5190247297286987\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0112,  -1.9389,  -0.6567,  -6.9818,  -2.3960,  -1.6597,  -4.9577,\n",
      "         -13.0499,  -3.5206,  -7.3360]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.3960471153259277\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4996,  -1.5337,  -1.1459,  -7.3269,  -1.4907,  -1.7559,  -4.9935,\n",
      "         -13.0816,  -3.4983,  -7.7384]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  13.081624984741211\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1395,  -1.3960,  -1.9173,  -7.7134,  -0.9209,  -2.0471,  -5.1053,\n",
      "         -12.3861,  -3.5745,  -8.1763]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.3959741592407227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0440,  -0.9357,  -2.9228,  -8.2540,  -0.9019,  -2.5985,  -5.4023,\n",
      "         -11.9512,  -3.8551,  -8.7631]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.598487138748169\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9315,  -0.7303,  -3.8050,  -8.6740,  -1.1251,  -2.3356,  -5.6056,\n",
      "         -11.4921,  -4.0556,  -9.2247]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.605605125427246\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6794,  -0.6876,  -4.4214,  -8.8560,  -1.3752,  -1.9744,  -4.9129,\n",
      "         -10.8817,  -4.0521,  -9.4441]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.421432971954346\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3305,  -0.8212,  -3.9985,  -8.8395,  -1.6113,  -1.5720,  -4.1131,\n",
      "         -10.1511,  -3.8806,  -9.4612]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.330474615097046\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2991, -1.2996, -3.6822, -8.8749, -2.0253, -1.4148, -3.4536, -9.5429,\n",
      "         -3.7910, -9.5269]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.79097843170166\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7402, -2.0591, -3.5549, -9.0444, -2.6360, -1.5924, -3.0186, -9.1325,\n",
      "         -3.1560, -9.7237]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  9.723724365234375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5892, -2.7788, -3.4090, -9.1431, -3.1866, -1.8504, -2.6058, -8.7085,\n",
      "         -2.5598, -9.1360]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.8504040241241455\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8727, -3.4204, -3.2535, -9.1815, -3.6635, -1.4032, -2.2340, -8.2760,\n",
      "         -2.0268, -8.5559]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  8.55589771270752\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4246, -3.9653, -3.0882, -9.1599, -4.0565, -1.1271, -1.9161, -7.8301,\n",
      "         -1.5837, -7.2768]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.9653046131134033\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1012, -3.7414, -2.9521, -9.1166, -4.4000, -1.0957, -1.7069, -7.4048,\n",
      "         -1.3064, -6.1009]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.101201057434082\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9566, -3.5459, -2.8613, -9.0674, -4.7086, -1.3058, -1.6330, -7.0118,\n",
      "         -1.2387, -5.0324]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.545914649963379\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8522, -2.6030, -2.7330, -8.9304, -4.9009, -1.6040, -1.6080, -6.5656,\n",
      "         -1.2909, -3.9815]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.9008588790893555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8641, -1.7790, -2.6441, -8.7812, -4.2924, -1.9965, -1.6976, -6.1388,\n",
      "         -1.5074, -3.0219]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.8641047477722168\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3739, -1.3595, -2.8270, -8.8524, -3.9600, -2.6569, -2.1101, -5.9615,\n",
      "         -2.0655, -2.3972]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.3971762657165527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3205, -1.3376, -3.2168, -9.0936, -3.8519, -3.4814, -2.7423, -5.9807,\n",
      "         -2.8356, -1.3756]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.742337703704834\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6286, -1.6340, -3.7338, -9.4443, -3.9040, -4.3807, -2.8004, -6.1334,\n",
      "         -3.7047, -0.7669]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.704697847366333\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0232, -1.9904, -4.1724, -9.7136, -3.9194, -5.1535, -2.8476, -6.2260,\n",
      "         -3.7458, -0.5001]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.9904289245605469\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3575, -1.5802, -4.4484, -9.8245, -3.8166, -5.7226, -2.7983, -6.1793,\n",
      "         -3.6679, -0.5553]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.7983312606811523\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6019, -1.2176, -4.5706, -9.7885, -3.6049, -6.1018, -1.9771, -6.0029,\n",
      "         -3.4798, -0.8714]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.1017889976501465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8559, -1.0684, -4.6609, -9.7279, -3.4065, -5.6687, -1.3037, -5.8177,\n",
      "         -3.3040, -1.4206]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.8559341430664062\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3445, -1.2172, -4.7947, -9.7180, -3.2978, -5.3256, -0.9276, -5.6979,\n",
      "         -3.2163, -2.1292]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.7179536819458\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8926, -1.4862, -4.8513, -8.9156, -3.1576, -4.9494, -0.7891, -5.5220,\n",
      "         -3.0952, -2.7805]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.486222505569458\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6418, -1.2225, -4.9399, -8.2238, -3.0949, -4.6469, -1.0060, -5.3980,\n",
      "         -3.0495, -3.4420]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.0494613647460938\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5049, -1.1169, -4.9536, -7.5286, -3.0012, -4.3095, -1.3792, -5.2180,\n",
      "         -2.2617, -3.9887]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.3792448043823242\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6508, -1.3329, -5.0564, -6.9872, -3.0395, -4.1001, -1.2882, -5.1448,\n",
      "         -1.7104, -4.5790]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.578963279724121\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8624, -1.6307, -5.0747, -6.4204, -3.0314, -3.8443, -1.3146, -5.0042,\n",
      "         -1.2624, -4.3343]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.004168510437012\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1032, -1.9555, -5.0171, -5.8317, -2.9821, -3.5507, -1.4424, -3.9884,\n",
      "         -0.9806, -4.0438]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.017147064208984\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3281, -2.2526, -4.0617, -5.2097, -2.8830, -3.2140, -1.6250, -2.9945,\n",
      "         -0.8992, -3.7006]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.994467258453369\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6882, -2.6693, -3.2908, -4.7291, -2.9129, -3.0168, -2.0000, -1.4139,\n",
      "         -1.1902, -3.4846]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.4138519763946533\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9608, -3.9845, -3.5180, -5.1939, -3.8733, -3.7674, -3.3218, -0.2812,\n",
      "         -2.5594, -4.2030]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.5180141925811768\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3548, -5.4137, -3.1757, -5.8480, -4.9859, -4.6924, -4.7688, -0.1069,\n",
      "         -4.0793, -5.0920]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.354767322540283\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2499, -6.1727, -2.3691, -5.9076, -5.4619, -5.0009, -5.5465, -0.1397,\n",
      "         -4.9289, -5.3655]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.000857353210449\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7073, -6.4056, -1.2656, -5.5109, -5.4417, -4.0831, -5.7975, -0.4035,\n",
      "         -5.2473, -5.1629]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.797499656677246\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2245, -6.6152, -0.4990, -5.1550, -5.4254, -3.2673, -5.3394, -1.1615,\n",
      "         -5.5366, -4.9829]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.224534034729004\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0078, -6.8286, -0.3240, -4.8620, -5.4376, -2.5843, -4.9535, -2.1127,\n",
      "         -5.8235, -4.8491]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.1126835346221924\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8314, -6.9009, -0.6267, -4.4830, -5.3314, -1.9049, -4.4899, -2.1562,\n",
      "         -5.9635, -4.6134]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.48297119140625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9878, -7.0513, -1.4105, -3.5066, -5.3240, -1.4891, -4.1643, -2.3702,\n",
      "         -6.1760, -4.4925]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.176000118255615\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6713, -7.3240, -2.4483, -2.7852, -5.4576, -1.4208, -4.0182, -2.7724,\n",
      "         -5.7927, -4.5281]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.785226583480835\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8112, -7.5752, -3.4578, -1.4662, -5.5863, -1.5460, -3.9038, -3.1887,\n",
      "         -5.4544, -4.5728]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.8111803531646729\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8886, -8.2082, -4.7990, -0.8518, -6.1116, -2.2256, -4.2209, -4.0023,\n",
      "         -5.5590, -5.0268]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.8517785668373108\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6869, -9.1706, -6.4060, -0.2781, -6.9784, -3.3111, -4.9085, -5.1415,\n",
      "         -6.0478, -5.8323]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.405966758728027\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3739, -9.8542, -6.8668, -0.1296, -7.5766, -4.1331, -5.3495, -5.9890,\n",
      "         -6.3062, -6.3765]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.133114337921143\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5640, -9.9649, -6.7776, -0.1239, -7.6107, -3.6296, -5.2450, -6.2494,\n",
      "         -6.0352, -6.3629]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.777614593505859\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2721, -9.5384, -5.3832, -0.2211, -7.1156, -2.6695, -4.6280, -5.9592,\n",
      "         -5.2663, -5.8256]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.22106218338012695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2577, -9.3183, -4.2945, -0.3313, -6.8342, -2.0205, -4.2430, -5.8638,\n",
      "         -4.7414, -5.5076]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.2944560050964355\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1396, -8.9290, -2.3578, -0.7473, -6.3904, -1.3442, -3.7150, -5.5891,\n",
      "         -4.0835, -5.0330]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.7473093867301941\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5848, -9.0332, -1.1419, -1.2019, -6.4468, -1.3857, -3.7110, -5.7995,\n",
      "         -3.9578, -5.0649]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.95780086517334\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2538, -9.3329, -0.5033, -2.0301, -6.7045, -1.8167, -3.9300, -6.1971,\n",
      "         -3.3527, -5.3039]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.30388069152832\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8140, -9.5286, -0.3288, -2.7951, -6.8634, -2.2530, -4.0666, -6.4826,\n",
      "         -2.7580, -4.7359]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.758023738861084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1501, -9.5181, -0.5459, -3.3410, -6.8204, -2.5382, -4.0147, -6.5542,\n",
      "         -1.3770, -4.0434]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.014670372009277\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6469, -9.6897, -1.3709, -4.0390, -6.9635, -3.0358, -3.4714, -6.8007,\n",
      "         -0.4931, -3.6129]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.471365213394165\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2507, -9.9925, -2.4591, -4.8286, -7.2414, -3.6685, -2.4708, -7.1720,\n",
      "         -0.2796, -3.3925]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.392502546310425\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6561, -10.1224,  -3.3630,  -5.4029,  -7.3494,  -4.1150,  -1.4843,\n",
      "          -7.3641,  -0.4789,  -2.3687]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2.3686656951904297\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.2725, -10.4877,  -4.4527,  -6.1718,  -7.6955,  -4.7779,  -0.9997,\n",
      "          -7.7860,  -1.3417,  -1.0623]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.0623340606689453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.6716, -11.6590,  -6.2856,  -7.7082,  -8.8498,  -6.2236,  -1.6584,\n",
      "          -9.0086,  -3.1446,  -0.2725]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.28564453125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.9368, -12.7185,  -7.1646,  -9.0970,  -9.8941,  -7.5319,  -2.3871,\n",
      "         -10.1144,  -4.8037,  -0.1073]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.531899452209473\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.5674, -13.1637,  -7.4477,  -9.8391, -10.3256,  -7.4476,  -2.5974,\n",
      "         -10.6013,  -5.7949,  -0.0821]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.839065551757812\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.5514, -12.9806,  -7.1190,  -9.2097, -10.1302,  -6.7878,  -2.2539,\n",
      "         -10.4559,  -6.1059,  -0.1159]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.13021183013916\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.0377, -12.3163,  -6.3240,  -8.1432,  -8.6632,  -5.6947,  -1.5174,\n",
      "          -9.8254,  -5.8883,  -0.2586]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.5173794031143188\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.7117, -11.8544,  -5.7459,  -7.3193,  -7.4783,  -4.8491,  -0.4548,\n",
      "          -9.3942,  -5.8310,  -1.0500]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.478304386138916\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.6284, -11.6486,  -5.4378,  -6.7877,  -5.8437,  -4.3035,  -0.1440,\n",
      "          -9.2160,  -5.9917,  -2.2122]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.787734031677246\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.2203, -11.1300,  -4.8304,  -5.2707,  -4.0399,  -3.4888,  -0.1215,\n",
      "          -8.7224,  -5.8052,  -3.0014]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  11.129990577697754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5092, -9.6018, -3.9457, -3.5638, -2.0848, -2.4343, -0.3551, -7.9341,\n",
      "         -5.2956, -3.4030]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.295621395111084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.2305, -8.5864, -3.5251, -2.4075, -0.7828, -1.9121, -1.3974, -7.5857,\n",
      "         -4.4946, -4.1493]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.58566427230835\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.4734, -8.1651, -3.6625, -1.9230, -0.4644, -2.0471, -2.9967, -6.9687,\n",
      "         -4.2742, -5.3261]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.165143966674805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5573, -6.9416, -3.6709, -1.4551, -0.5364, -2.1312, -4.3360, -6.2781,\n",
      "         -3.9499, -6.2543]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.5572829246521\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5916, -5.6307, -3.4892, -0.9906, -0.8492, -2.0880, -5.3425, -5.4481,\n",
      "         -3.4622, -6.8827]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.882748603820801\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6078, -4.3372, -3.2345, -0.7217, -1.3494, -2.0285, -6.1378, -4.5888,\n",
      "         -2.9300, -6.6427]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.13775110244751\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6256, -3.0823, -2.9370, -0.7261, -1.9036, -1.9762, -6.0748, -3.7240,\n",
      "         -2.3896, -6.3286]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.625621795654297\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9372, -1.9912, -2.7173, -1.0797, -2.5261, -2.0413, -6.0263, -2.9708,\n",
      "         -1.9744, -6.0535]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.937187433242798\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0997, -1.5509, -3.0159, -2.0837, -3.5942, -2.6438, -6.4290, -2.7780,\n",
      "         -2.1436, -6.2520]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.1436362266540527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4057, -1.9938, -4.0108, -3.7641, -5.2655, -3.9282, -7.4802, -3.3415,\n",
      "         -2.3601, -7.1195]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.010817527770996\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.2507, -2.4119, -4.0621, -5.2159, -6.6966, -5.0216, -8.3490, -3.7988,\n",
      "         -2.5430, -7.8228]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.822804927825928\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.2848, -2.3922, -3.6609, -6.0669, -7.5261, -5.5510, -8.6710, -3.7680,\n",
      "         -2.3026, -7.3106]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.392220973968506\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6417, -1.4465, -3.0398, -6.5557, -7.9944, -5.7514, -8.6816, -3.4792,\n",
      "         -1.8772, -6.5699]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.4791805744171143\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4726, -0.8511, -2.6056, -7.0852, -8.5045, -6.0223, -8.7793, -2.5347,\n",
      "         -1.6904, -5.9914]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.779281616210938\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5038, -0.7193, -2.3709, -7.6616, -9.0631, -6.3671, -8.2899, -1.8458,\n",
      "         -1.7518, -5.5707]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.5037970542907715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6662, -0.9221, -2.2059, -8.1546, -9.5398, -6.6523, -7.8223, -1.3248,\n",
      "         -1.9035, -5.1675]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.3248274326324463\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1386,  -1.6591,  -2.4141,  -8.8696, -10.2399,  -7.1809,  -7.6720,\n",
      "          -0.5446,  -2.4168,  -5.0788]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.67198371887207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5783,  -2.4385,  -2.6515,  -9.4935, -10.8503,  -7.6373,  -6.8471,\n",
      "          -0.2851,  -2.9222,  -4.9826]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.9826273918151855\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6202,  -2.8266,  -2.5441,  -9.6790, -11.0236,  -7.6722,  -5.7280,\n",
      "          -0.2714,  -3.0393,  -3.8415]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  11.023639678955078\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2954,  -2.8346,  -2.1251,  -9.4621, -10.0079,  -7.3200,  -4.3378,\n",
      "          -0.4732,  -2.7948,  -2.4439]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.4732322096824646\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3467, -3.1982, -2.1558, -9.5811, -9.4071, -7.3175, -3.4083, -0.6722,\n",
      "         -2.9325, -1.5587]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.6722425222396851\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6960, -3.8299, -2.5496, -9.9631, -9.1406, -7.5905, -2.8680, -0.7415,\n",
      "         -3.3695, -1.1806]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.5495553016662598\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9390,  -4.3230,  -2.0898, -10.2158,  -8.8089,  -7.7452,  -2.3279,\n",
      "          -1.0857,  -3.6961,  -0.9598]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.6961488723754883\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1000,  -4.7033,  -1.6989, -10.3698,  -8.4365,  -7.8114,  -1.8337,\n",
      "          -1.5865,  -3.2218,  -0.9507]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.099955081939697\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4156,  -5.0086,  -1.4461, -10.4646,  -8.0572,  -7.8273,  -1.4529,\n",
      "          -2.1540,  -2.7787,  -1.1641]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.057175636291504\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7757,  -5.2423,  -1.3557, -10.4989,  -6.8829,  -7.7881,  -1.2193,\n",
      "          -2.7098,  -2.3698,  -1.5247]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.5247061252593994\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3226,  -5.5237,  -1.5453, -10.6068,  -5.9077,  -7.8353,  -1.2819,\n",
      "          -3.3305,  -2.1505,  -1.3788]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.3787530660629272\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1265,  -5.9172,  -2.0193, -10.8362,  -5.1609,  -8.0079,  -1.6609,\n",
      "          -4.0547,  -2.1655,  -0.8741]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.6608788967132568\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1052,  -6.3337,  -2.6106, -11.1030,  -4.5525,  -8.2235,  -1.5135,\n",
      "          -4.7807,  -2.3210,  -0.7649]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.7648657560348511\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3762,  -6.9027,  -3.3936, -11.5358,  -4.2052,  -8.6106,  -1.7223,\n",
      "          -5.6340,  -2.7237,  -0.4951]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.902706623077393\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4644,  -6.4651,  -3.8951, -11.6954,  -3.6736,  -8.7292,  -1.8010,\n",
      "          -6.1753,  -2.9032,  -0.4379]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.903223991394043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3856,  -5.8455,  -4.1365, -11.6128,  -2.9881,  -8.6096,  -1.7572,\n",
      "          -6.4382,  -2.1656,  -0.5984]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.7572128772735596\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4354,  -5.3362,  -4.4134, -11.5851,  -2.4570,  -8.5488,  -1.2057,\n",
      "          -6.7231,  -1.6295,  -1.1618]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.4353604316711426\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8929,  -5.0218,  -4.8135, -11.7013,  -2.1871,  -8.6353,  -1.0523,\n",
      "          -7.1219,  -1.4273,  -2.0224]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.4273052215576172\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7309,  -4.9497,  -5.3870, -12.0125,  -2.2391,  -8.9198,  -1.3565,\n",
      "          -7.6883,  -0.9134,  -3.0940]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.0940308570861816\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6842,  -4.8478,  -5.8651, -12.2507,  -2.3280,  -9.1341,  -1.7623,\n",
      "          -8.1568,  -0.6937,  -3.3678]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.3677866458892822\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6227,  -4.5938,  -6.1304, -12.2975,  -2.3175,  -9.1595,  -2.0761,\n",
      "          -8.4114,  -0.6829,  -2.7982]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.6828721761703491\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9020,  -4.5492,  -6.5479, -12.5165,  -2.5628,  -9.3593,  -2.6206,\n",
      "          -8.8177,  -0.4996,  -2.5028]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.359298706054688\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0277,  -4.2714,  -6.6800, -12.4686,  -2.5997,  -8.5130,  -2.9152,\n",
      "          -8.9388,  -0.5190,  -2.0464]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.680001735687256\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0201,  -3.8049,  -5.7851, -12.1992,  -2.4656,  -7.5243,  -2.9911,\n",
      "          -8.8216,  -0.7296,  -1.4960]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.465606212615967\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1244,  -3.4057,  -4.9862, -11.9614,  -1.6278,  -6.6388,  -3.0985,\n",
      "          -8.7211,  -1.2631,  -1.1559]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.405735492706299\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4077,  -2.4429,  -4.3653, -11.8406,  -1.1214,  -5.9356,  -3.3194,\n",
      "          -8.7242,  -2.0362,  -1.1551]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.3193740844726562\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7891,  -1.6920,  -3.8697, -11.7856,  -0.9760,  -5.3578,  -2.9187,\n",
      "          -8.7809,  -2.8786,  -1.4205]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.7890591621398926\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4112,  -1.1788,  -3.4696, -11.7660,  -1.1719,  -4.8710,  -2.6242,\n",
      "          -8.8621,  -3.7072,  -1.8523]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.7071855068206787\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1182,  -0.9150,  -3.1096, -11.7243,  -1.5681,  -4.4142,  -2.3838,\n",
      "          -8.9113,  -3.7390,  -2.3232]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.9150192737579346\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2252,  -0.5204,  -3.0956, -11.9617,  -2.3642,  -4.2872,  -2.5047,\n",
      "          -9.2307,  -4.0594,  -3.0885]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.230701446533203\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2435,  -0.4300,  -2.9544, -12.0111,  -2.9912,  -4.0192,  -2.5047,\n",
      "          -8.5583,  -4.1957,  -3.6445]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.6444597244262695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0783,  -0.5499,  -2.6021, -11.7892,  -3.3293,  -3.5254,  -2.2937,\n",
      "          -7.6862,  -4.0627,  -3.2207]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.078343391418457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2256,  -1.0621,  -2.3349, -11.5806,  -3.6536,  -3.0951,  -2.1635,\n",
      "          -6.8921,  -3.9463,  -2.8571]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.946329116821289\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7950,  -1.8748,  -2.2750, -11.4967,  -4.0702,  -2.8471,  -2.2283,\n",
      "          -6.2814,  -3.2581,  -2.6722]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.7949954867362976\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3914,  -3.1351,  -2.7211, -11.8392,  -4.8772,  -3.0878,  -2.7783,\n",
      "          -6.1508,  -3.0832,  -2.9703]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.877225399017334\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3364,  -4.0734,  -2.9468, -11.9193,  -4.5921,  -3.1122,  -3.0876,\n",
      "          -5.8064,  -2.7292,  -3.0451]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.112215042114258\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5583,  -4.6402,  -2.9013, -11.7006,  -4.0524,  -2.0932,  -3.1067,\n",
      "          -5.2076,  -2.1653,  -2.8538]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.8538272380828857\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2306,  -5.1825,  -2.9287, -11.5283,  -3.6043,  -1.2969,  -3.1791,\n",
      "          -4.6971,  -1.7626,  -2.0724]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.072406530380249\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4001,  -6.0103,  -3.3312, -11.7082,  -3.5570,  -1.1300,  -3.6078,\n",
      "          -4.5793,  -1.8555,  -1.1215]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.57933235168457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6850,  -6.9100,  -3.8596, -12.0232,  -3.6651,  -1.3948,  -4.1604,\n",
      "          -3.8169,  -2.1859,  -0.6361]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.6651432514190674\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8357,  -7.6600,  -4.2233, -12.2534,  -2.8381,  -1.8106,  -4.5885,\n",
      "          -2.9799,  -2.4313,  -0.5010]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  12.253448486328125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6598,  -8.1574,  -4.4596, -11.5349,  -2.0815,  -2.0920,  -4.8255,\n",
      "          -2.2139,  -2.6148,  -0.6051]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.825533866882324\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.3416,  -8.5422,  -4.6184, -10.8239,  -1.4342,  -2.3793,  -4.2976,\n",
      "          -1.5474,  -2.7683,  -0.9995]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.542208671569824\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.9902,  -8.2000,  -4.8023, -10.2164,  -1.0711,  -2.7442,  -3.8642,\n",
      "          -1.1498,  -2.9839,  -1.6329]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.20003604888916\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5081, -7.1137, -4.9073, -9.6017, -0.9457, -3.0564, -3.4207, -0.9772,\n",
      "         -3.1467, -2.2665]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.2664742469787598\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.8475, -6.0079, -4.8803, -8.9205, -1.0096, -3.2474, -2.9161, -0.9944,\n",
      "         -3.1963, -2.1106]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.9943705797195435\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.2984, -5.1581, -5.0068, -8.4515, -1.4970, -3.5949, -2.6431, -0.6530,\n",
      "         -3.4147, -2.1954]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.451480865478516\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.5265, -4.2183, -4.9479, -7.1129, -1.9330, -3.7515, -2.2677, -0.5808,\n",
      "         -3.4565, -2.1677]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.112852096557617\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.5234, -3.1735, -4.6919, -4.9720, -2.2306, -3.7025, -1.7919, -0.7497,\n",
      "         -3.3080, -2.0102]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.7496612071990967\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.7761, -2.5174, -4.7239, -3.3035, -2.8384, -3.9332, -1.7329, -0.7387,\n",
      "         -3.4554, -2.2129]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.303518772125244\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.1283, -2.1086, -4.8843, -1.2316, -3.5562, -4.2810, -1.9256, -1.2301,\n",
      "         -3.7351, -2.5929]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.9256246089935303\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.2122,  -2.5941,  -5.8014,  -0.3463,  -4.9920,  -5.3718,  -2.2804,\n",
      "          -2.6698,  -4.7706,  -3.7518]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.280421257019043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.3268,  -3.2234,  -6.7683,  -0.2090,  -6.4289,  -6.4964,  -2.1293,\n",
      "          -4.1596,  -5.8477,  -4.9497]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.20901519060134888\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.5217,  -4.0096,  -7.8309,  -0.1386,  -7.9155,  -7.7015,  -2.2648,\n",
      "          -5.7049,  -7.0108,  -6.2243]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.2648110389709473\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.1965,  -4.3293,  -8.3869,  -0.3113,  -8.8533,  -8.3858,  -1.3819,\n",
      "          -6.6980,  -7.6576,  -6.9722]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.386890411376953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.6408,  -4.4633,  -7.9182,  -0.8343,  -9.5348,  -8.8389,  -0.5937,\n",
      "          -7.4301,  -8.0771,  -7.4831]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.463254451751709\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.0325,  -3.8677,  -7.4875,  -1.6103, -10.1402,  -9.2385,  -0.2514,\n",
      "          -8.0815,  -8.4465,  -7.9351]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.140159606933594\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.0940,  -3.0549,  -6.8087,  -2.1626,  -9.6067,  -9.3074,  -0.1793,\n",
      "          -8.3773,  -8.4882,  -8.0512]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.054859161376953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.8855,  -1.3841,  -5.9339,  -2.4794,  -8.8622,  -9.1055,  -0.4127,\n",
      "          -8.3800,  -8.2620,  -7.8921]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.479360342025757\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.0466,  -0.4071,  -5.4969,  -2.4500,  -8.5404,  -9.2726,  -1.4145,\n",
      "          -8.7316,  -8.4073,  -8.0979]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.4072847366333\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.3492,  -0.1611,  -5.2640,  -2.6432,  -8.4081,  -9.5808,  -2.6375,\n",
      "          -9.2060,  -7.9809,  -8.4410]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  9.580763816833496\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.2169,  -0.1395,  -4.6534,  -2.4637,  -7.8842,  -8.6563,  -3.3826,\n",
      "          -9.2285,  -7.1921,  -8.3454]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.13954783976078033\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.1957,  -0.1258,  -4.2090,  -2.4614,  -7.5105,  -7.9216,  -4.1746,\n",
      "          -9.3468,  -6.5799,  -8.3574]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.51048469543457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.6567,  -0.2146,  -3.3008,  -2.0010,  -5.8752,  -6.7400,  -4.3787,\n",
      "          -8.9336,  -5.5095,  -7.8484]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  13.656658172607422\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.0543,  -0.5406,  -2.1952,  -1.3668,  -4.0868,  -5.3591,  -4.2537,\n",
      "          -8.2442,  -4.2307,  -7.0729]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.359100341796875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.7262,  -1.3553,  -1.4053,  -1.0953,  -2.6042,  -3.4472,  -4.2663,\n",
      "          -7.7388,  -3.2046,  -6.4902]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.4472270011901855\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.0041,  -2.7438,  -1.3678,  -1.5668,  -1.8009,  -1.4494,  -4.7615,\n",
      "          -7.7582,  -2.7836,  -6.4407]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.80085027217865\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.1746,  -4.8610,  -2.3624,  -2.9637,  -1.2516,  -0.6558,  -6.0345,\n",
      "          -8.5970,  -3.2699,  -7.2183]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.034468650817871\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.4728,  -6.9184,  -3.4798,  -4.4041,  -1.1252,  -0.4959,  -6.6512,\n",
      "          -9.4975,  -3.8800,  -8.0639]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.651238918304443\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.4478,  -8.4791,  -4.2180,  -5.4171,  -0.9715,  -0.5376,  -6.2466,\n",
      "         -10.0152,  -4.1508,  -8.5323]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.246604919433594\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.0783,  -9.5383,  -4.5481,  -5.9860,  -0.7817,  -0.6851,  -4.8769,\n",
      "         -10.1346,  -4.0591,  -8.6073]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.059145927429199\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.4600, -10.2071,  -4.5686,  -6.2148,  -0.6819,  -0.9250,  -3.3624,\n",
      "          -9.9568,  -2.9876,  -8.3896]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  10.207145690917969\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.7758, -9.9758, -4.4685, -6.2954, -0.8577, -1.3223, -1.8940, -9.6695,\n",
      "         -1.9313, -8.0666]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.3222837448120117\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.5348, -10.1425,  -4.7629,  -6.7444,  -1.7199,  -1.4828,  -1.0466,\n",
      "          -9.7858,  -1.4589,  -8.1509]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.785821914672852\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4497, -10.4248,  -5.1671,  -7.2818,  -2.7677,  -1.9355,  -0.6499,\n",
      "          -9.2214,  -1.3326,  -8.3590]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.767693519592285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.2818, -10.5876,  -5.4445,  -7.6751,  -2.8903,  -2.3641,  -0.5498,\n",
      "          -8.6215,  -1.3171,  -8.4552]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.455227851867676\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.8640, -10.4677,  -5.4313,  -7.7630,  -2.7770,  -2.5565,  -0.5771,\n",
      "          -7.8144,  -1.2291,  -7.5939]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.814406394958496\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.2259, -10.0975,  -5.1609,  -7.5805,  -2.4609,  -2.5283,  -0.7122,\n",
      "          -6.0358,  -1.0982,  -6.5563]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.4609289169311523\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5898, -9.7023, -4.8602, -7.3546, -1.4108, -2.5031, -1.0970, -4.3735,\n",
      "         -1.1581, -5.5606]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.860236644744873\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1287, -9.4573, -3.8890, -7.2625, -0.7634, -2.6552, -1.7759, -2.9969,\n",
      "         -1.5487, -4.7772]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.775855302810669\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8678, -9.3892, -3.1834, -7.3328, -0.6914, -2.9998, -1.9862, -1.9492,\n",
      "         -2.2060, -4.2298]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.332767486572266\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6249, -9.3178, -2.5714, -6.6560, -1.0003, -3.3389, -2.2563, -1.1089,\n",
      "         -2.8674, -3.7364]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.656022548675537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4605, -9.3051, -2.1343, -5.3793, -1.6116, -3.7238, -2.6207, -0.6675,\n",
      "         -3.5559, -3.3598]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.5558648109436035\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2429, -9.2207, -1.7644, -4.1594, -2.2423, -4.0165, -2.9242, -0.6066,\n",
      "         -3.4016, -2.9713]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  9.22066879272461\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8888, -8.2785, -1.4093, -2.9094, -2.7297, -4.1319, -3.0711, -0.8228,\n",
      "         -3.1243, -2.4942]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.888825416564941\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7524, -7.4137, -1.2737, -1.8066, -3.2028, -4.2324, -3.2180, -1.3497,\n",
      "         -2.8899, -2.1051]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.2027792930603027\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9040, -6.7915, -1.5375, -1.0891, -3.0479, -4.4908, -3.5336, -2.1866,\n",
      "         -2.8751, -1.9948]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.9039711952209473\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5858, -6.4302, -2.1498, -0.8861, -3.1431, -4.9309, -4.0358, -3.2283,\n",
      "         -3.1009, -2.1876]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.1430511474609375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7742, -6.3169, -3.0082, -1.2141, -2.7144, -5.5442, -4.7111, -4.4094,\n",
      "         -3.5478, -2.6497]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.409359931945801\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4490, -6.2501, -3.8561, -1.7593, -2.4126, -6.1337, -5.3594, -4.7199,\n",
      "         -4.0051, -3.1487]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.005128860473633\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4311, -5.9535, -4.3997, -2.1378, -1.9710, -6.4288, -5.7090, -4.7689,\n",
      "         -3.4752, -3.3902]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.475222110748291\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7161, -5.4711, -4.6825, -2.3476, -1.4621, -6.4788, -5.8090, -4.6028,\n",
      "         -2.0949, -3.4140]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.682473182678223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4547, -5.1332, -4.2179, -2.6999, -1.2739, -6.6189, -5.9949, -4.5548,\n",
      "         -1.0330, -3.5520]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.4547169208526611\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7887, -5.1130, -4.0915, -3.3463, -1.5973, -7.0262, -6.4441, -4.7999,\n",
      "         -0.6107, -3.9762]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.6107136011123657\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5595, -5.4365, -4.3287, -4.2918, -2.3803, -7.7313, -7.1873, -5.3647,\n",
      "         -0.2433, -4.7088]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.3802852630615234\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0649, -5.4806, -4.3027, -4.9032, -2.1469, -8.1163, -7.6069, -5.6268,\n",
      "         -0.2219, -5.1246]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.903195858001709\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1382, -5.1042, -3.8713, -4.3122, -1.6060, -8.0444, -7.5661, -5.4467,\n",
      "         -0.3505, -5.0843]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.566124439239502\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9854, -4.5161, -3.2464, -3.5361, -1.0177, -7.7265, -6.6069, -5.0345,\n",
      "         -0.7082, -4.7989]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.0176749229431152\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2723, -4.3785, -3.0998, -3.2425, -0.3898, -7.8249, -6.1280, -5.0528,\n",
      "         -1.7602, -4.9320]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.378512382507324\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5050, -3.4992, -2.9488, -2.9504, -0.2807, -7.8579, -5.6420, -5.0184,\n",
      "         -2.7729, -5.0009]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.95035982131958\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5117, -2.5015, -2.6289, -1.7764, -0.5227, -7.6609, -4.9796, -4.7656,\n",
      "         -3.5024, -4.8406]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.628854751586914\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7317, -1.8511, -1.7734, -1.0317, -1.3738, -7.6740, -4.5776, -4.7349,\n",
      "         -4.3710, -4.8920]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.7734020948410034\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4561, -1.8841, -0.8408, -1.1264, -2.8369, -8.1932, -4.7294, -5.2214,\n",
      "         -5.6695, -5.4506]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.1263713836669922\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4221, -2.3260, -0.6569, -1.0291, -4.5030, -8.9653, -5.1762, -5.9681,\n",
      "         -7.1459, -6.2609]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.422086238861084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2473, -2.5407, -0.6600, -0.9471, -5.7593, -9.4079, -5.3295, -6.3897,\n",
      "         -8.2235, -6.7392]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.6600407361984253\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2350, -2.9313, -0.4140, -1.2946, -7.0345, -9.9477, -5.6118, -6.9119,\n",
      "         -9.3355, -7.3120]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.931281805038452\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.9138,  -2.2983,  -0.4135,  -1.4910,  -7.8695, -10.1196,  -5.5542,\n",
      "          -7.0687, -10.0229,  -7.5139]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.554189205169678\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3204,  -1.4897,  -0.6349,  -1.5209,  -8.3123,  -9.9648,  -4.5255,\n",
      "          -6.9010, -10.3324,  -7.3866]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.5209224224090576\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8985,  -1.0234,  -1.3604,  -1.0865,  -8.8135,  -9.9274,  -3.7081,\n",
      "          -6.8527, -10.7134,  -7.3743]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.713409423828125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5396,  -0.8639,  -2.2244,  -0.9434,  -9.2702,  -9.8988,  -2.9932,\n",
      "          -6.8151, -10.3524,  -7.3687]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.2244060039520264\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1675, -0.9475, -2.2138, -1.0226, -9.6097, -9.8011, -2.3110, -6.7101,\n",
      "         -9.9551, -7.2922]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.292193412780762\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7201, -1.1518, -2.1455, -1.2067, -9.7698, -9.5673, -1.6173, -6.4707,\n",
      "         -9.4515, -6.3772]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.4706878662109375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3227, -1.5129, -2.1304, -1.5407, -9.8671, -9.3097, -1.0791, -5.4085,\n",
      "         -8.9507, -5.5070]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.5406601428985596\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1513,  -2.1029,  -2.3201,  -1.3835, -10.0633,  -9.1861,  -0.9317,\n",
      "          -4.5632,  -8.6075,  -4.8340]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.186117172241211\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9729,  -2.6034,  -2.4517,  -1.3049, -10.1223,  -8.1569,  -0.9474,\n",
      "          -3.6931,  -8.1821,  -4.1164]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.4517409801483154\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8919,  -3.0755,  -1.8107,  -1.3968, -10.1441,  -7.1984,  -1.1908,\n",
      "          -2.8975,  -7.7670,  -3.4496]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.144060134887695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9254, -3.5191, -1.3486, -1.6425, -9.3934, -6.3209, -1.6002, -2.2105,\n",
      "         -7.3788, -2.8567]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.85667085647583\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1706, -4.0379, -1.2368, -2.1008, -8.8151, -5.6298, -2.2030, -1.7778,\n",
      "         -7.1274, -1.7628]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.2367942333221436\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8370, -4.8717, -0.9279, -2.9554, -8.6481, -5.3640, -3.1745, -1.8780,\n",
      "         -7.2555, -1.2516]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.25546932220459\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4414, -5.5853, -0.9202, -3.7197, -8.4547, -5.0852, -4.0349, -2.0484,\n",
      "         -6.6211, -0.9488]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.048384189605713\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9635, -6.1827, -1.1805, -4.3776, -8.2325, -4.7908, -4.7738, -1.4564,\n",
      "         -6.0023, -0.8996]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.790796279907227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3352, -6.6083, -1.5439, -4.8653, -7.9185, -3.6235, -5.3312, -0.9962,\n",
      "         -5.3327, -1.0264]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.60832405090332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5725, -6.1706, -1.9321, -5.2022, -7.5278, -2.4850, -5.7285, -0.7696,\n",
      "         -4.6247, -1.2834]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.728516101837158\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7120, -5.6952, -2.3138, -5.4270, -7.0936, -1.4435, -5.3289, -0.8535,\n",
      "         -3.9112, -1.6262]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.9112114906311035\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9141, -5.3384, -2.8052, -5.7019, -6.7722, -0.7637, -5.0412, -1.3382,\n",
      "         -2.6488, -2.1421]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.041222095489502\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1763, -5.0947, -3.3702, -6.0262, -6.5578, -0.5990, -4.1910, -2.0585,\n",
      "         -1.6359, -2.7634]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.176349639892578\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6142, -4.8811, -3.9081, -6.3218, -6.3674, -0.8909, -3.4368, -2.8111,\n",
      "         -0.8630, -3.3691]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.8110880851745605\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1571, -4.7357, -4.4502, -6.6309, -6.2387, -1.5220, -2.8205, -2.7784,\n",
      "         -0.5076, -3.9805]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.980520725250244\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6200, -4.4730, -4.8099, -6.7723, -5.9862, -2.1265, -2.1674, -2.6603,\n",
      "         -0.4753, -3.7037]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.1264760494232178\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0691, -4.1558, -5.0518, -6.8119, -5.6721, -1.8796, -1.5676, -2.5209,\n",
      "         -0.7955, -3.3828]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.382824182510376\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6155, -3.8867, -5.2801, -6.8538, -5.3970, -1.7836, -1.1732, -2.4648,\n",
      "         -1.4065, -2.4279]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.4647634029388428\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4131, -3.8062, -5.6372, -7.0395, -5.3000, -1.9777, -1.1738, -1.8369,\n",
      "         -2.2765, -1.7763]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.9777233600616455\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4634, -3.9100, -6.1221, -7.3679, -5.3768, -1.6319, -1.5433, -1.5579,\n",
      "         -3.2931, -1.4678]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.3767619132995605\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5461, -3.9866, -6.5293, -7.6327, -4.6587, -1.4436, -1.9888, -1.4421,\n",
      "         -4.2037, -1.3193]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.203727722167969\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5839, -3.9688, -6.7972, -7.7716, -3.9190, -1.3604, -2.3825, -1.4251,\n",
      "         -4.2276, -1.2720]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.968775749206543\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5621, -3.1347, -6.9226, -7.7801, -3.1509, -1.3714, -2.6827, -1.4836,\n",
      "         -4.1426, -1.3082]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.9225945472717285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5186, -2.3280, -6.1531, -7.7018, -2.4051, -1.4955, -2.9131, -1.6298,\n",
      "         -3.9907, -1.4431]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.40513277053833\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7084, -1.8348, -5.6253, -7.7952, -1.2113, -1.9481, -3.3210, -2.0805,\n",
      "         -4.0306, -1.8931]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.0805234909057617\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2411, -1.8127, -5.4603, -8.1873, -0.6700, -2.7763, -4.0207, -2.1010,\n",
      "         -4.3867, -2.7114]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.7114405632019043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7099, -1.8670, -5.2722, -8.4979, -0.5284, -3.5288, -4.6203, -2.1733,\n",
      "         -4.6735, -2.7536]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.8670263290405273\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0502, -1.2112, -5.0050, -8.6760, -0.7452, -4.1282, -5.0653, -2.2264,\n",
      "         -4.8365, -2.7341]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.7341246604919434\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3402, -0.8028, -4.7388, -8.8058, -1.2676, -4.6501, -5.4397, -2.3288,\n",
      "         -4.9582, -2.0389]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.4397125244140625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5672, -0.7106, -4.4612, -8.8779, -1.9056, -5.0830, -5.0571, -2.4533,\n",
      "         -5.0279, -1.4580]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.905585527420044\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7636, -0.9616, -4.2037, -8.9264, -1.8211, -5.4614, -4.7002, -2.6170,\n",
      "         -5.0788, -1.0797]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.079726219177246\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1683, -1.6810, -4.2045, -9.1910, -2.0874, -6.0265, -4.6056, -3.0432,\n",
      "         -5.3498, -0.5038]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.168308734893799\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6352, -2.3703, -4.1257, -9.3379, -2.3291, -6.4459, -4.4357, -3.3734,\n",
      "         -5.5058, -0.3127]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.505819320678711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8393, -2.7345, -3.7441, -9.1468, -2.2965, -6.5014, -3.9670, -3.3746,\n",
      "         -4.6205, -0.3220]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.146791458129883\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8373, -2.8065, -3.1168, -7.9379, -2.0405, -6.2502, -3.2553, -3.1004,\n",
      "         -3.5275, -0.5251]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.5274698734283447\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0113, -2.9438, -2.6166, -6.8782, -1.9371, -6.0547, -2.6695, -2.9184,\n",
      "         -1.8948, -1.1416]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.878230094909668\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7577, -3.4870, -2.6064, -5.5808, -2.3343, -6.2621, -2.5706, -3.1793,\n",
      "         -0.9114, -2.2972]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.58079719543457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8885, -4.2173, -2.8759, -3.9179, -2.9845, -6.6696, -2.7528, -3.6666,\n",
      "         -0.5277, -3.6263]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2.984499454498291\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0688, -4.8253, -3.1035, -2.3737, -2.7942, -6.9772, -2.8999, -4.0654,\n",
      "         -0.5362, -4.7815]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.977160930633545\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3382, -5.3829, -3.3489, -1.0544, -2.6728, -6.4627, -3.0740, -4.4425,\n",
      "         -0.9576, -5.8320]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.0740175247192383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9584, -6.1874, -3.8972, -0.4190, -2.9142, -6.2993, -2.8819, -5.0905,\n",
      "         -1.9042, -7.0793]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.41901129484176636\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0925, -7.4467, -4.9407, -0.1320, -3.7057, -6.6867, -3.2800, -6.2123,\n",
      "         -3.3944, -8.7366]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.7056515216827393\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7249, -8.1788, -5.4837, -0.1101, -3.2874, -6.6338, -3.2613, -6.8216,\n",
      "         -4.3574, -9.8268]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.2613489627838135\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8256,  -8.3622,  -5.4999,  -0.2607,  -2.4624,  -6.1109,  -2.1200,\n",
      "          -6.8952,  -4.7578, -10.3328]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.26065826416015625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1800,  -8.7847,  -5.7750,  -0.4882,  -2.0401,  -5.8988,  -1.4302,\n",
      "          -7.2194,  -5.3815, -11.0457]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  11.045693397521973\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3829,  -9.0445,  -5.9043,  -1.0127,  -1.6362,  -5.5889,  -0.8503,\n",
      "          -7.3910,  -5.8257, -10.8760]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.904331207275391\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5415,  -9.2506,  -5.1893,  -1.7177,  -1.3905,  -5.2848,  -0.5900,\n",
      "          -7.5182,  -6.2000, -10.6952]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.541486740112305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7108,  -9.2732,  -4.3865,  -2.3184,  -1.1930,  -4.8517,  -0.5681,\n",
      "          -7.4701,  -6.3754, -10.3692]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  10.369241714477539\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7392, -9.0631, -3.4427, -2.6998, -1.0121, -4.2373, -0.7005, -7.1966,\n",
      "         -6.3041, -9.1612]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.304144859313965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7154, -8.7061, -2.4505, -2.9239, -0.9538, -3.5275, -0.9865, -6.7830,\n",
      "         -5.3708, -7.9051]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.9239163398742676\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8840, -8.4216, -1.6634, -2.4811, -1.2269, -2.9488, -1.5324, -6.4484,\n",
      "         -4.5703, -6.8109]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.5323889255523682\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4835, -8.3899, -1.3321, -2.3665, -1.9169, -2.6940, -1.7171, -6.3726,\n",
      "         -4.0809, -6.0503]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.483535647392273\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7681, -8.6329, -1.5185, -2.6020, -2.9202, -2.7903, -2.2758, -6.5771,\n",
      "         -3.9232, -5.6382]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.923231363296509\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5030, -8.8539, -1.8656, -2.8691, -3.8664, -2.9283, -2.8503, -6.7644,\n",
      "         -3.1002, -5.2712]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.9283359050750732\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5982, -8.8970, -2.1475, -2.9946, -4.5786, -2.1397, -3.2510, -6.7781,\n",
      "         -2.2343, -4.7882]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.139690637588501\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3032, -9.1121, -2.6721, -3.3197, -5.4039, -0.9088, -3.8141, -6.9674,\n",
      "         -1.7053, -4.5349]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.9087643027305603\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0423, -10.1910,  -4.0858,  -4.5237,  -7.0359,  -0.2155,  -5.2213,\n",
      "          -8.0237,  -2.2412,  -5.1991]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.035895347595215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5124, -11.0278,  -5.2379,  -5.4810,  -7.6187,  -0.1009,  -6.3577,\n",
      "          -8.8405,  -2.6634,  -5.6663]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  11.027790069580078\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.2399, -10.4493,  -5.6744,  -5.7407,  -7.5383,  -0.1066,  -6.7768,\n",
      "          -8.9707,  -2.4869,  -5.4837]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.7767744064331055\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3024, -9.3310, -5.4732, -5.3797, -6.8691, -0.2155, -5.8820, -8.4909,\n",
      "         -1.7892, -4.7250]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.490913391113281\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0251, -7.9860, -4.9577, -4.7203, -5.9294, -0.5982, -4.7401, -6.9133,\n",
      "         -0.9404, -3.7100]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.740126609802246\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8266, -6.8207, -4.5452, -4.1788, -5.1309, -1.4120, -3.0944, -5.5390,\n",
      "         -0.4962, -2.8587]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.8207244873046875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7347, -5.1319, -4.2625, -3.7823, -4.4964, -2.4135, -1.7226, -4.3845,\n",
      "         -0.6029, -2.2119]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.13187837600708\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8970, -3.1414, -4.2573, -3.6796, -4.1711, -3.6229, -0.8449, -3.5925,\n",
      "         -1.3190, -1.9432]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.622929334640503\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3747, -1.7050, -4.5897, -3.9309, -4.2152, -4.2781, -0.6691, -3.2268,\n",
      "         -2.4766, -2.1263]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.1262588500976562\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0878, -0.8211, -5.1764, -4.4504, -4.5450, -5.1580, -1.1340, -3.2085,\n",
      "         -3.8573, -1.9603]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.176365852355957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8278, -0.4389, -4.9923, -5.0227, -4.9459, -6.0508, -1.8646, -3.3207,\n",
      "         -5.2117, -2.0041]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.050775051116943\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.2903, -0.3547, -4.6270, -5.3380, -5.1074, -5.8827, -2.4218, -3.2460,\n",
      "         -6.2305, -1.9319]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.2459771633148193\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.4393, -0.5141, -4.0377, -5.3574, -4.9893, -5.4653, -2.7154, -2.1374,\n",
      "         -6.8817, -1.6994]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.7153639793395996\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5454, -1.0560, -3.4926, -5.3496, -4.8594, -5.0639, -2.3239, -1.2054,\n",
      "         -7.4403, -1.5881]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.349630355834961\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.7495, -1.9004, -3.1343, -4.7295, -4.8563, -4.8152, -2.1449, -0.7163,\n",
      "         -8.0520, -1.7380]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.856332778930664\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.8694, -2.7037, -2.7828, -4.1130, -4.0428, -4.5331, -1.9979, -0.6064,\n",
      "         -8.5390, -1.9308]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.9308490753173828\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.9160, -3.4136, -2.4549, -3.5077, -3.2615, -4.2256, -1.8948, -0.8847,\n",
      "         -8.9161, -1.4498]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.915957450866699\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.1012, -4.0334, -2.1863, -2.9410, -2.5432, -3.9165, -1.8597, -1.4237,\n",
      "         -9.2126, -1.1358]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  9.212626457214355\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3704, -4.6069, -2.0386, -2.4713, -1.9580, -3.6558, -1.9352, -2.1052,\n",
      "         -8.7770, -1.0781]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.9351983070373535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8031, -5.2204, -2.1017, -2.1993, -1.6271, -3.5307, -1.5189, -2.9068,\n",
      "         -8.4744, -1.3515]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.1017045974731445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3941, -5.8765, -1.5443, -2.1346, -1.5771, -3.5401, -1.3903, -3.7725,\n",
      "         -8.3015, -1.8768]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.3903117179870605\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2038, -6.6440, -1.3904, -2.3368, -1.8627, -3.7454, -0.9474, -4.7453,\n",
      "         -8.3203, -2.6305]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.643983840942383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9606, -6.5416, -1.3782, -2.5133, -2.1612, -3.8725, -0.7321, -5.5525,\n",
      "         -8.2612, -3.2833]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.513345718383789\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6386, -6.3416, -1.4636, -1.8969, -2.4085, -3.8943, -0.7512, -6.1740,\n",
      "         -8.0995, -3.7887]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.4085497856140137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2983, -6.1047, -1.6708, -1.3926, -1.8869, -3.8716, -1.0254, -6.6776,\n",
      "         -7.8959, -4.2017]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.8716342449188232\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9776, -5.8675, -1.9852, -1.0935, -1.5059, -3.0724, -1.4865, -7.1069,\n",
      "         -7.6875, -4.5589]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  7.106904983520508\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6616, -5.6135, -2.3379, -1.0252, -1.2876, -2.3456, -2.0104, -6.6446,\n",
      "         -7.4577, -4.8455]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.457674026489258\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3221, -5.3114, -2.6584, -1.1481, -1.2231, -1.6888, -2.4960, -6.1532,\n",
      "         -6.4724, -5.0332]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.4959664344787598\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0250, -5.0219, -2.9834, -1.4682, -1.3660, -1.2190, -2.2983, -5.6914,\n",
      "         -5.5651, -5.1860]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.186024188995361\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7266, -4.6952, -3.2468, -1.8531, -1.6164, -0.9532, -2.1166, -5.2075,\n",
      "         -4.6798, -4.5606]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.1165642738342285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5350, -4.4309, -3.5395, -2.3372, -2.0153, -1.0347, -1.3921, -4.7994,\n",
      "         -3.9124, -4.0279]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.027926445007324\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4581, -4.2319, -3.8573, -2.8739, -2.5057, -1.4123, -0.9352, -4.4689,\n",
      "         -3.2655, -2.9017]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.4122569561004639\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6380, -4.2418, -4.3395, -3.5773, -3.1878, -1.3478, -0.9633, -4.3591,\n",
      "         -2.8885, -2.1039]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.241760730743408\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8224, -3.5073, -4.7480, -4.1947, -3.7969, -1.4529, -1.2057, -4.2339,\n",
      "         -2.5517, -1.4332]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.796891212463379\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0450, -2.8747, -5.1306, -4.7692, -3.6140, -1.7348, -1.6303, -4.1403,\n",
      "         -2.3109, -1.0018]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.130584239959717\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2517, -2.3122, -4.6298, -5.2599, -3.4364, -2.0912, -2.1099, -4.0357,\n",
      "         -2.1311, -0.8348]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.4363794326782227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4243, -1.8312, -4.1411, -5.6601, -2.5083, -2.4619, -2.5770, -3.9103,\n",
      "         -2.0077, -0.9396]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.9395626187324524\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8347, -1.7413, -3.9419, -6.2512, -1.9611, -3.0894, -3.2763, -4.0415,\n",
      "         -2.2199, -0.8403]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.041507244110107\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1450, -1.7093, -3.7009, -6.7078, -1.4965, -3.6126, -3.8543, -3.2918,\n",
      "         -2.4110, -0.9722]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.707761287689209\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3586, -1.7320, -3.4251, -6.3107, -1.1669, -4.0257, -4.3100, -2.5675,\n",
      "         -2.5678, -1.2735]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.5675125122070312\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6614, -1.9798, -3.3029, -6.0540, -1.2032, -4.5113, -4.8292, -1.2806,\n",
      "         -2.8634, -1.8379]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.6614179611206055\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3321, -2.5172, -3.4374, -6.0391, -1.6755, -5.1717, -5.5168, -0.5592,\n",
      "         -3.3848, -2.6709]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.516841411590576\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9967, -3.0099, -3.5353, -5.9777, -2.1918, -5.7215, -5.4220, -0.3191,\n",
      "         -3.8291, -3.4196]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.421973705291748\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3459, -3.1257, -3.2837, -5.5605, -2.3770, -5.8555, -4.3157, -0.3197,\n",
      "         -3.8810, -3.7530]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.125702381134033\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4985, -2.2505, -2.7975, -4.8972, -2.3232, -5.6881, -3.0376, -0.6052,\n",
      "         -3.6522, -3.7793]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.6052355766296387\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1309, -1.8660, -2.7376, -4.6331, -2.6763, -5.8680, -2.2461, -0.8295,\n",
      "         -3.7926, -4.1468]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.6763148307800293\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9081, -1.6412, -2.7469, -4.4125, -2.3059, -6.0423, -1.6134, -1.3867,\n",
      "         -3.9453, -4.4989]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.412490367889404\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8749, -1.6232, -2.8530, -3.5407, -2.0916, -6.2460, -1.2208, -2.1311,\n",
      "         -4.1417, -4.8688]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.8748955726623535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2980, -1.8981, -3.1448, -2.9252, -2.1399, -6.5798, -1.2120, -3.0445,\n",
      "         -4.4787, -5.3561]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.1399128437042236\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0889, -2.3394, -3.5287, -2.4955, -1.6122, -6.9672, -1.4875, -3.9907,\n",
      "         -4.8760, -5.8839]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.4954946041107178\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2432, -2.8720, -3.9643, -1.5120, -1.3512, -7.3824, -1.9514, -4.9232,\n",
      "         -5.3049, -6.4268]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.9643468856811523\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6952, -3.4686, -3.6282, -0.8622, -1.3852, -7.8328, -2.5396, -5.8449,\n",
      "         -5.7706, -6.9929]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.3852410316467285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4248, -4.1999, -3.5186, -0.7557, -1.0311, -8.4102, -3.2934, -6.8488,\n",
      "         -6.3638, -7.6748]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.410152435302734\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9878, -4.7025, -3.2771, -0.8341, -0.8109, -7.9870, -3.8302, -7.5869,\n",
      "         -6.7324, -8.1224]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.732390880584717\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2892, -4.9146, -2.8433, -0.9723, -0.6960, -7.3588, -4.0810, -8.0051,\n",
      "         -6.1016, -8.2786]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.8432719707489014\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4558, -4.9753, -1.5524, -1.2351, -0.8269, -6.6577, -4.1824, -8.2463,\n",
      "         -5.3993, -8.2837]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.24629020690918\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7229, -5.1259, -0.6535, -1.7732, -1.3598, -6.1181, -4.3750, -7.7599,\n",
      "         -4.8609, -8.3795]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.6535249948501587\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6767, -5.9591, -0.1479, -3.0742, -2.7232, -6.3270, -5.2501, -8.0154,\n",
      "         -5.0746, -9.1591]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.7232437133789062\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2406, -6.4086, -0.0947, -3.9769, -2.9550, -6.2136, -5.7390, -7.9429,\n",
      "         -4.9687, -9.5586]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.9549875259399414\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1867, -6.2485, -0.2143, -4.2373, -1.9024, -5.5467, -5.6152, -7.3115,\n",
      "         -4.3120, -9.3522]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.311495304107666\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8982, -5.8611, -0.7212, -4.2378, -0.8192, -4.7045, -5.2616, -5.7133,\n",
      "         -3.4855, -8.9218]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.921754837036133\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8155, -5.6851, -1.7356, -4.4197, -0.3386, -4.1238, -5.1175, -4.4473,\n",
      "         -2.9340, -8.0046]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.4197211265563965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6444, -5.4259, -2.6869, -3.7625, -0.3245, -3.5101, -4.8885, -3.2129,\n",
      "         -2.3723, -7.0754]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.075372695922852\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3299, -5.0271, -3.4298, -3.0189, -0.6694, -2.8123, -4.5189, -1.9642,\n",
      "         -1.7652, -5.3772]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.027061462402344\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2361, -4.1242, -4.3035, -2.5630, -1.5304, -2.4092, -4.3718, -1.1289,\n",
      "         -1.5204, -4.0293]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.029256820678711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4019, -3.5610, -5.3397, -2.4465, -2.7018, -2.3550, -4.4861, -0.8709,\n",
      "         -1.6961, -2.3784]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.44653058052063\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8006, -3.3134, -6.5162, -1.9221, -4.0450, -2.6197, -4.8358, -1.2086,\n",
      "         -2.2260, -1.1948]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.2085988521575928\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5612, -3.5114, -7.9716, -1.9499, -5.6623, -3.3098, -5.5506, -1.3546,\n",
      "         -3.1759, -0.7340]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.662308692932129\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1402, -3.6023, -9.1737, -1.9687, -6.2800, -3.8509, -6.0880, -1.5804,\n",
      "         -3.9526, -0.5442]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.850916862487793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4315,  -3.4720, -10.0245,  -1.8545,  -6.6056,  -3.3417,  -6.3415,\n",
      "          -1.7140,  -4.4341,  -0.5443]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.5442919731140137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8516,  -3.5335, -10.9472,  -2.0213,  -7.0563,  -3.0670,  -6.7273,\n",
      "          -2.1327,  -5.0326,  -0.4101]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.41011273860931396\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.4241,  -3.8035, -11.9717,  -2.4608,  -7.6561,  -3.0491,  -7.2689,\n",
      "          -2.7966,  -5.7698,  -0.2497]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  11.971721649169922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.5497,  -3.6725, -11.6994,  -2.5280,  -7.8062,  -2.6795,  -7.3667,\n",
      "          -3.0524,  -6.0456,  -0.2549]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.679548740386963\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.4247,  -3.3344, -11.2154,  -2.4078,  -7.7029,  -1.3863,  -7.2165,\n",
      "          -3.0813,  -6.0570,  -0.5546]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.216462135314941\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.4474,  -3.1908, -10.9144,  -2.4998,  -7.7452,  -0.5512,  -6.5411,\n",
      "          -3.2787,  -6.2039,  -1.3535]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.20393705368042\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.5077,  -3.1310, -10.6826,  -2.6817,  -7.8229,  -0.2875,  -5.9730,\n",
      "          -3.5256,  -5.6523,  -2.2899]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.681652545928955\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.2949,  -2.8415, -10.2061,  -1.9032,  -7.6256,  -0.3637,  -5.1954,\n",
      "          -3.5037,  -4.8904,  -2.9355]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.9355146884918213\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.9258, -2.4458, -9.5991, -1.1320, -7.2703, -0.7892, -4.3208, -3.3300,\n",
      "         -4.0316, -2.6854]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.270300388336182\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6319, -2.1907, -9.0900, -0.7086, -6.2608, -1.5591, -3.5796, -3.2397,\n",
      "         -3.3086, -2.5447]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.239655017852783\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3955, -2.0704, -8.6587, -0.7105, -5.3800, -2.4415, -2.9581, -2.4259,\n",
      "         -2.7110, -2.4989]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.395470142364502\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3204, -2.0274, -8.2429, -1.0393, -4.5624, -3.2760, -2.4060, -1.7352,\n",
      "         -2.1935, -2.4867]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.276031970977783\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4228, -2.1524, -7.9354, -1.6574, -3.9004, -3.3494, -2.0366, -1.3191,\n",
      "         -1.8751, -2.5997]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.8751413822174072\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8134, -2.5398, -7.8482, -2.5411, -3.5081, -3.6314, -1.9815, -1.3443,\n",
      "         -1.1643, -2.9424]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.344318151473999\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5379, -3.2001, -8.0319, -3.6510, -3.4351, -4.1593, -2.2769, -1.0343,\n",
      "         -0.9963, -3.5503]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.5379209518432617\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4045, -3.7457, -8.0999, -4.5824, -3.3025, -4.5669, -2.5377, -0.9646,\n",
      "         -1.0493, -4.0175]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.7457332611083984\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4067, -3.4640, -8.1167, -5.3789, -3.1616, -4.8885, -2.7706, -1.1438,\n",
      "         -1.2890, -4.4074]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.289016842842102\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9175, -3.4384, -8.3372, -6.3049, -3.2709, -5.3892, -3.2283, -1.7610,\n",
      "         -1.1864, -4.9721]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.76096510887146\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8114, -3.4403, -8.5374, -7.1417, -3.3985, -5.8451, -3.6690, -1.6682,\n",
      "         -1.3161, -5.4869]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.6689536571502686\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8746, -3.2546, -8.5068, -7.6850, -3.3270, -6.0470, -3.1920, -1.5214,\n",
      "         -1.4158, -5.7426]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.047034740447998\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0855, -2.9237, -8.2874, -7.9827, -3.0968, -5.2712, -2.5983, -1.3683,\n",
      "         -1.4889, -5.7829]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.9236721992492676\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5177, -1.8952, -8.0521, -8.2133, -2.8849, -4.5385, -2.0762, -1.3922,\n",
      "         -1.6801, -5.7836]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.78361177444458\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1634, -1.1536, -7.9150, -8.4957, -2.8096, -3.9612, -1.7659, -1.6831,\n",
      "         -2.0617, -5.1704]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.80959415435791\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9571, -0.8341, -7.9083, -8.8669, -2.1708, -3.5725, -1.7196, -2.2075,\n",
      "         -2.6142, -4.7386]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.908347129821777\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6694, -0.8192, -7.0490, -9.1555, -1.6330, -3.1980, -1.7541, -2.7203,\n",
      "         -3.1190, -4.3098]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.1189770698547363\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2627, -1.0593, -6.2061, -9.3460, -1.2223, -2.8226, -1.8339, -3.1645,\n",
      "         -2.8121, -3.8633]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.2223491668701172\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0632, -1.7836, -5.7027, -9.7720, -0.5923, -2.7846, -2.2691, -3.8522,\n",
      "         -2.8333, -3.7299]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.784550189971924\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8147,  -2.5844,  -5.2771, -10.1809,  -0.4550,  -2.0585,  -2.7568,\n",
      "          -4.5135,  -2.9200,  -3.6515]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.0584545135498047\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.5812,  -3.4481,  -4.9850, -10.6363,  -0.8813,  -0.8318,  -3.3267,\n",
      "          -5.2048,  -3.1242,  -3.6860]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.8318485021591187\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.1179,  -5.0945,  -5.5724, -11.8917,  -2.4117,  -0.1458,  -4.7097,\n",
      "          -6.6770,  -4.1850,  -4.5794]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  11.891653060913086\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.3565,  -6.4363,  -5.9588, -12.1467,  -3.7098,  -0.0451,  -5.8159,\n",
      "          -7.8583,  -5.0057,  -5.2456]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  12.146745681762695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.8263,  -7.0001,  -5.6630, -11.0098,  -4.2509,  -0.0332,  -6.1683,\n",
      "          -8.2767,  -5.1039,  -5.2032]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.6629958152771\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.5690, -6.8282, -3.9151, -9.3052, -4.0682, -0.0659, -5.8067, -7.9733,\n",
      "         -4.5162, -4.4885]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.516201496124268\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.8831, -6.2199, -1.9024, -7.3155, -3.4620, -0.3337, -5.0288, -7.2460,\n",
      "         -2.8193, -3.3982]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.8192951679229736\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.8768, -6.2849, -0.8216, -6.1352, -3.5502, -1.7131, -4.9440, -7.2029,\n",
      "         -1.2314, -3.0508]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.2313711643218994\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.9643, -7.4378, -1.2973, -6.1665, -4.7437, -4.1821, -5.9655, -8.2577,\n",
      "         -0.3913, -3.8639]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  9.964252471923828\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.1537,  -8.5215,  -1.9915,  -6.2411,  -5.8700,  -6.4623,  -6.9323,\n",
      "          -9.2528,  -0.1668,  -4.6558]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.16681243479251862\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.5312,  -9.7046,  -2.9339,  -6.5164,  -7.0934,  -8.7242,  -8.0106,\n",
      "         -10.3560,  -0.0617,  -5.5825]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.516404628753662\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.2789, -10.1781,  -3.2335,  -5.4536,  -7.6037, -10.1694,  -8.3898,\n",
      "         -10.7575,  -0.0487,  -5.8276]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  10.27888298034668\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.6007,  -9.9772,  -2.9078,  -3.8718,  -7.4362, -10.8439,  -8.1041,\n",
      "         -10.4917,  -0.0845,  -5.4229]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.422940254211426\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6382,  -9.3452,  -2.2077,  -2.0111,  -6.8348, -11.0004,  -7.3959,\n",
      "          -9.8013,  -0.3105,  -3.9146]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.638153553009033\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3165,  -9.0335,  -1.9237,  -0.6897,  -6.5514, -11.3989,  -7.0160,\n",
      "          -9.4369,  -1.2831,  -2.8274]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.2830710411071777\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8052,  -9.3217,  -2.3554,  -0.4334,  -6.8662, -12.3269,  -7.2434,\n",
      "          -9.6778,  -2.2175,  -2.4583]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.2174744606018066\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4897,  -9.5775,  -2.8174,  -0.6686,  -7.1466, -13.1588,  -7.4448,\n",
      "          -9.8908,  -2.4301,  -2.1816]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.4897260665893555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3233, -10.4538,  -3.9288,  -1.8969,  -8.0461, -14.5543,  -8.2732,\n",
      "         -10.7288,  -3.3292,  -2.6577]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.9287610054016113\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.1002, -11.4732,  -4.3642,  -3.3405,  -9.0852, -16.0407,  -9.2477,\n",
      "         -11.7132,  -4.3933,  -3.3640]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.085186004638672\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.0742, -11.8248,  -4.2013,  -4.1006,  -8.7210, -16.8134,  -9.5600,\n",
      "         -12.0335,  -4.7943,  -3.4585]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.100557804107666\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.1419, -11.4824,  -3.4075,  -3.4153,  -7.7339, -16.8503,  -9.1822,\n",
      "         -11.6629,  -4.5022,  -2.9067]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.14189991354942322\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2235, -11.3014,  -2.8467,  -2.9491,  -6.9725, -17.0108,  -8.9694,\n",
      "         -11.4565,  -4.3742,  -2.5752]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2.5752124786376953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6781, -10.8791,  -2.1292,  -2.3077,  -6.0281, -16.8963,  -8.5185,\n",
      "         -11.0114,  -4.0085,  -1.3735]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  11.011425018310547\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7184, -10.7244,  -1.8050,  -2.0273,  -5.4047, -17.0187,  -8.3381,\n",
      "         -10.0389,  -3.9174,  -0.6936]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  10.724361419677734\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8832,  -9.9253,  -1.7303,  -1.9540,  -4.9307, -17.2131,  -8.2599,\n",
      "          -9.2471,  -3.9335,  -0.5143]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.8831515312194824\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9932,  -9.0274,  -1.6286,  -1.8121,  -4.3308, -17.2099,  -8.0115,\n",
      "          -8.3557,  -3.7835,  -0.5910]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.011473655700684\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9008,  -7.9872,  -1.4647,  -1.5709,  -3.5687, -16.9757,  -6.8617,\n",
      "          -7.3215,  -3.4330,  -0.8131]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.43298602104187\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7738,  -6.9629,  -1.4170,  -1.4163,  -2.8154, -16.6770,  -5.7390,\n",
      "          -6.3027,  -2.3516,  -1.2330]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.416271448135376\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9596,  -6.2912,  -1.8209,  -0.9797,  -2.4314, -16.6582,  -4.9803,\n",
      "          -5.6369,  -1.6945,  -2.0638]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.9797328114509583\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5732,  -6.0924,  -2.7211,  -0.5422,  -2.5554, -17.0462,  -4.7065,\n",
      "          -5.4448,  -1.6363,  -3.3052]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.5421978235244751\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5431,  -6.3096,  -3.9800,  -0.2421,  -3.1192, -17.7903,  -4.8608,\n",
      "          -5.6698,  -2.1151,  -4.8436]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.8608198165893555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0848,  -6.1662,  -4.7888,  -0.1978,  -3.3195, -18.1202,  -3.9739,\n",
      "          -5.5349,  -2.2906,  -5.8945]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.534879207611084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1420,  -5.6028,  -5.0884,  -0.3095,  -3.0909, -17.9815,  -2.7522,\n",
      "          -4.1867,  -2.0841,  -6.4072]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  17.98151969909668\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0195,  -4.9195,  -5.1846,  -0.7534,  -2.7401, -16.9246,  -1.5174,\n",
      "          -2.8057,  -1.8068,  -6.6915]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.8057167530059814\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3438,  -4.7388,  -5.7052,  -1.9168,  -2.9014, -16.4018,  -0.9870,\n",
      "          -1.2532,  -2.1018,  -7.3778]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.738761901855469\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.1038,  -4.3029,  -6.6409,  -3.5335,  -3.5516, -16.3950,  -1.2327,\n",
      "          -0.5460,  -2.9176,  -8.4605]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.640862464904785\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.7401,  -3.8703,  -6.6208,  -4.9604,  -4.1085, -16.3387,  -1.6067,\n",
      "          -0.3198,  -3.6404,  -9.3858]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.8702728748321533\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.9805,  -2.4263,  -6.2701,  -5.9172,  -4.2887, -15.9544,  -1.7493,\n",
      "          -0.3571,  -3.9764,  -9.8857]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.917153835296631\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0478,  -1.0413,  -5.8058,  -5.9153,  -4.3113, -15.4582,  -1.8488,\n",
      "          -0.7904,  -4.1422, -10.1860]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.0412616729736328\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.9664,  -0.1753,  -6.2472,  -6.7728,  -5.1988, -15.8684,  -2.9053,\n",
      "          -2.3932,  -5.1600, -11.3137]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.17527860403060913\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.5402,  -0.0226,  -7.3926,  -8.2922,  -6.7486, -16.9841,  -4.6412,\n",
      "          -4.6548,  -6.8271, -13.0758]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  16.984128952026367\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0351e+01, -7.4962e-03, -7.8178e+00, -9.0540e+00, -7.5384e+00,\n",
      "         -1.6632e+01, -5.6046e+00, -6.0925e+00, -7.7224e+00, -1.4056e+01]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.817808151245117\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0363e+01, -6.8029e-03, -6.6773e+00, -9.0224e+00, -7.5324e+00,\n",
      "         -1.5597e+01, -5.7571e+00, -6.6714e+00, -7.8114e+00, -1.4221e+01]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  10.363396644592285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.8595,  -0.0167,  -4.9395,  -8.2824,  -6.8159, -13.9530,  -5.1851,\n",
      "          -6.4823,  -7.1803, -13.6580]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.8158674240112305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8754,  -0.1027,  -2.7502,  -6.9864,  -4.7970, -11.8426,  -4.0441,\n",
      "          -5.6835,  -5.9827, -12.5213]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.10268130898475647\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4639,  -0.4844,  -1.2050,  -6.1947,  -3.3596, -10.3166,  -3.4036,\n",
      "          -5.3416,  -5.2807, -11.8724]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  10.316554069519043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5626,  -1.6374,  -0.4229,  -5.8496,  -2.4573,  -8.5632,  -3.2166,\n",
      "          -5.4041,  -5.0186, -11.6545]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  11.654529571533203\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8612,  -2.9184,  -0.3510,  -5.6430,  -1.8107,  -7.0861,  -3.1783,\n",
      "          -5.5661,  -4.8893, -10.8572]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.35099273920059204\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5313,  -4.3962,  -0.3319,  -5.7442,  -1.6352,  -6.0411,  -3.4580,\n",
      "          -5.9999,  -5.0632, -10.4238]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.041076183319092\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8944, -5.3731, -0.5292, -5.4745, -1.2595, -3.9989, -3.3688, -6.0293,\n",
      "         -4.8609, -9.6702]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.5292498469352722\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6060, -6.4969, -0.6163, -5.4750, -1.3735, -2.4136, -3.5531, -6.2983,\n",
      "         -4.9248, -9.2320]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  9.231968879699707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3948, -7.4992, -1.1171, -5.4675, -1.6544, -1.0415, -3.7283, -6.5309,\n",
      "         -4.9765, -8.1283]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.499154090881348\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5834, -7.9796, -2.1357, -5.7688, -2.3553, -0.3757, -4.2080, -7.0468,\n",
      "         -5.3331, -7.4395]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.768784046173096\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7280, -8.3263, -3.0618, -5.2413, -2.9713, -0.2045, -4.5643, -7.4257,\n",
      "         -5.5714, -6.7331]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.20448307693004608\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1066, -8.8342, -4.1290, -4.9653, -3.7600, -0.1077, -5.0880, -7.9629,\n",
      "         -5.9841, -6.2930]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.834150314331055\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9172, -8.0054, -4.5367, -4.1551, -3.9212, -0.1229, -4.9974, -7.8805,\n",
      "         -5.7911, -5.3313]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.7910614013671875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2786, -6.7473, -4.4011, -2.9249, -3.5697, -0.2771, -4.4086, -7.2949,\n",
      "         -4.3949, -3.9569]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.2770918607711792\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0470, -5.8756, -4.5501, -2.1164, -3.5353, -0.4977, -4.1475, -7.0290,\n",
      "         -3.4066, -2.9936]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.147502422332764\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8076, -5.0032, -4.7712, -1.4916, -3.5604, -1.1379, -3.1042, -6.7970,\n",
      "         -2.3795, -2.2231]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.4916448593139648\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3987, -4.8074, -5.2405, -0.7600, -3.9525, -2.3738, -2.8306, -6.9897,\n",
      "         -2.2420, -1.9000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.989747524261475\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0026, -4.6768, -5.8607, -0.5734, -4.4729, -3.6721, -2.6420, -6.4982,\n",
      "         -2.1688, -1.8925]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.860655784606934\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4050, -4.3840, -5.4338, -0.6265, -4.7683, -4.6785, -2.3404, -5.8748,\n",
      "         -2.0028, -1.8101]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.8747711181640625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6098, -3.9445, -4.8680, -0.8707, -4.8560, -5.4071, -1.9520, -4.3473,\n",
      "         -1.7650, -1.6669]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.407066822052002\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7471, -3.4934, -4.2953, -1.3194, -4.8717, -5.2561, -1.6332, -2.9124,\n",
      "         -1.6041, -1.6020]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.871651649475098\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9482, -3.1672, -3.8486, -1.9722, -4.1981, -5.1821, -1.5422, -1.7210,\n",
      "         -1.6614, -1.7441]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.1820783615112305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2924, -3.0513, -3.6108, -2.8068, -3.7501, -4.5344, -1.7587, -0.9366,\n",
      "         -1.9963, -2.1432]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.0512914657592773\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7112, -2.3583, -3.5159, -3.6993, -3.4618, -4.0565, -2.1732, -0.6378,\n",
      "         -2.4929, -2.6832]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.6831915378570557\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0324, -1.7389, -3.3910, -4.4574, -3.1622, -3.5753, -2.5636, -0.7225,\n",
      "         -2.9362, -2.4474]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.390955686569214\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2778, -1.2587, -2.4560, -5.0994, -2.8750, -3.1132, -2.9207, -1.1317,\n",
      "         -3.3243, -2.2467]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.8749728202819824\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6128, -1.1412, -1.7923, -5.7917, -2.0214, -2.8393, -3.3902, -1.8636,\n",
      "         -3.8096, -2.2504]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.791686058044434\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0014, -1.3500, -1.4121, -5.7856, -1.4356, -2.7196, -3.9209, -2.7289,\n",
      "         -4.3467, -2.4120]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.719574451446533\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4198, -1.7919, -1.3320, -5.8488, -1.1532, -1.9962, -4.4794, -3.6259,\n",
      "         -4.9056, -2.6873]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.479357719421387\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7678, -2.2801, -1.4416, -5.8775, -1.1052, -1.4142, -4.2518, -4.4247,\n",
      "         -5.3844, -2.9533]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.767812252044678\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1842, -2.7127, -1.6492, -5.8242, -1.2291, -0.9870, -3.9758, -5.0727,\n",
      "         -5.7379, -3.1486]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.7127184867858887\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5797, -2.3478, -1.9101, -5.6979, -1.4794, -0.7950, -3.6601, -5.5808,\n",
      "         -5.9783, -3.2745]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.978271007537842\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8759, -1.9256, -2.1018, -5.4241, -1.7132, -0.7902, -3.2315, -5.8791,\n",
      "         -5.3148, -3.2524]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.2314605712890625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1686, -1.5708, -2.2931, -5.1010, -1.9793, -1.0378, -2.0902, -6.0704,\n",
      "         -4.6411, -3.1803]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.979264736175537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6988, -1.5559, -2.7014, -4.9690, -1.7276, -1.6742, -1.3042, -6.3992,\n",
      "         -4.1960, -3.2996]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.195959091186523\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3853, -1.7842, -3.2126, -4.9445, -1.7231, -2.4737, -0.8773, -6.7861,\n",
      "         -3.1822, -3.5227]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.8773032426834106\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4939, -2.4743, -4.0688, -5.2908, -2.2158, -3.6189, -0.4454, -7.4987,\n",
      "         -2.6619, -4.1079]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.498674392700195\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4801, -3.0203, -4.7172, -5.4698, -2.6046, -4.5334, -0.3722, -7.2140,\n",
      "         -2.1068, -4.5101]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.1067569255828857\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4498, -3.5041, -5.2652, -5.5908, -2.9670, -5.3218, -0.7476, -6.9150,\n",
      "         -0.9404, -4.8370]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.7475554347038269\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8099, -4.3231, -6.1245, -6.0639, -3.6934, -6.3970, -1.0776, -7.0078,\n",
      "         -0.5308, -5.4986]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.396986961364746\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9284, -4.8463, -6.6762, -6.2676, -4.1423, -6.4094, -1.3895, -6.8681,\n",
      "         -0.3585, -5.8733]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.35848620533943176\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2413, -5.5131, -7.3640, -6.6423, -4.7484, -6.6116, -2.0352, -6.9329,\n",
      "         -0.1787, -6.4027]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.6116437911987305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0760, -5.6578, -7.5251, -6.5219, -4.8419, -5.6109, -2.2496, -6.5331,\n",
      "         -0.1538, -6.4218]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.1537848860025406\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0323, -5.8819, -7.7619, -6.5057, -5.0234, -4.8035, -2.6081, -6.2654,\n",
      "         -0.1213, -6.5315]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.505733489990234\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4767, -5.5548, -7.4446, -5.2437, -4.6609, -3.5512, -2.4518, -5.4949,\n",
      "         -0.1879, -6.1003]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.660850524902344\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6835, -4.9448, -6.8410, -3.7924, -3.2739, -2.1258, -2.0533, -4.4858,\n",
      "         -0.5114, -5.3953]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.792372465133667\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3142, -4.6892, -6.5870, -2.0791, -2.3418, -1.2176, -2.0736, -3.8746,\n",
      "         -1.5116, -5.0523]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.0791192054748535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8546, -5.2570, -7.1505, -0.7101, -2.3655, -1.4067, -2.9716, -4.1318,\n",
      "         -3.3586, -5.5392]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.150547027587891\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8119, -6.1951, -7.2726, -0.2519, -2.8802, -2.1786, -4.2395, -4.7992,\n",
      "         -5.4698, -6.4035]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.239546775817871\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4511, -6.8003, -7.1417, -0.1532, -3.1446, -2.7150, -4.4461, -5.1655,\n",
      "         -7.1330, -6.9419]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.165492534637451\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5416, -6.8512, -6.5295, -0.1777, -2.9202, -2.7516, -4.1454, -4.2152,\n",
      "         -8.1368, -6.9325]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.215220928192139\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2560, -6.5219, -5.6033, -0.4126, -2.3825, -2.4552, -3.5097, -2.2155,\n",
      "         -8.6651, -6.5488]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.52191162109375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2520, -5.7401, -5.0135, -1.3292, -2.2093, -2.4925, -3.1996, -0.7418,\n",
      "         -9.3827, -6.4458]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.7417500615119934\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3847,  -6.1628,  -5.6121,  -3.4648,  -3.2603,  -3.7111,  -4.0735,\n",
      "          -0.1302, -11.1535,  -7.4785]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.47853946685791\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.1872,  -6.3233,  -5.9326,  -5.1888,  -4.0142,  -4.6050,  -4.6510,\n",
      "          -0.0516, -12.5269,  -7.4696]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  12.526902198791504\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.2401,  -5.7977,  -5.5519,  -6.0741,  -4.0354,  -4.7459,  -4.5064,\n",
      "          -0.0510, -12.3839,  -6.7904]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.05097482353448868\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.3294,  -5.3664,  -5.2521,  -6.9130,  -4.1078,  -4.9191,  -4.4239,\n",
      "          -0.0517, -12.2950,  -6.2194]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.32939338684082\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.9130,  -4.3106,  -4.3156,  -6.9986,  -3.5147,  -4.4098,  -3.6873,\n",
      "          -0.1149, -11.5442,  -5.0357]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.5146872997283936\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2998,  -3.0259,  -3.1394,  -6.7329,  -1.9078,  -3.6165,  -2.6980,\n",
      "          -0.5092, -10.5245,  -3.6308]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.6979660987854004\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4181,  -2.4451,  -2.6562,  -7.0353,  -1.1129,  -3.4625,  -1.6915,\n",
      "          -1.8630, -10.1468,  -2.9252]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.6561763286590576\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1989,  -2.4865,  -1.9696,  -7.8093,  -1.1452,  -3.8480,  -1.4159,\n",
      "          -3.7023, -10.3077,  -2.8294]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.8294496536254883\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1716,  -2.6628,  -1.5426,  -8.5849,  -1.4916,  -4.2891,  -1.4169,\n",
      "          -5.4562, -10.5309,  -2.1476]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.4169138669967651\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4128,  -3.0439,  -1.5027,  -9.4548,  -2.1439,  -4.8676,  -1.0575,\n",
      "          -7.2103, -10.9030,  -1.7884]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.210315704345703\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6398,  -3.3575,  -1.5830, -10.1738,  -2.7551,  -5.3297,  -0.9138,\n",
      "          -7.9537, -11.1736,  -1.5206]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.639775276184082\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0089,  -3.5959,  -1.7523, -10.7518,  -3.2838,  -5.6799,  -0.9967,\n",
      "          -8.5539, -11.3477,  -1.3671]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.9967434406280518\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7041,  -3.9833,  -2.1983, -11.4250,  -3.9407,  -6.1504,  -0.7817,\n",
      "          -9.2472, -11.6570,  -1.5647]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.247249603271484\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4200,  -4.1861,  -2.5302, -11.8715,  -4.3873,  -6.4159,  -0.7496,\n",
      "          -8.9494, -11.7758,  -1.7335]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.18607234954834\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1772,  -3.4614,  -2.7072, -12.0868,  -4.6120,  -6.4694,  -0.8652,\n",
      "          -8.4943, -11.6959,  -1.8258]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  12.086767196655273\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0322,  -2.6506,  -2.7398, -11.3910,  -4.6409,  -6.3376,  -1.0829,\n",
      "          -7.9036, -11.4429,  -1.8440]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.640888214111328\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0703,  -1.8465,  -2.6963, -10.6388,  -3.7961,  -6.0947,  -1.3904,\n",
      "          -7.2462, -11.0895,  -1.8489]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  1.0702778100967407\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8060,  -1.4819,  -2.9560, -10.2052,  -3.2960,  -6.1216,  -2.0857,\n",
      "          -6.8986, -11.0151,  -2.2108]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.805993914604187\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4451,  -1.6519,  -3.5643, -10.1465,  -3.2052,  -6.4792,  -3.1308,\n",
      "          -6.9180, -11.2799,  -2.9477]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.5642507076263428\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4114,  -1.7095,  -3.0861,  -9.8575,  -2.9178,  -6.5662,  -3.8666,\n",
      "          -6.7001, -11.2823,  -3.4131]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.4131076335906982\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6216,  -1.5926,  -2.3909,  -9.2956,  -2.3980,  -6.3441,  -4.2425,\n",
      "          -6.2031, -10.9828,  -2.8331]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.3909096717834473\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3285,  -1.7165,  -1.1145,  -8.8694,  -2.0783,  -6.2253,  -4.6710,\n",
      "          -5.8370, -10.7930,  -2.4328]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.3284729719161987\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7513,  -2.3481,  -0.6181,  -8.8735,  -2.2726,  -6.5076,  -5.4515,\n",
      "          -5.8973, -11.0099,  -2.5234]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.3480582237243652\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1782,  -2.1581,  -0.5111,  -8.7821,  -2.4301,  -6.6677,  -6.0623,\n",
      "          -5.8585, -11.1101,  -2.5676]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  11.110055923461914\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3683,  -1.7849,  -0.6106,  -8.4132,  -2.3519,  -6.5262,  -6.3275,\n",
      "          -5.5391, -10.2008,  -2.3761]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.3760550022125244\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5298, -1.4858, -1.0493, -7.9951, -2.2674, -6.3139, -6.4816, -5.1684,\n",
      "         -9.2959, -1.4663]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.2674484252929688\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8966, -1.5385, -1.8810, -7.7751, -1.6723, -6.2803, -6.7778, -4.9952,\n",
      "         -8.6371, -0.9690]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.5384674072265625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4606, -1.2003, -2.9409, -7.7657, -1.4662, -6.4400, -7.2338, -5.0329,\n",
      "         -8.2324, -0.9826]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.43998908996582\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8800, -1.0018, -3.8237, -7.6433, -1.3403, -5.7270, -7.5309, -4.9576,\n",
      "         -7.7538, -1.1495]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.8800430297851562\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2974, -0.9288, -4.4738, -7.3708, -1.2616, -4.9247, -7.6363, -4.7327,\n",
      "         -7.1604, -1.3648]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.924668788909912\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6381, -0.9869, -4.9039, -6.9612, -1.2395, -3.3067, -7.5669, -4.3722,\n",
      "         -6.4619, -1.5774]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.2394628524780273\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3038, -1.5126, -5.4989, -6.7944, -0.8861, -2.0780, -7.7064, -4.2588,\n",
      "         -6.0353, -2.1189]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.5126161575317383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2816, -1.6140, -6.2356, -6.8426, -1.0755, -1.2617, -8.0298, -4.3651,\n",
      "         -5.8504, -2.8905]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.850438117980957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3463, -1.8519, -6.9024, -6.8884, -1.5039, -0.7384, -8.3230, -4.4723,\n",
      "         -4.9756, -3.6272]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.346320152282715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6790, -2.1866, -7.5099, -6.9364, -2.0628, -0.6278, -8.5933, -4.5837,\n",
      "         -4.1986, -4.3159]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.315914630889893\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1140, -2.4547, -7.9421, -6.8650, -2.5465, -0.8082, -8.7216, -4.5767,\n",
      "         -3.3942, -4.1105]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.942135810852051\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7674, -2.6550, -7.4226, -6.6976, -2.9373, -1.1960, -8.7334, -4.4745,\n",
      "         -2.5898, -3.8334]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.589810848236084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8686, -2.9243, -6.9927, -6.5852, -3.3667, -1.8062, -8.7817, -4.4287,\n",
      "         -1.2473, -3.6368]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.585229873657227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5235, -3.4308, -6.8309, -5.9941, -4.0042, -2.7020, -9.0500, -4.6215,\n",
      "         -0.4681, -3.7034]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.5235137939453125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6039, -4.0331, -6.8084, -5.5858, -4.7146, -3.6810, -9.4142, -4.9252,\n",
      "         -0.3360, -3.9035]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  9.414166450500488\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4776, -4.2279, -6.4284, -4.8600, -5.0005, -4.2206, -8.6714, -4.8436,\n",
      "         -0.3644, -3.7375]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.428350448608398\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2038, -4.0699, -4.9460, -3.8678, -4.9190, -4.3736, -7.6584, -4.4323,\n",
      "         -0.5375, -3.2611]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.432252883911133\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0286, -3.7699, -3.4462, -2.8189, -4.6809, -4.3504, -6.5761, -3.1277,\n",
      "         -0.9350, -2.6894]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.680945873260498\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2585, -3.6166, -2.2207, -2.0169, -3.8194, -4.4391, -5.7022, -2.0865,\n",
      "         -1.6698, -2.3234]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.702167987823486\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9835, -3.7875, -1.4932, -1.6796, -3.3492, -4.8170, -4.5016, -1.5340,\n",
      "         -2.7539, -2.3537]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.501570701599121\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9279, -4.1387, -1.1988, -1.6905, -3.1328, -5.3440, -2.9105, -1.3841,\n",
      "         -3.9560, -2.6302]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.9279332160949707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1089, -4.5610, -1.2697, -1.9275, -3.0649, -5.9166, -1.6100, -1.5375,\n",
      "         -5.1466, -3.0257]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.0257060527801514\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4878, -5.1291, -1.7389, -2.4258, -3.2190, -6.6143, -0.7599, -2.0222,\n",
      "         -6.4031, -2.8762]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.61430549621582\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9259, -5.7176, -2.3747, -3.0108, -3.4604, -6.5731, -0.3975, -2.6338,\n",
      "         -7.6085, -2.8546]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.9259274005889893\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3266, -6.0382, -2.8102, -3.3614, -3.4897, -6.3252, -0.3336, -3.0286,\n",
      "         -8.4827, -2.6647]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.028561592102051\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5470, -6.0603, -2.9824, -3.4337, -3.2707, -5.8347, -0.5107, -2.3799,\n",
      "         -9.0017, -2.2755]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.5469822883605957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1907, -6.1556, -3.2519, -3.5960, -3.1760, -5.4689, -1.1638, -1.9410,\n",
      "         -9.5431, -2.0728]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.251898765563965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5607,  -6.5926,  -3.0743,  -4.1115,  -3.4718,  -5.4920,  -2.3201,\n",
      "          -2.0061, -10.3803,  -2.3306]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.592621803283691\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3957,  -6.1993,  -2.8993,  -4.5357,  -3.7097,  -5.4640,  -3.3784,\n",
      "          -2.1167, -11.0825,  -2.5812]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.535654544830322\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4667,  -5.5330,  -2.4723,  -3.8907,  -3.6291,  -5.1283,  -4.0421,\n",
      "          -1.9960, -11.4014,  -2.5481]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.9960453510284424\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9567,  -4.8678,  -2.0872,  -3.2566,  -3.5087,  -4.7625,  -4.5843,\n",
      "          -1.1540, -11.6207,  -2.5069]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  11.620660781860352\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7773,  -4.3514,  -1.9168,  -2.7902,  -3.5000,  -4.5163,  -5.1568,\n",
      "          -0.7158, -11.1831,  -2.6059]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.156824111938477\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5928,  -3.8389,  -1.8243,  -2.3576,  -3.4583,  -4.2459,  -4.9168,\n",
      "          -0.6410, -10.7322,  -2.6918]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.8243072032928467\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4208,  -3.4276,  -1.1062,  -2.0709,  -3.4792,  -4.0475,  -4.7402,\n",
      "          -1.0128, -10.3606,  -2.8527]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.4276108741760254\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2407,  -2.3969,  -0.7720,  -1.9519,  -3.5696,  -3.9301,  -4.6355,\n",
      "          -1.6747, -10.0741,  -3.0878]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.5696492195129395\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9985, -1.5434, -0.8478, -1.9555, -2.9227, -3.8471, -4.5560, -2.4227,\n",
      "         -9.8241, -3.3407]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.556034088134766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.7026, -0.9481, -1.2734, -2.0773, -2.3969, -3.8045, -3.8106, -3.1808,\n",
      "         -9.6151, -3.6104]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2.07733154296875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4405, -0.7983, -1.9806, -1.6571, -2.0935, -3.8838, -3.2557, -3.9968,\n",
      "         -9.5280, -3.9741]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  9.52801513671875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0331, -0.9209, -2.6542, -1.3428, -1.8404, -3.8974, -2.7095, -4.6726,\n",
      "         -8.6678, -4.2420]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.033144950866699\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6795, -1.2267, -3.2201, -1.1513, -1.6360, -3.8279, -2.1671, -5.1914,\n",
      "         -7.7961, -4.3968]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.679491996765137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4956, -1.6313, -3.6756, -1.1211, -1.5139, -3.6956, -1.6728, -5.5771,\n",
      "         -6.9253, -4.4592]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.695554256439209\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3803, -2.0872, -4.0540, -1.2769, -1.5189, -2.7958, -1.3068, -5.8752,\n",
      "         -6.0894, -4.4718]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.8751912117004395\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3521, -2.5555, -4.3752, -1.5849, -1.6564, -1.9976, -1.1334, -5.3416,\n",
      "         -5.3046, -4.4578]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.6563878059387207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6107, -3.1918, -4.8319, -2.1675, -1.3232, -1.5374, -1.3600, -5.0220,\n",
      "         -4.7587, -4.6111]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.022006034851074\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0127, -3.8072, -5.2617, -2.7871, -1.2370, -1.2960, -1.7560, -3.9895,\n",
      "         -4.2851, -4.7685]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.296005129814148\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8209, -4.6198, -5.8949, -3.6316, -1.6213, -0.7791, -2.4756, -3.3155,\n",
      "         -4.1102, -5.1584]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.619801998138428\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7358, -4.5830, -6.4278, -4.3718, -2.0777, -0.6170, -3.1432, -2.6966,\n",
      "         -3.9249, -5.4742]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.1432301998138428\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6478, -4.4073, -6.7592, -4.8978, -2.4338, -0.7236, -2.9237, -2.0409,\n",
      "         -3.6221, -5.6118]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.759222030639648\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5915, -4.1296, -6.1303, -5.2484, -2.6927, -1.0520, -2.6351, -1.4214,\n",
      "         -3.2401, -5.6099]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.5914976596832275\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0784, -4.0531, -5.7274, -5.7298, -3.1390, -1.7691, -2.5871, -1.2103,\n",
      "         -3.0857, -5.7727]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.7690832614898682\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9294, -4.0432, -5.4133, -6.2121, -3.6203, -1.8435, -2.6428, -1.2950,\n",
      "         -3.0257, -5.9678]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.8434706926345825\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0745, -4.0171, -5.1038, -6.6178, -4.0440, -1.2586, -2.7129, -1.5512,\n",
      "         -2.9763, -6.1153]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.617798805236816\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3837, -3.9180, -4.7405, -6.1703, -4.3497, -0.8531, -2.7337, -1.8556,\n",
      "         -2.8792, -6.1606]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.160556793212891\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7652, -3.7223, -4.1702, -5.6322, -4.4380, -0.6618, -2.7185, -2.1632,\n",
      "         -2.6353, -5.2451]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.718474864959717\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0681, -3.4432, -3.7954, -5.0594, -4.5513, -0.7860, -1.8550, -2.3413,\n",
      "         -2.4913, -4.5027]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.7953813076019287\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4714, -3.2214, -2.5692, -4.5396, -4.5980, -1.2214, -1.2304, -2.6130,\n",
      "         -2.3585, -3.7540]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.2213833332061768\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1620, -3.3123, -1.7874, -4.3405, -4.9092, -1.3538, -1.1336, -3.1753,\n",
      "         -2.5678, -3.3577]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.909184455871582\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7975, -3.4028, -1.1926, -4.1481, -4.4101, -1.6478, -1.2528, -3.6946,\n",
      "         -2.8000, -3.0146]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.797456741333008\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5732, -3.5027, -0.8075, -3.9187, -3.8848, -2.0864, -1.5434, -4.1561,\n",
      "         -3.1436, -2.8327]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.8075351119041443\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7172, -3.9152, -0.4036, -4.0862, -3.8053, -2.8349, -2.2633, -4.8992,\n",
      "         -3.6925, -2.9240]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.08620548248291\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6386, -4.0739, -0.3460, -3.3003, -3.5243, -3.3240, -2.7570, -5.3468,\n",
      "         -3.9756, -2.8164]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.300283432006836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3601, -4.0011, -0.6263, -1.6754, -3.0653, -3.5628, -3.0179, -5.5254,\n",
      "         -4.0158, -2.5352]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.525364875793457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3914, -4.2041, -1.5556, -0.6020, -2.9425, -4.0538, -3.5422, -5.1749,\n",
      "         -4.3200, -2.5954]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.5555580854415894\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7493, -4.7013, -2.0710, -0.3343, -3.1754, -4.8122, -4.3380, -5.1668,\n",
      "         -4.9070, -3.0080]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.749267339706421\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0158, -4.8605, -2.3392, -0.3131, -3.1217, -5.2059, -4.7686, -4.8684,\n",
      "         -5.1455, -3.1207]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.145516395568848\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0679, -4.6841, -2.3312, -0.4921, -2.7814, -5.2389, -4.8369, -4.2801,\n",
      "         -4.3179, -2.9292]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.781404972076416\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3161, -4.5354, -2.4040, -1.0926, -1.7654, -5.2759, -4.9072, -3.7641,\n",
      "         -3.5854, -2.7995]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.2759480476379395\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0466, -4.6076, -2.7392, -2.0708, -1.1789, -4.7729, -5.1740, -3.5154,\n",
      "         -3.1439, -2.9260]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.070835590362549\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1435, -4.7456, -3.1575, -2.3910, -0.9503, -4.3915, -5.4837, -3.3798,\n",
      "         -2.8427, -3.1451]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.390998601913452\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3891, -4.7862, -3.4778, -1.9438, -0.9486, -3.9669, -5.6754, -3.1937,\n",
      "         -2.5234, -3.2841]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.675425052642822\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6890, -4.7132, -3.6750, -1.5269, -1.1258, -3.4827, -5.0315, -2.9421,\n",
      "         -2.1780, -3.3215]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.689041018486023\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4020, -4.7327, -3.9512, -1.3841, -1.6103, -3.1478, -4.5346, -2.8347,\n",
      "         -2.0274, -3.4604]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.9511818885803223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2864, -4.7083, -3.3771, -1.3850, -2.1501, -2.8295, -4.0460, -2.7349,\n",
      "         -1.9385, -3.5603]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.3770885467529297\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3857, -4.6816, -2.0954, -1.5521, -2.7135, -2.5749, -3.6068, -2.6836,\n",
      "         -1.9512, -3.6599]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.6836328506469727\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8294, -4.8243, -1.1973, -2.0129, -3.4311, -2.5618, -3.3901, -2.0799,\n",
      "         -2.2254, -3.9286]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.8242902755737305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4885, -4.3479, -0.7600, -2.6575, -4.2367, -2.7418, -3.3532, -1.7670,\n",
      "         -2.6853, -4.3198]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.319824695587158\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0804, -3.8620, -0.6666, -3.2216, -4.9070, -2.8853, -3.2783, -1.5505,\n",
      "         -3.0825, -3.8739]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.5505027770996094\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7250, -3.5157, -1.0599, -3.8337, -5.5920, -3.1317, -3.3130, -0.8274,\n",
      "         -3.5493, -3.5633]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.5493316650390625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3191, -3.2207, -1.6795, -4.3951, -6.2064, -3.3807, -3.3647, -0.5074,\n",
      "         -3.2609, -3.2992]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.3806583881378174\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6980, -2.8183, -2.2167, -4.7431, -6.5949, -2.7240, -3.2692, -0.5149,\n",
      "         -2.8624, -2.9223]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.2691879272460938\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9173, -2.3714, -2.6567, -4.9336, -6.8167, -2.0518, -2.3774, -0.8495,\n",
      "         -2.4156, -2.4936]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.656717300415039\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2309, -2.1491, -2.4363, -5.2206, -7.1277, -1.6520, -1.7499, -1.5876,\n",
      "         -2.1883, -2.2792]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.220630168914795\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5983, -2.1169, -2.3866, -4.8511, -7.4892, -1.5146, -1.3880, -2.4892,\n",
      "         -2.1455, -2.2431]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.38799250125885\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1639, -2.4100, -2.6454, -4.7557, -8.0469, -1.7856, -0.7676, -3.5966,\n",
      "         -2.4237, -2.5214]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.596647024154663\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6491, -2.7155, -2.9080, -4.6500, -8.5237, -2.1282, -0.5100, -3.8232,\n",
      "         -2.7128, -2.8060]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.907959222793579\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.9086, -2.8617, -2.2322, -4.3830, -8.7748, -2.3465, -0.5217, -3.8654,\n",
      "         -2.8427, -2.9289]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.9288928508758545\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0073, -2.9005, -1.5711, -4.0156, -8.8651, -2.4783, -0.8122, -3.7835,\n",
      "         -2.8663, -2.2010]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.478259801864624\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.1632, -3.0431, -1.2035, -3.7639, -9.0130, -1.9852, -1.4508, -3.7934,\n",
      "         -2.9952, -1.6939]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.2034910917282104\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.6487, -3.5519, -0.6758, -3.8982, -9.4907, -1.9871, -2.5345, -4.1640,\n",
      "         -3.4923, -1.7183]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.4922540187835693\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.0275, -3.9728, -0.5367, -3.9749, -9.8622, -2.0315, -3.5073, -4.4508,\n",
      "         -3.1777, -1.8148]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.972848653793335\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.1300, -3.3774, -0.6249, -3.8184, -9.9578, -1.9296, -4.1655, -4.4790,\n",
      "         -2.6857, -1.7838]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.8183555603027344\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.0611, -2.7053, -0.9559, -2.8204, -9.8826, -1.7841, -4.6080, -4.3518,\n",
      "         -2.1306, -1.7196]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.7053208351135254\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.1248, -1.5321, -1.6755, -2.0894, -9.9404, -1.9029, -5.1389, -4.3725,\n",
      "         -1.8423, -1.9205]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.5321420431137085\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.7928,  -0.5073,  -3.0784,  -2.1297, -10.6028,  -2.7309,  -6.2316,\n",
      "          -5.0112,  -2.3082,  -2.8209]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.1296911239624023\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.6668,  -0.3065,  -4.6497,  -1.8146, -11.4717,  -3.7972,  -7.4894,\n",
      "          -5.8638,  -3.0723,  -3.9486]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  11.471726417541504\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.1587,  -0.3781,  -5.7772,  -1.3514, -11.1895,  -4.4791,  -8.3274,\n",
      "          -6.3387,  -3.4990,  -4.6834]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.777199745178223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.3121,  -0.6596,  -5.7324,  -0.8288, -10.6456,  -4.8119,  -8.7925,\n",
      "          -6.4779,  -3.6155,  -5.0623]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.6595787405967712\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.5676,  -0.6739,  -5.8121,  -0.7863, -10.2730,  -5.2350,  -9.3290,\n",
      "          -6.7219,  -3.8575,  -5.5257]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.235044479370117\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.4674,  -0.7325,  -5.5557,  -0.7415,  -9.6072,  -4.5485,  -9.4819,\n",
      "          -6.6123,  -3.7604,  -5.6157]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.548539638519287\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.0886,  -0.8504,  -5.0391,  -0.7506,  -8.7188,  -2.9164,  -9.3311,\n",
      "          -6.2259,  -3.4014,  -5.4109]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  9.331055641174316\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.6487, -1.1720, -4.4802, -0.9945, -7.8201, -1.3875, -8.3919, -5.7807,\n",
      "         -3.0036, -5.1310]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.3874775171279907\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.0524,  -2.4893,  -4.7853,  -2.2760,  -7.8109,  -0.2626,  -8.3460,\n",
      "          -6.1820,  -3.4815,  -5.6833]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.345995903015137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.6665,  -3.9872,  -5.3170,  -3.7534,  -8.0533,  -0.0678,  -7.8570,\n",
      "          -6.7954,  -4.1848,  -6.4336]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  10.666465759277344\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.8947, -4.8150, -5.2647, -4.5658, -7.7368, -0.0422, -6.8818, -6.8137,\n",
      "         -4.2943, -6.5756]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.264650344848633\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.5600, -4.9269, -3.8142, -4.6653, -6.8125, -0.0750, -5.3646, -6.1915,\n",
      "         -3.7634, -6.0649]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.364609241485596\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.9138, -4.5890, -2.0806, -4.3175, -5.5367, -0.3272, -2.8635, -5.1885,\n",
      "         -2.8581, -5.1626]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.3271653652191162\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1073, -4.9675, -1.2906, -4.6890, -5.0660, -1.0275, -1.3261, -4.9648,\n",
      "         -2.7601, -5.0295]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.066032886505127\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8524, -5.7833, -1.2607, -5.5000, -4.3472, -2.3859, -0.5971, -5.2384,\n",
      "         -3.1881, -5.3843]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.384328842163086\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6748, -6.5701, -1.5017, -6.2831, -3.7595, -3.7257, -0.3760, -5.5388,\n",
      "         -3.6536, -5.0078]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.57008695602417\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2314, -6.2543, -1.6040, -6.7036, -2.9620, -4.6636, -0.3702, -5.5262,\n",
      "         -3.8058, -4.3874]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.6039762496948242\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7638, -5.8987, -1.0103, -7.0106, -2.2110, -5.4426, -0.7726, -5.4453,\n",
      "         -3.8866, -3.7654]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.442615032196045\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3355, -5.5666, -0.7414, -7.2739, -1.6056, -5.4085, -1.4417, -5.3621,\n",
      "         -3.9607, -3.2088]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.335489273071289\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1392, -5.2370, -0.8310, -7.4782, -1.1824, -5.3477, -2.1752, -5.2573,\n",
      "         -4.0081, -2.7044]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.1823561191558838\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4082, -5.2563, -1.5573, -7.9749, -0.5792, -5.6085, -3.2271, -5.4793,\n",
      "         -4.3764, -2.6126]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.408205509185791\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2077, -5.4458, -2.5410, -8.5908, -0.6375, -6.0144, -4.3705, -5.8507,\n",
      "         -4.8857, -2.7534]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.445755958557129\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4885, -5.0115, -3.6137, -9.2719, -1.2236, -6.5081, -5.5354, -6.3138,\n",
      "         -5.4763, -3.0545]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.0544707775115967\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.2843, -4.5847, -4.5599, -9.8448, -1.9371, -6.9131, -6.5467, -6.6917,\n",
      "         -5.9707, -2.5722]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.69168758392334\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3405,  -3.8574,  -5.0699, -10.0106,  -2.3405,  -6.9284,  -7.1083,\n",
      "          -5.9074,  -6.0676,  -1.8448]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.907407283782959\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6976, -2.9699, -5.2859, -9.9118, -2.5298, -6.6947, -7.3666, -4.1891,\n",
      "         -5.9085, -1.0602]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.911803245544434\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4448, -2.2471, -5.5231, -9.1456, -2.8005, -6.5239, -7.6384, -2.6919,\n",
      "         -5.8059, -0.6522]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.523106575012207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3986, -1.7715, -5.0700, -8.5530, -3.1886, -6.4685, -7.9809, -1.4931,\n",
      "         -5.8131, -0.7726]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.468489646911621\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4767, -1.6170, -4.8150, -8.1676, -3.7182, -5.8463, -8.4379, -0.7353,\n",
      "         -5.9701, -1.3747]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.6169869899749756\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6802, -1.0971, -4.7999, -8.0290, -4.4224, -5.4963, -9.0580, -0.6321,\n",
      "         -6.3217, -2.3145]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.321693420410156\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6319, -0.7355, -4.6530, -7.7649, -4.9264, -5.0446, -9.4771, -0.8096,\n",
      "         -5.7613, -3.0955]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.926373481750488\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2623, -0.5333, -4.2985, -7.2978, -4.3849, -4.4128, -9.6250, -1.0825,\n",
      "         -5.0292, -3.6032]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.029209136962891\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5659, -0.5165, -3.7238, -6.6118, -3.6410, -3.5868, -9.4926, -1.3230,\n",
      "         -3.3771, -3.8152]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.8151791095733643\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7374, -0.8352, -3.1218, -5.8920, -2.8883, -2.7599, -9.2703, -1.6416,\n",
      "         -1.8113, -3.1699]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.73738431930542\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4050, -1.7337, -2.9077, -5.5398, -2.5474, -2.3552, -9.3644, -2.3717,\n",
      "         -0.8156, -2.9142]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.9142298698425293\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3945, -2.9600, -3.0445, -5.5130, -2.5884, -2.3471, -9.7369, -3.3888,\n",
      "         -0.5329, -2.2694]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.9599523544311523\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2974, -3.2780, -3.1153, -5.4029, -2.5944, -2.3203, -9.9835, -4.2420,\n",
      "         -0.6214, -1.6765]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.6213828921318054\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4099,  -3.7906,  -3.4118,  -5.5054,  -2.8559,  -2.5660, -10.4040,\n",
      "          -5.2201,  -0.5597,  -1.4803]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  6.4098944664001465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4843,  -4.0147,  -3.4503,  -5.3467,  -2.8819,  -2.5892, -10.5289,\n",
      "          -5.8512,  -0.6698,  -1.2192]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.881937026977539\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5059,  -4.0818,  -3.3614,  -5.0592,  -2.0314,  -2.5166, -10.4933,\n",
      "          -6.2738,  -0.9957,  -1.0562]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.505865573883057\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8427,  -4.1303,  -3.2839,  -4.7806,  -1.3421,  -2.4858, -10.4371,\n",
      "          -6.6317,  -1.5355,  -1.1441]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.6316986083984375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5203,  -4.3165,  -3.3737,  -4.6664,  -1.0532,  -2.6493, -10.5171,\n",
      "          -6.3132,  -2.3099,  -1.5910]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.591020941734314\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8048,  -4.8003,  -3.7874,  -4.8767,  -1.3679,  -3.1544, -10.8956,\n",
      "          -6.3341,  -3.3865,  -1.7071]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.3865349292755127\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4904,  -5.2259,  -4.1613,  -5.0554,  -1.8312,  -3.6243, -11.2202,\n",
      "          -6.3381,  -3.6308,  -1.9302]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.6307718753814697\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4425,  -5.3755,  -4.2726,  -4.9834,  -2.1342,  -3.8293, -11.2750,\n",
      "          -6.1054,  -2.9060,  -2.0013]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.983402252197266\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6177,  -5.2382,  -4.1080,  -3.9271,  -2.2227,  -3.7543, -11.0489,\n",
      "          -5.6220,  -2.0175,  -1.8904]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.2227184772491455\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2147,  -5.1445,  -3.9987,  -3.0161,  -1.6427,  -3.7300, -10.8713,\n",
      "          -5.2155,  -1.3401,  -1.9289]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.998706817626953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1041,  -5.1886,  -3.2670,  -2.3552,  -1.3931,  -3.8499, -10.8356,\n",
      "          -4.9778,  -1.0449,  -2.1961]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.8498897552490234\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0259,  -5.2597,  -2.6645,  -1.8557,  -1.3861,  -3.2716, -10.8306,\n",
      "          -4.7962,  -1.0622,  -2.5467]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.796241760253906\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8599,  -5.2938,  -2.1420,  -1.4852,  -1.5382,  -2.7448, -10.7925,\n",
      "          -3.8374,  -1.2957,  -2.8872]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.8872272968292236\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6537,  -5.3548,  -1.7887,  -1.3420,  -1.8667,  -2.3436, -10.7847,\n",
      "          -3.0168,  -1.7315,  -2.5177]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.653692245483398\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6088,  -5.4161,  -1.6026,  -1.4050,  -2.2843,  -2.0552, -10.7806,\n",
      "          -2.3183,  -2.2557,  -2.2476]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.284250259399414\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6337,  -5.5322,  -1.6483,  -1.6969,  -2.0284,  -1.9465, -10.8345,\n",
      "          -1.8227,  -2.8618,  -2.1404]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.9464874267578125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7698,  -5.7459,  -1.9447,  -2.1988,  -2.0049,  -1.3320, -10.9893,\n",
      "          -1.6072,  -3.5557,  -2.2377]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.004920482635498\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0226,  -6.0646,  -2.4461,  -2.8549,  -1.4483,  -1.0946, -11.2525,\n",
      "          -1.6916,  -4.3251,  -2.5284]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  11.25251579284668\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.2048,  -6.3027,  -2.9142,  -3.4370,  -1.0759,  -1.0739, -10.7284,\n",
      "          -1.8591,  -4.9772,  -2.7990]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.0759114027023315\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6238,  -6.7692,  -3.6286,  -4.2354,  -0.4910,  -1.5547, -10.5072,\n",
      "          -2.3811,  -5.8204,  -3.3389]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.3389153480529785\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8883,  -7.0746,  -4.1767,  -4.8494,  -0.3158,  -2.0259, -10.1922,\n",
      "          -2.8070,  -6.4663,  -2.9936]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.3157555162906647\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.3516,  -7.5733,  -4.9054,  -5.6311,  -0.1753,  -2.7693, -10.1316,\n",
      "          -3.4603,  -7.2723,  -2.9429]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.272281169891357\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2790, -7.5314, -5.0761, -5.8463, -0.1953, -2.9932, -9.5857, -3.5817,\n",
      "         -6.7772, -2.4450]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.444967269897461\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9624, -7.2416, -4.9821, -5.7898, -0.5810, -2.9789, -8.8415, -3.4600,\n",
      "         -6.0796, -1.0708]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.841506004333496\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9261, -7.2279, -5.1497, -5.9879, -1.5954, -3.2499, -7.7107, -3.6215,\n",
      "         -5.6997, -0.3339]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.5953953266143799\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9306, -7.2513, -5.3403, -6.2033, -1.9416, -3.5575, -6.7277, -3.8230,\n",
      "         -5.3952, -0.2354]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.557480812072754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5165, -6.8526, -5.0955, -5.9786, -1.9408, -2.7064, -5.4229, -3.6011,\n",
      "         -4.7040, -0.3077]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.422904014587402\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8780, -6.2257, -4.6112, -5.5093, -1.7795, -1.7199, -3.2795, -3.1538,\n",
      "         -3.8195, -0.6418]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.7795262336730957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6543, -6.0081, -4.5283, -5.4352, -1.3549, -1.3072, -1.7211, -3.1295,\n",
      "         -3.3844, -1.6724]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.1295435428619385\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8746, -6.2283, -4.8767, -5.7857, -1.5801, -1.5467, -0.8585, -2.7814,\n",
      "         -3.4317, -3.1528]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.8585370182991028\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6737, -7.0225, -5.7919, -6.6975, -2.5317, -2.5113, -0.2700, -3.1093,\n",
      "         -4.0926, -5.1129]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.092592239379883\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2593, -7.6024, -6.4798, -7.3853, -3.3128, -3.3050, -0.1475, -3.3056,\n",
      "         -3.8354, -6.7435]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.479752540588379\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3101, -7.6467, -5.8450, -7.5261, -3.5652, -3.5675, -0.1674, -3.0314,\n",
      "         -3.1413, -7.7360]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.5674855709075928\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9602, -7.2899, -4.8786, -7.2561, -3.4165, -2.7000, -0.3810, -2.4245,\n",
      "         -2.1507, -8.2333]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.256117343902588\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6007, -6.9226, -3.9678, -6.2368, -3.2609, -1.9211, -1.0035, -1.9002,\n",
      "         -1.2970, -8.6351]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.2970471382141113\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8323, -7.1450, -3.7147, -5.8727, -3.7021, -1.8786, -2.3725, -2.0966,\n",
      "         -0.5526, -9.5496]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.832259654998779\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3250,  -7.4005,  -3.5602,  -5.6014,  -4.1726,  -2.0060,  -3.7252,\n",
      "          -2.4234,  -0.3571, -10.4278]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.0059807300567627\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7086,  -7.4678,  -3.2800,  -5.1964,  -4.4448,  -1.3308,  -4.7972,\n",
      "          -2.6234,  -0.5269, -11.0556]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.3307664394378662\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4194,  -7.7877,  -3.3160,  -5.0946,  -4.9576,  -0.4517,  -6.0274,\n",
      "          -3.1189,  -1.3667, -11.8799]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.027444362640381\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2402,  -8.1482,  -3.4488,  -5.0795,  -5.4969,  -0.1940,  -6.5068,\n",
      "          -3.6715,  -2.3798, -12.6943]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.19395102560520172\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3400,  -8.7231,  -3.8432,  -5.3204,  -6.2357,  -0.0846,  -7.1896,\n",
      "          -4.4391,  -3.6095, -13.6779]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.843209743499756\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9057,  -8.7068,  -2.9043,  -5.0067,  -6.3683,  -0.1156,  -7.2709,\n",
      "          -4.6055,  -4.2025, -14.0295]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.006749629974365\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0951,  -8.2572,  -1.6662,  -3.5659,  -6.0540,  -0.3463,  -6.9095,\n",
      "          -4.3279,  -4.3123, -13.9111]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.565906047821045\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5636,  -8.0157,  -0.8618,  -1.7309,  -5.9360,  -1.2213,  -6.7481,\n",
      "          -4.2517,  -4.5843, -13.9678]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.015718460083008\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6718,  -7.5754,  -0.9936,  -0.7342,  -6.3588,  -2.7469,  -7.1306,\n",
      "          -4.7212,  -5.3638, -14.5460]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.358844757080078\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9741,  -7.3303,  -1.5517,  -0.3377,  -6.1380,  -4.3178,  -7.6268,\n",
      "          -5.3022,  -6.2205, -15.2179]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.220460414886475\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0179,  -6.8418,  -1.9509,  -0.2313,  -5.6725,  -5.4740,  -7.8058,\n",
      "          -5.5610,  -5.9980, -15.5548]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.9509339332580566\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8012,  -6.1084,  -1.3501,  -0.4151,  -4.9616,  -6.2241,  -7.6731,\n",
      "          -5.5030,  -5.5053, -15.5640]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  15.564005851745605\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4453,  -5.2414,  -0.8020,  -0.8478,  -4.1184,  -6.6930,  -7.3457,\n",
      "          -5.2458,  -4.8563, -14.6242]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.8020043969154358\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6101,  -4.8823,  -0.2994,  -1.9632,  -3.7892,  -7.5341,  -7.4692,\n",
      "          -5.4361,  -4.6953, -14.1956]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.436119556427002\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6203,  -4.3690,  -0.2253,  -2.8735,  -3.3141,  -8.0963,  -7.3852,\n",
      "          -4.6352,  -4.3613, -13.6140]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.361279487609863\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3064,  -3.5364,  -0.3926,  -3.3541,  -2.5339,  -8.2231,  -6.9301,\n",
      "          -3.5415,  -2.9674, -12.7103]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.930067539215088\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0555,  -2.7624,  -1.0138,  -3.7662,  -1.8452,  -8.2914,  -5.7739,\n",
      "          -2.5330,  -1.7033, -11.8503]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.532975673675537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4048,  -2.5882,  -2.3262,  -4.6293,  -1.8199,  -8.8283,  -5.2100,\n",
      "          -1.3875,  -1.1719, -11.5509]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.3875001668930054\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4728,  -3.1708,  -4.2659,  -6.0965,  -2.6028,  -9.9947,  -5.3888,\n",
      "          -0.4616,  -1.6008, -11.9641]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.994706153869629\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5394,  -3.8078,  -6.1041,  -7.5000,  -3.4444, -10.4067,  -5.6334,\n",
      "          -0.1990,  -2.2138, -12.4166]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.539395809173584\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2933,  -3.9636,  -7.3268,  -8.3298,  -3.7920, -10.3431,  -5.4215,\n",
      "          -0.1629,  -2.4105, -12.3895]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.4215087890625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5510,  -3.5870,  -7.8972,  -8.5461,  -3.5910,  -9.7546,  -4.0052,\n",
      "          -0.2519,  -2.1215, -11.8339]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.005160331726074\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6735,  -3.0375,  -8.1799,  -8.5096,  -3.1995,  -8.9932,  -1.8195,\n",
      "          -0.6933,  -1.7169, -11.1021]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.179878234863281\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5081,  -3.1500,  -8.2352,  -9.0481,  -3.4491,  -8.8787,  -0.5353,\n",
      "          -2.0426,  -2.0542, -11.0141]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.048057556152344\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8336,  -3.6949,  -8.6962,  -9.2194,  -4.1090,  -9.1866,  -0.1993,\n",
      "          -3.7677,  -2.8620, -11.3458]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.8620240688323975\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8875,  -3.9192,  -8.8262,  -9.0885,  -4.4306,  -9.1787,  -0.1827,\n",
      "          -5.0539,  -2.6204, -11.3593]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.620389461517334\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6636,  -3.8203,  -8.6274,  -8.6547,  -4.4133,  -8.8557,  -0.4287,\n",
      "          -5.9011,  -1.4201, -11.0555]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.42873093485832214\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8393,  -4.0708,  -8.7715,  -8.5871,  -4.7300,  -8.8878,  -0.7317,\n",
      "          -6.9893,  -0.8367, -11.1048]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.887775421142578\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9007,  -4.1667,  -8.7586,  -8.3835,  -4.8791,  -8.0574,  -1.1945,\n",
      "          -7.8273,  -0.4814, -11.0065]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.758586883544922\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7492,  -4.0151,  -7.7332,  -7.9506,  -4.7695,  -7.0600,  -1.5708,\n",
      "          -8.3325,  -0.3571, -10.6681]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.950596332550049\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3144,  -3.5439,  -6.4615,  -6.4921,  -4.3288,  -5.8138,  -1.7050,\n",
      "          -8.4393,  -0.3990, -10.0149]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.3144125938415527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1358, -3.0582, -5.2341, -5.0963, -3.8586, -4.6102, -1.8683, -8.4523,\n",
      "         -0.8331, -9.3434]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.610227584838867\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5539, -2.8852, -4.3613, -4.0722, -3.6799, -3.0496, -2.3510, -8.6928,\n",
      "         -1.7633, -8.9672]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.36128568649292\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5945, -2.8886, -2.9430, -3.2787, -3.6549, -1.7945, -2.9683, -9.0261,\n",
      "         -2.8405, -8.7451]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.9682722091674805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2568, -3.1310, -1.9025, -2.7881, -3.8489, -0.9800, -3.0625, -9.5232,\n",
      "         -4.0492, -8.7418]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.9024879932403564\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5671,  -3.8753,  -0.8165,  -2.8834,  -4.5326,  -1.0086,  -3.6723,\n",
      "         -10.4635,  -5.6430,  -9.2317]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.883357286453247\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0440,  -4.7986,  -0.4127,  -2.5278,  -5.3937,  -1.5329,  -4.4761,\n",
      "         -11.5475,  -7.3181,  -9.9100]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  9.909980773925781\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1773,  -5.4260,  -0.3426,  -2.0548,  -5.9623,  -1.9495,  -4.9975,\n",
      "         -12.3133,  -8.6168,  -9.5629]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  12.313307762145996\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8729,  -5.6649,  -0.4877,  -1.3917,  -6.1468,  -2.0971,  -5.1422,\n",
      "         -11.9044,  -9.4570,  -8.9208]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.1422200202941895\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.3172,  -5.6984,  -0.8970,  -0.7899,  -6.1303,  -2.1339,  -4.4023,\n",
      "         -11.3518, -10.0294,  -8.1583]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.133869171142578\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.7345,  -5.7468,  -1.5883,  -0.5916,  -6.1328,  -1.5518,  -3.7601,\n",
      "         -10.8698, -10.5607,  -7.4874]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.132783889770508\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0013,  -5.6829,  -2.2549,  -0.7022,  -5.2602,  -1.0692,  -3.0877,\n",
      "         -10.3257, -10.9292,  -6.7736]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.929203033447266\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.1154,  -5.5010,  -2.8076,  -1.0313,  -4.3513,  -0.7532,  -2.3868,\n",
      "          -9.7086, -10.4134,  -6.0047]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.115355968475342\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3219, -5.2235, -3.2341, -1.4673, -3.4256, -0.6884, -1.7023, -9.0360,\n",
      "         -9.8320, -5.1971]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.7023301124572754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8061, -5.1750, -3.8449, -2.2235, -2.8147, -1.1861, -0.7200, -8.6281,\n",
      "         -9.5062, -4.6713]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.62814712524414\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5156, -5.3075, -4.5832, -3.1542, -2.4820, -2.0239, -0.3435, -7.6679,\n",
      "         -9.3844, -4.3766]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.154236078262329\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0851, -5.2586, -5.0839, -3.1289, -2.0745, -2.7008, -0.3214, -6.6312,\n",
      "         -9.1026, -3.9485]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.6311845779418945\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4093, -4.9258, -5.2472, -2.8443, -1.5110, -3.0652, -0.5065, -4.6481,\n",
      "         -8.5556, -3.2846]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.648141384124756\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7883, -4.6104, -5.3921, -2.5947, -1.1378, -3.3872, -1.0748, -2.0835,\n",
      "         -8.0205, -2.6930]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.1377904415130615\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1356, -5.2236, -6.4721, -3.2572, -1.1165, -4.5136, -2.7439, -0.7122,\n",
      "         -8.3458, -3.0991]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.345826148986816\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8084, -6.1245, -7.7243, -4.2873, -1.7565, -5.9612, -4.5896, -0.2633,\n",
      "         -8.3595, -3.8471]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.26330992579460144\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8136, -7.3306, -9.2453, -5.6179, -2.8584, -7.6597, -6.6518, -0.0768,\n",
      "         -8.7649, -4.9297]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.07675144821405411\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8908,  -8.5868, -10.7848,  -6.9884,  -4.0644,  -9.3594,  -8.6795,\n",
      "          -0.0222,  -9.2996,  -6.0797]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.359357833862305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.1587,  -9.0153, -11.4683,  -7.5204,  -4.4608,  -9.4700,  -9.8028,\n",
      "          -0.0150,  -9.0782,  -6.4142]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  7.520430564880371\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6731,  -8.6738, -11.3563,  -6.5536,  -4.0991,  -8.8422, -10.0870,\n",
      "          -0.0227,  -8.1514,  -5.9891]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.55355978012085\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5537,  -7.6835, -10.5726,  -4.2892,  -3.1033,  -7.5939,  -9.6601,\n",
      "          -0.0749,  -6.6339,  -4.9253]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.633904457092285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1917, -6.4349, -9.5098, -1.9026, -1.8840, -6.1130, -8.9187, -0.4498,\n",
      "         -4.1967, -3.6157]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.9025945663452148\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1744, -6.5091, -9.7501, -0.3482, -2.1006, -5.9784, -9.4485, -2.4548,\n",
      "         -3.2099, -3.6541]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.209852457046509\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8979,  -7.3042, -10.6936,  -0.1813,  -3.1171,  -6.5860, -10.6528,\n",
      "          -5.0514,  -2.3674,  -4.4353]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.897861480712891\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4935,  -7.7400, -11.2627,  -0.3449,  -3.7861,  -6.8535, -11.4567,\n",
      "          -7.1140,  -1.3949,  -4.8673]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  11.262744903564453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0359,  -8.0308, -10.9123,  -0.8919,  -4.3040,  -6.9930, -12.0786,\n",
      "          -8.8702,  -0.5946,  -5.1600]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.8918846845626831\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8066,  -8.4619, -10.7658,  -1.1360,  -4.9500,  -7.2883, -12.8078,\n",
      "         -10.6210,  -0.4386,  -5.5970]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  12.807819366455078\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2714,  -8.5042, -10.2876,  -1.2367,  -5.1911,  -7.2087, -12.4281,\n",
      "         -11.8517,  -0.4131,  -5.6473]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.647297382354736\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4779,  -8.2013,  -9.5159,  -1.1915,  -5.0714,  -6.7963, -11.7449,\n",
      "         -12.6190,  -0.5201,  -4.5967]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.5200554132461548\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9873,  -8.0870,  -8.9791,  -1.5238,  -5.1267,  -6.5840, -11.2879,\n",
      "         -13.4683,  -0.4857,  -3.8164]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.5238134860992432\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5845,  -7.9157,  -8.4272,  -1.2014,  -5.1126,  -6.3252, -10.8078,\n",
      "         -14.1647,  -0.8233,  -3.0618]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.915718078613281\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2906,  -6.8924,  -7.8382,  -1.0313,  -5.0125,  -6.0013, -10.2833,\n",
      "         -14.6998,  -1.3469,  -2.3256]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  10.283272743225098\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1768,  -5.9064,  -7.2429,  -1.0644,  -4.8623,  -5.6463,  -9.0593,\n",
      "         -15.1166,  -1.9378,  -1.6716]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  9.059253692626953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2358,  -4.9402,  -6.6270,  -1.2571,  -4.6528,  -5.2487,  -7.1962,\n",
      "         -15.4117,  -2.4921,  -1.1452]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  15.411696434020996\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4183,  -3.9768,  -5.9746,  -1.5325,  -4.3728,  -4.7958,  -5.4200,\n",
      "         -14.8310,  -2.9515,  -0.8141]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.976813793182373\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6939,  -2.2736,  -5.3103,  -1.8543,  -4.0517,  -4.3152,  -3.7447,\n",
      "         -14.2292,  -3.3237,  -0.7736]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.7446951866149902\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3423,  -1.0753,  -4.9716,  -2.5105,  -4.0320,  -4.1478,  -1.8302,\n",
      "         -13.9431,  -3.9405,  -1.3426]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.3422865867614746\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8636,  -0.9095,  -5.3201,  -3.8071,  -4.6763,  -4.6568,  -0.8641,\n",
      "         -14.3338,  -5.1582,  -2.7013]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  14.333765029907227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5364,  -1.2314,  -5.7964,  -5.1493,  -5.4225,  -5.2807,  -0.4416,\n",
      "         -14.1028,  -6.4175,  -4.1345]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.2313655614852905\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1771,  -0.9868,  -6.2396,  -6.3741,  -6.1098,  -5.8582,  -0.5136,\n",
      "         -13.9067,  -7.5648,  -5.4495]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.374053955078125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4598,  -0.7490,  -6.3339,  -6.4641,  -6.4243,  -6.0740,  -0.6806,\n",
      "         -13.4239,  -8.2922,  -6.3307]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.42432975769043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4120,  -0.5889,  -6.1088,  -6.2349,  -5.6201,  -5.9587,  -0.8645,\n",
      "         -12.6775,  -8.6360,  -6.8143]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.108779430389404\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0470,  -0.5411,  -4.8124,  -5.6982,  -4.5670,  -5.5251,  -0.9851,\n",
      "         -11.6737,  -8.6143,  -6.9191]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.525116920471191\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4355,  -0.6491,  -3.3546,  -4.9209,  -3.3302,  -4.1176,  -1.0513,\n",
      "         -10.4732,  -8.2984,  -6.7178]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.717848300933838\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8476, -1.0845, -2.0059, -4.1634, -2.1816, -2.7993, -1.2859, -9.3296,\n",
      "         -7.9516, -5.7141]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.084463119506836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8275, -1.4295, -1.3581, -3.9560, -1.6989, -2.1198, -2.1490, -8.7634,\n",
      "         -8.1032, -5.2763]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.103224754333496\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9607, -2.0286, -1.0766, -3.8874, -1.5115, -1.6996, -3.1105, -8.3583,\n",
      "         -7.6293, -4.9907]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.629287242889404\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0758, -2.6236, -1.0386, -3.7946, -1.4690, -1.4082, -3.9612, -7.9481,\n",
      "         -6.4487, -4.6930]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.9612460136413574\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0926, -3.0919, -1.1522, -3.6037, -1.4870, -1.1999, -3.9337, -7.4555,\n",
      "         -5.2633, -4.3085]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.1999413967132568\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3015, -3.7066, -1.6544, -3.6090, -1.8374, -0.6645, -4.0802, -7.1704,\n",
      "         -4.3574, -4.1305]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.7066454887390137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4468, -3.4384, -2.1812, -3.5611, -2.2053, -0.4832, -4.1517, -6.8422,\n",
      "         -3.4786, -3.9105]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.910461664199829\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4190, -3.0377, -2.5584, -3.3543, -2.4389, -0.5820, -4.0431, -6.3636,\n",
      "         -2.5254, -2.7870]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.5819696187973022\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6999, -2.9936, -3.2376, -3.4730, -2.9976, -0.6320, -4.2372, -6.2140,\n",
      "         -2.0040, -2.1019]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.237637519836426\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9027, -2.9226, -3.0427, -3.5321, -3.4700, -0.9908, -4.3522, -6.0109,\n",
      "         -1.5609, -1.5079]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.9907861948013306\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2835, -3.0820, -3.0857, -3.7884, -4.1019, -1.0423, -4.6466, -6.0120,\n",
      "         -1.4939, -1.3231]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.3231472969055176\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7673, -3.3908, -3.2893, -4.1653, -4.8140, -1.4729, -5.0483, -6.1448,\n",
      "         -1.7239, -0.7325]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.4728589057922363\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2574, -3.7423, -3.5488, -4.5634, -5.5093, -1.3539, -5.4621, -6.3136,\n",
      "         -2.1061, -0.6128]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.106132745742798\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5485, -3.9228, -3.6503, -4.7750, -5.9843, -1.2781, -5.6833, -6.3126,\n",
      "         -1.6703, -0.7605]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.548535346984863\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8437, -3.9201, -3.5810, -4.7911, -6.2336, -1.2297, -5.7043, -6.1326,\n",
      "         -1.2314, -1.0659]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.2297463417053223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3462, -4.0640, -3.6711, -4.9426, -6.5907, -0.8094, -5.8567, -6.1032,\n",
      "         -1.1754, -1.7317]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.064026355743408\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8083, -3.3403, -3.6716, -4.9841, -6.8133, -0.6505, -5.8957, -5.9784,\n",
      "         -1.2449, -2.3649]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.6505005359649658\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5704, -2.9447, -3.9207, -5.2554, -7.2438, -0.3937, -6.1618, -6.0968,\n",
      "         -1.7418, -3.2352]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.9446654319763184\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2189, -1.7092, -4.0008, -5.3440, -7.4726, -0.4867, -6.2435, -6.0458,\n",
      "         -2.1548, -3.8893]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.472552299499512\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9423, -0.7432, -4.0953, -5.4356, -6.9036, -1.0178, -6.3267, -6.0099,\n",
      "         -2.6177, -4.5022]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  1.0178401470184326\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9853, -0.4874, -4.4435, -5.7714, -6.6422, -1.2897, -6.6531, -6.2297,\n",
      "         -3.3371, -5.3128]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.22972297668457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7698, -0.4314, -4.4720, -5.7819, -6.1136, -1.4369, -6.6538, -5.3834,\n",
      "         -3.7161, -5.7524]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.383417129516602\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3021, -0.5514, -4.1831, -5.4703, -5.3159, -1.4159, -6.3320, -3.5577,\n",
      "         -3.7516, -5.8275]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.315925598144531\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8572, -0.9926, -3.8316, -5.0895, -3.7211, -1.4670, -5.9402, -1.8317,\n",
      "         -3.6973, -5.7942]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.8316798210144043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3515, -2.4416, -4.3028, -5.5221, -3.0747, -2.4489, -6.3603, -0.4268,\n",
      "         -4.4372, -6.5377]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.448864221572876\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3813, -4.3216, -5.2466, -6.4236, -3.0376, -3.1893, -7.2489, -0.1603,\n",
      "         -5.6211, -7.7173]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.189281463623047\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9544, -5.6435, -5.7193, -6.8553, -2.6603, -2.7955, -7.6682, -0.1750,\n",
      "         -6.3085, -8.3987]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.398693084716797\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0363, -6.3872, -5.6981, -6.7953, -1.9256, -2.0347, -7.5966, -0.3606,\n",
      "         -6.4793, -7.8049]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.0346994400024414\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2263, -7.1605, -5.7838, -6.8443, -1.4803, -0.8395, -7.6348, -1.1436,\n",
      "         -6.7366, -7.3726]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.226325035095215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9352, -8.1762, -6.1820, -7.2078, -1.5761, -0.3881, -7.9881, -2.4021,\n",
      "         -7.2877, -7.3024]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.4020802974700928\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5572, -8.9600, -6.4110, -7.4046, -1.6930, -0.3306, -8.1754, -2.7321,\n",
      "         -7.6534, -7.1085]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.7320737838745117\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9354, -9.3620, -6.3145, -7.2782, -1.6385, -0.4813, -8.0402, -2.0406,\n",
      "         -7.6791, -6.6305]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.4813082814216614\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5969, -9.9036, -6.4085, -7.3443, -1.9210, -0.5272, -8.0981, -1.6924,\n",
      "         -7.8820, -6.3804]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.5272390842437744\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5143, -10.5544,  -6.6575,  -7.5674,  -2.4533,  -0.4432,  -8.3136,\n",
      "          -1.6768,  -8.2281,  -6.3195]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.22807788848877\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2052, -10.8416,  -6.5837,  -7.4697,  -2.7011,  -0.5203,  -8.2088,\n",
      "          -1.5007,  -7.5229,  -5.9670]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.5203415155410767\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1547, -11.2406,  -6.6586,  -7.5224,  -3.1174,  -0.4448,  -8.2549,\n",
      "          -1.6459,  -7.0284,  -5.7918]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.117374897003174\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9351, -11.3336,  -6.4608,  -7.3040,  -2.4775,  -0.5605,  -8.0303,\n",
      "          -1.6518,  -6.3175,  -5.3701]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.3700785636901855\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6639, -11.2291,  -6.0955,  -6.9194,  -1.7785,  -0.8761,  -7.6399,\n",
      "          -1.6094,  -5.4901,  -4.0492]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.6638600826263428\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9769, -11.3353,  -5.9686,  -6.7741,  -1.4814,  -1.6519,  -7.4890,\n",
      "          -1.9183,  -4.9483,  -3.0732]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.6518837213516235\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8045, -11.5785,  -6.0039,  -6.7916,  -1.5392,  -1.9303,  -7.5010,\n",
      "          -2.4519,  -4.6130,  -2.3768]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.5010151863098145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8652, -11.6591,  -5.8991,  -6.6697,  -1.6207,  -2.1440,  -6.6804,\n",
      "          -2.8573,  -4.1796,  -1.6815]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.17958402633667\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1753, -11.6541,  -5.7293,  -6.4833,  -1.7712,  -2.3408,  -5.8646,\n",
      "          -3.1870,  -3.0070,  -1.1192]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.007045030593872\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8222, -11.7730,  -5.7023,  -6.4399,  -2.1634,  -2.7090,  -5.2553,\n",
      "          -3.6378,  -1.4000,  -0.9843]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.9842647314071655\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1132, -12.4607,  -6.2613,  -6.9826,  -3.1872,  -3.6678,  -5.2907,\n",
      "          -4.6437,  -0.7099,  -0.9689]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.9688718318939209\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5802, -13.3490,  -7.0351,  -7.7410,  -4.4106,  -4.8182,  -5.5951,\n",
      "          -5.8257,  -0.7097,  -0.7556]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.7556100487709045\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.0990, -14.3385,  -7.9222,  -8.6139,  -5.7115,  -6.0494,  -6.0613,\n",
      "          -7.0820,  -1.2507,  -0.3537]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.3537098169326782\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.8122, -15.5733,  -9.0650,  -9.7437,  -7.2293,  -7.5035,  -6.8263,\n",
      "          -8.5576,  -2.2861,  -0.1107]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.812206745147705\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.0571, -16.1795,  -9.5884, -10.2553,  -8.0909,  -8.3076,  -7.0102,\n",
      "          -9.3808,  -2.7852,  -0.0658]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.06579696387052536\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.3379, -16.7855, -10.1199, -10.7763,  -8.9272,  -9.0921,  -7.2366,\n",
      "         -10.1823,  -3.3389,  -0.0375]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.3388819694519043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.9417, -16.6820,  -9.9494, -10.5961,  -9.0312,  -9.1493,  -6.7916,\n",
      "         -10.2549,  -2.5018,  -0.0875]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.031221389770508\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0898, -16.0934,  -9.3004,  -9.9386,  -7.8455,  -8.7056,  -5.8962,\n",
      "          -9.8250,  -1.3109,  -0.3201]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.32008230686187744\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6472, -15.8872,  -9.0400,  -9.6703,  -7.1019,  -8.6301,  -5.4157,\n",
      "          -9.7618,  -0.7545,  -0.6486]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  9.040000915527344\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.0630, -15.5149,  -7.8370,  -9.2422,  -6.2462,  -8.3755,  -4.7995,\n",
      "          -9.5183,  -0.4018,  -1.1471]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.518253326416016\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.2586, -14.8996,  -6.4738,  -8.5765,  -5.1969,  -7.8664,  -3.9702,\n",
      "          -8.2805,  -0.2794,  -1.5523]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.8663554191589355\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1701, -13.9772,  -4.8791,  -7.6091,  -3.8882,  -6.3366,  -2.8683,\n",
      "          -6.7977,  -0.3357,  -1.7070]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.60906457901001\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0367, -12.9811,  -3.2834,  -5.8422,  -2.5602,  -4.7947,  -1.7504,\n",
      "          -5.2978,  -0.7243,  -1.8162]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.8421630859375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3889, -12.4190,  -2.2107,  -3.8645,  -1.7598,  -3.7469,  -1.2002,\n",
      "          -4.2855,  -1.7504,  -2.3708]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.370823383331299\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2940, -12.3283,  -1.7462,  -2.5143,  -1.5899,  -3.2354,  -1.3315,\n",
      "          -3.7997,  -3.2128,  -2.6063]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.235358476638794\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4798, -12.4377,  -1.6559,  -1.5483,  -1.7883,  -2.2938,  -1.8259,\n",
      "          -3.5697,  -4.7494,  -3.0644]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  12.437715530395508\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8787, -11.9284,  -1.8895,  -0.9983,  -2.2635,  -1.6816,  -2.5491,\n",
      "          -3.5484,  -6.3044,  -3.6767]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.263514757156372\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3877, -11.5747,  -2.3237,  -0.8769,  -2.0936,  -1.3661,  -3.3603,\n",
      "          -3.6556,  -7.8112,  -4.3521]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.6555774211883545\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7788, -11.1619,  -2.6974,  -0.9765,  -1.9429,  -1.1669,  -4.0211,\n",
      "          -2.9404,  -9.0743,  -4.8757]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.02107048034668\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0331, -10.6739,  -2.9708,  -1.2244,  -1.8035,  -1.0902,  -3.8108,\n",
      "          -2.2191, -10.0958,  -5.2368]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  10.673935890197754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1853,  -9.3767,  -3.1665,  -1.5706,  -1.7163,  -1.1664,  -3.5459,\n",
      "          -1.5589, -10.9249,  -5.4751]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.7162507772445679\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4714,  -8.3454,  -3.5129,  -2.1708,  -1.1336,  -1.5908,  -3.4645,\n",
      "          -1.2569, -11.8086,  -5.8297]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.4645180702209473\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7443,  -7.4227,  -3.8543,  -2.8004,  -0.8669,  -2.1221,  -2.7221,\n",
      "          -1.2012, -12.6104,  -6.1574]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.2012434005737305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1479,  -6.7431,  -4.3295,  -3.5627,  -1.1063,  -2.8357,  -2.2502,\n",
      "          -0.7868, -13.4835,  -6.6049]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.562697410583496\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4132,  -6.0290,  -4.6649,  -3.4384,  -1.4775,  -3.4169,  -1.7960,\n",
      "          -0.6470, -14.1669,  -6.9061]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.029047966003418\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4788,  -4.4477,  -4.7976,  -3.1729,  -1.8133,  -3.7865,  -1.3262,\n",
      "          -0.7302, -14.6056,  -7.0013]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  14.605581283569336\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4182,  -2.9094,  -4.8006,  -2.8412,  -2.1201,  -4.0123,  -0.9658,\n",
      "          -1.0364, -14.1654,  -6.9646]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.909383773803711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5851,  -1.0256,  -5.0277,  -2.8029,  -2.7083,  -4.4464,  -1.1255,\n",
      "          -1.7909, -13.9869,  -7.1502]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.125454306602478\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4920,  -0.3582,  -5.9911,  -3.5661,  -4.0439,  -5.5993,  -1.5511,\n",
      "          -3.3468, -14.5799,  -8.0717]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.3581615388393402\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.8749,  -0.0924,  -7.4256,  -4.8390,  -5.8253,  -7.2050,  -2.6474,\n",
      "          -5.3389, -15.6787,  -9.4666]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.87494421005249\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.8182,  -0.0503,  -8.2139,  -5.4871,  -6.9280,  -8.1476,  -3.1802,\n",
      "          -6.6325, -16.1643, -10.2189]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.8181891441345215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.3015,  -0.0593,  -8.2472,  -5.3968,  -7.2450,  -8.3198,  -3.0123,\n",
      "          -7.1215, -15.9246, -10.2196]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.3968353271484375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3088,  -0.1496,  -7.6492,  -3.9645,  -6.9027,  -7.8469,  -2.2672,\n",
      "          -6.9343, -15.0806,  -9.5920]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.649169921875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2485,  -0.5984,  -6.0447,  -2.4120,  -6.3188,  -7.1449,  -1.3923,\n",
      "          -6.4901, -14.0441,  -8.7504]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.3923187255859375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2401,  -2.1763,  -5.3648,  -1.8421,  -6.5575,  -7.2764,  -0.8424,\n",
      "          -6.8543, -13.8739,  -8.7557]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.364770889282227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8810,  -4.0011,  -4.2931,  -1.7630,  -7.0924,  -7.7141,  -0.9671,\n",
      "          -7.5018, -14.0392,  -9.0794]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.092385292053223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7546,  -5.5255,  -3.2059,  -1.6837,  -6.6580,  -7.9757,  -1.2122,\n",
      "          -7.9526, -14.0553,  -9.2381]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.212206482887268\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0481,  -6.9352,  -2.2924,  -1.7813,  -6.3015,  -8.2453,  -0.9766,\n",
      "          -8.3925, -14.1035,  -9.4149]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.3015055656433105\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5038,  -8.1187,  -1.4623,  -1.9051,  -5.1193,  -8.4015,  -0.9404,\n",
      "          -8.7021, -14.0601,  -9.4874]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.462312936782837\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4685,  -9.5628,  -0.4931,  -2.5031,  -4.4373,  -8.9203,  -1.5581,\n",
      "          -9.3590, -14.3990,  -9.9307]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  9.93066692352295\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5072, -10.9659,  -0.2038,  -3.2038,  -3.9348,  -9.4901,  -2.3637,\n",
      "         -10.0533, -14.8067,  -9.6791]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  10.965899467468262\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0571, -11.0654,  -0.1731,  -3.4551,  -3.0880,  -9.5939,  -2.7454,\n",
      "         -10.2691, -14.7645,  -9.0432]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  11.065375328063965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0926,  -9.9351,  -0.3259,  -3.2310,  -1.8875,  -9.2141,  -2.6606,\n",
      "          -9.9900, -14.2530,  -7.9971]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.66064715385437\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1025,  -8.8819,  -0.9859,  -3.0228,  -0.8894,  -8.8366,  -1.9002,\n",
      "          -9.7034, -13.7570,  -7.0198]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.8893598318099976\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8636,  -8.6724,  -2.6077,  -3.6098,  -0.2711,  -9.2358,  -2.0585,\n",
      "         -10.1843, -14.0493,  -6.8794]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.6097946166992188\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4369,  -8.3656,  -4.0071,  -3.3105,  -0.1920,  -9.4771,  -2.1717,\n",
      "         -10.4991, -14.1942,  -6.6353]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.310509443283081\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5529,  -7.6856,  -4.8778,  -1.9409,  -0.3573,  -9.2906,  -1.9493,\n",
      "         -10.3788, -13.9209,  -6.0127]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.9409228563308716\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.0200,  -7.4330,  -6.0273,  -0.4522,  -1.4053,  -9.4823,  -2.2077,\n",
      "         -10.6300, -14.0343,  -5.8133]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.8133158683776855\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.9745,  -7.7379,  -7.5963,  -0.1055,  -3.0704, -10.1868,  -3.0492,\n",
      "         -11.3882, -14.6683,  -5.4169]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.416873931884766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.4595,  -7.6375,  -8.6346,  -0.0688,  -4.2306, -10.4461,  -3.4648,\n",
      "         -11.6957, -14.8640,  -3.9444]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.9443578720092773\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.4985,  -7.1490,  -9.1713,  -0.3067,  -4.8883, -10.2812,  -3.4626,\n",
      "         -11.5743, -14.6418,  -1.4973]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.888331413269043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.2795,  -7.4552, -10.4004,  -1.7910,  -5.4573, -10.8782,  -4.2280,\n",
      "         -12.2104, -15.1872,  -0.2064]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.4552202224731445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.3629,  -7.3658, -11.8871,  -3.6267,  -6.3528, -11.7957,  -5.3074,\n",
      "         -13.1631, -16.0583,  -0.0346]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  16.058259963989258\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.7541e+00, -6.7012e+00, -1.2641e+01, -4.7144e+00, -6.5761e+00,\n",
      "         -1.2037e+01, -5.6984e+00, -1.3437e+01, -1.5539e+01, -1.5121e-02]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  13.436649322509766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.4012,  -5.3983, -12.6156,  -4.9952,  -6.0729, -11.5499,  -5.3476,\n",
      "         -12.2320, -14.3663,  -0.0186]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  14.36628532409668\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4059,  -3.5506, -11.9147,  -4.5753,  -4.9440, -10.4333,  -4.3574,\n",
      "         -10.4696, -11.9193,  -0.0611]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.550628185272217\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.3303,  -0.9874, -11.1042,  -4.0252,  -3.7534,  -9.2483,  -3.2953,\n",
      "          -8.7030,  -9.5362,  -0.6013]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.753406524658203\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.5666,  -0.1617, -11.5786,  -4.7470,  -3.1348,  -9.3855,  -3.5692,\n",
      "          -8.3164,  -8.5945,  -2.6892]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.16173996031284332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.5267,  -0.0539, -12.7528,  -6.1502,  -3.3581, -10.2561,  -4.5826,\n",
      "          -8.7154,  -8.4933,  -5.3661]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.3581154346466064\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.8463,  -0.1188, -13.2651,  -6.8702,  -2.2785, -10.4949,  -4.9572,\n",
      "          -8.5297,  -7.8571,  -7.2351]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.87020206451416\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.7661,  -0.4659, -13.3582,  -6.4340,  -1.0165, -10.3419,  -4.9314,\n",
      "          -7.9943,  -6.9163,  -8.5506]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  10.341893196105957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.8391,  -1.3856, -13.5873,  -6.1874,  -0.3029,  -9.6310,  -5.0583,\n",
      "          -7.6576,  -6.2147,  -9.8807]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.385561466217041\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.9054,  -1.6598, -13.7940,  -5.9673,  -0.2270,  -8.9913,  -5.1775,\n",
      "          -7.3551,  -5.5848, -11.0791]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.991326332092285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4716,  -1.5532, -13.4865,  -5.2772,  -0.2719,  -7.2094,  -4.7952,\n",
      "          -6.5895,  -4.5266, -11.6648]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.589460849761963\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.6790,  -1.2109, -12.8076,  -4.2573,  -0.4872,  -5.2031,  -4.0547,\n",
      "          -4.7542,  -3.1792, -11.7902]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.754215240478516\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.9415,  -1.0978, -12.1720,  -3.3249,  -1.1205,  -3.3760,  -3.3760,\n",
      "          -2.3462,  -1.9717, -11.8791]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.097773790359497\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0750,  -1.3013, -12.3966,  -3.3079,  -2.7343,  -2.5520,  -3.5858,\n",
      "          -1.0457,  -1.7817, -12.7561]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.3078997135162354\n",
      "torch.Size([1, 1, 40])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -7.6023,  -2.0911, -13.0052,  -3.0108,  -4.6432,  -2.2721,  -4.2007,\n",
      "          -0.5427,  -2.1385, -13.9523]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.200715065002441\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.0065,  -2.8222, -13.4822,  -2.7074,  -6.2986,  -2.0230,  -3.9894,\n",
      "          -0.4516,  -2.4739, -14.9585]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.9893593788146973\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.1453,  -3.2990, -13.6863,  -2.2564,  -7.5655,  -1.6682,  -2.8880,\n",
      "          -0.6165,  -2.6113, -15.6392]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.298980474472046\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.2084,  -2.9583, -13.8081,  -1.8631,  -8.6447,  -1.4221,  -1.8730,\n",
      "          -1.1023,  -2.7261, -16.1901]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.422052025794983\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.5674,  -2.9915, -14.2196,  -1.9221,  -9.9186,  -0.9593,  -1.3688,\n",
      "          -2.0873,  -3.1788, -16.9883]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.368788480758667\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.1990,  -3.3665, -14.8984,  -2.3883, -11.3742,  -1.1258,  -0.7028,\n",
      "          -3.3744,  -3.9249, -18.0152]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  9.199028968811035\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.9190,  -3.6880, -15.4682,  -2.8325, -12.6436,  -1.4669,  -0.4094,\n",
      "          -4.5173,  -4.5695, -18.8985]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.6879513263702393\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4086,  -3.0070, -15.7231,  -3.0165, -13.5285,  -1.6813,  -0.3527,\n",
      "          -5.2965,  -4.8993, -19.4358]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  15.723087310791016\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.6254,  -2.1061, -14.8419,  -2.8936, -14.0017,  -1.6841,  -0.4688,\n",
      "          -5.6781,  -4.8779, -19.5959]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  14.001714706420898\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.7553,  -1.2189, -13.8832,  -2.6577, -13.5008,  -1.6547,  -0.8438,\n",
      "          -5.8593,  -4.6992, -19.5750]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.8437817096710205\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.1997,  -0.8637, -13.2468,  -2.7227, -13.2767,  -1.9926,  -1.0108,\n",
      "          -6.2517,  -4.7719, -19.7832]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  13.276677131652832\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5173,  -0.6690, -12.4900,  -2.6448, -12.1368,  -2.2110,  -1.2308,\n",
      "          -6.4228,  -4.6598, -19.7871]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  12.489989280700684\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6701,  -0.6326, -10.7918,  -2.3900, -10.8745,  -2.2508,  -1.3963,\n",
      "          -6.3423,  -4.3299, -19.5547]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  10.791849136352539\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6837,  -0.7566,  -8.2592,  -1.9956,  -9.5066,  -2.1312,  -1.4866,\n",
      "          -6.0401,  -3.8114, -19.1144]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.25920295715332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6842,  -1.0788,  -5.0825,  -1.6068,  -8.1432,  -1.9775,  -1.5938,\n",
      "          -5.6382,  -3.2290, -18.5864]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.082533359527588\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0293,  -1.8066,  -1.6587,  -1.5911,  -7.1053,  -2.1284,  -2.0217,\n",
      "          -5.4686,  -2.9231, -18.3006]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.9231324195861816\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0233,  -4.0589,  -0.1996,  -3.2008,  -7.6481,  -3.8271,  -3.9763,\n",
      "          -6.7960,  -3.4370, -19.5202]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  19.520231246948242\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4696,  -6.6115,  -0.0359,  -5.1915,  -8.6489,  -5.8841,  -6.2612,\n",
      "          -8.5039,  -4.4346, -20.3910]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  20.391029357910156\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1648e+00, -8.2948e+00, -1.8178e-02, -6.3718e+00, -8.9337e+00,\n",
      "         -7.1221e+00, -7.7038e+00, -9.4255e+00, -4.7251e+00, -1.9827e+01]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.933709144592285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0656,  -9.0810,  -0.0233,  -6.7059,  -7.7077,  -7.5077,  -8.2733,\n",
      "          -9.5256,  -4.2631, -18.5890]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.707705497741699\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2815,  -9.0893,  -0.0675,  -6.3079,  -5.1590,  -7.1554,  -8.0866,\n",
      "          -8.9160,  -3.1575, -16.7742]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.15541934967041\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1517,  -8.6618,  -0.3732,  -5.5158,  -2.4329,  -5.6825,  -7.4836,\n",
      "          -7.9321,  -1.7579, -14.7048]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.151691436767578\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0933,  -9.0123,  -1.8984,  -5.5407,  -0.7792,  -5.0938,  -7.6763,\n",
      "          -7.7815,  -1.3583, -13.5764]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.781548500061035\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9741, -10.0620,  -4.1183,  -6.2998,  -0.3701,  -5.3019,  -8.5841,\n",
      "          -7.6341,  -1.9199, -13.2940]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  10.061955451965332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7797, -10.0737,  -5.9300,  -6.7850,  -0.3221,  -5.2930,  -9.2019,\n",
      "          -7.3019,  -2.3328, -12.8399]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.332827568054199\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4556,  -9.7981,  -7.2776,  -6.9367,  -0.5358,  -5.0026,  -9.4723,\n",
      "          -6.7171,  -1.7615, -12.1448]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  9.798126220703125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1741,  -8.6437,  -8.3125,  -6.8948,  -0.9858,  -4.5666,  -9.5366,\n",
      "          -6.0121,  -1.1927, -11.3395]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.643723487854004\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0952,  -6.8075,  -9.1683,  -6.7813,  -1.5930,  -4.1050,  -9.5181,\n",
      "          -5.3025,  -0.8248, -10.5379]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.0952088832855225\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6685,  -5.3390, -10.1234,  -6.8642,  -2.4761,  -3.8856,  -9.6859,\n",
      "          -4.8515,  -0.9967, -10.0003]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.864245891571045\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5141,  -3.8344, -10.7981,  -6.0290,  -3.1486,  -3.5172,  -9.6514,\n",
      "          -4.2656,  -1.2340,  -9.3305]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.5140734910964966\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3245,  -2.7699, -11.6806,  -5.5535,  -4.0613,  -3.4819,  -9.8953,\n",
      "          -4.0234,  -1.9343,  -9.0024]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.769865036010742\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6701,  -1.0702, -12.4076,  -5.0603,  -4.8284,  -3.4045, -10.0472,\n",
      "          -3.7509,  -2.6022,  -8.6390]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  12.407593727111816\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8638,  -0.2589, -12.7759,  -5.0911,  -5.9957,  -3.8293, -10.6545,\n",
      "          -3.9935,  -3.7281,  -8.7825]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  12.77592945098877\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0704,  -0.0952, -12.3655,  -5.1300,  -7.0555,  -4.2343, -11.2081,\n",
      "          -4.2325,  -4.7663,  -8.9184]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.129961013793945\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6820,  -0.0910, -11.4835,  -3.9356,  -7.4981,  -4.0971, -11.1942,\n",
      "          -3.9461,  -5.1950,  -8.5284]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.6820168495178223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9566,  -0.2509, -10.1996,  -2.3846,  -7.4077,  -3.4961, -10.6922,\n",
      "          -3.2132,  -5.0957,  -7.6879]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.2509114742279053\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6592,  -0.5499,  -9.3575,  -1.3686,  -7.6409,  -3.2911, -10.5542,\n",
      "          -2.8976,  -5.3249,  -7.2454]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.6408820152282715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4740,  -1.2574,  -8.6254,  -0.6645,  -7.1271,  -3.1596, -10.4563,\n",
      "          -2.6811,  -5.5610,  -6.8736]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.1596250534057617\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4377,  -2.1606,  -8.0290,  -0.4659,  -6.7278,  -2.4105, -10.4309,\n",
      "          -2.6005,  -5.8393,  -6.6023]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.4104995727539062\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5036,  -3.0848,  -7.5205,  -0.7690,  -6.3974,  -1.1102, -10.4364,\n",
      "          -2.6121,  -6.1204,  -6.3873]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.0848236083984375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8734,  -3.4769,  -7.3075,  -1.6209,  -6.3458,  -0.4221, -10.6859,\n",
      "          -2.9226,  -6.6198,  -6.4396]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.9225575923919678\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2378,  -3.8379,  -7.1021,  -2.5167,  -6.2864,  -0.2621, -10.8965,\n",
      "          -2.4772,  -7.0564,  -6.4737]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.2378289699554443\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4992,  -3.8828,  -6.6220,  -3.0861,  -5.9387,  -0.3761, -10.7905,\n",
      "          -1.8436,  -7.1545,  -6.2099]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.154517650604248\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7169,  -3.7549,  -6.0076,  -3.4489,  -5.4445,  -0.7874, -10.5121,\n",
      "          -1.2089,  -6.3296,  -5.7909]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  10.512104988098145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1874, -3.6873, -5.4870, -3.8296, -5.0335, -1.5142, -9.5847, -0.8926,\n",
      "         -5.6188, -5.4466]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.687288284301758\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9352, -2.9110, -5.0011, -4.1679, -4.6481, -2.3061, -8.7292, -0.8953,\n",
      "         -4.9612, -5.1196]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.3060593605041504\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9331, -2.1609, -4.4788, -4.3941, -4.2184, -2.2821, -7.8692, -1.1145,\n",
      "         -4.2842, -4.7398]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.2184038162231445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1576, -1.4788, -3.9283, -4.5180, -3.0055, -2.2447, -7.0062, -1.4693,\n",
      "         -3.5959, -4.3155]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.4788211584091187\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9661, -0.6709, -3.8021, -4.9923, -2.3051, -2.6416, -6.5844, -2.3164,\n",
      "         -3.3509, -4.2983]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.3163509368896484\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9844, -0.4856, -3.8833, -5.6023, -1.9270, -3.2280, -6.3833, -2.5790,\n",
      "         -3.3338, -4.4708]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.9270374774932861\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9645, -0.7787, -3.9945, -6.1768, -0.9728, -3.8069, -6.2259, -2.8948,\n",
      "         -3.3670, -4.6572]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.9727867841720581\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4460, -1.9518, -4.6921, -7.2792, -0.2353, -4.9277, -6.6691, -3.8042,\n",
      "         -4.0057, -5.4158]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.415774345397949\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7088, -3.0343, -5.2525, -8.1977, -0.0888, -5.8676, -6.9944, -4.5651,\n",
      "         -4.5195, -5.2798]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.08881031721830368\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.9895, -4.1858, -5.9036, -9.1675, -0.0361, -6.8584, -7.4303, -5.4005,\n",
      "         -5.1326, -5.3036]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.167548179626465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.4728, -4.5632, -5.8216, -8.6444, -0.0363, -7.0810, -7.1529, -5.4859,\n",
      "         -5.0187, -4.6583]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.018687725067139\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.2581, -4.2604, -5.1000, -7.5233, -0.0975, -6.6321, -6.2536, -4.9158,\n",
      "         -3.5396, -3.4342]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.915828227996826\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.7203, -3.6531, -4.1100, -6.1694, -0.4713, -5.8841, -5.1004, -3.3150,\n",
      "         -1.8842, -2.0112]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.100378513336182\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.7085, -3.5968, -3.7031, -5.4237, -1.7356, -5.6845, -3.8292, -2.3725,\n",
      "         -0.9768, -1.3023]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.5968236923217773\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.0985, -3.2549, -3.7557, -5.1556, -3.4036, -5.9076, -3.1000, -1.9939,\n",
      "         -0.8360, -1.2682]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.403583526611328\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.3965, -2.9209, -3.7675, -4.8650, -4.1384, -6.0570, -2.4220, -1.7015,\n",
      "         -0.9732, -1.3953]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.4219913482666016\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.7305, -2.7237, -3.8610, -4.6741, -4.8772, -6.2586, -1.2337, -1.6403,\n",
      "         -1.4386, -1.7609]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.723677396774292\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.2898, -2.1442, -4.2198, -4.7675, -5.8066, -6.6999, -0.6288, -1.9890,\n",
      "         -2.2898, -2.4777]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.4776878356933594\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.8454, -1.7572, -4.6059, -4.9096, -6.6976, -7.1501, -0.5145, -2.4574,\n",
      "         -3.1824, -2.4881]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  9.845369338989258\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.3327, -1.3238, -4.7541, -4.8357, -7.2937, -7.3489, -0.6277, -2.7364,\n",
      "         -3.8095, -2.3524]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.8094534873962402\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.7051, -0.9562, -4.7281, -4.6090, -7.6651, -7.3624, -0.9409, -2.8703,\n",
      "         -3.4919, -2.1355]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.870326519012451\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.0634, -0.8212, -4.6349, -4.3355, -7.9233, -7.2984, -1.4219, -2.2079,\n",
      "         -3.1517, -1.9522]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.952197790145874\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5649, -1.0903, -4.6375, -4.1779, -8.2352, -7.3204, -2.1044, -1.7727,\n",
      "         -2.9555, -1.2256]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.5649003982543945\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3497, -1.6029, -4.6795, -4.0793, -8.5486, -7.3729, -2.8376, -1.5403,\n",
      "         -2.8492, -0.8230]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.6028833389282227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2826, -1.5244, -4.7503, -4.0289, -8.8568, -7.4465, -3.5651, -1.5173,\n",
      "         -2.8217, -0.8144]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.5173331499099731\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3603, -1.6423, -4.8554, -4.0310, -9.1691, -7.5479, -4.2750, -0.9483,\n",
      "         -2.8752, -1.1718]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.031042575836182\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4841, -1.8296, -4.9002, -3.2615, -9.3946, -7.5838, -4.8684, -0.6698,\n",
      "         -2.9088, -1.6690]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.668997049331665\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7135, -2.1057, -4.9401, -2.5902, -9.5917, -7.6103, -5.4022, -0.7951,\n",
      "         -2.9730, -1.5051]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.591682434082031\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9740, -2.3417, -4.8827, -1.9416, -8.9361, -7.5357, -5.7872, -1.1456,\n",
      "         -2.9694, -1.4238]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.97402024269104\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8849, -2.8860, -5.1005, -1.7259, -8.6094, -7.7326, -6.3998, -1.9620,\n",
      "         -3.2676, -1.7936]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.100466251373291\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4339, -3.6141, -4.7339, -1.8602, -8.5137, -8.1085, -7.1510, -3.0004,\n",
      "         -3.7625, -2.4489]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.000373363494873\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.3580, -4.0997, -4.2211, -1.9055, -8.2383, -8.2581, -7.6388, -3.0370,\n",
      "         -4.0359, -2.9141]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.63883638381958\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4676, -4.1693, -3.3912, -1.6757, -7.6111, -8.0134, -6.9895, -2.7263,\n",
      "         -3.9158, -2.9941]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.013445854187012\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8181, -3.9973, -2.4239, -1.3601, -6.8009, -6.8220, -6.1597, -2.2494,\n",
      "         -3.5765, -2.8578]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.8578438758850098\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5383, -3.9102, -1.6755, -1.3183, -6.1268, -5.8045, -5.4686, -1.9532,\n",
      "         -3.3463, -2.0878]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.087759256362915\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6682, -4.1569, -1.4561, -1.7874, -5.8321, -5.2012, -5.1601, -2.1030,\n",
      "         -3.4759, -1.0578]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.057803750038147\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4012, -5.0505, -2.0979, -2.9926, -6.2292, -5.3222, -5.5466, -2.9891,\n",
      "         -4.2756, -0.3100]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.0979361534118652\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9991, -5.8872, -2.0321, -4.1422, -6.6157, -5.4620, -5.9248, -3.8520,\n",
      "         -5.0335, -0.2085]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.033484935760498\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0013, -6.2038, -1.6344, -4.7503, -6.5259, -5.1522, -5.8285, -4.2062,\n",
      "         -4.5465, -0.2775]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.5258684158325195\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5433, -6.1291, -1.0643, -4.9430, -5.3510, -4.5161, -5.3824, -4.1749,\n",
      "         -3.7544, -0.5342]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.543265342712402\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0799, -5.9089, -0.6607, -4.9672, -4.1419, -3.7967, -4.8295, -4.0037,\n",
      "         -2.9038, -1.0395]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.908865928649902\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5848, -4.9225, -0.6140, -4.9157, -2.9863, -3.0867, -4.2588, -3.7848,\n",
      "         -2.0996, -1.6747]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.7847530841827393\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1658, -4.0652, -1.0107, -4.9005, -2.0084, -2.5063, -3.7807, -2.8849,\n",
      "         -1.4914, -2.4097]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.9005045890808105\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9718, -3.4870, -1.8273, -4.3402, -1.4084, -2.2250, -3.5481, -2.2978,\n",
      "         -1.2912, -3.3192]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.2912261486053467\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1296, -3.3185, -3.0161, -4.1757, -1.3788, -2.3811, -3.6896, -2.1745,\n",
      "         -0.9085, -4.4953]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.318511486053467\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2471, -2.4585, -4.0978, -4.0125, -1.5114, -2.5629, -3.8086, -2.1219,\n",
      "         -0.8343, -5.5364]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.247118949890137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4662, -1.6471, -4.9871, -3.7811, -1.6959, -2.6855, -3.8339, -2.0662,\n",
      "         -0.9890, -6.3793]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.987102031707764\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7401, -1.0272, -5.0010, -3.5634, -1.9712, -2.8197, -3.8461, -2.0846,\n",
      "         -1.3754, -7.1135]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.000965118408203\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0721, -0.7024, -4.2396, -3.3671, -2.3010, -2.9633, -3.8515, -2.1731,\n",
      "         -1.8881, -7.7544]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.173081398010254\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4725, -0.7502, -3.5534, -3.2042, -2.6603, -3.1189, -3.8599, -1.5813,\n",
      "         -2.4495, -8.3203]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.553377151489258\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9440, -1.1151, -2.1922, -3.0742, -3.0225, -3.2784, -3.8695, -1.1886,\n",
      "         -3.0055, -8.8171]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.1150707006454468\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7892, -1.2463, -1.3302, -3.2705, -3.6640, -3.7290, -4.1724, -1.3412,\n",
      "         -3.8220, -9.5440]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.172440052032471\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7269,  -1.5964,  -0.7822,  -3.5035,  -4.2890,  -4.1807,  -3.7706,\n",
      "          -1.7017,  -4.6017, -10.2269]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.726860284805298\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9306,  -2.0521,  -0.6318,  -3.7324,  -4.8588,  -4.5957,  -3.4219,\n",
      "          -2.1591,  -5.3082, -10.8387]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.85884428024292\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2255,  -2.4508,  -0.7951,  -3.8533,  -4.5364,  -4.8739,  -3.0285,\n",
      "          -2.5543,  -5.8453, -11.2870]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.2254937887191772\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4125,  -3.2478,  -1.6593,  -4.3548,  -4.6308,  -5.5070,  -3.0856,\n",
      "          -3.3450,  -6.7079, -12.0675]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  12.067545890808105\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.1923,  -3.9811,  -2.5690,  -4.8037,  -4.7108,  -6.0681,  -3.1576,\n",
      "          -4.0714,  -7.4736, -12.0210]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.710848331451416\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.1951,  -4.2065,  -2.9977,  -4.7658,  -3.6084,  -6.1267,  -2.8046,\n",
      "          -4.2899,  -7.7153, -11.5308]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.206475734710693\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4284,  -3.2993,  -3.0096,  -4.3260,  -2.2235,  -5.7692,  -2.1181,\n",
      "          -4.0850,  -7.5214, -10.6773]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.11814546585083\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3737,  -2.7370,  -3.2862,  -4.1683,  -1.2846,  -5.6782,  -1.1010,\n",
      "          -4.1417,  -7.5757, -10.1374]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.16829252243042\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7983,  -2.6527,  -3.9397,  -3.6773,  -1.0190,  -5.9749,  -0.7991,\n",
      "          -4.5809,  -8.0013, -10.0273]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.93971848487854\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0651, -2.5630, -3.7243, -3.1900, -0.9818, -6.1803, -0.7849, -4.9203,\n",
      "         -8.3210, -9.8644]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  9.864437103271484\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0090, -2.3265, -3.3381, -2.5711, -1.0135, -6.1564, -0.8875, -5.0211,\n",
      "         -8.3987, -8.7739]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.398727416992188\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.7014, -2.0199, -2.8541, -1.9072, -1.1460, -5.9735, -1.1105, -4.9539,\n",
      "         -7.5670, -7.6291]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.567014694213867\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2642, -1.7746, -2.3984, -1.3557, -1.4357, -5.7474, -1.4829, -4.8354,\n",
      "         -6.0233, -6.5351]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.3984146118164062\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8930, -1.7946, -1.4262, -1.1698, -1.9917, -5.6665, -2.1005, -4.8550,\n",
      "         -4.7551, -5.6712]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.9917478561401367\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.6296, -2.1002, -0.9009, -1.4012, -2.0264, -5.7658, -2.9137, -5.0480,\n",
      "         -3.7888, -5.0654]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.0263750553131104\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.3617, -2.5308, -0.8017, -1.8598, -1.4914, -5.9259, -3.7531, -5.2950,\n",
      "         -3.0037, -4.5927]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.592714786529541\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.9681, -2.9222, -0.9962, -2.3347, -1.1212, -6.0189, -4.4727, -5.4682,\n",
      "         -2.2799, -3.3902]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.3347392082214355\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.5570, -3.3556, -1.4912, -2.1384, -1.0690, -6.1471, -5.1717, -5.6699,\n",
      "         -1.7463, -2.3747]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.4911834001541138\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.2379,  -3.9213,  -1.5061,  -2.1989,  -1.4235,  -6.4147,  -5.9557,\n",
      "          -6.0048,  -1.5449,  -1.6791]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.414724349975586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.8199,  -4.4136,  -1.6543,  -2.3038,  -1.8877,  -5.8856,  -6.6324,\n",
      "          -6.2769,  -1.4897,  -1.1586]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.8877161741256714\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.3714,  -4.8930,  -1.9585,  -2.4995,  -1.7134,  -5.4386,  -7.2701,\n",
      "          -6.5508,  -1.6337,  -0.9484]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.550754547119141\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.7182,  -5.1802,  -2.1883,  -2.5863,  -1.5380,  -4.8893,  -7.6950,\n",
      "          -5.8973,  -1.7576,  -0.8941]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.5380183458328247\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.0986,  -5.5109,  -2.5473,  -2.7882,  -0.8774,  -4.4682,  -8.1461,\n",
      "          -5.3790,  -2.0646,  -1.2139]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.379011154174805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.4015,  -5.7720,  -2.8898,  -2.9759,  -0.5459,  -4.0579,  -8.5128,\n",
      "          -4.1314,  -2.3952,  -1.6806]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.5458943247795105\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.0012,  -6.3363,  -3.5669,  -3.5095,  -0.2687,  -4.0281,  -9.1702,\n",
      "          -3.3468,  -3.0873,  -2.5646]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.346829652786255\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.3391,  -6.6435,  -3.9957,  -3.8100,  -0.3730,  -3.8122,  -9.5601,\n",
      "          -1.7247,  -3.5420,  -3.2152]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.809988260269165\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.7988,  -7.0765,  -4.5511,  -3.5148,  -1.1211,  -3.7897, -10.0667,\n",
      "          -0.5524,  -4.1284,  -3.9860]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.5523725748062134\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-15.1227,  -8.3769,  -5.9691,  -4.1807,  -2.9404,  -4.6960, -11.4328,\n",
      "          -0.0916,  -5.5783,  -5.6037]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.940422534942627\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-16.0042,  -9.2375,  -6.9373,  -4.4811,  -3.5822,  -5.2084, -12.3524,\n",
      "          -0.0494,  -6.5761,  -6.7527]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  16.004222869873047\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-15.3504,  -9.3520,  -7.1494,  -4.0992,  -3.5196,  -5.0132, -12.5199,\n",
      "          -0.0572,  -6.8152,  -7.1276]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.149379730224609\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.1318,  -8.8254,  -5.9603,  -3.1379,  -2.8549,  -4.2126, -12.0411,\n",
      "          -0.1292,  -6.4015,  -6.8361]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  12.041065216064453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.6422,  -7.9591,  -4.4992,  -1.9120,  -1.9057,  -3.1106, -10.4983,\n",
      "          -0.4435,  -5.6381,  -6.1823]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.9056800603866577\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.7178,  -7.5963,  -3.6087,  -1.3343,  -0.8545,  -2.5683,  -9.5260,\n",
      "          -1.6108,  -5.3702,  -6.0120]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.5683484077453613\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.3225,  -7.7071,  -3.2644,  -1.4462,  -0.6521,  -1.8316,  -9.0877,\n",
      "          -3.2453,  -5.5698,  -6.2977]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.2453207969665527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.9241,  -7.7648,  -2.9406,  -1.6787,  -0.8025,  -1.2447,  -8.6506,\n",
      "          -3.9670,  -5.7098,  -6.5139]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.6786893606185913\n",
      "torch.Size([1, 1, 40])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-10.6011,  -7.8529,  -2.7245,  -1.3229,  -1.2962,  -0.9664,  -8.2928,\n",
      "          -4.6666,  -5.8742,  -6.7455]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.874183177947998\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.2063,  -7.8286,  -2.4754,  -1.0954,  -1.8336,  -0.8950,  -7.8669,\n",
      "          -5.1996,  -5.1785,  -6.8512]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.8335940837860107\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.7862, -7.7423, -2.2498, -1.0727, -1.6480, -1.0697, -7.4190, -5.6189,\n",
      "         -4.4915, -6.8824]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.0697171688079834\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.4957, -7.7529, -2.2139, -1.3925, -1.7069, -0.8268, -7.1039, -6.0872,\n",
      "         -3.9690, -6.9991]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.9690043926239014\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.0946, -7.6231, -2.1244, -1.7243, -1.7507, -0.7932, -6.6812, -6.3709,\n",
      "         -2.6363, -6.9654]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.370943546295166\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.6791, -7.4521, -2.0796, -2.1002, -1.8604, -1.0437, -6.2469, -5.8429,\n",
      "         -1.4346, -6.8812]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.842873573303223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.4399, -7.4335, -2.2685, -2.6642, -2.2061, -1.6651, -5.9922, -4.7809,\n",
      "         -0.6638, -6.9412]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.206083297729492\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.3182, -7.5107, -2.6102, -3.3171, -1.9717, -2.4584, -5.8581, -3.9240,\n",
      "         -0.4444, -7.0894]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.9717174768447876\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.1691, -7.5409, -2.9339, -3.8922, -1.1070, -3.1966, -5.6997, -3.1270,\n",
      "         -0.6808, -7.1838]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.196626901626587\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.0701, -7.6035, -3.3006, -4.4604, -0.5999, -3.1845, -5.5946, -2.4762,\n",
      "         -1.3017, -7.3045]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  8.070060729980469\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.1238, -7.5918, -3.5903, -4.9120, -0.4672, -3.1356, -5.4340, -1.8826,\n",
      "         -1.9928, -7.3451]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.912049293518066\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0901, -7.3994, -3.6899, -4.4023, -0.6125, -2.9416, -5.1105, -1.2767,\n",
      "         -2.5335, -7.2000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.2766519784927368\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4222, -7.4879, -4.0598, -4.2134, -1.3901, -3.0672, -5.0847, -0.4698,\n",
      "         -3.3403, -7.3311]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.331139087677002\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8503, -7.5941, -4.4321, -4.0805, -2.2939, -3.2410, -5.0922, -0.2240,\n",
      "         -4.1192, -6.7327]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.2409706115722656\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0206, -7.3693, -4.4556, -3.6524, -2.8588, -2.3674, -4.7825, -0.2605,\n",
      "         -4.5118, -5.8737]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.020638942718506\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2917, -6.9557, -4.2740, -3.0744, -3.1969, -1.4383, -4.2981, -0.6367,\n",
      "         -4.6620, -4.8907]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.298108100891113\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1158, -6.8854, -4.4226, -2.8896, -3.8320, -1.0784, -3.4491, -1.6571,\n",
      "         -5.1057, -4.3125]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.6571481227874756\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6601, -7.1673, -4.9100, -3.1088, -4.7640, -1.3501, -3.0520, -2.3358,\n",
      "         -5.8543, -4.1462]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.7640204429626465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5159, -7.2801, -5.2127, -3.1976, -4.7534, -1.6446, -2.5870, -2.8747,\n",
      "         -6.3888, -3.8665]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.6445550918579102\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7643, -7.2908, -5.3983, -3.2166, -4.6588, -1.2235, -2.1315, -3.3093,\n",
      "         -6.7802, -3.5390]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.780179023742676\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2317, -7.1792, -5.4471, -3.1416, -4.4585, -0.9394, -1.6857, -3.6053,\n",
      "         -6.2716, -3.1439]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.271603107452393\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8009, -6.9986, -5.4136, -3.0254, -4.2057, -0.8909, -1.3383, -3.8108,\n",
      "         -5.0014, -2.7396]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.8009402751922607\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6650, -6.8443, -5.3946, -2.9647, -3.9964, -1.1570, -1.2238, -4.0195,\n",
      "         -3.8702, -2.4316]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.6649905443191528\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0255, -6.8218, -5.4966, -3.0639, -3.9367, -1.7436, -1.4501, -4.3361,\n",
      "         -2.9824, -2.3355]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.821813583374023\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7477, -6.0922, -5.6096, -3.2060, -3.9148, -2.4186, -1.8423, -4.6486,\n",
      "         -2.2381, -2.3393]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.60955810546875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7837, -5.3536, -4.8704, -3.2809, -3.8262, -3.0090, -2.2276, -4.8538,\n",
      "         -1.5633, -2.3317]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.2808785438537598\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1249, -4.6449, -4.1635, -2.5876, -3.7150, -3.5301, -2.6060, -4.9972,\n",
      "         -1.0630, -2.3507]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.6060400009155273\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7105, -4.0393, -3.5644, -2.0446, -3.6579, -4.0467, -2.2989, -5.1570,\n",
      "         -0.8929, -2.4649]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.156970977783203\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3353, -3.4635, -3.0032, -1.6084, -3.5816, -4.4815, -2.0517, -4.5405,\n",
      "         -0.9981, -2.5881]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.540480613708496\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9505, -2.9448, -2.5125, -1.3411, -3.5099, -4.8585, -1.8995, -3.2552,\n",
      "         -1.3413, -2.7325]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.950496196746826\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8227, -2.5736, -2.1898, -1.3521, -3.5242, -5.2611, -1.9285, -2.1828,\n",
      "         -1.9002, -2.9688]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.182788848876953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0540, -2.5952, -2.2849, -1.8542, -3.8583, -5.9278, -2.3605, -0.8864,\n",
      "         -2.8141, -3.5204]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.0539586544036865\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8828, -3.0265, -2.8053, -2.7799, -4.5316, -6.8873, -3.1753, -0.3718,\n",
      "         -4.0384, -4.3966]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.1753218173980713\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6469, -3.3253, -3.1951, -3.5345, -5.0206, -7.6271, -3.0890, -0.2776,\n",
      "         -5.0289, -5.0698]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.028891563415527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1232, -3.2547, -3.2114, -3.8698, -5.0996, -7.9276, -2.6782, -0.3675,\n",
      "         -4.8220, -5.3147]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.3147478103637695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4925, -2.9676, -3.0051, -3.9354, -4.9234, -7.9468, -2.1063, -0.6886,\n",
      "         -4.3899, -4.5368]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.9467620849609375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0700, -2.7179, -2.8284, -3.9803, -4.7411, -7.1955, -1.6508, -1.3052,\n",
      "         -3.9810, -3.8155]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.980997085571289\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9906, -2.5768, -2.7497, -4.0699, -4.6184, -6.5548, -1.4151, -2.0880,\n",
      "         -2.9298, -3.2176]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.554762363433838\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1913, -2.4902, -2.7125, -4.1480, -4.4998, -5.2299, -1.3639, -2.8658,\n",
      "         -2.0069, -2.6938]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.147951602935791\n",
      "torch.Size([1, 1, 40])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6489, -2.5148, -2.7716, -3.5280, -4.4426, -4.0824, -1.5451, -3.6484,\n",
      "         -1.3161, -2.3147]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.5280280113220215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3160, -2.7026, -2.9789, -2.3607, -4.5057, -3.1675, -1.9694, -4.4778,\n",
      "         -0.9970, -2.1536]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.477827072143555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0838, -3.0116, -3.2952, -1.4698, -4.6611, -2.4651, -2.5435, -4.6108,\n",
      "         -1.0711, -2.1863]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.4697513580322266\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2485, -3.7637, -4.0461, -0.5398, -5.2455, -2.3330, -3.5553, -5.1752,\n",
      "         -1.8267, -2.7380]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.7379941940307617\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4664, -4.6161, -4.8938, -0.2920, -5.9335, -2.4435, -4.6452, -5.8455,\n",
      "         -2.7833, -2.6918]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.466378688812256\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4643, -5.0645, -5.3364, -0.2935, -6.2285, -2.2806, -5.3073, -6.1247,\n",
      "         -3.3636, -2.3744]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.464288711547852\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3393, -5.1140, -5.3797, -0.4834, -6.1367, -1.8505, -5.5481, -6.0187,\n",
      "         -3.5528, -1.7995]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.114029884338379\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1924, -4.2838, -5.2784, -0.9617, -5.9117, -1.4356, -5.6240, -5.7811,\n",
      "         -3.6003, -1.2621]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.6002731323242188\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2488, -3.6039, -5.2488, -1.7294, -5.7687, -1.2955, -5.7527, -5.6270,\n",
      "         -2.9871, -1.0483]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.2487664222717285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9759, -3.2712, -5.4857, -2.8102, -5.9016, -1.6313, -6.1304, -5.7503,\n",
      "         -2.7313, -1.3785]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.9759310483932495\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.2078, -3.8517, -6.5546, -4.6799, -6.8757, -2.9308, -7.3245, -6.7159,\n",
      "         -3.4010, -2.7172]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.851716995239258\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.0900, -3.6076, -7.4668, -6.3191, -7.7021, -4.0891, -8.3488, -7.5348,\n",
      "         -3.9771, -3.9210]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.08995651453733444\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.0519, -3.5412, -8.4223, -7.9302, -8.5804, -5.2783, -9.4051, -8.4064,\n",
      "         -4.6434, -5.1536]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.05187865346670151\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.0378,  -3.5616,  -9.3419,  -9.4403,  -9.4304,  -6.4119, -10.4153,\n",
      "          -9.2504,  -5.3093,  -6.3270]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.411866188049316\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.0663,  -2.9059,  -9.4753, -10.1054,  -9.5010,  -5.9996, -10.6301,\n",
      "          -9.3156,  -5.2177,  -6.6901]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  10.630147933959961\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2109,  -1.7660,  -9.0059, -10.1149,  -8.9751,  -5.0407,  -9.5039,\n",
      "          -8.7848,  -4.5497,  -6.4285]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  9.005899429321289\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7820, -0.6970, -7.6446, -9.9553, -8.3333, -4.0137, -8.3216, -8.1387,\n",
      "         -3.7877, -6.0259]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.7819849848747253\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2310,  -0.4462,  -6.7647, -10.1572,  -8.1013,  -3.4478,  -7.6026,\n",
      "          -7.9028,  -3.4638,  -6.0108]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  10.157242774963379\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5779, -0.4122, -5.6957, -9.3265, -7.6151, -2.6843, -6.6780, -7.4131,\n",
      "         -2.9177, -5.7217]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.721675395965576\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8060, -0.6255, -4.4958, -8.3385, -6.9377, -1.8074, -5.6065, -6.7327,\n",
      "         -2.2260, -4.4717]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.338512420654297\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1407, -1.2130, -3.4291, -6.7254, -6.3338, -1.1445, -4.6495, -6.1262,\n",
      "         -1.6880, -3.3600]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.725432872772217\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6740, -2.1022, -2.6367, -4.6943, -5.9342, -0.9265, -3.9378, -5.7246,\n",
      "         -1.4831, -2.5280]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.1022181510925293\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3322, -2.3842, -2.1042, -2.9977, -5.7023, -1.1492, -3.4370, -5.4912,\n",
      "         -1.5919, -1.9647]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.4369606971740723\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1106, -2.8639, -1.8776, -1.6647, -5.6544, -1.7427, -2.4395, -5.4425,\n",
      "         -1.9988, -1.7216]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.442530632019043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1175, -3.6311, -2.0854, -0.8958, -5.9074, -2.7004, -1.8985, -4.9797,\n",
      "         -2.7588, -1.9308]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.0854287147521973\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2275, -4.5401, -1.7963, -0.7000, -6.3359, -3.8113, -1.7194, -4.7666,\n",
      "         -3.6888, -2.4273]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.4272828102111816\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.1603, -5.2981, -1.5957, -0.8173, -6.6547, -4.7598, -1.6208, -4.5123,\n",
      "         -4.4765, -2.1212]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.65471076965332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.8442, -5.8277, -1.4147, -1.0876, -6.0561, -5.4636, -1.5198, -4.1345,\n",
      "         -5.0376, -1.7789]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.519843339920044\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.5593, -6.4056, -1.5383, -1.6749, -5.6176, -6.1995, -0.9587, -3.9045,\n",
      "         -5.6465, -1.6964]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.617586135864258\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.1532, -6.8771, -1.7652, -2.2899, -4.4511, -6.8135, -0.6833, -3.6618,\n",
      "         -6.1473, -1.7099]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.6617860794067383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.5602, -7.1745, -1.9737, -2.7895, -3.2810, -7.2393, -0.6756, -2.6202,\n",
      "         -6.4719, -1.7301]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.9737012386322021\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.9763, -7.4924, -1.5476, -3.3337, -2.3042, -7.6729, -1.0888, -1.7839,\n",
      "         -6.8150, -1.9312]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.304172992706299\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.6549,  -8.0829,  -1.6314,  -4.1536,  -1.0790,  -8.3675,  -2.0096,\n",
      "          -1.4547,  -7.4285,  -2.5252]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.079000473022461\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.0427,  -9.3917,  -2.6345,  -5.6802,  -0.2775,  -9.7699,  -3.7132,\n",
      "          -2.1024,  -8.7583,  -3.8973]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.6345090866088867\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.3233, -10.6011,  -2.8570,  -7.0881,  -0.1388, -11.0636,  -5.2959,\n",
      "          -2.8039,  -9.9866,  -5.1789]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.178866863250732\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.9753, -11.1890,  -2.6002,  -7.8555,  -0.1436, -11.7275,  -6.2237,\n",
      "          -2.9779, -10.5916,  -5.0844]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  11.189034461975098\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.0526, -10.4760,  -1.9161,  -8.0370,  -0.2614, -11.8155,  -6.5508,\n",
      "          -2.6612, -10.6266,  -4.4941]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.550759792327881\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.8376,  -9.5492,  -1.1285,  -7.9161,  -0.6339, -11.6102,  -5.8329,\n",
      "          -2.1415, -10.3735,  -3.6863]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.6863253116607666\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.7008,  -8.7715,  -0.7248,  -7.8642,  -1.4049, -11.4820,  -5.2453,\n",
      "          -1.8146, -10.2024,  -2.2883]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.8146133422851562\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.8568,  -8.3504,  -1.0125,  -8.0970,  -2.5539, -11.6459,  -4.9992,\n",
      "          -1.2001, -10.3276,  -1.3845]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.350431442260742\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.1268,  -7.3729,  -1.6797,  -8.4364,  -3.7739, -11.9229,  -4.9119,\n",
      "          -0.9921, -10.5698,  -0.8878]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.436373710632324\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.2883,  -6.4114,  -2.3421,  -7.9301,  -4.8074, -12.0908,  -4.7571,\n",
      "          -0.9889, -10.7063,  -0.6673]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.757110118865967\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.1970,  -5.3099,  -2.7757,  -7.2376,  -5.5073, -12.0052,  -3.6626,\n",
      "          -1.0157, -10.5926,  -0.6160]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  10.59256362915039\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.8603,  -4.0671,  -2.9595,  -6.3600,  -5.8860, -11.6737,  -2.4410,\n",
      "          -1.0445,  -9.4911,  -0.7185]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.360030651092529\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.4794,  -2.8827,  -3.0874,  -4.7682,  -6.1514, -11.2974,  -1.3265,\n",
      "          -1.2445,  -8.4215,  -1.0964]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.326542854309082\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.7490,  -2.4698,  -3.8503,  -3.9534,  -7.0046, -11.5713,  -0.4047,\n",
      "          -2.2434,  -8.0711,  -2.2984]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.243393659591675\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.1923,  -2.3603,  -4.7541,  -3.4340,  -7.9740, -12.0183,  -0.2599,\n",
      "          -2.7023,  -7.9562,  -3.6563]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  12.018282890319824\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.2410,  -1.9805,  -5.2243,  -2.6394,  -8.4968, -11.3222,  -0.3371,\n",
      "          -2.8131,  -7.5025,  -4.5480]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.502538681030273\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.0295,  -1.4843,  -5.3964,  -1.7204,  -8.7124, -10.4399,  -0.6653,\n",
      "          -2.7003,  -6.0986,  -5.1036]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.6653370261192322\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.0930,  -1.4577,  -5.8090,  -1.2774,  -9.1607,  -9.8993,  -0.8643,\n",
      "          -2.9007,  -5.0898,  -5.8624]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.900744676589966\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.0546,  -1.5092,  -6.0873,  -0.9864,  -9.4689,  -9.3170,  -1.2512,\n",
      "          -2.3116,  -4.0905,  -6.4524]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.2512258291244507\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.1034,  -1.8011,  -6.4229,  -1.0798,  -9.8298,  -8.8759,  -1.1689,\n",
      "          -1.9350,  -3.2862,  -7.0682]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.42291784286499\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.0252,  -2.0632,  -5.8338,  -1.2896, -10.0329,  -8.3568,  -1.1960,\n",
      "          -1.5768,  -2.4676,  -7.5014]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.5013580322265625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.8866,  -2.3244,  -5.2372,  -1.6111, -10.1475,  -7.8211,  -1.3695,\n",
      "          -1.3336,  -1.7254,  -7.0746]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.147502899169922\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.7307,  -2.6005,  -4.6730,  -2.0152,  -9.4991,  -7.3081,  -1.6774,\n",
      "          -1.2716,  -1.1588,  -6.6600]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.6774287223815918\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.6560,  -2.9694,  -4.2378,  -2.5421,  -8.9807,  -6.9121,  -1.4358,\n",
      "          -1.4816,  -0.9482,  -6.3531]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.4815864562988281\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.6216,  -3.3723,  -3.8899,  -3.1071,  -8.5470,  -6.5892,  -1.4218,\n",
      "          -1.1523,  -1.0802,  -6.1109]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.1522927284240723\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.7831,  -3.9530,  -3.7848,  -3.8410,  -8.3490,  -6.4919,  -1.7748,\n",
      "          -0.5622,  -1.6445,  -6.0870]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.6444709300994873\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.9465,  -4.5080,  -3.7256,  -4.5356,  -8.1888,  -6.4234,  -2.2323,\n",
      "          -0.4548,  -1.5697,  -6.0851]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  13.946484565734863\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.0277,  -4.7195,  -3.3945,  -4.8726,  -7.7482,  -6.0665,  -2.4250,\n",
      "          -0.5123,  -1.3607,  -5.7887]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.3606858253479004\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.2433,  -4.9597,  -3.1654,  -5.2248,  -7.3950,  -5.7899,  -2.7053,\n",
      "          -1.0317,  -0.6643,  -5.5672]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.6642856001853943\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.0510,  -5.6952,  -3.5057,  -6.0600,  -7.5913,  -6.0572,  -3.5197,\n",
      "          -2.2656,  -0.1920,  -5.8845]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.884518146514893\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.6046,  -6.0869,  -3.5622,  -6.5406,  -7.4952,  -6.0264,  -4.0013,\n",
      "          -3.1773,  -0.1063,  -5.1531]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.562230110168457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.6982,  -5.9369,  -2.3607,  -6.4701,  -6.9048,  -5.4962,  -3.9438,\n",
      "          -3.5236,  -0.1875,  -3.9944]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.9943723678588867\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.7091, -5.6310, -1.1785, -6.2349, -6.2009, -4.8489, -3.7331, -3.6834,\n",
      "         -0.6948, -2.0514]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.84891414642334\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.3406, -5.8803, -0.8735, -6.5467, -6.0906, -4.0422, -4.0828, -4.3675,\n",
      "         -2.0389, -0.9196]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.367476940155029\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.2877, -6.3858, -1.1997, -7.1075, -6.2719, -3.6078, -4.6889, -4.5609,\n",
      "         -3.6237, -0.4768]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.560912132263184\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.0566, -6.6587, -1.5420, -7.4296, -6.2530, -3.0534, -5.0577, -3.8545,\n",
      "         -4.8870, -0.3569]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.252967357635498\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.5257, -6.5826, -1.6923, -7.3973, -5.1928, -2.2670, -5.0716, -2.9104,\n",
      "         -5.7074, -0.4455]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.692273736000061\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.0591, -6.5265, -1.2108, -7.3799, -4.2534, -1.6483, -5.1001, -2.1100,\n",
      "         -6.4600, -1.0102]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.110042095184326\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.9222, -6.7601, -1.2893, -7.6479, -3.7008, -1.5194, -5.4131, -1.0560,\n",
      "         -7.4220, -2.0709]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.070918083190918\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.0282, -7.2003, -1.8007, -8.1185, -3.4499, -1.7975, -5.9273, -0.5810,\n",
      "         -8.5178, -2.6069]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.200295448303223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.9837, -6.7166, -2.2481, -8.4024, -3.1069, -2.0330, -6.2521, -0.4075,\n",
      "         -9.3646, -3.0039]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.1068525314331055\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.7292, -6.0671, -2.5175, -8.4435, -1.8963, -2.1293, -6.3313, -0.5041,\n",
      "         -9.9125, -3.1833]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.729213237762451\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6921,  -5.4472,  -2.7855,  -8.4438,  -0.8777,  -2.2691,  -6.3671,\n",
      "          -0.9777, -10.3693,  -3.3387]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.367093563079834\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8847,  -5.0177,  -3.1999,  -8.5700,  -0.3866,  -2.5989,  -5.8035,\n",
      "          -1.7933, -10.9062,  -3.6305]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.90619945526123\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.9837,  -4.4597,  -3.4284,  -8.5076,  -0.2586,  -2.7760,  -5.1220,\n",
      "          -2.4683, -10.4764,  -3.7368]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.25862783193588257\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3663,  -4.1545,  -3.8480,  -8.6403,  -0.1679,  -3.1715,  -4.7014,\n",
      "          -3.3244, -10.2780,  -4.0390]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.27802562713623\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3543, -3.4256, -3.7766, -8.2942, -0.2282, -3.0936, -3.8634, -3.6549,\n",
      "         -8.9028, -3.8584]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.3543248176574707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5150, -2.6062, -3.5428, -7.7956, -0.6644, -2.8708, -2.9368, -3.7837,\n",
      "         -7.4772, -3.5243]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.795620441436768\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5230, -2.4179, -3.8493, -7.1031, -1.9193, -3.2078, -2.6354, -4.4103,\n",
      "         -6.6885, -3.7399]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.103133201599121\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.2894, -2.5163, -4.3435, -5.9502, -3.3560, -3.7436, -2.6176, -5.1848,\n",
      "         -6.1808, -4.1535]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.2893586754798889\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.1611, -2.9404, -5.0740, -5.1892, -4.9503, -4.5196, -2.9300, -6.1616,\n",
      "         -6.0005, -4.8129]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.9299545288085938\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.2549, -2.9158, -5.2907, -4.0619, -5.9451, -4.7807, -2.0819, -6.5968,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -5.3940, -4.9669]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.9157705307006836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7379, -1.9974, -5.2955, -2.8652, -6.6486, -4.8279, -1.2142, -6.7955,\n",
      "         -4.6568, -4.9164]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.648613452911377\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7366, -1.4701, -5.5026, -2.0284, -6.7631, -5.0755, -0.8465, -7.1740,\n",
      "         -4.1989, -5.0754]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.846514105796814\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2200, -1.6154, -6.1417, -1.8211, -7.3165, -5.7526, -0.5529, -7.9649,\n",
      "         -4.2469, -5.6725]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.246870994567871\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4377, -1.7452, -6.5701, -1.6051, -7.6664, -6.2159, -0.5558, -8.5286,\n",
      "         -3.4210, -6.0641]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.6050931215286255\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5716, -2.0202, -6.9852, -0.8525, -8.0102, -6.6630, -1.0004, -9.0646,\n",
      "         -2.7294, -6.4467]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.571600437164307\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8466, -2.3843, -7.3775, -0.5068, -8.3378, -7.0843, -1.6836, -9.5651,\n",
      "         -2.1722, -6.8102]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.377503395080566\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9406, -2.6247, -6.8014, -0.4828, -8.4770, -7.3085, -2.2767, -9.8600,\n",
      "         -1.5981, -6.9824]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.982396125793457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8179, -2.6860, -6.0742, -0.7046, -8.3933, -7.3016, -2.6756, -9.9163,\n",
      "         -1.0205, -6.1853]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.301583290100098\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5681, -2.6503, -5.2794, -1.1245, -8.1764, -6.3931, -2.9428, -9.8254,\n",
      "         -0.6235, -5.3272]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.327219009399414\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1751, -2.4999, -4.3968, -1.5695, -7.8105, -5.4055, -3.0507, -9.5728,\n",
      "         -0.4886, -3.6498]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.6497528553009033\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8039, -2.4040, -3.5897, -2.1010, -7.4594, -4.4977, -3.1604, -9.3236,\n",
      "         -0.7942, -1.4050]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.160405397415161\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2287, -3.1379, -3.6372, -3.4222, -7.8966, -4.4415, -3.3205, -9.8521,\n",
      "         -2.1527, -0.3177]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.637179136276245\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8723,  -4.0882,  -3.1869,  -4.8929,  -8.5475,  -4.6568,  -3.7476,\n",
      "         -10.5850,  -3.7180,  -0.1346]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.7476212978363037\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.0356,  -4.5381,  -2.3949,  -5.8044,  -8.7154,  -4.4396,  -3.0140,\n",
      "         -10.8266,  -4.7271,  -0.1951]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.439582347869873\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8787,  -4.6454,  -1.4463,  -6.3217,  -8.5609,  -3.1896,  -2.0828,\n",
      "         -10.7384,  -5.3365,  -0.5455]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.5454814434051514\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.1032,  -5.1129,  -1.1380,  -7.1526,  -8.7856,  -2.4589,  -1.6974,\n",
      "         -11.0226,  -6.2525,  -0.9170]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.6973741054534912\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4642,  -5.6955,  -1.2654,  -8.0585,  -9.1451,  -2.0229,  -0.9239,\n",
      "         -11.4357,  -7.2360,  -1.7007]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.69552755355835\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8517,  -5.5374,  -1.6596,  -8.9357,  -9.5301,  -1.7922,  -0.5736,\n",
      "         -11.8690,  -8.1833,  -2.6010]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.6010494232177734\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0756,  -5.2722,  -2.0359,  -9.6000,  -9.7511,  -1.5854,  -0.5366,\n",
      "         -12.1333,  -8.9108,  -2.6094]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.5365824103355408\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.4480,  -5.2072,  -2.6458, -10.3683, -10.1202,  -1.7252,  -0.3764,\n",
      "         -12.5413,  -9.7362,  -2.8407]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.645845890045166\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.5065,  -4.8755,  -2.2007, -10.7830, -10.1753,  -1.7095,  -0.4461,\n",
      "         -12.6316, -10.2022,  -2.8143]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.202232360839844\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.2879,  -4.3107,  -1.6135, -10.8847,  -9.9533,  -1.5615,  -0.6939,\n",
      "         -12.4411,  -9.6152,  -2.5625]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.6135127544403076\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.2936,  -4.0142,  -0.6722, -11.1784,  -9.9554,  -1.7902,  -1.4746,\n",
      "         -12.4716,  -9.2886,  -2.5941]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.955413818359375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.4064,  -3.8677,  -0.3250, -11.5499,  -9.3432,  -2.2304,  -2.4480,\n",
      "         -12.6061,  -9.1016,  -2.7843]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.230391502380371\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.3070,  -3.5501,  -0.3659, -11.6832,  -8.5906,  -1.7462,  -3.1848,\n",
      "         -12.5260,  -8.7319,  -2.7993]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.731917381286621\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.9261,  -2.9936,  -0.6409, -11.5113,  -7.6210,  -1.1508,  -3.5860,\n",
      "         -12.1618,  -7.3772,  -2.5655]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.565453290939331\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.5736,  -2.5199,  -1.2800, -11.3462,  -6.7380,  -0.8449,  -3.9569,\n",
      "         -11.8237,  -6.1473,  -1.6711]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.6710789203643799\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6173,  -2.5136,  -2.4278, -11.5577,  -6.3037,  -1.2559,  -4.6646,\n",
      "         -11.8792,  -5.4015,  -0.6370]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.303667068481445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8382,  -2.7492,  -3.7092, -11.9286,  -5.3765,  -2.0227,  -5.4892,\n",
      "         -12.1097,  -4.9135,  -0.2718]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.838160037994385\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.9822,  -2.7234,  -4.5961, -11.9766,  -4.2589,  -2.5278,  -5.9488,\n",
      "         -12.0314,  -4.1935,  -0.2107]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  12.031353950500488\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8080,  -2.3442,  -4.9972, -11.6146,  -2.8573,  -2.6381,  -5.9592,\n",
      "         -10.8403,  -3.1508,  -0.3357]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.33573728799819946\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0218,  -2.3398,  -5.6285, -11.5535,  -1.9015,  -3.0568,  -6.2354,\n",
      "         -10.0327,  -2.5083,  -0.5069]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.62851095199585\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2776,  -2.3583,  -5.3833, -11.4485,  -1.0985,  -3.4197,  -6.4355,\n",
      "          -9.2553,  -1.9393,  -1.0455]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.383310317993164\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7488,  -2.5584,  -4.5196, -11.4663,  -0.7286,  -3.8837,  -6.7292,\n",
      "          -8.6677,  -1.6450,  -1.8963]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.8837318420410156\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2901,  -2.7649,  -3.7182, -11.4504,  -0.7119,  -3.5241,  -6.9626,\n",
      "          -8.1067,  -1.4899,  -2.7390]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.7649431228637695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8887,  -2.1805,  -2.9484, -11.3695,  -0.9840,  -3.1562,  -7.1070,\n",
      "          -7.5352,  -1.4495,  -3.4780]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.1804537773132324\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7989,  -1.1476,  -2.4497, -11.4515,  -1.6530,  -3.0119,  -7.3924,\n",
      "          -7.1757,  -1.7405,  -4.3207]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.3206892013549805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0259,  -0.6350,  -2.2462, -11.7052,  -2.5733,  -3.0993,  -7.8297,\n",
      "          -7.0323,  -2.3115,  -4.5450]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.032304763793945\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2464,  -0.4841,  -2.0575, -11.8477,  -3.3711,  -3.1263,  -8.1379,\n",
      "          -6.1042,  -2.8127,  -4.6687]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.668674945831299\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2781,  -0.5594,  -1.7362, -11.7273,  -3.8657,  -2.9353,  -8.1669,\n",
      "          -5.0212,  -3.0595,  -3.8200]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.820012092590332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2457,  -0.9123,  -1.4407, -11.4786,  -4.1859,  -2.6633,  -8.0528,\n",
      "          -3.9102,  -3.1761,  -2.2189]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.052813529968262\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4700,  -1.7002,  -1.5266, -11.4261,  -4.6569,  -2.6431,  -7.4033,\n",
      "          -3.0957,  -3.4834,  -1.0264]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.643080711364746\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0687,  -2.8768,  -2.1007, -11.7100,  -5.4189,  -2.2509,  -7.1500,\n",
      "          -2.7257,  -4.1139,  -0.5405]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.1499714851379395\n",
      "torch.Size([1, 1, 40])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -3.5870,  -3.9215,  -2.6540, -11.9087,  -6.0515,  -1.9207,  -6.1524,\n",
      "          -2.3826,  -4.6369,  -0.4634]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.051461219787598\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8565,  -4.6582,  -2.9872, -11.8689,  -5.6812,  -1.5159,  -5.0368,\n",
      "          -1.9210,  -4.8962,  -0.6246]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.0367560386657715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9958,  -5.2090,  -3.2061, -11.7133,  -5.2305,  -1.1986,  -3.2087,\n",
      "          -1.4908,  -5.0155,  -1.0316]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  11.713266372680664\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1959,  -5.7694,  -3.4944, -10.8874,  -4.8888,  -1.2023,  -1.6516,\n",
      "          -1.3256,  -5.1881,  -1.7124]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.202344298362732\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8462,  -6.7349,  -4.2357, -10.6020,  -5.0449,  -1.1334,  -0.8447,\n",
      "          -1.8261,  -5.8062,  -2.9126]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.13340425491333\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.7409,  -7.9082,  -5.2173, -10.6480,  -5.4931,  -0.8620,  -0.7284,\n",
      "          -2.6955,  -6.6679,  -4.3351]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.8619857430458069\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.7748,  -9.1907,  -6.3311, -10.9152,  -6.1253,  -0.4079,  -1.1942,\n",
      "          -3.7528,  -7.6706,  -5.8512]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.19424569606781\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.6485, -10.2875,  -7.2773, -11.0974,  -6.6380,  -0.4453,  -1.0600,\n",
      "          -4.6635,  -8.5156,  -7.1603]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.0600472688674927\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4444, -11.2840,  -8.1386, -11.2703,  -7.1094,  -0.9717,  -0.4849,\n",
      "          -5.4991,  -9.2855,  -8.3485]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  9.285493850708008\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.9945, -12.0146,  -8.7477, -11.2593,  -7.3677,  -1.5641,  -0.2391,\n",
      "          -6.0878,  -9.0724,  -9.2520]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  9.251972198486328\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.0875, -12.2701,  -8.8938, -10.8468,  -7.1983,  -1.8528,  -0.1745,\n",
      "          -6.2171,  -8.4780,  -8.9480]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.948047637939453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.6654, -11.9941,  -8.5195,  -9.9693,  -6.5402,  -1.7250,  -0.2035,\n",
      "          -5.8290,  -7.4368,  -7.4596]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.829012393951416\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.8365, -11.2968,  -7.7338,  -8.7303,  -5.4998,  -1.2954,  -0.3539,\n",
      "          -4.3134,  -6.0508,  -5.6707]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.670714855194092\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8803, -10.4587,  -6.8164,  -7.4045,  -4.3557,  -0.9048,  -0.7707,\n",
      "          -2.7480,  -4.5943,  -3.1482]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.1481692790985107\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6060, -10.2901,  -6.5771,  -6.7971,  -3.9208,  -1.4439,  -2.0561,\n",
      "          -1.9704,  -3.8762,  -0.7936]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.970427393913269\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.6093, -11.3874,  -7.6120,  -7.5002,  -4.7928,  -3.3564,  -4.5527,\n",
      "          -1.9033,  -4.4941,  -0.2427]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.609286308288574\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.6281, -12.2703,  -8.4389,  -8.0283,  -5.4786,  -4.9997,  -6.7032,\n",
      "          -1.8446,  -4.9534,  -0.1964]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.028306007385254\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.1974, -12.6172,  -8.7356,  -7.3085,  -5.6512,  -6.0365,  -8.1925,\n",
      "          -1.4571,  -4.9241,  -0.2849]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.9241437911987305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4696, -12.5892,  -8.6625,  -6.3202,  -5.4688,  -6.6316,  -9.1934,\n",
      "          -0.9352,  -3.8244,  -0.5508]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  12.58918285369873\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6507, -11.6482,  -8.4321,  -5.2670,  -5.1429,  -7.0038,  -9.9303,\n",
      "          -0.5827,  -2.6855,  -1.0280]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.5827070474624634\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.2839, -11.1688,  -8.5927,  -4.6902,  -5.2215,  -7.7076, -10.9617,\n",
      "          -0.3161,  -2.0783,  -2.0753]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  11.1687593460083\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7578,  -9.7925,  -8.5377,  -3.9779,  -5.0965,  -8.1419, -11.6909,\n",
      "          -0.3994,  -1.4244,  -2.9065]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.141949653625488\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1035,  -8.3660,  -8.3011,  -3.1633,  -4.8012,  -7.5896, -12.1603,\n",
      "          -0.7668,  -0.8268,  -3.5061]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.103466510772705\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7101,  -7.0410,  -8.0477,  -2.4209,  -4.5007,  -7.0520, -12.5426,\n",
      "          -1.3887,  -0.5723,  -4.0266]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.500738620758057\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5230,  -5.8642,  -7.8356,  -1.8350,  -3.5265,  -6.5843, -12.9026,\n",
      "          -2.1427,  -0.7763,  -4.5236]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.14274263381958\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8449,  -5.0275,  -7.8658,  -1.6484,  -2.8914,  -6.3851, -13.4478,\n",
      "          -2.4098,  -1.5207,  -5.1998]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.4098000526428223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6706,  -4.3802,  -7.9945,  -1.7263,  -2.4613,  -6.3083, -14.0401,\n",
      "          -2.1036,  -2.4539,  -5.9138]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.103588581085205\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9364,  -3.8311,  -8.1353,  -1.9550,  -2.1606,  -6.2650, -14.5979,\n",
      "          -1.2314,  -3.3824,  -6.5833]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  14.59792709350586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5223,  -3.3948,  -8.3041,  -2.3093,  -2.0157,  -6.2693, -14.4344,\n",
      "          -0.6950,  -4.2856,  -7.2290]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.269315242767334\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1579,  -2.9653,  -8.3946,  -2.6415,  -1.9207,  -5.4603, -14.2254,\n",
      "          -0.5045,  -5.0474,  -7.7492]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.394556999206543\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6047,  -2.4018,  -7.4878,  -2.7789,  -1.7267,  -4.5195, -13.8216,\n",
      "          -0.5452,  -5.5227,  -8.0025]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.6047253608703613\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1598,  -1.8356,  -6.5449,  -2.8227,  -1.5551,  -3.5537, -13.3313,\n",
      "          -0.8646,  -5.8270,  -8.1042]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  13.331281661987305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8143,  -1.4115,  -5.6625,  -2.8727,  -1.5204,  -2.6712, -12.1520,\n",
      "          -1.4153,  -6.0688,  -8.1615]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  12.151956558227539\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6466,  -1.2300,  -4.8876,  -2.9774,  -1.6660,  -1.9456, -10.4091,\n",
      "          -2.0996,  -6.3053,  -8.2304]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.6465791463851929\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0597, -1.4755, -4.3844, -3.2991, -2.1241, -1.5892, -9.0286, -2.9915,\n",
      "         -6.7086, -8.4815]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.9914989471435547\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8089, -1.8778, -3.9502, -3.6260, -2.6334, -1.4317, -7.7946, -3.1309,\n",
      "         -7.0819, -8.7170]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.1308724880218506\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8090, -2.2368, -3.4556, -3.8219, -3.0260, -1.3519, -6.5651, -2.4656,\n",
      "         -7.3001, -8.8107]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.810674667358398\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0085, -2.4960, -2.8901, -3.8704, -3.2706, -1.3312, -5.3143, -1.7816,\n",
      "         -7.3526, -8.0464]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.046356201171875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4116, -2.7334, -2.3658, -3.8717, -3.4605, -1.4541, -4.1332, -1.2259,\n",
      "         -7.3423, -6.6017]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.225895643234253\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2979, -3.3313, -2.3017, -4.2238, -3.9896, -2.0764, -3.4159, -0.5651,\n",
      "         -7.6685, -5.6368]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.0764243602752686\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2524, -3.9754, -2.4004, -4.6306, -4.5584, -2.0542, -2.8718, -0.4483,\n",
      "         -8.0413, -4.8490]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.041284561157227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9108, -4.3387, -2.3290, -4.7733, -4.8474, -1.8998, -2.1907, -0.5600,\n",
      "         -7.4024, -3.9140]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.5599814653396606\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7170, -4.8735, -2.5382, -5.1061, -5.3111, -2.0715, -1.8540, -0.5579,\n",
      "         -7.0252, -3.2839]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.025231838226318\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2484, -5.1593, -2.5866, -5.2088, -5.5308, -2.1197, -1.4598, -0.7551,\n",
      "         -5.7471, -2.5412]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.5411596298217773\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.7855, -5.4754, -2.7432, -5.3598, -5.7860, -2.3082, -1.3232, -1.3155,\n",
      "         -4.6527, -1.2837]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.785491466522217\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.7296, -5.9957, -3.1667, -5.7318, -6.2504, -2.7855, -1.6207, -2.2401,\n",
      "         -3.9066, -0.5782]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.250392913818359\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6854, -6.4697, -3.5847, -6.0729, -5.9395, -3.2656, -2.0319, -3.1509,\n",
      "         -3.2533, -0.3402]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.031877040863037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4753, -6.7248, -3.8098, -6.2089, -5.4886, -3.5539, -1.6165, -3.8282,\n",
      "         -2.5207, -0.4511]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.6164524555206299\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3733, -7.0395, -4.1138, -6.4169, -5.1696, -3.9193, -0.7642, -4.5373,\n",
      "         -2.0046, -1.0793]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.113846302032471\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4073, -7.4458, -3.7442, -6.7277, -5.0087, -4.3856, -0.4470, -5.3058,\n",
      "         -1.7622, -2.0042]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.3855743408203125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2785, -7.6492, -3.2667, -6.8456, -4.7058, -3.8963, -0.4479, -5.8383,\n",
      "         -1.5086, -2.7682]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.27847957611084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1604, -7.5961, -2.6297, -6.7160, -4.2030, -3.2345, -0.6599, -6.0833,\n",
      "         -1.2079, -3.2635]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.263519287109375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0807, -7.4639, -2.0275, -6.5153, -3.6764, -2.5833, -1.1275, -6.2207,\n",
      "         -1.0745, -2.9524]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.080691337585449\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5312, -7.4963, -1.7388, -6.4869, -3.3719, -2.2052, -1.9262, -6.4970,\n",
      "         -1.3592, -2.8597]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.496318817138672\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6503, -7.1160, -1.9642, -6.8107, -3.4713, -2.2963, -3.0958, -7.0951,\n",
      "         -2.1548, -3.1644]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.116034507751465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.3454, -6.1098, -2.3632, -7.1898, -3.6703, -2.5411, -4.2674, -7.7210,\n",
      "         -3.0440, -3.5550]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.5410635471343994\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.3922, -4.9836, -2.5742, -7.3101, -3.6466, -1.8459, -5.1106, -8.0632,\n",
      "         -3.6586, -3.7049]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.110647678375244\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7211, -3.7455, -2.5946, -7.1898, -3.4154, -1.1098, -4.9430, -8.1425,\n",
      "         -4.0021, -3.6280]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.9430389404296875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3743, -2.6348, -2.6579, -7.0686, -3.2179, -0.6823, -4.0873, -8.2006,\n",
      "         -4.3116, -3.5638]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.5637779235839844\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1785, -1.7119, -2.7926, -6.9831, -3.0928, -0.7014, -3.3514, -8.2762,\n",
      "         -4.6233, -2.8521]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.3514392375946045\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0796, -1.1078, -3.0524, -6.9972, -3.1040, -1.1823, -2.1116, -8.4349,\n",
      "         -5.0018, -2.3418]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.434925079345703\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0984, -0.9861, -3.4955, -7.1830, -3.3196, -2.0182, -1.2515, -8.0462,\n",
      "         -5.5200, -2.1216]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.519997596740723\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1013, -1.2314, -3.9910, -7.4235, -3.6131, -2.9437, -0.7487, -7.7690,\n",
      "         -5.3173, -2.0796]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.9437408447265625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9365, -1.6004, -4.3791, -7.5679, -3.8249, -2.9908, -0.5523, -7.4471,\n",
      "         -5.0658, -2.0563]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.6004185676574707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6156, -1.2550, -4.6634, -7.6234, -3.9567, -2.9959, -0.7003, -7.0826,\n",
      "         -4.7690, -2.0497]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.615625381469727\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2723, -0.9683, -4.7360, -7.4829, -3.8989, -2.8472, -0.9869, -6.5642,\n",
      "         -4.3172, -1.9429]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.736024856567383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8160, -0.8480, -3.8779, -7.2083, -3.7132, -2.6083, -1.3546, -5.9497,\n",
      "         -3.7717, -1.7983]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.7131807804107666\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3079, -0.9629, -3.0218, -6.8621, -2.7253, -2.3492, -1.7652, -5.2987,\n",
      "         -3.1982, -1.6844]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.7252917289733887\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0012, -1.5010, -2.4360, -6.6982, -1.2974, -2.3348, -2.4008, -4.8632,\n",
      "         -2.8593, -1.8588]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.863163471221924\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0872, -2.5104, -2.3339, -6.9086, -0.5701, -2.7516, -3.3930, -4.1308,\n",
      "         -2.9539, -2.4818]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.953914165496826\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2470, -3.5584, -2.3956, -7.1766, -0.4100, -3.2528, -4.3876, -3.5603,\n",
      "         -2.4125, -3.1791]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.5603187084198\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2294, -4.3581, -2.3568, -7.2529, -0.5884, -3.5678, -5.1264, -2.2028,\n",
      "         -1.8260, -3.6707]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.3568336963653564\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3617, -5.2321, -1.7605, -7.4662, -1.3001, -4.0167, -5.9399, -1.2019,\n",
      "         -1.5618, -4.2752]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.2018623352050781\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0921, -6.6308, -1.9655, -8.2665, -2.7486, -5.0423, -7.2821, -0.4207,\n",
      "         -2.0879, -5.4372]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.092105388641357\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0237, -7.9254, -2.2933, -9.0212, -4.1340, -6.0047, -8.5251, -0.2132,\n",
      "         -2.6879, -6.5205]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.293333053588867\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6766, -8.8040, -1.6039, -9.4136, -5.1059, -6.5859, -9.3573, -0.3055,\n",
      "         -2.9916, -7.2097]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.105897903442383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1098, -9.3387, -0.8829, -9.5103, -4.9947, -6.8535, -9.8499, -0.6458,\n",
      "         -3.0457, -7.5741]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.994718074798584\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5119,  -9.7281,  -0.4638,  -9.5054,  -4.0800,  -7.0032, -10.2016,\n",
      "          -1.2249,  -3.0378,  -7.8106]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.003215789794922\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7713,  -9.8684,  -0.3648,  -9.2904,  -3.0580,  -6.1743, -10.3078,\n",
      "          -1.7403,  -2.8560,  -7.8133]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.057957172393799\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0053,  -9.8780,  -0.6964,  -8.9802,  -1.3322,  -5.3127, -10.2867,\n",
      "          -2.2099,  -2.6185,  -7.6993]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.699324607849121\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7858, -10.3191,  -1.8125,  -9.1334,  -0.4025,  -4.9730, -10.7002,\n",
      "          -3.1417,  -2.8916,  -7.3271]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.7857601642608643\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0781, -10.9196,  -3.1470,  -9.4746,  -0.2554,  -4.8754, -11.2757,\n",
      "          -4.2141,  -3.3822,  -7.1956]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.147020101547241\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2913, -11.2154,  -3.3615,  -9.5369,  -0.4396,  -4.5483, -11.5491,\n",
      "          -4.9452,  -3.6045,  -6.8327]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.8326735496521\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6487, -11.3379,  -3.4375,  -9.4492,  -0.9267,  -4.1178, -11.6513,\n",
      "          -5.4647,  -3.6811,  -5.6649]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.449219703674316\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3705, -11.3499,  -3.4325,  -8.4970,  -1.5527,  -3.6442, -11.6452,\n",
      "          -5.8372,  -3.6707,  -4.5174]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.496952056884766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3677, -11.0833,  -3.1755,  -6.5947,  -1.9918,  -2.9600, -11.3622,\n",
      "          -5.8973,  -3.4030,  -3.2142]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  11.083325386047363\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6851,  -9.8804,  -2.7722,  -4.6785,  -2.2816,  -2.1789, -10.9032,\n",
      "          -5.7491,  -2.9828,  -1.8646]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.982759714126587\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6159,  -9.0611,  -2.7212,  -3.2240,  -2.8803,  -1.8252, -10.7538,\n",
      "          -5.8819,  -2.1580,  -1.0219]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.0219006538391113\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2662,  -8.9850,  -3.3878,  -2.6065,  -4.1217,  -2.2903, -11.2808,\n",
      "          -6.6650,  -2.1633,  -0.4773]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.606513023376465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8910,  -9.0262,  -4.1240,  -1.4517,  -5.3611,  -2.8955, -11.8651,\n",
      "          -7.4807,  -2.3638,  -0.5320]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.8955180644989014\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4314,  -9.1349,  -4.8710,  -0.6640,  -6.5521,  -2.7984, -12.4629,\n",
      "          -8.2873,  -2.6862,  -1.0639]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.6862430572509766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.8606,  -9.2736,  -5.5903,  -0.3929,  -7.6664,  -2.7977, -13.0419,\n",
      "          -9.0545,  -2.3233,  -1.8249]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  13.04189682006836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.8889,  -9.1395,  -5.9820,  -0.4097,  -8.4113,  -2.5842, -12.6029,\n",
      "          -9.4865,  -1.8105,  -2.3638]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  12.602871894836426\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.5477,  -8.7516,  -6.0694,  -0.6666,  -8.8149,  -2.1816, -11.2445,\n",
      "          -9.6083,  -1.2036,  -2.6477]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.069441795349121\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.0308,  -8.2921,  -5.2664,  -1.1802,  -9.0682,  -1.7942,  -9.9108,\n",
      "          -9.6077,  -0.7710,  -2.8425]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.607739448547363\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.3633,  -7.7759,  -4.4447,  -1.7752,  -9.1938,  -1.4686,  -8.6073,\n",
      "          -8.8035,  -0.6242,  -2.9563]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.775909423828125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.4749,  -6.3661,  -3.5258,  -2.2527,  -9.1191,  -1.1618,  -7.2456,\n",
      "          -7.8915,  -0.7032,  -2.9073]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.161846399307251\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.7625,  -5.2851,  -2.9083,  -2.9504,  -9.2391,  -0.5532,  -6.2070,\n",
      "          -7.2575,  -1.3298,  -3.0886]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  10.76254653930664\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.2017,  -4.2568,  -2.3359,  -3.5603,  -9.2886,  -0.3813,  -5.2145,\n",
      "          -6.6286,  -2.0322,  -3.2253]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.335904598236084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.6618, -3.3067, -1.0903, -4.0965, -9.2984, -0.7061, -4.2897, -6.0282,\n",
      "         -2.7276, -3.3415]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.02824592590332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.3972, -2.7006, -0.4500, -4.8138, -9.5290, -1.5912, -3.6882, -5.0130,\n",
      "         -3.6243, -3.6926]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.692575454711914\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.1526, -2.1994, -0.3590, -5.4595, -9.7302, -2.5352, -3.1575, -4.0969,\n",
      "         -4.4452, -3.3183]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.1575429439544678\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.7861, -1.6861, -0.6675, -5.8979, -9.7651, -3.2986, -1.8657, -3.1371,\n",
      "         -5.0469, -2.8603]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.686076045036316\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.8337,  -0.9843,  -1.7162,  -6.6725, -10.1742,  -4.3915,  -1.1884,\n",
      "          -2.6809,  -5.9712,  -2.8657]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.6809139251708984\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.1402,  -0.9000,  -3.0619,  -7.6345, -10.8061,  -5.6486,  -1.0555,\n",
      "          -1.8855,  -7.0689,  -3.1739]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.885469675064087\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.6268,  -1.3433,  -4.5202,  -8.7116, -11.5857,  -6.9938,  -1.3901,\n",
      "          -0.7925,  -8.2686,  -3.6912]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.711627960205078\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.2472,  -2.1229,  -6.0241,  -9.0953, -12.4699,  -8.3881,  -2.0480,\n",
      "          -0.3070,  -9.5313,  -4.3569]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.095322608947754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.5933,  -2.7032,  -7.1676,  -8.4673, -13.0536,  -9.4313,  -2.5182,\n",
      "          -0.1712, -10.4559,  -4.7526]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.467254638671875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.4347,  -2.8063,  -7.7277,  -6.6775, -13.1089,  -9.9005,  -2.5279,\n",
      "          -0.1645, -10.8183,  -4.6448]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.16448169946670532\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.3806,  -3.0338,  -8.3212,  -5.1554, -13.2474, -10.4117,  -2.6813,\n",
      "          -0.1419, -11.2333,  -4.6432]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.6812593936920166\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.9320,  -2.8754,  -8.4558,  -3.3892, -12.9722, -10.4723,  -1.7680,\n",
      "          -0.3221, -11.2071,  -4.2486]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  12.972234725952148\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.4901,  -2.7377,  -8.5394,  -1.7864, -11.9557, -10.4889,  -1.0271,\n",
      "          -0.9457, -11.1457,  -3.8654]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.8653957843780518\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.4748,  -3.0456,  -8.9974,  -0.8532, -11.4230, -10.8865,  -0.9931,\n",
      "          -2.1575, -11.4730,  -3.2161]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.8532412052154541\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.1342,  -4.0322, -10.0830,  -0.2513, -11.6163, -11.9176,  -1.8946,\n",
      "          -4.0017, -12.4408,  -3.3327]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  10.083016395568848\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.5549,  -4.7610, -10.1173,  -0.1295, -11.6171, -12.6730,  -2.6384,\n",
      "          -5.5020, -13.1392,  -3.2895]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  12.673038482666016\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.3921,  -4.8822,  -9.6065,  -0.1441, -11.0763, -12.0546,  -2.8166,\n",
      "          -6.3142, -13.2264,  -2.7352]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  9.606466293334961\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.7418,  -4.4935,  -7.8795,  -0.3051, -10.0856, -10.9940,  -2.5153,\n",
      "          -6.5432, -12.8014,  -1.7779]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.5431671142578125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.9852,  -3.9809,  -6.1536,  -0.8309,  -9.0224,  -9.8679,  -2.1296,\n",
      "          -5.8865, -12.2475,  -0.8638]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.02236270904541\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4080,  -3.6376,  -4.7050,  -1.7345,  -7.4407,  -8.9579,  -1.9697,\n",
      "          -5.4011, -11.8528,  -0.4413]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.957863807678223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.7744,  -3.2346,  -3.2934,  -2.5667,  -5.9027,  -7.2726,  -1.8094,\n",
      "          -4.8531, -11.3834,  -0.3985]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.272552967071533\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0458,  -2.7434,  -1.8924,  -3.2155,  -4.3614,  -4.8519,  -1.6217,\n",
      "          -4.2067, -10.8023,  -0.6716]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.206705570220947\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6118,  -2.5719,  -0.9678,  -4.0514,  -3.2041,  -2.8994,  -1.8128,\n",
      "          -3.1678, -10.5005,  -1.4962]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.8993875980377197\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8205,  -3.0745,  -1.0258,  -5.4158,  -2.7903,  -1.0396,  -2.6980,\n",
      "          -2.8598, -10.8273,  -2.9942]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.8597559928894043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.7061,  -4.2592,  -2.0499,  -7.3447,  -3.1593,  -0.3270,  -4.2393,\n",
      "          -2.6338, -11.8184,  -5.0751]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  11.818371772766113\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4695,  -5.3025,  -3.0365,  -9.0477,  -3.4882,  -0.1927,  -5.6029,\n",
      "          -2.4452, -11.9230,  -6.9189]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.302515029907227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.7204,  -5.0445,  -3.5251, -10.1447,  -3.3701,  -0.2514,  -6.3968,\n",
      "          -1.8983, -11.5805,  -8.1434]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.044543743133545\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.6030,  -3.7163,  -3.6442, -10.7891,  -2.9455,  -0.5385,  -6.7694,\n",
      "          -1.1653, -10.9285,  -8.9027]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  10.789137840270996\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4530,  -2.4944,  -3.7273, -10.5706,  -2.5573,  -1.1847,  -7.0614,\n",
      "          -0.6756, -10.2971,  -9.5423]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.061437606811523\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.3707,  -1.5094,  -3.8732, -10.4263,  -2.3172,  -2.0457,  -6.6739,\n",
      "          -0.6373,  -9.7810, -10.1709]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  9.78104019165039\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.3188,  -0.8127,  -4.0426, -10.3184,  -2.1954,  -2.9388,  -6.3478,\n",
      "          -0.9880,  -8.5890, -10.7590]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  8.318784713745117\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.4600,  -0.4809,  -4.1661, -10.1788,  -2.1251,  -3.7399,  -6.0129,\n",
      "          -1.5168,  -7.4732, -11.2461]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.4808509945869446\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0086,  -0.2133,  -4.6108, -10.3745,  -2.4710,  -4.8003,  -6.0344,\n",
      "          -2.4652,  -6.7902, -12.0063]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.610762119293213\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.2048,  -0.1887,  -3.8526, -10.1528,  -2.4467,  -5.3635,  -5.6575,\n",
      "          -2.9797,  -5.7780, -12.2928]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.9797229766845703\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0644,  -0.3739,  -2.7681,  -9.5350,  -2.0705,  -5.4560,  -4.9024,\n",
      "          -2.3720,  -4.4508, -12.1328]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.7680625915527344\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1143,  -1.1303,  -1.1490,  -9.0508,  -1.8966,  -5.6146,  -4.2997,\n",
      "          -1.9607,  -3.3363, -12.0607]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.896590232849121\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8965,  -2.6797,  -0.5590,  -9.2400,  -1.7400,  -6.3852,  -4.3917,\n",
      "          -2.3120,  -2.9847, -12.6209]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.240008354187012\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7083,  -4.1191,  -0.4580,  -8.6517,  -1.7203,  -7.0727,  -4.4756,\n",
      "          -2.6888,  -2.6985, -13.1178]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.119086265563965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2902,  -4.4025,  -0.5824,  -7.8543,  -1.5667,  -7.4250,  -4.2915,\n",
      "          -2.8071,  -2.2240, -13.2976]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.5824294090270996\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1157,  -4.8402,  -0.5310,  -7.3098,  -1.7550,  -7.9158,  -4.3086,\n",
      "          -3.1284,  -2.0516, -13.6327]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.051614284515381\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9017,  -5.1491,  -0.8413,  -6.7287,  -1.9606,  -8.2668,  -4.2423,\n",
      "          -3.3565,  -1.1500, -13.8433]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.8412925004959106\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0007,  -5.6809,  -0.9370,  -6.4556,  -2.4986,  -8.8324,  -4.4421,\n",
      "          -3.8353,  -0.8261, -14.2822]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.8261196613311768\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3751,  -6.4090,  -1.5678,  -6.4575,  -3.2904,  -9.5886,  -4.8769,\n",
      "          -4.5280,  -0.3591, -14.9242]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.588571548461914\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4954,  -6.8226,  -2.0511,  -6.2170,  -3.7874,  -9.2810,  -5.0305,\n",
      "          -4.9159,  -0.2214, -15.2589]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.915870189666748\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1699,  -6.7385,  -2.1267,  -5.5445,  -3.7943,  -8.5467,  -4.7161,\n",
      "          -4.1254,  -0.2410, -15.1028]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.24097272753715515\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0385,  -6.7928,  -2.4147,  -5.0710,  -3.9463,  -8.0147,  -4.5684,\n",
      "          -3.5539,  -0.2273, -15.0915]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.9463095664978027\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5508,  -6.4359,  -2.3356,  -4.2427,  -2.9547,  -7.1293,  -4.0362,\n",
      "          -2.6523,  -0.4032, -14.6747]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.03620719909668\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0912,  -6.0348,  -2.2571,  -3.4267,  -2.0190,  -6.2515,  -2.7820,\n",
      "          -1.8079,  -0.9774, -14.2184]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.9773985743522644\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1664,  -6.0684,  -2.6592,  -3.1095,  -1.6671,  -5.8555,  -2.0892,\n",
      "          -1.5533,  -1.4210, -14.2005]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  14.2005033493042\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3335,  -6.1107,  -3.0851,  -2.8679,  -1.4995,  -5.5114,  -1.5633,\n",
      "          -1.4800,  -2.0106, -13.4850]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.110669136047363\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5337,  -5.3707,  -3.4777,  -2.6675,  -1.4871,  -5.1787,  -1.2121,\n",
      "          -1.5449,  -2.6154, -12.8149]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.4871423244476318\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8955,  -4.8275,  -3.9745,  -2.6594,  -1.0270,  -5.0030,  -1.2263,\n",
      "          -1.8700,  -3.3344, -12.3312]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.0269821882247925\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5731,  -4.6532,  -4.7451,  -3.0139,  -0.4514,  -5.1585,  -1.7555,\n",
      "          -2.5778,  -4.3172, -12.2043]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.5777504444122314\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1169,  -4.4151,  -5.3574,  -3.2821,  -0.3128,  -5.2147,  -2.2661,\n",
      "          -2.4907,  -5.1239, -12.0018]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  12.00179386138916\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2551,  -3.8456,  -5.5481,  -3.1879,  -0.3591,  -4.9050,  -2.4351,\n",
      "          -2.1049,  -5.4906, -10.7487]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.255073070526123\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3296, -3.0658, -5.4399, -2.8513, -0.6269, -4.3487, -2.3664, -1.5584,\n",
      "         -5.5409, -9.3372]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.5583618879318237\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7436, -2.6185, -5.5653, -2.8118, -1.4763, -4.0770, -2.5907, -0.7441,\n",
      "         -5.8087, -8.2858]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.076980113983154\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4311, -2.4360, -5.8465, -2.9871, -2.5729, -3.2642, -3.0111, -0.5027,\n",
      "         -6.2174, -7.5044]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.0111489295959473\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1329, -2.2527, -6.0166, -3.0981, -3.5308, -2.4755, -2.6305, -0.6150,\n",
      "         -6.5016, -6.7159]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.016622066497803\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8624, -2.0731, -5.3127, -3.1382, -4.3207, -1.7340, -2.2445, -0.9921,\n",
      "         -6.6646, -5.9124]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.0730702877044678\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8968, -1.4087, -4.8397, -3.3645, -5.1989, -1.3556, -2.1292, -1.7427,\n",
      "         -6.9695, -5.3480]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.839700698852539\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1054, -1.0558, -3.7220, -3.6554, -6.0544, -1.2683, -2.1702, -2.5991,\n",
      "         -7.3054, -4.9037]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.055802583694458\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6886, -0.5478, -3.0344, -4.2374, -7.1270, -1.7006, -2.5885, -3.7217,\n",
      "         -7.9088, -4.8094]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.688570976257324\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4305, -0.4680, -2.3928, -4.7136, -8.0345, -2.1675, -2.9595, -4.6903,\n",
      "         -8.3935, -4.6712]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.034491539001465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0444, -0.6456, -1.6626, -4.9272, -7.8982, -2.4517, -3.1084, -5.3469,\n",
      "         -8.6082, -4.3314]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.645566463470459\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0193, -0.6700, -1.3718, -5.3472, -7.9979, -2.9941, -3.4962, -6.1634,\n",
      "         -9.0236, -4.2568]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.997875213623047\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8835, -0.8600, -1.0870, -5.5126, -7.1457, -3.3037, -3.6505, -6.6837,\n",
      "         -9.1814, -3.9833]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.086987018585205\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0721, -1.5412, -0.5193, -5.8572, -6.5715, -3.8026, -4.0005, -7.3458,\n",
      "         -9.5162, -3.9429]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  9.516157150268555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2090, -2.1844, -0.3306, -6.0389, -5.9245, -4.1378, -4.1979, -7.8115,\n",
      "         -8.9365, -3.7895]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.137836933135986\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0758, -2.5064, -0.3645, -5.8624, -5.0020, -3.3612, -4.0444, -7.8893,\n",
      "         -8.0728, -3.3256]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.889347076416016\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7597, -2.5637, -0.6261, -5.4118, -3.8822, -2.3939, -3.6248, -6.9782,\n",
      "         -7.0013, -2.6396]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.8821561336517334\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6530, -2.7170, -1.3089, -5.0532, -2.2097, -1.6349, -3.3098, -6.2021,\n",
      "         -6.0809, -2.1168]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.2097039222717285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3316, -3.5304, -2.7533, -5.3608, -0.6897, -1.7229, -3.6776, -6.1302,\n",
      "         -5.8793, -2.3577]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.3315980434417725\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7989, -4.8441, -4.6615, -6.2005, -0.2444, -2.4950, -4.5862, -6.6261,\n",
      "         -6.2590, -3.2017]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.24442727863788605\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6555, -6.4215, -6.7754, -7.3467, -0.0753, -3.6406, -5.8000, -7.4620,\n",
      "         -6.9908, -4.3792]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.990832805633545\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9015, -7.2978, -8.1346, -7.8340, -0.0500, -4.1464, -6.3499, -7.6697,\n",
      "         -6.3577, -4.9032]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.29779052734375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4982, -6.6941, -8.7181, -7.6325, -0.0707, -3.9732, -6.2056, -7.2165,\n",
      "         -5.1482, -4.7398]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.148220062255859\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6254, -5.6183, -8.7106, -6.9183, -0.2214, -3.2982, -5.5441, -6.2757,\n",
      "         -2.7884, -4.0658]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.544082164764404\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0491, -4.8055, -8.8573, -6.4292, -1.0796, -2.8714, -4.3916, -5.5831,\n",
      "         -0.8626, -3.6245]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.429187774658203\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4391, -4.8883, -9.7981, -6.0320, -2.9027, -3.3382, -4.1712, -5.7706,\n",
      "         -0.2530, -4.0547]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.171156406402588\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7586,  -4.8688, -10.5456,  -5.5764,  -4.4839,  -3.6855,  -3.1760,\n",
      "          -5.8418,  -0.1848,  -4.3550]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.18482305109500885\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2725,  -5.0338, -11.3956,  -5.3457,  -6.0927,  -4.1939,  -2.4862,\n",
      "          -6.0848,  -0.1746,  -4.8114]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  11.39559268951416\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3365,  -4.7589, -10.9731,  -4.7133,  -7.1146,  -4.2347,  -1.4959,\n",
      "          -5.8767,  -0.3617,  -4.7998]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  4.713322162628174\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3391,  -4.4349, -10.5098,  -3.3062,  -7.9527,  -4.1995,  -0.6807,\n",
      "          -5.6085,  -0.9630,  -4.7126]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.9630312919616699\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6267,  -4.4097, -10.3500,  -2.3244,  -8.9652,  -4.4366,  -0.5646,\n",
      "          -5.6269,  -1.3030,  -4.8979]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.5645534992218018\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1632,  -4.6529, -10.4630,  -1.7721, -10.1339,  -4.9159,  -0.4104,\n",
      "          -5.9029,  -2.0670,  -5.3270]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  10.463041305541992\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4432,  -4.6637,  -9.5954,  -1.1895, -10.9710,  -5.1377,  -0.5278,\n",
      "          -5.9379,  -2.6334,  -5.5016]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.137656211853027\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5210,  -4.4971,  -8.6305,  -0.7145, -11.5412,  -4.4064,  -0.8680,\n",
      "          -5.7876,  -3.0132,  -5.4782]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  11.541224479675293\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4176,  -4.1735,  -7.5799,  -0.4797, -11.1561,  -3.5752,  -1.2896,\n",
      "          -5.4726,  -3.2097,  -5.2782]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.472589015960693\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0784,  -3.6382,  -6.3785,  -0.4854, -10.5538,  -2.5921,  -1.6088,\n",
      "          -4.2453,  -3.1610,  -4.8462]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.553796768188477\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6260, -3.0157, -5.1377, -0.7987, -9.1400, -1.6029, -1.8776, -2.9898,\n",
      "         -2.9884, -4.3026]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.7986768484115601\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5867, -2.8395, -4.3719, -1.0076, -8.2142, -1.2109, -2.5755, -2.2411,\n",
      "         -3.2176, -4.1701]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.214159965515137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5414, -2.6935, -3.6603, -1.4420, -6.6428, -1.0507, -3.2263, -1.6090,\n",
      "         -3.4221, -4.0304]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.6089531183242798\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7715, -2.8615, -3.2871, -2.2615, -5.4769, -1.4178, -4.0887, -0.7364,\n",
      "         -3.8788, -4.1656]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.7715234756469727\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3362, -3.1784, -3.1016, -3.2010, -4.5521, -2.0529, -4.9995, -0.4043,\n",
      "         -4.4277, -4.4209]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.052947521209717\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8676, -3.3909, -2.8643, -3.9737, -3.6223, -1.8646, -5.7201, -0.4618,\n",
      "         -4.8264, -4.5549]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.554949760437012\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2975, -3.4154, -2.5013, -4.4914, -2.6115, -1.6188, -6.1788, -0.7551,\n",
      "         -4.9989, -3.7677]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.767725944519043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9112, -3.5106, -2.2851, -5.0145, -1.8017, -1.5947, -6.6416, -1.3907,\n",
      "         -5.2075, -2.4064]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.3907289505004883\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9742, -3.9141, -2.4627, -5.7855, -1.4849, -2.0204, -7.3543, -1.7403,\n",
      "         -5.6945, -1.5404]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.354276657104492\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1943, -4.3471, -2.7419, -6.5367, -1.4155, -2.5579, -7.3393, -2.2302,\n",
      "         -6.1900, -0.9696]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.536693096160889\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4314, -4.6983, -2.9939, -6.4021, -1.4774, -3.0517, -7.2778, -2.6968,\n",
      "         -6.5892, -0.6808]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.9938814640045166\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5738, -4.8815, -2.3602, -6.1420, -1.5556, -3.3919, -7.0828, -3.0233,\n",
      "         -6.8096, -0.6456]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.809597492218018\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5758, -4.8661, -1.6751, -5.7234, -1.5903, -3.5375, -6.7217, -3.1647,\n",
      "         -6.0778, -0.8053]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.86607551574707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5462, -4.0073, -1.1091, -5.2576, -1.6756, -3.5993, -6.3060, -3.2299,\n",
      "         -5.3291, -1.1790]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.007314682006836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5762, -2.4902, -0.8450, -4.8372, -1.8810, -3.6706, -5.9282, -3.3110,\n",
      "         -4.6537, -1.7317]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.4901516437530518\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0034, -0.7790, -1.2734, -4.8051, -2.5150, -4.0945, -5.9302, -3.7496,\n",
      "         -4.3930, -2.6971]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.930167198181152\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0298, -0.1876, -2.4741, -5.3850, -3.7463, -5.0913, -5.8276, -4.7633,\n",
      "         -4.7699, -4.2176]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.474053382873535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8037, -0.1166, -2.6968, -5.7463, -4.7075, -5.8292, -5.5729, -5.5177,\n",
      "         -4.9513, -5.4331]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.11658015102148056\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6102, -0.0732, -3.0516, -6.1773, -5.6828, -6.5991, -5.4495, -6.3031,\n",
      "         -5.2231, -6.6340]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.0515613555908203\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.7724, -0.1643, -2.0871, -6.0000, -5.9965, -6.7265, -4.7743, -6.4445,\n",
      "         -4.9049, -7.1493]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.0871262550354004\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9408, -0.8981, -0.5839, -5.8621, -6.3006, -6.8619, -4.1921, -6.5929,\n",
      "         -4.6437, -7.6339]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.861922740936279\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5777, -2.3451, -0.1338, -6.2232, -7.0590, -6.7136, -4.1618, -7.2106,\n",
      "         -4.8989, -8.5538]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.898911952972412\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8473, -3.4145, -0.0805, -6.2450, -7.4375, -6.2760, -3.8406, -7.4624,\n",
      "         -4.0852, -9.0772]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.275986194610596\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5309, -3.8422, -0.1604, -5.7061, -7.2189, -4.5753, -3.0067, -7.1296,\n",
      "         -2.8049, -8.9888]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.575272083282471\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0601, -4.0562, -0.6759, -5.0362, -6.8354, -2.1225, -2.1038, -6.6433,\n",
      "         -1.5101, -8.7221]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.06011438369751\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5955, -5.0070, -2.2616, -5.1832, -7.2360, -0.7486, -2.1230, -6.9515,\n",
      "         -1.2542, -9.2273]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.236007213592529\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6372,  -6.3255,  -4.2240,  -5.7771,  -7.3387,  -0.3235,  -2.6829,\n",
      "          -7.6869,  -1.6939, -10.1395]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.777066707611084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4231,  -7.2598,  -5.7477,  -5.2950,  -7.1773,  -0.2284,  -2.9815,\n",
      "          -8.0951,  -1.9728, -10.7066]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.095061302185059\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7710,  -7.6388,  -6.6594,  -4.4019,  -6.5697,  -0.2729,  -2.8237,\n",
      "          -7.3073,  -1.8650, -10.7545]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.8237197399139404\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9009,  -7.6910,  -7.1919,  -3.3175,  -5.7340,  -0.5878,  -1.7225,\n",
      "          -6.3088,  -1.5941, -10.5081]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.734007358551025\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2109,  -7.8159,  -7.7495,  -2.4463,  -4.3495,  -1.3597,  -0.9357,\n",
      "          -5.4885,  -1.5795, -10.3638]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.749518394470215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7968,  -8.1041,  -7.6825,  -1.9036,  -3.2875,  -2.4203,  -0.6822,\n",
      "          -4.9281,  -1.8958, -10.4093]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.28745174407959\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5509,  -8.4427,  -7.7012,  -1.6081,  -1.7288,  -3.5201,  -0.8926,\n",
      "          -4.5072,  -2.3718, -10.5291]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.44269847869873\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6456,  -8.2537,  -7.9728,  -1.7501,  -0.7060,  -4.7869,  -1.6278,\n",
      "          -4.3902,  -3.1247, -10.8914]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.6277952194213867\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0377,  -8.3346,  -8.4685,  -2.2622,  -0.3881,  -6.1848,  -1.9688,\n",
      "          -4.5444,  -4.0864, -11.4685]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.334564208984375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1552,  -7.3916,  -8.6413,  -2.5297,  -0.3112,  -7.1714,  -2.1014,\n",
      "          -4.4169,  -4.6914, -11.7146]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.31117066740989685\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4478,  -6.6960,  -8.9501,  -2.9848,  -0.2051,  -8.2135,  -2.4608,\n",
      "          -4.4635,  -5.3961, -12.0892]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2.984842300415039\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3360,  -5.6700,  -8.8279,  -2.2668,  -0.2873,  -8.7517,  -2.4446,\n",
      "          -4.1130,  -5.6336, -12.0261]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.827869415283203\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9733,  -4.4584,  -7.6871,  -1.4093,  -0.6010,  -8.9462,  -2.2015,\n",
      "          -3.5186,  -5.5600, -11.6790]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.687054634094238\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6926,  -3.3812,  -5.9313,  -0.8297,  -1.2754,  -9.1269,  -2.0667,\n",
      "          -3.0092,  -5.5019, -11.3718]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.8296869993209839\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9941,  -2.9371,  -4.8526,  -0.3772,  -2.5804,  -9.7901,  -2.5360,\n",
      "          -3.0855,  -5.9533, -11.5957]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.790142059326172\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1514,  -2.4228,  -3.7330,  -0.3408,  -3.6550,  -9.4889,  -2.8610,\n",
      "          -3.0320,  -6.2076, -11.6433]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.6550047397613525\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0666,  -1.7655,  -2.4821,  -0.5898,  -3.6719,  -8.9574,  -2.9341,\n",
      "          -2.7572,  -6.1778, -11.4258]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.4820637702941895\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2649,  -1.5391,  -0.9223,  -1.4730,  -3.9426,  -8.7164,  -3.2754,\n",
      "          -2.7916,  -6.3901, -11.4675]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.71639347076416\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9750,  -1.9967,  -0.3124,  -2.9439,  -4.7012,  -8.2617,  -4.1109,\n",
      "          -3.3666,  -7.0837, -12.0062]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.3665642738342285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5200,  -2.4010,  -0.1936,  -4.1991,  -5.2812,  -7.7430,  -4.7655,\n",
      "          -3.1021,  -7.5994, -12.3819]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.742985248565674\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5666,  -2.3800,  -0.2386,  -4.8881,  -5.3544,  -6.0899,  -4.9083,\n",
      "          -2.4425,  -7.6114, -12.2673]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.379969835281372\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3871,  -1.4542,  -0.6245,  -5.2846,  -5.1939,  -4.3733,  -4.8124,\n",
      "          -1.6794,  -7.3928, -11.9345]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.387112140655518\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5752,  -0.9289,  -1.4961,  -5.7796,  -5.1873,  -2.9707,  -4.8659,\n",
      "          -1.2564,  -7.3305, -11.7687]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.779580116271973\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0059,  -0.8902,  -2.5838,  -5.6040,  -5.3248,  -1.8850,  -5.0591,\n",
      "          -1.2137,  -7.4144, -11.7590]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.4144287109375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5775,  -1.2065,  -3.6636,  -5.4937,  -5.4971,  -1.0646,  -5.2827,\n",
      "          -1.4276,  -6.7826, -11.7954]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.20654296875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4631,  -1.1802,  -4.8656,  -5.6085,  -5.8662,  -0.7921,  -5.6987,\n",
      "          -1.9987,  -6.4255, -12.0390]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.8656158447265625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2554,  -1.2128,  -5.0490,  -5.5423,  -6.0282,  -0.7091,  -5.9033,\n",
      "          -2.4351,  -5.9327, -12.0860]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.4351131916046143\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9847,  -1.2965,  -5.0518,  -5.3186,  -6.0087,  -0.8308,  -5.9225,\n",
      "          -2.0245,  -5.3239, -11.9614]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.922484397888184\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6881,  -1.4133,  -4.8967,  -4.9587,  -5.8307,  -1.0993,  -5.0640,\n",
      "          -1.5845,  -4.6171, -11.6869]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.0993430614471436\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6967,  -1.8280,  -4.8910,  -4.7684,  -5.8010,  -0.9773,  -4.4239,\n",
      "          -1.4596,  -4.1166, -11.5682]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.4596388339996338\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9312,  -2.4021,  -4.9722,  -4.6843,  -5.8572,  -1.2254,  -3.9369,\n",
      "          -0.8940,  -3.7589, -11.5422]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.9311869144439697\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5245,  -3.0482,  -5.1121,  -4.6774,  -5.9716,  -1.7268,  -3.5740,\n",
      "          -0.7312,  -3.5162, -11.5805]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.524476408958435\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7206,  -3.8455,  -5.4225,  -4.8583,  -6.2564,  -2.4894,  -3.4473,\n",
      "          -1.0995,  -3.5001, -11.7950]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  11.794971466064453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3800,  -4.5770,  -5.7028,  -5.0247,  -6.5118,  -3.2348,  -3.3536,\n",
      "          -1.6601,  -3.5060, -11.2504]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.024707794189453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3246,  -4.9537,  -5.6680,  -4.1289,  -6.4532,  -3.6455,  -3.0046,\n",
      "          -2.0075,  -3.2443, -10.4703]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.6454625129699707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5094, -4.9641, -5.3050, -3.0003, -6.0674, -2.9631, -2.3917, -2.0796,\n",
      "         -2.7040, -9.4336]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  9.433599472045898\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0626, -4.8941, -4.8972, -1.9373, -5.6370, -2.3020, -1.8209, -2.1471,\n",
      "         -2.1836, -7.6851]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.183647632598877\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1575, -5.1623, -4.8610, -1.4157, -5.5777, -2.1060, -1.7489, -2.6148,\n",
      "         -1.3708, -6.4365]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.3708151578903198\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7352, -5.9089, -5.3350, -1.6319, -6.0277, -2.5199, -2.3099, -3.5878,\n",
      "         -0.5794, -5.8142]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.908941268920898\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1991, -5.8608, -5.7898, -2.0003, -6.4592, -2.9764, -2.9109, -4.5078,\n",
      "         -0.3144, -5.2803]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.199121952056885\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3875, -5.4739, -5.8559, -2.0895, -6.5031, -3.0793, -3.1456, -4.9982,\n",
      "         -0.2800, -4.4576]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.503111362457275\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1519, -4.7198, -5.5087, -1.8556, -5.4229, -2.7971, -2.9791, -5.0358,\n",
      "         -0.4067, -3.3164]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.71976900100708\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7589, -3.1203, -5.0137, -1.5790, -4.2679, -2.4025, -2.6804, -4.8888,\n",
      "         -0.8323, -2.1300]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.120284080505371\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7554, -1.3203, -4.9165, -1.8311, -3.5815, -2.4577, -2.8046, -5.1054,\n",
      "         -1.8839, -1.4929]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.5815072059631348\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3818, -0.5204, -5.4570, -2.8033, -2.8978, -3.1934, -3.5828, -5.9274,\n",
      "         -3.5671, -1.7074]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.803287982940674\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0563, -0.3483, -6.0538, -3.0683, -2.4282, -3.9931, -4.4104, -6.7763,\n",
      "         -5.2109, -2.1410]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.210881233215332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3696, -0.4200, -6.2970, -3.0464, -1.7720, -4.4309, -4.8686, -7.2456,\n",
      "         -5.6490, -2.3221]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.4200242757797241\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8422, -0.4206, -6.7064, -3.2520, -1.4912, -5.0230, -5.4758, -7.8579,\n",
      "         -6.2353, -2.7467]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.491181492805481\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.2565, -0.8937, -7.0639, -3.4546, -0.6778, -5.5491, -6.0135, -8.3974,\n",
      "         -6.7526, -3.1642]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.164201498031616\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.6536, -1.6447, -7.4101, -3.6847, -0.3302, -6.0492, -6.5231, -8.9069,\n",
      "         -7.2429, -2.8594]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.65364933013916\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.9685, -2.2040, -7.4630, -3.6519, -0.2683, -6.2422, -6.7239, -9.1067,\n",
      "         -7.4258, -2.3680]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.425830841064453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9967, -2.4336, -7.1556, -3.2866, -0.3975, -6.0618, -6.5500, -8.9311,\n",
      "         -6.4908, -1.6387]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.490787029266357\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9414, -2.5229, -6.6972, -2.8041, -0.8051, -5.7190, -6.2123, -8.5910,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -4.7297, -0.9429]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.804096221923828\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0962, -2.7621, -6.3849, -1.7537, -1.5863, -5.5123, -6.0092, -8.3844,\n",
      "         -3.2500, -0.7027]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.512290954589844\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4859, -3.1620, -6.2426, -1.0776, -2.5719, -4.7269, -5.9659, -8.3363,\n",
      "         -2.0840, -0.9883]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.0839643478393555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3738, -3.9666, -6.5293, -1.1417, -3.9267, -4.4395, -6.3421, -8.7064,\n",
      "         -0.8034, -1.9323]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.342097759246826\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6220, -5.0276, -7.1109, -1.7650, -5.4829, -4.5117, -6.2809, -9.3622,\n",
      "         -0.3047, -3.2112]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.280930995941162\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6514, -5.7727, -7.4200, -2.2417, -6.6720, -4.3697, -5.2945, -9.7376,\n",
      "         -0.1867, -4.1773]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.177280426025391\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2386, -5.9863, -7.2391, -2.2923, -7.2841, -3.7915, -3.9501, -9.6160,\n",
      "         -0.2320, -3.8628]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.232016921043396\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0487, -6.3314, -7.2277, -2.5658, -7.9868, -3.4385, -2.9042, -9.6575,\n",
      "         -0.2714, -3.7459]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.331429481506348\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6126, -5.6016, -6.9155, -2.5685, -8.3173, -2.8420, -1.6995, -9.3925,\n",
      "         -0.5638, -3.3556]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.5638456344604492\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6153, -5.2846, -6.9726, -2.9668, -8.9527, -2.6856, -1.0841, -9.4914,\n",
      "         -0.8479, -3.3672]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.0841197967529297\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0179, -5.3455, -7.3673, -3.7075, -9.8675, -2.9380, -0.3968, -9.9230,\n",
      "         -1.7603, -3.7456]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.367307662963867\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3599,  -5.3446,  -6.9233,  -4.3340, -10.6321,  -3.1455,  -0.2045,\n",
      "         -10.2526,  -2.6489,  -4.0444]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.632101058959961\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2732,  -4.9252,  -6.1021,  -4.4862, -10.1899,  -2.9422,  -0.1956,\n",
      "         -10.1273,  -3.0788,  -3.9044]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.4861602783203125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7942, -4.1219, -4.9332, -3.4375, -9.3608, -2.3674, -0.3449, -9.5835,\n",
      "         -3.0689, -3.3621]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.360838890075684\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2429, -3.2424, -3.7178, -2.3495, -7.7426, -1.7514, -0.8160, -8.9257,\n",
      "         -2.9259, -2.7311]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.731144666671753\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1063, -2.7551, -2.9171, -1.7183, -6.5616, -1.6018, -1.8310, -8.6092,\n",
      "         -3.1125, -1.7523]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.8310298919677734\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3627, -2.6465, -2.5193, -1.5698, -5.7820, -1.9002, -2.4257, -8.6073,\n",
      "         -3.5962, -1.2813]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.5961756706237793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6626, -2.5957, -2.2154, -1.5895, -5.0766, -2.2749, -3.0189, -8.6003,\n",
      "         -3.3112, -1.0557]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.3111958503723145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9481, -2.5655, -1.9830, -1.7231, -4.4060, -2.6491, -3.5479, -8.5543,\n",
      "         -2.3120, -1.0684]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.0683894157409668\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4849, -2.8336, -2.1144, -2.2179, -4.0488, -3.2770, -4.2831, -8.7511,\n",
      "         -1.7228, -0.8363]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.7228071689605713\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1885, -3.3145, -2.5183, -2.9425, -3.9353, -4.0665, -5.1508, -9.1242,\n",
      "         -0.7916, -1.1412]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.1412200927734375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0923, -4.0327, -3.2002, -3.8934, -4.1050, -5.0483, -6.1944, -9.7185,\n",
      "         -0.5423, -1.1758]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.200151205062866\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6847,  -4.4663,  -2.8758,  -4.5390,  -4.0432,  -5.7110,  -6.9094,\n",
      "         -10.0273,  -0.5158,  -1.2067]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.043245315551758\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.9425,  -4.5870,  -2.3473,  -4.8503,  -3.0179,  -6.0319,  -7.2756,\n",
      "         -10.0271,  -0.6482,  -1.1754]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.031892776489258\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0196, -4.5460, -1.7851, -4.9793, -1.9718, -5.4190, -7.4487, -9.8698,\n",
      "         -0.9899, -1.2160]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.9898595213890076\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3206, -4.7468, -1.6333, -5.3305, -1.3578, -5.1002, -7.8347, -9.9578,\n",
      "         -1.0705, -1.6994]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.834654331207275\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5305, -4.8714, -1.5792, -5.5878, -0.9240, -4.7550, -7.4050, -9.9745,\n",
      "         -1.3293, -2.2059]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.7549591064453125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6182, -4.8869, -1.5812, -5.7200, -0.7115, -3.6070, -6.9161, -9.8871,\n",
      "         -1.6519, -2.6403]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.6518696546554565\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6862, -4.8943, -1.7240, -5.8294, -0.8545, -2.5812, -6.4644, -9.7963,\n",
      "         -1.3439, -3.0717]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.464414119720459\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6715, -4.8298, -1.9084, -5.8534, -1.2064, -1.6369, -5.2717, -9.6377,\n",
      "         -1.1786, -3.4173]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.8297834396362305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6879, -4.0621, -2.2135, -5.9058, -1.7630, -0.9600, -4.2299, -9.5236,\n",
      "         -1.2813, -3.7813]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.062061786651611\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7363, -2.6781, -2.6022, -5.9876, -2.4178, -0.6682, -3.3347, -9.4535,\n",
      "         -1.6075, -4.1585]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.158459663391113\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7925, -1.4944, -3.0192, -6.0749, -3.0820, -0.7982, -2.5656, -9.4021,\n",
      "         -2.0580, -3.7874]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.0820093154907227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0074, -0.7584, -3.5945, -6.3188, -3.1693, -1.4129, -2.0912, -9.5192,\n",
      "         -2.7197, -3.6332]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.594496965408325\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.2694, -0.5113, -3.4560, -6.6074, -3.3453, -2.2149, -1.8200, -9.6925,\n",
      "         -3.4311, -3.5815]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.607431888580322\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.3144, -0.5419, -3.1634, -5.9094, -3.3372, -2.8269, -1.5001, -9.6572,\n",
      "         -3.9038, -3.3639]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.3144097328186035\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3397, -0.7804, -2.7123, -5.0640, -3.1360, -3.2030, -1.1524, -9.4064,\n",
      "         -4.1251, -2.9744]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.1524124145507812\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6795, -1.5496, -2.5717, -4.5237, -3.2017, -3.7882, -0.5678, -9.3969,\n",
      "         -4.5525, -2.8773]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.552455425262451\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0477, -2.3590, -2.4619, -4.0054, -3.2495, -4.2920, -0.4059, -9.3483,\n",
      "         -4.1791, -2.7912]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.2495203018188477\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2816, -2.9556, -2.2243, -3.3505, -2.4138, -4.5536, -0.5323, -9.1024,\n",
      "         -3.6518, -2.5564]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.281601428985596\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7474, -3.4675, -2.0271, -2.7238, -1.6603, -4.7332, -0.9991, -8.8172,\n",
      "         -3.1318, -2.3383]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.3382644653320312\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7026, -4.2374, -2.2335, -2.4958, -1.4015, -5.1873, -1.9667, -8.8463,\n",
      "         -2.9810, -1.7652]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  1.702590823173523\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6485, -5.4722, -3.0302, -2.8848, -1.8728, -6.1313, -3.4682, -9.4034,\n",
      "         -3.4129, -1.9056]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.403388977050781\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.2904, -6.7626, -3.9589, -3.4534, -2.5808, -7.1582, -5.0179, -9.3628,\n",
      "         -4.0010, -2.3164]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.001005172729492\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.2365, -7.6009, -4.4850, -3.6653, -2.9472, -7.7590, -6.0936, -9.0017,\n",
      "         -3.4965, -2.4342]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.9472455978393555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4069, -7.9528, -4.5637, -3.4725, -2.2076, -7.8970, -6.6604, -8.2733,\n",
      "         -2.6606, -2.2012]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.660441875457764\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9224, -8.1099, -4.4824, -3.1628, -1.4588, -7.8614, -6.2992, -7.4574,\n",
      "         -1.7985, -1.9127]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.7985236644744873\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0829, -8.6363, -4.8022, -3.3011, -1.3328, -8.2143, -6.3599, -7.1078,\n",
      "         -0.8059, -2.1460]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.636263847351074\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4108, -8.5537, -5.2814, -3.6393, -1.5900, -8.7174, -6.6008, -6.9785,\n",
      "         -0.4204, -2.6272]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.6392509937286377\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4331, -8.2800, -5.5173, -2.9949, -1.7658, -8.9711, -6.6192, -6.6634,\n",
      "         -0.3485, -2.9143]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.6633620262146\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0371, -7.7078, -5.4068, -2.1272, -1.7185, -8.8737, -6.3108, -5.3388,\n",
      "         -0.4659, -2.8868]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.8867745399475098\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4856, -7.0922, -5.2101, -1.3372, -1.7017, -8.6855, -5.9338, -4.0489,\n",
      "         -0.9216, -2.0679]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.9215768575668335\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1684, -6.8143, -5.3128, -1.1038, -2.0908, -8.7920, -5.8720, -3.1755,\n",
      "         -1.1741, -1.6990]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.168423652648926\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9114, -6.4784, -5.3226, -1.0629, -2.4419, -8.8015, -5.7319, -2.3327,\n",
      "         -1.5370, -1.4147]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.332703113555908\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8120, -6.3070, -5.4650, -1.4220, -2.9494, -8.9401, -5.7379, -1.0592,\n",
      "         -2.1481, -1.4672]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.940122604370117\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9778, -6.4070, -5.8494, -2.1843, -3.6964, -8.5692, -5.9987, -0.4145,\n",
      "         -3.0352, -1.9368]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.6964187622070312\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0520, -6.4211, -6.1206, -2.8803, -3.6042, -8.1581, -6.1582, -0.2310,\n",
      "         -3.7916, -2.3885]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.052036762237549\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9354, -6.0307, -5.9621, -3.1459, -3.1359, -7.3837, -5.8989, -0.2287,\n",
      "         -4.0845, -2.4584]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.084462642669678\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5528, -5.2981, -5.4386, -3.0356, -2.3620, -6.3041, -5.2846, -0.4098,\n",
      "         -3.2586, -2.2016]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.438564777374268\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2498, -4.5618, -4.1399, -2.8930, -1.6512, -5.2529, -4.6547, -0.9631,\n",
      "         -2.4621, -1.9713]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.6511788368225098\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6370, -4.3846, -3.4604, -3.2855, -0.9212, -4.7883, -4.5724, -2.2102,\n",
      "         -2.2841, -2.3446]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.344630241394043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4751, -4.4718, -3.1096, -3.9054, -0.7815, -4.6137, -4.7432, -3.6488,\n",
      "         -2.4345, -2.2530]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.252959728240967\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5043, -4.5546, -2.8230, -4.4749, -0.9734, -4.4596, -4.8989, -4.9584,\n",
      "         -2.6286, -1.5121]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.8229899406433105\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7459, -4.6783, -1.9041, -5.0379, -1.4529, -4.3708, -5.0857, -6.1841,\n",
      "         -2.8965, -1.0477]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.8965303897857666\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1818, -4.8783, -1.2698, -5.6315, -2.1307, -4.3820, -5.3401, -7.3709,\n",
      "         -2.5424, -0.9683]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.63151741027832\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6326, -5.0338, -0.8790, -5.3659, -2.7943, -4.3712, -5.5423, -8.4099,\n",
      "         -2.2495, -1.1446]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.542298793792725\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9709, -5.0546, -0.7142, -5.0063, -3.3108, -4.2469, -4.8882, -9.2216,\n",
      "         -1.9374, -1.4124]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.054562568664551\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1369, -4.1547, -0.7534, -4.5088, -3.6228, -3.9670, -4.1258, -9.7738,\n",
      "         -1.5809, -1.6531]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.508776664733887\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1947,  -3.2302,  -1.0146,  -3.1766,  -3.7968,  -3.6033,  -3.3249,\n",
      "         -10.1453,  -1.2817,  -1.8841]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  10.145263671875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2937, -2.4419, -1.5354, -2.0239, -3.9840, -3.3112, -2.6442, -9.7805,\n",
      "         -1.2263, -2.2183]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.9840378761291504\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5750, -1.9599, -2.3282, -1.2504, -3.6248, -3.2386, -2.2451, -9.6150,\n",
      "         -1.5501, -2.7619]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.574979782104492\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1955, -1.7605, -3.2446, -0.9041, -3.4495, -3.3323, -2.0911, -9.5955,\n",
      "         -2.1234, -3.4273]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.0911240577697754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9581, -1.7817, -4.1713, -0.9762, -3.3862, -3.5160, -1.3991, -9.6503,\n",
      "         -2.7980, -4.1227]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.9762018918991089\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0236, -2.1650, -5.2559, -0.8012, -3.5916, -3.9425, -1.1912, -9.9383,\n",
      "         -3.6879, -4.9993]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.5916495323181152\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9698,  -2.4451,  -6.0857,  -0.8377,  -2.9446,  -4.1903,  -1.0705,\n",
      "         -10.0467,  -4.3563,  -5.6428]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.356259346008301\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7806, -2.5812, -6.6536, -1.0218, -2.2178, -4.2439, -1.0262, -9.9634,\n",
      "         -4.0678, -6.0439]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.243913650512695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5541, -2.6555, -7.0612, -1.3588, -1.5349, -3.4441, -1.1378, -9.7836,\n",
      "         -3.7155, -6.3020]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.061160087585449\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3916, -2.7554, -6.6597, -1.8397, -1.0518, -2.7282, -1.4478, -9.6021,\n",
      "         -3.3960, -6.5161]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.755397319793701\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3607, -2.1897, -6.3427, -2.4382, -0.9057, -2.1764, -1.9386, -9.4822,\n",
      "         -3.1760, -6.7536]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.482193946838379\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3700, -1.7269, -6.0215, -3.0072, -1.0210, -1.7283, -2.4466, -8.6250,\n",
      "         -2.9708, -6.9313]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.7268717288970947\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6439, -0.8913, -5.9260, -3.7495, -1.5696, -1.6508, -3.1579, -8.0452,\n",
      "         -3.0148, -7.2840]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.15787410736084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0299, -0.5281, -5.9255, -4.5195, -2.2932, -1.8096, -3.1963, -7.6067,\n",
      "         -3.1731, -7.6856]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.0299267768859863\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4758, -0.4851, -5.7720, -5.0663, -2.8608, -1.9213, -3.1051, -7.0572,\n",
      "         -3.1908, -7.8925]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.105142116546631\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8573, -0.7179, -5.4508, -5.3782, -3.2267, -1.9473, -2.1583, -6.3775,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -3.0511, -7.8937]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.377546310424805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4096, -1.2757, -5.1514, -5.6493, -3.5708, -2.0654, -1.3747, -5.0440,\n",
      "         -2.9459, -7.8818]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.2756844758987427\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4048, -1.4493, -5.0927, -6.1028, -4.1072, -2.4743, -1.0559, -4.0544,\n",
      "         -3.0958, -8.0780]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.4493272304534912\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6621, -1.1091, -5.1135, -6.5818, -4.6707, -2.9753, -1.0857, -3.2445,\n",
      "         -3.3323, -8.3239]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.109107255935669\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2838, -0.5504, -5.3778, -7.2554, -5.4259, -3.7062, -1.5942, -2.7841,\n",
      "         -3.8122, -8.7865]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.283795118331909\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1138, -0.4472, -5.5930, -7.8362, -6.0827, -4.3568, -2.1705, -2.3872,\n",
      "         -4.2340, -9.1770]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.356784343719482\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8083, -0.5786, -5.5428, -8.1126, -6.4290, -3.9486, -2.5239, -1.8486,\n",
      "         -4.3774, -9.2818]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.948617696762085\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5316, -0.9787, -5.3704, -8.2318, -6.6119, -2.7152, -2.7693, -1.3459,\n",
      "         -4.3856, -9.2463]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.231768608093262\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4830, -1.6461, -5.2498, -7.5998, -6.8087, -1.6855, -3.0662, -1.1103,\n",
      "         -4.4331, -9.2454]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.6461265087127686\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7763, -1.8126, -5.3045, -7.1904, -7.1461, -1.0573, -3.5262, -1.2928,\n",
      "         -4.6439, -9.4041]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.7763315439224243\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4577, -2.1491, -5.4244, -6.8890, -7.5172, -0.8202, -4.0282, -1.7200,\n",
      "         -4.9075, -9.6139]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.8202061653137207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6133,  -2.7980,  -5.7960,  -6.8789,  -8.1122,  -0.4468,  -4.7534,\n",
      "          -2.4930,  -5.4106, -10.0632]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.7960124015808105\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6679,  -3.1860,  -5.1406,  -6.6295,  -8.4072,  -0.3512,  -5.1715,\n",
      "          -3.0071,  -5.6258, -10.2268]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.1715288162231445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4921,  -3.1932,  -4.1823,  -6.0333,  -8.3004,  -0.4205,  -4.4657,\n",
      "          -3.1328,  -5.4496, -10.0016]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.449590682983398\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2193, -2.9395, -3.0404, -5.2079, -7.9140, -0.6834, -3.5480, -2.9869,\n",
      "         -4.2807, -9.5084]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.914005756378174\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1405, -2.6858, -1.9840, -4.4048, -6.7954, -1.2327, -2.6780, -2.8275,\n",
      "         -3.1740, -9.0003]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.685845375061035\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5408, -1.9948, -1.3577, -3.9124, -6.0103, -2.1665, -2.1650, -2.9478,\n",
      "         -2.4292, -8.7642]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.9947991371154785\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4269, -1.1006, -1.3458, -3.8427, -5.6633, -3.4513, -2.1432, -3.4519,\n",
      "         -2.1804, -8.9100]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.842733383178711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4422, -0.6871, -1.6793, -3.1753, -5.5013, -4.7801, -2.3555, -4.0768,\n",
      "         -2.1863, -9.1894]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.1752824783325195\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3704, -0.6718, -2.1092, -1.8322, -5.3473, -5.9719, -2.6035, -4.6406,\n",
      "         -2.2620, -9.4301]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.8322391510009766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6925,  -1.5075,  -3.0641,  -0.4620,  -5.6884,  -7.5234,  -3.3561,\n",
      "          -5.6315,  -2.8820, -10.1233]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.064115524291992\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.3013,  -2.8371,  -3.6224,  -0.1283,  -6.4134,  -9.3365,  -4.4742,\n",
      "          -6.9420,  -3.8964, -11.1630]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.837143659591675\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.3499,  -2.9477,  -3.7445,  -0.1012,  -6.6667, -10.5686,  -5.0886,\n",
      "          -7.7221,  -4.4240, -11.6986]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.666705131530762\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.6884,  -2.4796,  -3.2663,  -0.1582,  -5.5845, -11.0723,  -5.0404,\n",
      "          -7.8190,  -4.3019, -11.5750]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.040429592132568\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.5502,  -1.6759,  -2.4212,  -0.4109,  -4.1694, -11.0826,  -3.8442,\n",
      "          -7.4634,  -3.7586, -11.0205]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.7586288452148438\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4554,  -1.1181,  -1.7566,  -1.1668,  -2.9355, -11.1215,  -2.8119,\n",
      "          -7.1731,  -2.5919, -10.5508]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  11.121519088745117\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.6566,  -1.1404,  -1.5745,  -2.3682,  -2.1483, -10.6920,  -2.2115,\n",
      "          -7.1985,  -1.8817, -10.4141]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.2114553451538086\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.1144,  -1.6699,  -1.8431,  -3.7974,  -1.7986, -10.5818,  -1.3143,\n",
      "          -7.4986,  -1.6292, -10.5676]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  10.581754684448242\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.6504,  -2.4076,  -2.3279,  -5.2250,  -1.7246,  -9.8614,  -0.8218,\n",
      "          -7.8928,  -1.6676, -10.8295]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.892760276794434\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.0622,  -3.0667,  -2.7670,  -6.4436,  -1.7134,  -9.1419,  -0.6211,\n",
      "          -7.4578,  -1.7681, -10.9943]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.0666589736938477\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.2472,  -2.7794,  -3.0241,  -7.3565,  -1.6452,  -8.3081,  -0.6376,\n",
      "          -6.8807,  -1.7967, -10.9570]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.779362201690674\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.2838,  -1.7120,  -3.1621,  -8.0489,  -1.5907,  -7.4274,  -0.8984,\n",
      "          -6.2317,  -1.8126, -10.7933]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.8984266519546509\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.5592,  -1.1243,  -3.5610,  -8.9152,  -1.9286,  -6.8773,  -0.9538,\n",
      "          -5.8912,  -2.1880, -10.8884]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.8911662101745605\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.7171,  -0.7406,  -3.8514,  -9.6051,  -2.2459,  -6.2924,  -1.1873,\n",
      "          -4.7809,  -2.5173, -10.8838]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.245854616165161\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.7804,  -0.6620,  -4.0502, -10.1477,  -1.8188,  -5.6883,  -1.5355,\n",
      "          -3.7082,  -2.7936, -10.8009]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  10.147684097290039\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.6841,  -0.8113,  -4.0890,  -9.7253,  -1.3958,  -4.9935,  -1.8488,\n",
      "          -2.6066,  -2.9336, -10.5729]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.3958061933517456\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.8341,  -1.5036,  -4.3733,  -9.5816,  -0.7202,  -4.6095,  -2.4795,\n",
      "          -1.9042,  -3.3350, -10.6043]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.3732781410217285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.0558,  -2.3746,  -3.9705,  -9.5390,  -0.5430,  -4.3579,  -3.1939,\n",
      "          -1.4655,  -3.8092, -10.7192]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.5429805517196655\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.5363,  -3.5070,  -3.9027,  -9.7813,  -0.3684,  -4.4217,  -4.1471,\n",
      "          -1.5173,  -4.5330, -11.1035]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.902707815170288\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.6867,  -4.2662,  -2.8253,  -9.7174,  -0.4178,  -4.2058,  -4.7345,\n",
      "          -1.4395,  -4.9104, -11.1673]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  11.686653137207031\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.8042,  -4.7313,  -1.6708,  -9.4310,  -0.6973,  -3.7938,  -5.0408,\n",
      "          -1.3111,  -5.0268, -10.9959]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.793808937072754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.0754,  -5.2224,  -0.8387,  -9.2391,  -1.3650,  -2.7586,  -5.3872,\n",
      "          -1.4554,  -5.2023, -10.9074]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.239062309265137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.5289,  -5.7783,  -0.5246,  -8.4224,  -2.2556,  -1.9836,  -5.8122,\n",
      "          -1.8629,  -5.4741, -10.9376]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  9.528945922851562\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.1491,  -6.1762,  -0.5817,  -7.5822,  -3.0266,  -1.2838,  -6.0921,\n",
      "          -2.2367,  -5.6171, -10.8598]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.5816959142684937\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.1414,  -6.7707,  -0.5367,  -7.0606,  -3.9896,  -1.0960,  -6.5804,\n",
      "          -2.8850,  -5.9831, -11.0244]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.141366481781006\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1667,  -7.0158,  -0.6436,  -6.3005,  -4.5788,  -0.8861,  -6.7301,\n",
      "          -3.2179,  -6.0235, -10.8816]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.6436440944671631\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5088,  -7.3532,  -0.5001,  -5.7333,  -5.2327,  -1.1218,  -6.9817,\n",
      "          -3.6625,  -6.1776, -10.8690]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.353166103363037\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8207,  -6.7125,  -0.6062,  -5.0064,  -5.6065,  -1.3591,  -6.9902,\n",
      "          -3.8628,  -6.0992, -10.6389]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  10.638941764831543\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6027, -6.3116, -1.2842, -4.5319, -6.1209, -1.9401, -7.1737, -4.2334,\n",
      "         -6.2053, -9.8510]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.205290794372559\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.1984, -6.2142, -2.3640, -4.3751, -6.8480, -2.8333, -7.6018, -4.8400,\n",
      "         -5.8343, -9.4038]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.19836395978927612\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.0603, -6.4948, -3.7735, -4.6104, -7.8704, -4.0486, -8.3546, -5.7588,\n",
      "         -5.8692, -9.3681]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.04859733581543\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.0612, -6.1365, -4.4479, -4.2176, -8.1792, -3.7946, -8.4205, -5.9764,\n",
      "         -5.2906, -8.7238]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.217591762542725\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.1857, -5.2090, -4.4576, -2.5151, -7.8511, -2.9763, -7.8736, -5.5677,\n",
      "         -4.1668, -7.5374]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.873589038848877\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8562, -4.2956, -4.3928, -0.9610, -7.4738, -2.1953, -6.5833, -5.1204,\n",
      "         -3.0840, -6.3872]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.29555606842041\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3459, -3.3176, -4.9021, -0.4091, -7.6927, -2.1336, -5.9808, -5.2802,\n",
      "         -2.7008, -5.9111]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.69273567199707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7542, -2.4558, -5.3589, -0.4065, -7.1753, -2.1593, -5.4326, -5.4203,\n",
      "         -2.3975, -5.4769]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.40650081634521484\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2851, -1.9866, -6.0184, -0.3969, -6.9546, -2.5134, -5.1867, -5.7944,\n",
      "         -2.4356, -5.3338]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.794441223144531\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3847, -1.3808, -6.3312, -0.6118, -6.4735, -2.6100, -4.6863, -5.1271,\n",
      "         -2.2512, -4.9257]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.6099746227264404\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.3233, -0.9648, -6.5613, -1.1598, -5.9885, -1.9518, -4.1894, -4.4776,\n",
      "         -2.1094, -4.5107]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.1598029136657715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.3201, -1.0181, -6.9207, -1.2876, -5.7045, -1.6163, -3.9039, -4.0519,\n",
      "         -2.2219, -4.2965]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.018068790435791\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.3504, -0.7354, -7.3774, -1.7422, -5.5836, -1.5950, -3.7937, -3.8136,\n",
      "         -2.5351, -4.2464]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.8136229515075684\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.1412,  -0.6915,  -7.6523,  -2.1461,  -5.3404,  -1.5905,  -3.5736,\n",
      "          -2.7583,  -2.7385,  -4.0752]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.5904839038848877\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.9257,  -1.0869,  -7.9723,  -2.6699,  -5.1970,  -1.0652,  -3.4679,\n",
      "          -1.9259,  -3.0413,  -4.0061]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.6699371337890625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.7012,  -1.7561,  -8.3299,  -2.5121,  -5.1410,  -0.9185,  -3.4642,\n",
      "          -1.3507,  -3.4183,  -4.0270]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.329937934875488\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.3456,  -2.4298,  -7.8466,  -2.3767,  -5.0407,  -1.0300,  -3.4295,\n",
      "          -0.9661,  -3.7280,  -4.0054]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.9661082625389099\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.1940,  -3.3684,  -7.6796,  -2.5925,  -5.2231,  -1.6645,  -3.6896,\n",
      "          -0.4417,  -4.2926,  -4.2680]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.292584419250488\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.8140,  -4.0945,  -7.3856,  -2.6989,  -5.2470,  -2.2329,  -3.7978,\n",
      "          -0.2900,  -3.9326,  -4.3710]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.932574510574341\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.0428,  -4.4311,  -6.7918,  -2.5158,  -4.9429,  -2.4952,  -3.5819,\n",
      "          -0.3625,  -2.5648,  -4.1440]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.791777610778809\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.1101,  -4.6040,  -5.3722,  -2.2727,  -4.5354,  -2.6542,  -3.2688,\n",
      "          -0.7880,  -1.2505,  -3.8130]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.272711753845215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.5141,  -5.1104,  -4.4407,  -1.7258,  -4.5194,  -3.1933,  -3.3578,\n",
      "          -1.8403,  -0.6201,  -3.8752]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.1933000087738037\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.9678,  -5.6607,  -3.7007,  -1.4565,  -4.6027,  -3.0535,  -3.5529,\n",
      "          -2.9917,  -0.5361,  -4.0369]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.0534768104553223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-15.2527,  -6.0352,  -2.9291,  -1.2650,  -4.5612,  -2.0990,  -3.6257,\n",
      "          -3.9409,  -0.7640,  -4.0725]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.7639952898025513\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-15.7406,  -6.6054,  -2.5057,  -1.5353,  -4.7625,  -1.5618,  -3.9418,\n",
      "          -5.0410,  -0.8107,  -4.3489]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.5353162288665771\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-16.2287,  -7.1686,  -2.2345,  -1.2411,  -4.9987,  -1.2824,  -4.2892,\n",
      "          -6.0850,  -1.2258,  -4.6564]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.234485149383545\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-16.7140,  -7.7222,  -1.3697,  -1.2382,  -5.2620,  -1.2825,  -4.6578,\n",
      "          -7.0726,  -1.8593,  -4.9865]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.72219181060791\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.1637,  -7.5070,  -0.7943,  -1.4651,  -5.5156,  -1.5013,  -5.0093,\n",
      "          -7.9753,  -2.5561,  -5.3016]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.009334564208984\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.4757,  -7.2205,  -0.5219,  -1.7491,  -5.6537,  -1.7705,  -4.5157,\n",
      "          -8.6953,  -3.1471,  -5.4962]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.69532299041748\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.4971,  -6.7035,  -0.4612,  -1.8754,  -5.5211,  -1.8799,  -3.8196,\n",
      "          -8.3645,  -3.4512,  -5.4151]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.415072441101074\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.2187,  -5.9411,  -0.5792,  -1.8061,  -5.1068,  -1.7940,  -2.9109,\n",
      "          -7.7691,  -3.4505,  -4.2823]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.8061285018920898\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-16.9873,  -5.2759,  -1.1220,  -1.1385,  -4.7575,  -1.8596,  -2.1513,\n",
      "          -7.2526,  -3.4925,  -3.2922]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.1220262050628662\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.0197,  -4.9213,  -1.3478,  -1.0171,  -4.6898,  -2.2751,  -1.7922,\n",
      "          -7.0287,  -3.7933,  -2.6698]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.01711106300354\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.2689,  -4.8273,  -1.9644,  -0.6522,  -4.8554,  -2.9458,  -1.8093,\n",
      "          -7.0477,  -4.3006,  -2.3824]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.300620079040527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.3646,  -4.6198,  -2.4955,  -0.5834,  -4.8814,  -3.4601,  -1.8146,\n",
      "          -6.9368,  -3.9082,  -2.0657]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.5833927989006042\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.6641,  -4.6534,  -3.2484,  -0.4057,  -5.1236,  -4.1600,  -2.1506,\n",
      "          -7.0508,  -3.7827,  -2.0911]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.1506288051605225\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.7305,  -4.4873,  -3.7521,  -0.5386,  -5.1427,  -4.5986,  -1.6116,\n",
      "          -6.9509,  -3.4831,  -2.0055]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.950932502746582\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.6028,  -4.1585,  -4.0358,  -0.9039,  -4.9767,  -4.8136,  -1.0831,\n",
      "          -5.9570,  -3.0482,  -1.8444]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.957011699676514\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.4196,  -3.8056,  -4.2362,  -1.4648,  -4.7638,  -4.9450,  -0.7835,\n",
      "          -4.2839,  -2.6231,  -1.7525]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.763821601867676\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.1973,  -3.4468,  -4.3702,  -2.0841,  -3.8046,  -5.0114,  -0.7863,\n",
      "          -2.7298,  -2.2360,  -1.7457]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.7863202691078186\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.3311,  -3.4808,  -4.8342,  -3.0680,  -3.2906,  -5.4101,  -0.7296,\n",
      "          -1.7110,  -2.2995,  -2.2077]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.299490451812744\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.5635,  -3.6460,  -5.3699,  -4.1006,  -2.9665,  -5.8844,  -1.1383,\n",
      "          -1.0349,  -1.8127,  -2.8202]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.8202128410339355\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.8470,  -3.8880,  -5.9301,  -5.1170,  -2.7857,  -6.3878,  -1.8115,\n",
      "          -0.7552,  -1.5677,  -2.7236]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.8115193843841553\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-18.0787,  -4.0974,  -6.4129,  -6.0131,  -2.6437,  -6.8188,  -1.7911,\n",
      "          -0.8164,  -1.4758,  -2.6634]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.6634042263031006\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-18.1915,  -4.2022,  -6.7531,  -6.7260,  -2.4709,  -7.1118,  -1.7969,\n",
      "          -1.0920,  -1.4640,  -1.8037]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.7969406843185425\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-18.4125,  -4.4270,  -7.1797,  -7.4884,  -2.4956,  -7.4958,  -1.3230,\n",
      "          -1.6996,  -1.7418,  -1.2750]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.6996384859085083\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-18.7040,  -4.7307,  -7.6569,  -8.2678,  -2.6695,  -7.9345,  -1.1801,\n",
      "          -1.7548,  -2.2124,  -1.1051]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.1050821542739868\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-19.1469,  -5.1911,  -8.2675,  -9.1503,  -3.0565,  -8.5102,  -1.4527,\n",
      "          -2.1085,  -2.8966,  -0.6232]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.89664363861084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-19.4184,  -5.4824,  -8.6901,  -9.8177,  -3.3114,  -8.9014,  -1.7389,\n",
      "          -2.3864,  -2.6963,  -0.4718]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.311429023742676\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-19.4006,  -5.4855,  -8.8085, -10.1565,  -2.5875,  -8.9916,  -1.8606,\n",
      "          -2.4401,  -2.3028,  -0.5488]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  10.156453132629395\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-19.1907,  -5.2975,  -8.7214,  -9.5224,  -1.7958,  -8.8789,  -1.8881,\n",
      "          -2.3568,  -1.8274,  -0.8634]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.878904342651367\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-18.9865,  -5.1167,  -8.6280,  -8.9365,  -1.1869,  -8.0140,  -2.0067,\n",
      "          -2.3346,  -1.5016,  -1.4518]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  18.986549377441406\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-18.0156,  -4.9617,  -8.5473,  -8.4122,  -0.8613,  -7.2388,  -2.2135,\n",
      "          -2.3872,  -1.3741,  -2.1628]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.547296524047852\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.0201,  -4.7062,  -7.6038,  -7.8192,  -0.7505,  -6.4202,  -2.3574,\n",
      "          -2.3794,  -1.3230,  -2.7694]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.819218158721924\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-15.9231,  -4.2822,  -6.5541,  -6.3445,  -0.7889,  -5.4837,  -2.3547,\n",
      "          -2.2381,  -1.2707,  -3.1629]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.554097652435303\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.7495,  -3.7248,  -4.6799,  -4.8320,  -0.9632,  -4.4576,  -2.2348,\n",
      "          -2.0016,  -1.2427,  -3.3637]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.45761251449585\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.6508,  -3.1989,  -2.9574,  -3.4342,  -1.3517,  -2.7558,  -2.1622,\n",
      "          -1.8438,  -1.3862,  -3.5291]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.1988930702209473\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.9944,  -2.3529,  -1.7780,  -2.5323,  -2.2199,  -1.6037,  -2.5128,\n",
      "          -2.1481,  -2.0309,  -4.0333]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  12.994405746459961\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.0477,  -2.0921,  -1.2735,  -2.2102,  -3.5108,  -1.1477,  -3.3181,\n",
      "          -2.9370,  -3.1384,  -4.9319]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.936980724334717\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.2985,  -2.0514,  -1.1320,  -2.1051,  -4.7980,  -1.0779,  -4.1726,\n",
      "          -3.0709,  -4.2706,  -5.8499]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.849874019622803\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.4838,  -1.9694,  -1.1059,  -1.9612,  -5.8230,  -1.1295,  -4.8134,\n",
      "          -3.0848,  -5.1604,  -5.7761]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.084838390350342\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.6307, -1.8789, -1.2106, -1.8168, -6.6287, -1.2981, -5.2767, -2.2973,\n",
      "         -5.8465, -5.5925]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.2106157541275024\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.0124, -2.0598, -0.9305, -1.9579, -7.5051, -1.8039, -5.8476, -1.8099,\n",
      "         -6.6163, -5.5799]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  9.012434005737305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5823, -2.2263, -0.8825, -2.0996, -8.2043, -2.2921, -6.2733, -1.3976,\n",
      "         -7.2201, -5.4811]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.226344585418701\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2577, -1.6832, -1.1110, -2.2815, -8.7970, -2.7701, -6.6210, -1.1658,\n",
      "         -7.7272, -5.3581]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.257684230804443\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2065, -1.2482, -1.4798, -2.4388, -9.2482, -3.1648, -6.8523, -1.0974,\n",
      "         -8.1015, -5.1683]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.0973747968673706\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5972, -1.2936, -2.2078, -2.8716, -9.8807, -3.7780, -7.2875, -0.7863,\n",
      "         -8.6649, -5.2277]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.8715832233428955\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3003,  -1.6302,  -3.0394,  -2.6527, -10.5441,  -4.4411,  -7.7737,\n",
      "          -0.9254,  -9.2662,  -5.3792]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  9.266189575195312\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5373,  -2.2679,  -4.0146,  -2.6986, -11.3321,  -5.2377,  -8.4024,\n",
      "          -1.5240,  -9.2651,  -5.7098]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.5372797250747681\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.1374,  -3.5308,  -5.5185,  -3.4023, -12.6540,  -6.5713,  -9.5811,\n",
      "          -2.8309,  -9.8765,  -6.6222]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.530764102935791\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.0852,  -3.5765,  -6.4974,  -3.6823, -13.4659,  -7.3948, -10.2640,\n",
      "          -3.6713, -10.0486,  -7.0664]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.4973859786987305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.1191,  -3.0020,  -5.9966,  -3.3170, -13.5608,  -7.5006, -10.2428,\n",
      "          -3.8100,  -9.5674,  -6.8309]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.8100345134735107\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3389,  -2.0223,  -5.0487,  -2.5163, -13.1475,  -7.0975,  -9.7249,\n",
      "          -2.7389,  -8.6354,  -6.1208]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.120811939239502\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0575,  -1.2084,  -4.1710,  -1.8266, -12.7464,  -6.7063,  -9.2298,\n",
      "          -1.7915,  -7.7673,  -4.6925]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.20842707157135\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5937,  -0.5825,  -4.0130,  -1.9466, -13.0061,  -6.9757,  -9.4048,\n",
      "          -1.6781,  -7.6068,  -4.0342]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.5936591625213623\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2962,  -0.4676,  -3.9229,  -2.1999, -13.2786,  -7.2578,  -9.6011,\n",
      "          -1.7477,  -7.5012,  -3.4935]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.9229211807250977\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7063,  -0.5718,  -2.8623,  -2.2596, -13.2730,  -7.2611,  -9.5269,\n",
      "          -1.6836,  -7.1555,  -2.7787]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.70625901222229\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2149,  -0.9693,  -1.8412,  -2.2829, -13.1592,  -7.1561,  -9.3515,\n",
      "          -1.6496,  -6.7361,  -2.0739]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.2828869819641113\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9866,  -1.7875,  -1.2231,  -1.8170, -13.2401,  -7.2454,  -9.3769,\n",
      "          -1.9395,  -6.5426,  -1.7185]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.718496561050415\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1015,  -2.9282,  -1.1676,  -1.8004, -13.5946,  -7.6080,  -9.6814,\n",
      "          -2.5848,  -6.6511,  -1.0558]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.0558464527130127\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6731,  -4.4281,  -1.7828,  -2.3421, -14.3473,  -8.3684, -10.3892,\n",
      "          -3.6532,  -7.1832,  -0.3983]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.6531982421875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1082,  -5.6884,  -2.3631,  -2.8025, -14.9260,  -8.9542, -10.9275,\n",
      "          -3.8212,  -7.5638,  -0.2196]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  10.927538871765137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0567,  -6.3697,  -2.4998,  -2.8064, -14.9911,  -9.0258, -10.2275,\n",
      "          -3.5321,  -7.4509,  -0.2126]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  10.227458953857422\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5529,  -6.5137,  -2.2133,  -2.3843, -14.5789,  -8.6196,  -8.4033,\n",
      "          -2.8217,  -6.8789,  -0.3461]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.5528879165649414\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1700,  -6.4610,  -1.8534,  -1.8895, -14.0243,  -8.0704,  -6.5773,\n",
      "          -2.0410,  -6.1810,  -0.8148]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.8894660472869873\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3916,  -6.7938,  -2.0254,  -1.1901, -13.9039,  -7.9553,  -5.3132,\n",
      "          -1.8098,  -5.9333,  -1.9487]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.9487444162368774\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1200,  -7.3325,  -2.5169,  -1.0253, -14.0337,  -8.0900,  -4.4165,\n",
      "          -1.9565,  -5.9503,  -2.5594]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.950261116027832\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9966,  -7.6884,  -2.8902,  -1.0147, -14.0209,  -8.0818,  -3.4881,\n",
      "          -2.0600,  -5.1018,  -3.0378]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.0599684715270996\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1251,  -7.9652,  -3.2240,  -1.2314, -13.9654,  -8.0308,  -2.6304,\n",
      "          -1.4873,  -4.2983,  -3.4607]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.030781745910645\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4567,  -8.1813,  -3.5208,  -1.6104, -13.8820,  -7.1961,  -1.8770,\n",
      "          -1.0991,  -3.5512,  -3.8317]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.0991381406784058\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2635,  -8.7054,  -4.1396,  -2.4299, -14.1361,  -6.7744,  -1.6395,\n",
      "          -0.6050,  -3.2290,  -4.5114]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.774392604827881\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0101,  -9.1177,  -4.6489,  -3.1737, -14.3052,  -5.5861,  -1.5073,\n",
      "          -0.4893,  -2.9082,  -5.0719]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.1737494468688965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5110,  -9.2797,  -4.9054,  -2.9198, -14.2481,  -4.3095,  -1.3404,\n",
      "          -0.6114,  -2.4503,  -5.3721]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.309452533721924\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8641,  -9.3047,  -5.0209,  -2.6102, -14.0757,  -2.3043,  -1.2600,\n",
      "          -0.9852,  -1.9807,  -5.5249]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.9852132201194763\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6263,  -9.7553,  -5.5579,  -2.8141, -14.3485,  -1.0016,  -1.8225,\n",
      "          -1.3048,  -2.0878,  -6.0935]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.814138412475586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6322, -10.4731,  -6.3565,  -2.6132, -14.9062,  -0.4170,  -2.7590,\n",
      "          -2.0970,  -2.5881,  -6.9194]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.5880558490753174\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4806, -11.0593,  -7.0166,  -2.4264, -15.3482,  -0.3259,  -3.5883,\n",
      "          -2.8371,  -2.2968,  -7.6035]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.5883312225341797\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.9345, -11.2760,  -7.3005,  -2.0125, -15.4350,  -0.4734,  -3.3151,\n",
      "          -3.2341,  -1.7976,  -7.9088]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.934520244598389\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.3788, -11.2757,  -7.3613,  -1.5436, -15.3177,  -0.8755,  -2.9001,\n",
      "          -3.4240,  -1.2749,  -7.9885]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.5436201095581055\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.1163, -11.5120,  -7.6530,  -0.7764, -15.4486,  -1.7848,  -2.8030,\n",
      "          -3.8548,  -1.2470,  -8.2972]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.297188758850098\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.9181, -11.7613,  -7.9526,  -0.4634, -15.6031,  -2.7653,  -2.7962,\n",
      "          -4.2943,  -1.4706,  -7.8574]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.7962026596069336\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5689, -11.8130,  -8.0499,  -0.4747, -15.5693,  -3.5225,  -1.9361,\n",
      "          -4.5270,  -1.6686,  -7.2888]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  11.813019752502441\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0807, -10.9450,  -7.9610,  -0.7675, -15.3622,  -4.0497,  -1.0897,\n",
      "          -4.5675,  -1.8095,  -6.6005]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.600525856018066\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6270, -10.1446,  -7.8624,  -1.3545, -15.1570,  -4.5187,  -0.5534,\n",
      "          -4.5926,  -2.0384,  -5.2138]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  10.144579887390137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1059,  -8.5712,  -7.6538,  -1.9533, -14.8520,  -4.8290,  -0.3680,\n",
      "          -4.5023,  -2.2207,  -3.8490]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.829013824462891\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3990,  -6.9043,  -7.2160,  -2.3469, -14.3270,  -4.1163,  -0.4520,\n",
      "          -4.1785,  -2.2147,  -2.3857]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.178520202636719\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7843,  -5.4000,  -6.8184,  -2.7681, -13.8504,  -3.4828,  -0.9833,\n",
      "          -3.1828,  -2.2863,  -1.1334]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.983330249786377\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7154,  -4.4856,  -6.8981,  -3.6307, -13.8581,  -3.3722,  -1.4446,\n",
      "          -2.7525,  -2.8628,  -0.6852]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.4446007013320923\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7544,  -3.7205,  -7.0207,  -4.4772, -13.9151,  -3.3482,  -1.3577,\n",
      "          -2.4604,  -3.4743,  -0.7111]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.47716760635376\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6614,  -2.8720,  -6.9543,  -4.3301, -13.7889,  -3.1754,  -1.2877,\n",
      "          -2.0807,  -3.8704,  -0.9262]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  13.788928031921387\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5373,  -2.0553,  -6.8010,  -4.1132, -12.8450,  -2.9567,  -1.3295,\n",
      "          -1.7335,  -4.1484,  -1.3230]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.80096435546875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4845,  -1.4121,  -5.9073,  -3.9276, -11.9927,  -2.7964,  -1.5558,\n",
      "          -1.5443,  -4.4081,  -1.8780]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.7963974475860596\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5724,  -1.0838,  -5.1755,  -3.8459, -11.2961,  -2.0234,  -1.9829,\n",
      "          -1.5970,  -4.7220,  -2.5636]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.175536155700684\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7152,  -1.0424,  -3.7769,  -3.7927, -10.6734,  -1.4304,  -2.4714,\n",
      "          -1.7933,  -5.0158,  -3.2435]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.2435288429260254\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9001,  -1.2704,  -2.5398,  -3.7665, -10.1177,  -1.0799,  -2.9774,\n",
      "          -2.0937,  -5.2904,  -3.1376]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.117666244506836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1185, -1.6919, -1.4942, -3.7692, -8.8937, -1.0268, -3.4791, -2.4613,\n",
      "         -5.5505, -3.0839]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.691941499710083\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5218, -1.6419, -0.8940, -3.9610, -7.9640, -1.4184, -4.1255, -3.0257,\n",
      "         -5.9601, -3.2422]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.5217809677124023\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0992, -1.7045, -0.6267, -4.1128, -7.0920, -1.9164, -4.6843, -3.5335,\n",
      "         -6.2958, -3.3791]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.295772075653076\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5609, -1.7023, -0.5953, -4.0691, -6.1148, -2.2821, -5.0017, -3.8190,\n",
      "         -5.6644, -3.3354]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.114840507507324\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9292, -1.6280, -0.7742, -3.8358, -4.3004, -2.4809, -5.0857, -3.8853,\n",
      "         -4.8918, -3.1162]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.8358120918273926\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4424, -1.6755, -1.2505, -2.8727, -2.6459, -2.6920, -5.1355, -3.9292,\n",
      "         -4.1712, -2.9218]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.171169757843018\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4020, -2.0712, -2.1089, -2.2621, -1.4232, -3.1477, -5.3995, -4.1978,\n",
      "         -3.0111, -3.0021]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.147733688354492\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8705, -2.8350, -3.2875, -2.1037, -0.8137, -3.1580, -5.9550, -4.7650,\n",
      "         -2.3173, -3.4263]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.8704781532287598\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7853, -3.7126, -4.5233, -2.1977, -0.7372, -3.3454, -6.6036, -5.4282,\n",
      "         -1.9119, -3.9793]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.7372148036956787\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0635, -4.7463, -5.8696, -2.5899, -0.5117, -3.7657, -7.4139, -6.2539,\n",
      "         -1.8816, -4.7166]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.511673629283905\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6665, -5.9378, -7.3385, -3.2528, -0.2698, -4.4158, -8.3984, -7.2531,\n",
      "         -2.2216, -5.6416]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.2216200828552246\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9944, -6.7440, -8.3929, -3.6098, -0.3442, -4.7414, -9.0163, -7.8847,\n",
      "         -1.6021, -6.2085]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.6021066904067993\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4149, -7.5574, -9.4292, -4.0378, -1.0162, -5.1278, -9.6594, -8.5403,\n",
      "         -0.5454, -6.8071]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  9.429150581359863\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9749,  -8.4462,  -9.7659,  -4.5921,  -2.0414,  -5.6359, -10.3944,\n",
      "          -9.2866,  -0.1783,  -7.5028]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.50280237197876\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1309,  -8.8838,  -9.7064,  -4.7361,  -2.6967,  -5.7334, -10.6935,\n",
      "          -9.5960,  -0.1017,  -7.0143]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.5960111618042\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7059,  -8.7001,  -9.0750,  -4.2942,  -2.7581,  -5.2457, -10.3850,\n",
      "          -8.5798,  -0.1164,  -5.9971]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.245701313018799\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8258, -8.0184, -7.9899, -3.3900, -2.3433, -3.5495, -9.5907, -7.1483,\n",
      "         -0.2609, -4.5665]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.343308925628662\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1067, -7.4322, -7.0407, -2.6284, -1.3365, -2.0710, -8.9030, -5.8873,\n",
      "         -0.9766, -3.3137]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.432224273681641\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0184, -6.6296, -6.6514, -2.4611, -1.0864, -1.2984, -8.7487, -5.2187,\n",
      "         -2.3592, -2.6777]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.651362419128418\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1882, -6.0541, -5.6999, -2.5201, -1.2536, -0.9527, -8.7561, -4.7667,\n",
      "         -3.8192, -2.3032]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.303166627883911\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4865, -5.5958, -4.9038, -2.6915, -1.6706, -0.9874, -8.8212, -4.4241,\n",
      "         -5.2082, -1.3487]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.595823287963867\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8685, -4.4996, -4.2414, -2.9450, -2.2322, -1.3451, -8.9287, -4.1730,\n",
      "         -6.5118, -0.7334]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.928718566894531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2070, -3.4709, -3.6060, -3.1629, -2.7666, -1.8117, -8.2467, -3.9083,\n",
      "         -7.6372, -0.4912]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.4911845326423645\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8529, -2.8771, -3.3638, -3.7003, -3.6033, -2.6634, -7.9423, -3.9940,\n",
      "         -8.9605, -0.2913]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.603311777114868\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1569, -2.0899, -2.8776, -3.9085, -3.3526, -3.1882, -7.3743, -3.7903,\n",
      "         -9.8582, -0.3786]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.374320030212402\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2407,  -1.2702,  -2.2798,  -3.9088,  -2.9500,  -3.4894,  -5.9363,\n",
      "          -3.4210, -10.4644,  -0.7674]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.7673511505126953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5978,  -1.0101,  -2.0888,  -4.1944,  -2.8961,  -4.0538,  -4.9138,\n",
      "          -3.3824, -11.2808,  -0.9864]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.3823726177215576\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8116,  -0.9295,  -1.8944,  -4.3473,  -2.7722,  -4.4595,  -3.8827,\n",
      "          -2.5385, -11.9003,  -1.3468]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.3468055725097656\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1125,  -1.2506,  -1.9345,  -4.5968,  -2.8083,  -4.9355,  -3.0713,\n",
      "          -1.9375, -12.5603,  -1.2203]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.112530708312988\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5684,  -1.7089,  -2.0372,  -4.7866,  -2.8426,  -5.3273,  -2.3321,\n",
      "          -1.4576, -13.1123,  -1.2844]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.327272891998291\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0759,  -2.2448,  -2.2173,  -4.9534,  -2.9055,  -4.9262,  -1.7267,\n",
      "          -1.1825, -13.5989,  -1.5383]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.5382769107818604\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7672,  -2.9272,  -2.5830,  -5.2303,  -3.1236,  -4.6919,  -1.4329,\n",
      "          -1.2768, -14.1586,  -1.3029]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.927248001098633\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4401,  -2.7753,  -2.9023,  -5.4166,  -3.2852,  -4.4207,  -1.2754,\n",
      "          -1.4954, -14.5955,  -1.2264]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.9022932052612305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0830,  -2.5970,  -2.3914,  -5.5003,  -3.3706,  -4.0980,  -1.2501,\n",
      "          -1.7661, -14.9016,  -1.2887]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.2500511407852173\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9451,  -2.6393,  -2.1481,  -5.7267,  -3.6206,  -3.9678,  -0.8554,\n",
      "          -2.2808, -15.3251,  -1.6981]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.1481409072875977\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9233,  -2.7915,  -1.3299,  -5.9943,  -3.9267,  -3.9261,  -0.8712,\n",
      "          -2.8793, -15.7679,  -2.2644]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.926068067550659\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9547,  -2.9830,  -0.8008,  -6.2465,  -4.2261,  -3.1687,  -1.1995,\n",
      "          -3.4680, -16.1758,  -2.8612]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  16.17582130432129\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9502,  -3.1194,  -0.5877,  -6.4015,  -4.4328,  -2.4445,  -1.6410,\n",
      "          -3.9471, -15.7364,  -3.3678]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.950195789337158\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1112,  -3.1758,  -0.7127,  -6.4432,  -4.5286,  -1.7580,  -2.0805,\n",
      "          -4.2934, -15.2416,  -3.7505]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.0805037021636963\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5031,  -3.3107,  -1.2449,  -6.5352,  -4.6760,  -1.3216,  -1.8924,\n",
      "          -4.6683, -14.8492,  -4.1660]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.3215686082839966\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4408,  -3.7714,  -2.2517,  -6.9314,  -5.1279,  -0.6963,  -2.1448,\n",
      "          -5.3250, -14.8082,  -4.8640]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.4407931566238403\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9820,  -4.3915,  -3.4252,  -7.4771,  -5.7273,  -0.6929,  -2.6453,\n",
      "          -6.1079, -14.9594,  -5.6865]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.107916355133057\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6808,  -4.7800,  -4.3272,  -7.7898,  -6.0904,  -0.8831,  -2.9687,\n",
      "          -5.9143, -14.9165,  -6.2506]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.6808071136474609\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2776,  -5.3860,  -5.3993,  -8.3217,  -6.6689,  -1.6115,  -3.5472,\n",
      "          -5.9918, -15.1278,  -7.0100]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.321660995483398\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.1730,  -5.6057,  -6.0387,  -7.7204,  -6.8615,  -2.0864,  -3.7597,\n",
      "          -5.7340, -14.9887,  -7.3651]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.17297345399856567\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.0942,  -5.9446,  -6.7545,  -7.3175,  -7.1739,  -2.7446,  -4.1063,\n",
      "          -5.6425, -15.0016,  -7.8236]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.7545061111450195\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.1070,  -5.6330,  -6.0324,  -6.3366,  -6.8372,  -2.7665,  -3.8117,\n",
      "          -4.9440, -14.3947,  -7.6182]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.10695359855890274\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.1141,  -5.4290,  -5.4579,  -5.5285,  -6.6086,  -2.9069,  -3.6365,\n",
      "          -4.3940, -13.9220,  -7.5074]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.528517723083496\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2526,  -4.6964,  -4.3916,  -3.5049,  -5.8516,  -2.5218,  -2.9459,\n",
      "          -3.3555, -12.9442,  -6.8560]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  12.944180488586426\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8711,  -3.9446,  -3.3417,  -1.6064,  -5.0733,  -2.1361,  -2.2634,\n",
      "          -2.3467, -11.2317,  -6.1713]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.8710935711860657\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6860,  -3.9873,  -3.1281,  -0.7525,  -5.0822,  -2.5821,  -2.4301,\n",
      "          -2.2127, -10.3949,  -6.2615]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.4300904273986816\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7244, -4.2024, -3.1314, -0.5003, -5.2577, -3.2030, -2.0782, -2.3342,\n",
      "         -9.8042, -6.5071]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.257741928100586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5268, -4.2244, -2.9842, -0.5445, -4.5005, -3.6095, -1.6696, -2.3307,\n",
      "         -9.0895, -6.5464]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.546437740325928\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0692, -4.0523, -2.6868, -0.8152, -3.6240, -3.7930, -1.2362, -2.1953,\n",
      "         -8.2432, -5.6303]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.069189071655273\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7254, -3.8319, -2.3916, -1.3106, -2.7759, -3.8967, -0.9793, -2.0756,\n",
      "         -7.4028, -4.7296]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.8318774700164795\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4281, -2.9001, -2.1884, -1.9520, -2.0521, -3.9992, -1.0158, -2.0528,\n",
      "         -6.6404, -3.9190]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.9520432949066162\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2908, -2.2075, -2.1951, -1.9928, -1.6006, -4.2107, -1.4179, -2.2308,\n",
      "         -6.0604, -3.3096]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.210721015930176\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2238, -1.6938, -2.3131, -2.1594, -1.3712, -3.6938, -1.9848, -2.4973,\n",
      "         -5.5681, -2.8164]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.56806755065918\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1980, -1.3721, -2.4977, -2.3995, -1.3561, -3.2510, -2.5995, -2.8012,\n",
      "         -4.3990, -2.4214]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.497706890106201\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2435, -1.3087, -2.0130, -2.7209, -1.5701, -2.9186, -3.2448, -3.1564,\n",
      "         -3.3928, -2.1699]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.3086905479431152\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5319, -0.9271, -1.8942, -3.2771, -2.1339, -2.8771, -4.0719, -3.7248,\n",
      "         -2.7289, -2.2469]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.7288691997528076\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8900, -0.9536, -1.9760, -3.8821, -2.8051, -2.9578, -4.9051, -4.3301,\n",
      "         -1.5254, -2.4718]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.330140590667725\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3548, -1.3903, -2.2802, -4.5688, -3.5808, -3.1958, -5.7874, -4.2852,\n",
      "         -0.7280, -2.8644]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.568847179412842\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8086, -1.9940, -2.6564, -4.4745, -4.3254, -3.4662, -6.6097, -4.2803,\n",
      "         -0.3900, -3.2865]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.609654903411865\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9569, -2.3721, -2.7813, -4.1314, -4.7391, -3.4665, -6.3537, -4.0192,\n",
      "         -0.3153, -3.4281]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.353728771209717\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7275, -2.4136, -2.5719, -3.4660, -4.7497, -3.1217, -5.0314, -3.4288,\n",
      "         -0.4124, -3.2117]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.4136271476745605\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4080, -1.6552, -2.3211, -2.7704, -4.6459, -2.7245, -3.7257, -2.8010,\n",
      "         -0.8618, -2.9275]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.8617812395095825\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4262, -1.4106, -2.4656, -2.4874, -4.8563, -2.7127, -2.8641, -2.5764,\n",
      "         -1.1414, -3.0087]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.8640856742858887\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5290, -1.4483, -2.7368, -2.3717, -5.1286, -2.8288, -1.4851, -2.5065,\n",
      "         -1.7026, -3.1962]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2.736844778060913\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9164, -1.9432, -2.5654, -2.6238, -5.6647, -3.2643, -0.6943, -2.7895,\n",
      "         -2.6273, -3.6825]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.6825175285339355\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3403, -2.5645, -2.5381, -2.9744, -6.2195, -3.7545, -0.4142, -3.1585,\n",
      "         -3.5820, -3.4550]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.754500150680542\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4966, -2.9519, -2.3437, -3.0992, -6.4914, -3.2361, -0.4117, -3.2926,\n",
      "         -4.2329, -3.0448]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.491427898406982\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3735, -3.0727, -1.9737, -2.9784, -5.7296, -2.5318, -0.6210, -3.1734,\n",
      "         -4.5626, -2.4444]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.978386402130127\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2435, -3.1930, -1.7222, -2.1389, -5.0231, -1.9342, -1.1739, -3.0738,\n",
      "         -4.8443, -1.9463]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.9342206716537476\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4335, -3.6349, -1.9330, -1.7738, -4.6949, -1.0621, -2.1976, -3.3209,\n",
      "         -5.4068, -1.9086]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.433481216430664\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9762, -4.1896, -2.3687, -1.7088, -4.5431, -0.6722, -3.3367, -3.7068,\n",
      "         -6.0537, -2.1237]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.976179599761963\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6868, -4.5795, -2.7106, -1.6646, -4.2935, -0.5817, -4.2672, -3.9514,\n",
      "         -6.5171, -2.2868]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.951375961303711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3699, -4.7634, -2.8937, -1.5913, -3.9040, -0.7419, -4.9405, -3.2826,\n",
      "         -6.7605, -2.3356]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.5913186073303223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4429, -5.1225, -3.2874, -1.1192, -3.7554, -1.4277, -5.7390, -2.8949,\n",
      "         -7.1678, -2.6398]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.2874395847320557\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9441, -5.6050, -3.0733, -1.0923, -3.7936, -2.3784, -6.6152, -2.7408,\n",
      "         -7.6898, -3.1224]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.68980598449707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7253, -5.9741, -2.8471, -1.2500, -3.7767, -3.2355, -7.3370, -2.5809,\n",
      "         -7.3614, -3.5223]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.8471014499664307\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7914, -6.2005, -1.8324, -1.4975, -3.6705, -3.9288, -7.8796, -2.3842,\n",
      "         -6.9581, -3.7968]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.928755283355713\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1776, -6.3858, -1.0184, -1.8670, -3.5738, -3.8022, -8.3484, -2.2542,\n",
      "         -6.5756, -4.0409]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.573762893676758\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8176, -6.6106, -0.6128, -2.3716, -2.8233, -3.7615, -8.8274, -2.2704,\n",
      "         -6.2888, -4.3307]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.371649742126465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4782, -6.7741, -0.6132, -2.1108, -2.1516, -3.7022, -9.2189, -2.3205,\n",
      "         -5.9920, -4.5617]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.1516013145446777\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2131, -6.9979, -1.0940, -2.0417, -0.9713, -3.7429, -9.6472, -2.5131,\n",
      "         -5.8023, -4.8535]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.0939537286758423\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2614,  -7.5559,  -1.3857,  -2.4318,  -0.5448,  -4.1528, -10.3887,\n",
      "          -3.1015,  -5.9894,  -5.4778]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.5448437929153442\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5703,  -8.4128,  -2.1892,  -3.2025,  -0.2050,  -4.8878, -11.4105,\n",
      "          -4.0183,  -6.5137,  -6.3972]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.513743877410889\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.3811,  -8.8137,  -2.6255,  -3.5560,  -0.1318,  -5.1844, -11.9598,\n",
      "          -4.4862,  -5.8875,  -6.8556]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  11.959845542907715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.5603,  -8.6228,  -2.5203,  -3.3435,  -0.1592,  -4.9035, -11.1769,\n",
      "          -4.3636,  -4.7734,  -6.7170]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.903530597686768\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.2614,  -7.9895,  -2.0243,  -2.7170,  -0.3467,  -3.4522, -10.0105,\n",
      "          -3.8012,  -3.3149,  -6.1318]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.3149337768554688\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0740, -7.4998, -1.7566, -2.2825, -1.1114, -2.2491, -9.0405, -3.3914,\n",
      "         -1.3834, -5.6867]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  9.040542602539062\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5985, -7.7509, -2.3362, -2.6589, -2.7319, -1.9357, -8.1379, -3.7387,\n",
      "         -0.5184, -5.9801]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.7386534214019775\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.2261, -8.1313, -3.0846, -3.2042, -4.3928, -1.9150, -7.4794, -3.4915,\n",
      "         -0.3282, -6.4003]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.0845677852630615\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5109, -8.1933, -2.7647, -3.4447, -5.6168, -1.7251, -6.6060, -3.0104,\n",
      "         -0.4000, -6.4991]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.39995473623275757\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.9233, -8.4049, -2.6791, -3.8407, -6.8771, -1.8423, -5.9760, -2.7686,\n",
      "         -0.3807, -6.7447]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.6790575981140137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.0639, -8.3645, -1.6796, -3.9823, -7.7817, -1.8347, -5.1794, -2.3659,\n",
      "         -0.6281, -6.7357]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  8.063859939575195\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.4103, -8.3162, -0.9063, -4.1117, -8.5845, -1.9348, -4.4541, -2.0598,\n",
      "         -1.2249, -6.7165]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.454054355621338\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8926, -8.3432, -0.5811, -4.3108, -9.3780, -2.2028, -3.1604, -1.9480,\n",
      "         -2.0453, -6.7704]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.9479618072509766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4963,  -8.4369,  -0.7732,  -4.5693, -10.1617,  -2.5958,  -2.0953,\n",
      "          -1.2903,  -2.9470,  -6.8891]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.436941146850586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.1988,  -7.8284,  -1.3468,  -4.8680, -10.9256,  -3.0634,  -1.2832,\n",
      "          -0.9575,  -3.8551,  -7.0547]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.2831928730010986\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.3615,  -7.7099,  -2.4854,  -5.5719, -12.0426,  -3.9485,  -0.4616,\n",
      "          -1.3676,  -5.1173,  -7.6337]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.9484596252441406\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.5442,  -7.6384,  -3.6075,  -6.2434, -13.0833,  -4.0497,  -0.2128,\n",
      "          -1.9580,  -6.2932,  -8.1904]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.21278910338878632\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.9448,  -7.8092,  -4.8730,  -7.0845, -14.2554,  -4.3888,  -0.0856,\n",
      "          -2.8278,  -7.5883,  -8.9267]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.809211730957031\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.7446,  -6.6549,  -5.4566,  -7.2809, -14.7493,  -4.1416,  -0.0716,\n",
      "          -3.0927,  -8.1933,  -9.0283]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.4566121101379395\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.9661,  -5.0172,  -4.6433,  -6.8591, -14.5949,  -3.3319,  -0.1267,\n",
      "          -2.7653,  -8.1391,  -8.5207]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.966083526611328\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0890,  -3.1357,  -3.5063,  -6.0684, -14.0441,  -2.2175,  -0.3919,\n",
      "          -2.1048,  -7.6789,  -7.6520]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.1357369422912598\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7932,  -1.1123,  -2.8864,  -5.7397, -13.9297,  -1.6769,  -1.4921,\n",
      "          -1.9810,  -7.6463,  -7.2518]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.492107629776001\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5596,  -0.4228,  -3.2557,  -6.3323, -14.7129,  -2.2157,  -2.8140,\n",
      "          -2.8568,  -8.5036,  -7.7781]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.8568100929260254\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4044,  -0.2886,  -3.6126,  -6.8631, -15.4140,  -2.7780,  -4.0427,\n",
      "          -2.9512,  -9.2715,  -8.2481]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.951228141784668\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0294,  -0.4224,  -3.6494,  -7.0372, -15.7406,  -3.0262,  -4.8570,\n",
      "          -2.0429,  -9.6584,  -8.3670]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.4223785400390625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0173,  -0.5107,  -3.9263,  -7.4190, -16.2591,  -3.5103,  -5.8203,\n",
      "          -1.5439, -10.2312,  -8.6985]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.41896915435791\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8841,  -0.8121,  -3.9655,  -6.7871, -16.5013,  -3.7438,  -6.4650,\n",
      "          -1.0255, -10.5223,  -8.7725]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.465021133422852\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7498,  -1.2819,  -3.8835,  -6.0875, -16.5880,  -3.8403,  -6.2025,\n",
      "          -0.6889, -10.6531,  -8.7078]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.840329647064209\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6128,  -1.7612,  -3.6751,  -5.3093, -16.5161,  -3.0477,  -5.8177,\n",
      "          -0.6017, -10.6209,  -8.4997]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  16.516101837158203\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4535,  -2.1310,  -3.3168,  -4.4228, -15.5234,  -2.1798,  -5.2837,\n",
      "          -0.7323, -10.4025,  -8.1230]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.422798156738281\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4335,  -2.4957,  -2.9645,  -2.8296, -14.5727,  -1.4260,  -4.7498,\n",
      "          -1.1424, -10.1491,  -7.7273]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.727323532104492\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7386,  -3.0247,  -2.8249,  -1.5784, -13.8559,  -1.0657,  -4.4144,\n",
      "          -1.8826, -10.0602,  -6.7417]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.8825794458389282\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4018,  -3.7902,  -2.9965,  -0.8596, -13.4634,  -1.2513,  -4.3741,\n",
      "          -2.1844, -10.2332,  -6.1081]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.9964981079101562\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0929,  -4.5205,  -2.4684,  -0.5544, -13.1340,  -1.6559,  -4.3708,\n",
      "          -2.5619, -10.4131,  -5.5633]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.413081169128418\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5693,  -5.0052,  -1.8748,  -0.5293, -12.6564,  -1.9816,  -4.1958,\n",
      "          -2.7768,  -9.6635,  -4.8947]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.894673824310303\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8363,  -5.2629,  -1.2707,  -0.7634, -12.0425,  -2.1941,  -3.8651,\n",
      "          -2.8318,  -8.8047,  -3.3502]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.831760883331299\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1332,  -5.5386,  -0.9755,  -1.3622, -11.5295,  -2.5085,  -3.6222,\n",
      "          -2.2384,  -8.0713,  -2.0261]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.133162021636963\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8030,  -5.9520,  -1.1524,  -2.2548, -11.2298,  -3.0146,  -3.5847,\n",
      "          -1.9435,  -7.5733,  -1.0972]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.152408242225647\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8201,  -6.6234,  -1.1002,  -3.4343, -11.2570,  -3.8042,  -3.8679,\n",
      "          -2.0789,  -7.4224,  -0.8146]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.100182294845581\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9831,  -7.3598,  -0.6896,  -4.6513, -11.4123,  -4.6626,  -4.2687,\n",
      "          -2.4223,  -7.4177,  -1.0310]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.268704414367676\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9561,  -7.8352,  -0.5045,  -5.5663, -11.3640,  -5.2546,  -3.7386,\n",
      "          -2.6078,  -7.2257,  -1.3115]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.254640579223633\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6609,  -7.9779,  -0.4998,  -6.1074, -11.0348,  -4.7584,  -2.9925,\n",
      "          -2.5427,  -6.7677,  -1.4850]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.6608598232269287\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4401,  -7.8997,  -0.7370,  -6.3893, -10.5314,  -4.1110,  -2.1494,\n",
      "          -2.3341,  -6.1492,  -1.6081]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.389339447021484\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4508,  -7.8725,  -1.3468,  -5.9378, -10.1211,  -3.5831,  -1.5164,\n",
      "          -2.2597,  -5.6366,  -1.9155]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.5831069946289062\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9538, -8.0617, -2.3014, -5.7466, -9.9651, -2.5993, -1.3167, -2.4820,\n",
      "         -5.3912, -2.5189]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.5188651084899902\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8906, -8.3203, -3.3230, -5.6648, -9.9125, -1.8567, -1.4162, -2.8309,\n",
      "         -5.2614, -2.4440]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.4161996841430664\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2633, -8.6674, -4.3837, -5.7077, -9.9793, -1.4184, -1.0799, -3.3021,\n",
      "         -5.2625, -2.5572]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.0798884630203247\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0788,  -9.2428,  -5.6109,  -6.0116, -10.3022,  -1.4668,  -0.5704,\n",
      "          -4.0159,  -5.5299,  -2.9812]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.5704202651977539\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3197, -10.1713,  -7.1289,  -6.6974, -11.0033,  -2.0925,  -0.2132,\n",
      "          -5.0822,  -6.1840,  -3.8122]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.184038162231445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1330, -10.6757,  -8.1647,  -6.9841, -11.3028,  -2.4161,  -0.1364,\n",
      "          -5.7150,  -5.7103,  -4.2457]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.714996337890625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3547, -10.6068,  -8.5745,  -6.7198, -11.0495,  -2.2510,  -0.1635,\n",
      "          -5.0369,  -4.7630,  -4.1239]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  10.606762886047363\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1020,  -9.3325,  -8.4814,  -6.0204, -10.3590,  -1.7185,  -0.3250,\n",
      "          -3.9686,  -3.4540,  -3.5644]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.35903263092041\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7246, -8.0226, -8.2352, -5.2299, -8.8311, -1.2103, -0.8160, -2.8579,\n",
      "         -2.1359, -2.9197]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.7245724201202393\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8710, -7.0801, -8.2504, -4.7589, -7.6921, -1.2118, -1.8059, -2.1362,\n",
      "         -1.2725, -2.6174]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.6174402236938477\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4313, -6.5173, -8.5497, -4.6265, -6.9521, -1.7205, -3.0985, -1.8576,\n",
      "         -0.9863, -1.9202]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.8576351404190063\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3118, -6.2205, -9.0283, -4.7236, -6.4953, -2.5211, -4.5032, -1.2036,\n",
      "         -1.2116, -1.6136]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  9.02827262878418\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2910, -5.9654, -8.7275, -4.8283, -6.0958, -3.3127, -5.7866, -0.8435,\n",
      "         -1.6439, -1.5009]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.965439796447754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2313, -4.8721, -8.3380, -4.8099, -5.6189, -3.9340, -6.8257, -0.7130,\n",
      "         -2.0563, -1.4516]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.2312874794006348\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4335, -3.8332, -7.9274, -4.7393, -5.1321, -4.4480, -7.7021, -0.8911,\n",
      "         -2.4616, -1.5268]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.461610794067383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9328, -2.9486, -7.5926, -4.7171, -4.7329, -4.9544, -8.5263, -1.3837,\n",
      "         -2.1893, -1.7958]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.954378128051758\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7645, -2.1720, -7.2722, -4.6845, -4.3606, -4.6488, -9.2493, -1.9895,\n",
      "         -2.0068, -2.1461]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.146054744720459\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9831, -1.5716, -6.9975, -4.6755, -4.0483, -4.3941, -9.9139, -2.6478,\n",
      "         -1.9546, -1.7980]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.394101142883301\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4382,  -1.1586,  -6.7227,  -4.6463,  -3.7520,  -3.4040, -10.4841,\n",
      "          -3.2637,  -1.9833,  -1.5832]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  10.484142303466797\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9964,  -0.9890,  -6.4427,  -4.5938,  -3.4693,  -2.5037, -10.2558,\n",
      "          -3.8128,  -2.0768,  -1.5135]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.5036542415618896\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7272,  -1.2395,  -6.3159,  -4.6783,  -3.3621,  -1.1399, -10.1744,\n",
      "          -4.4474,  -2.3772,  -1.7435]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.1399024724960327\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2526,  -2.4995,  -7.0202,  -5.5786,  -4.1088,  -0.2288, -10.9183,\n",
      "          -5.8445,  -3.5331,  -2.9018]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.9017841815948486\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.7231,  -3.7817,  -7.7411,  -6.4781,  -4.8795,  -0.0858, -11.6741,\n",
      "          -7.1908,  -4.6815,  -3.3084]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.879500865936279\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4960,  -4.3995,  -7.8366,  -6.7354,  -4.2790,  -0.0815, -11.8008,\n",
      "          -7.8497,  -5.1685,  -3.1485]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.399478435516357\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6181,  -3.6403,  -7.3480,  -6.3931,  -3.1736,  -0.1790, -11.3400,\n",
      "          -7.8684,  -5.0363,  -2.4624]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.393083095550537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4277,  -2.6749,  -6.6071,  -5.0303,  -1.9080,  -0.5752, -10.6235,\n",
      "          -7.5842,  -4.6208,  -1.6083]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  10.623515129089355\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4761, -2.0758, -6.1602, -4.0286, -1.0973, -1.5623, -9.4903, -7.5507,\n",
      "         -4.4773, -1.2117]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.160170078277588\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7141, -1.8235, -5.2102, -3.3352, -0.8095, -2.7987, -8.6623, -7.7172,\n",
      "         -4.5542, -1.2760]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.7987253665924072\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8622, -1.6503, -4.2882, -2.6614, -0.8195, -3.1480, -7.8545, -7.7847,\n",
      "         -4.5418, -1.4770]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.1480021476745605\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8867, -1.5285, -3.3605, -2.0031, -1.0460, -2.6616, -7.0149, -7.7452,\n",
      "         -4.4416, -1.7248]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.0459946393966675\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.1025, -1.7745, -2.7439, -1.7052, -0.9579, -2.4673, -6.4524, -7.9029,\n",
      "         -4.5531, -2.2772]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.4672584533691406\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.3095, -2.1352, -2.2486, -1.5865, -1.1770, -1.6424, -5.9590, -8.0571,\n",
      "         -4.6732, -2.8652]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.057104110717773\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5219, -2.5742, -1.9067, -1.6600, -1.6295, -1.0653, -5.5420, -7.4922,\n",
      "         -4.8138, -3.4638]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.574237585067749\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.7467, -2.3099, -1.7429, -1.9032, -2.2165, -0.8286, -5.2024, -7.0171,\n",
      "         -4.9795, -4.0599]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.309903144836426\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.9589, -1.4105, -1.7354, -2.2445, -2.8358, -0.9410, -4.9099, -6.5994,\n",
      "         -5.1432, -4.6194]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.4105294942855835\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.5616, -0.4516, -2.2717, -3.0436, -3.8487, -1.7360, -5.0630, -6.6355,\n",
      "         -5.7063, -5.5422]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  8.561553001403809\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.4426, -0.1721, -2.9402, -3.9077, -4.8853, -2.6879, -5.3140, -6.7775,\n",
      "         -6.3244, -6.4846]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.885277271270752\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.9146, -0.1256, -3.1605, -4.2800, -4.6563, -3.1732, -5.1223, -6.4850,\n",
      "         -6.4611, -6.9132]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.461113929748535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8837, -0.1800, -2.8349, -4.0700, -3.9015, -3.0849, -4.3982, -5.6671,\n",
      "         -5.2906, -6.7444]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.290610313415527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5674, -0.4542, -2.1969, -3.5052, -2.8481, -2.6497, -3.3661, -4.5444,\n",
      "         -3.1184, -6.2044]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.567376136779785\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8280, -1.3750, -1.9140, -3.2277, -2.1511, -2.5176, -2.6698, -3.7495,\n",
      "         -1.4033, -5.9282]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.9139554500579834\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9833, -3.0948, -1.7269, -3.7130, -2.3153, -3.1621, -2.7969, -3.7559,\n",
      "         -0.7451, -6.3864]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.386402130126953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3548, -4.7702, -1.7845, -4.2618, -2.6301, -3.8664, -3.0481, -3.8720,\n",
      "         -0.5957, -6.1257]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.8720359802246094\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7185, -6.1418, -1.8186, -4.6235, -2.8242, -4.3726, -3.1648, -3.1192,\n",
      "         -0.7239, -5.7493]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.1191787719726562\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2811, -7.3760, -1.9680, -4.9541, -3.0408, -4.8351, -3.2975, -1.7465,\n",
      "         -1.1931, -5.4103]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.41033411026001\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3028, -8.6897, -2.4090, -5.4591, -3.4734, -5.4592, -3.6453, -0.8394,\n",
      "         -2.0403, -4.5480]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.6452808380126953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6519, -9.9932, -2.9936, -6.0374, -4.0066, -6.1447, -3.3862, -0.4581,\n",
      "         -3.0191, -3.8999]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.037371635437012\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9202, -10.9735,  -3.3640,  -5.6063,  -4.3068,  -6.5699,  -2.9835,\n",
      "          -0.3819,  -3.7429,  -3.1382]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.606316566467285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0009, -11.5825,  -3.4498,  -4.1937,  -4.3134,  -6.6802,  -2.3831,\n",
      "          -0.5352,  -4.1384,  -2.2118]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.193717002868652\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1715, -12.1247,  -3.5446,  -2.1793,  -4.3233,  -6.7742,  -1.9019,\n",
      "          -1.0911,  -4.5001,  -1.4552]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.1714916229248047\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1329, -13.1020,  -4.1407,  -0.9396,  -4.8311,  -7.3487,  -2.0641,\n",
      "          -2.3238,  -5.3231,  -1.4419]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.323086738586426\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4890, -14.2818,  -4.9891,  -0.4183,  -5.5942,  -8.1662,  -2.6003,\n",
      "          -3.8046,  -5.6314,  -1.9110]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.8046250343322754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7067, -15.1776,  -5.5916,  -0.2794,  -6.1174,  -8.7360,  -2.9695,\n",
      "          -4.2617,  -5.7450,  -2.2802]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.2793753147125244\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1369, -16.1670,  -6.3198,  -0.1538,  -6.7731,  -9.4320,  -3.5213,\n",
      "          -4.8663,  -6.0325,  -2.8739]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  16.167030334472656\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0290, -15.7892,  -6.4480,  -0.1571,  -6.8356,  -9.5300,  -3.5106,\n",
      "          -4.8875,  -5.7643,  -2.9230]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.510568618774414\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4981, -14.9781,  -6.0939,  -0.3282,  -6.4218,  -9.1475,  -2.3398,\n",
      "          -4.4412,  -5.0543,  -2.5377]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.147467613220215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9605, -14.1249,  -5.6538,  -0.8955,  -5.9275,  -7.9510,  -1.2313,\n",
      "          -3.9250,  -4.2967,  -2.1286]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.2312841415405273\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2370, -14.0086,  -5.9122,  -2.3624,  -6.1366,  -7.5259,  -0.3830,\n",
      "          -4.1265,  -4.2767,  -2.5038]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.5037918090820312\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7086, -14.0443,  -6.2873,  -3.8940,  -6.4668,  -7.2838,  -0.2450,\n",
      "          -4.4601,  -4.4092,  -2.2778]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  14.044316291809082\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8191, -12.9749,  -6.2609,  -4.9228,  -6.3997,  -6.7007,  -0.3104,\n",
      "          -4.4032,  -4.1720,  -1.7873]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.17195987701416\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6812, -11.7285,  -5.9551,  -5.5712,  -6.0572,  -5.8932,  -0.6037,\n",
      "          -4.0775,  -2.9520,  -1.1906]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.89319372177124\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5743, -10.5705,  -5.6461,  -6.1224,  -5.7148,  -4.4064,  -1.2177,\n",
      "          -3.7609,  -1.8562,  -0.8507]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.574262857437134\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9385, -9.7000, -5.5427, -6.7926, -5.5813, -3.2488, -2.1516, -3.6649,\n",
      "         -1.1566, -1.0443]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.542741775512695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5878, -9.0271, -4.8116, -7.5079, -5.5749, -2.3456, -3.1858, -3.7081,\n",
      "         -0.8692, -1.5990]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.5990333557128906\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5471, -8.5390, -4.2770, -8.2702, -5.6897, -1.7197, -4.2639, -3.8825,\n",
      "         -1.0365, -1.6047]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.6046684980392456\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7828, -8.2080, -3.9145, -9.0653, -5.9041, -1.3953, -5.3533, -4.1630,\n",
      "         -1.5564, -1.1092]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.904062747955322\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0799, -7.8655, -3.5584, -9.7367, -5.3012, -1.2392, -6.2928, -4.3822,\n",
      "         -2.1349, -0.8700]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.736664772033691\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2895, -7.4030, -3.1049, -9.4377, -4.6078, -1.1557, -6.9859, -4.4345,\n",
      "         -2.5885, -0.8200]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.8200085759162903\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7357, -7.1665, -2.9097, -9.3480, -4.1704, -1.4896, -7.7901, -4.6696,\n",
      "         -3.2317, -0.5283]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.9097118377685547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0334, -6.7998, -1.8710, -9.1132, -3.6339, -1.8005, -8.3605, -4.7340,\n",
      "         -3.6858, -0.5605]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.6858201026916504\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2781, -6.4100, -0.9908, -8.8412, -3.1102, -2.1405, -8.8136, -4.7378,\n",
      "         -3.3168, -0.9627]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.9626525640487671\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7776, -6.3101, -0.7276, -8.8464, -2.9223, -2.7826, -9.4718, -4.9977,\n",
      "         -3.2611, -1.1049]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.7276184558868408\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4951,  -6.4716,  -0.3531,  -9.1012,  -3.0438,  -3.6560, -10.3147,\n",
      "          -5.4867,  -3.4893,  -1.7345]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.4892797470092773\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.9030,  -6.3713,  -0.2970,  -9.0839,  -2.9424,  -4.2145, -10.8268,\n",
      "          -5.6831,  -2.7388,  -2.1884]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.1884114742279053\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0399,  -6.0461,  -0.5664,  -8.8323,  -2.6548,  -4.4922, -11.0518,\n",
      "          -5.6265,  -1.8742,  -1.6881]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.5664426684379578\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4105,  -5.9974,  -0.7278,  -8.8481,  -2.6914,  -4.9927, -11.4968,\n",
      "          -5.8204,  -1.4506,  -1.6198]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.992722511291504\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5747,  -5.7823,  -1.0608,  -8.6895,  -2.6026,  -4.5447, -11.7245,\n",
      "          -5.8241,  -1.0679,  -1.5352]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.689471244812012\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5914,  -5.4568,  -1.4851,  -7.6656,  -2.4447,  -4.0150, -11.7954,\n",
      "          -5.6956,  -0.8414,  -1.4882]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.59137487411499\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6806,  -5.0107,  -1.8802,  -6.5877,  -2.2121,  -3.3950, -11.7032,\n",
      "          -5.4261,  -0.7971,  -1.4607]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  11.703166961669922\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7093,  -4.4557,  -2.1916,  -5.4598,  -1.9274,  -2.7028, -10.7507,\n",
      "          -5.0284,  -0.9288,  -1.4534]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.9288121461868286\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0414,  -4.1523,  -2.7434,  -4.6351,  -1.9691,  -2.3163, -10.0807,\n",
      "          -4.8628,  -0.7916,  -1.8118]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.862788200378418\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3760, -3.7901, -3.1876, -3.7989, -2.0118, -1.9395, -9.3766, -3.8873,\n",
      "         -0.8987, -2.1576]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.011798620223999\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9373, -3.5693, -3.7071, -3.1513, -1.4822, -1.7940, -8.8313, -3.1124,\n",
      "         -1.3810, -2.6452]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.4822030067443848\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9924, -3.7302, -4.5320, -2.9389, -0.7614, -2.1233, -8.6789, -2.7858,\n",
      "         -2.3377, -3.4769]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.1232833862304688\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2718, -4.0173, -5.4071, -2.9116, -0.5898, -1.9013, -8.6662, -2.6612,\n",
      "         -3.3942, -4.3736]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.373590469360352\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4189, -4.1048, -6.0141, -2.7435, -0.6695, -1.6261, -8.4703, -2.4158,\n",
      "         -4.1856, -4.2470]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.415761947631836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5613, -4.1371, -6.5036, -2.5815, -1.0680, -1.4630, -8.2353, -1.4718,\n",
      "         -4.8506, -4.0849]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.137078285217285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8167, -3.5002, -7.0128, -2.5597, -1.7528, -1.5525, -8.0910, -0.8568,\n",
      "         -5.5223, -4.0189]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.01281213760376\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0784, -2.9345, -6.7076, -2.5836, -2.4854, -1.7732, -7.9467, -0.5990,\n",
      "         -6.1156, -3.9585]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.9466657638549805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1764, -2.2914, -6.2603, -2.4886, -3.0345, -1.9227, -6.9332, -0.5947,\n",
      "         -6.4780, -3.7451]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.4885661602020264\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2270, -1.7177, -5.7889, -1.6453, -3.4952, -2.0941, -5.9512, -0.9230,\n",
      "         -6.7354, -3.5009]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.6452751159667969\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6671, -1.6988, -5.7304, -0.6478, -4.2966, -2.7023, -5.4324, -1.8716,\n",
      "         -7.3318, -3.6676]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.331785678863525\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2500, -1.9852, -5.8469, -0.3088, -5.1954, -3.4658, -5.1352, -3.0049,\n",
      "         -7.3027, -4.0039]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.4658284187316895\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5054, -2.0651, -5.6734, -0.2721, -5.7283, -3.1645, -4.5911, -3.7809,\n",
      "         -6.9964, -4.0399]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.0651116371154785\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5041, -1.2466, -5.2798, -0.5664, -5.9707, -2.6842, -3.8685, -4.2564,\n",
      "         -6.4813, -3.8459]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.6841838359832764\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5829, -0.7952, -5.0006, -1.3241, -6.2623, -1.6461, -3.3041, -4.7663,\n",
      "         -6.0899, -3.7588]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.7952367663383484\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1738, -0.4929, -5.2662, -2.7160, -7.0384, -1.3638, -3.3340, -5.7438,\n",
      "         -6.2512, -4.2101]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.038365364074707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5540, -0.5195, -5.3528, -3.8622, -6.8260, -1.1395, -3.2301, -6.4699,\n",
      "         -6.2414, -4.4714]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.553959846496582\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8434, -0.7063, -5.1553, -4.6309, -6.3565, -0.8914, -2.8855, -6.8457,\n",
      "         -5.9549, -4.4362]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.845672607421875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9727, -1.0036, -4.7447, -5.0933, -5.6980, -0.7296, -2.3782, -6.2170,\n",
      "         -5.4618, -4.1766]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.461759567260742\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0326, -1.3724, -4.2110, -5.3437, -4.9369, -0.7639, -1.8171, -5.4818,\n",
      "         -4.1191, -3.7839]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.93692684173584\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1951, -1.8640, -3.7130, -5.5443, -3.4779, -1.1046, -1.3997, -4.7943,\n",
      "         -2.8936, -3.4192]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.713015079498291\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7210, -2.6152, -2.7263, -5.9213, -2.3807, -1.8455, -1.3939, -4.3747,\n",
      "         -2.0240, -3.3092]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.393883466720581\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8240, -3.7368, -2.2777, -6.6536, -1.8530, -3.0183, -1.2416, -4.3968,\n",
      "         -1.7285, -3.6288]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.628824234008789\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0893, -4.8115, -1.9977, -7.3609, -1.5431, -4.1569, -1.3582, -4.4727,\n",
      "         -1.6397, -3.2224]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.811480522155762\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3630, -4.9796, -1.7860, -7.9368, -1.3634, -5.1320, -1.5853, -4.4878,\n",
      "         -1.6405, -2.8251]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.9796247482299805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5933, -4.3089, -1.6319, -8.3661, -1.3050, -5.9250, -1.8470, -4.4202,\n",
      "         -1.6941, -2.4232]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.5933353900909424\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0551, -3.6879, -1.6133, -8.7259, -1.4299, -6.6140, -2.1684, -4.3411,\n",
      "         -1.8502, -2.1018]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.0550522804260254\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0526, -3.3020, -1.9012, -9.2049, -1.8775, -7.3903, -2.6945, -4.4342,\n",
      "         -2.2611, -2.0604]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.3019745349884033\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5981, -2.4255, -2.4506, -9.8139, -2.5736, -8.2674, -3.3944, -4.7045,\n",
      "         -2.8853, -2.2980]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.5981342196464539\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2940,  -2.1538,  -3.4627, -10.8148,  -3.7104,  -9.5099,  -4.5010,\n",
      "          -5.4069,  -3.9409,  -3.0411]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.71036958694458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3156,  -1.7126,  -4.1156, -11.4341,  -3.7172, -10.3467,  -5.2235,\n",
      "          -5.7607,  -4.6237,  -3.4648]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  10.346735954284668\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5500,  -1.1009,  -4.3685, -11.6443,  -3.3942, -10.0232,  -5.5305,\n",
      "          -5.7341,  -4.8983,  -3.5227]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.3942246437072754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0915,  -0.6826,  -4.4929, -11.7209,  -2.2679,  -9.6191,  -5.6970,\n",
      "          -5.5998,  -5.0383,  -3.4846]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.492923259735107\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8327,  -0.6742,  -3.8570, -11.7855,  -1.3270,  -9.2510,  -5.8452,\n",
      "          -5.4773,  -5.1649,  -3.4696]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.469586133956909\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6700,  -1.0884,  -3.3471, -11.8907,  -0.7258,  -8.9666,  -6.0275,\n",
      "          -5.4170,  -5.3301,  -2.7644]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.0883537530899048\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6307,  -1.1265,  -3.0678, -12.1388,  -0.7009,  -8.8639,  -6.3469,\n",
      "          -5.5194,  -5.6358,  -2.3308]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.86387825012207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3015,  -1.1844,  -2.6366, -12.1475,  -0.8355,  -7.8309,  -6.4210,\n",
      "          -5.3998,  -5.6989,  -1.7997]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.420971870422363\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7703,  -1.3156,  -2.1565, -12.0096,  -1.1354,  -6.7554,  -5.6257,\n",
      "          -5.1497,  -5.6126,  -1.3021]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.3020988702774048\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4765,  -1.9085,  -2.0889, -12.1630,  -1.9233,  -6.0652,  -5.1897,\n",
      "          -5.2063,  -5.8151,  -0.5777]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.065208911895752\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.1072,  -2.5430,  -2.1129, -12.2927,  -2.7337,  -4.7152,  -4.7927,\n",
      "          -5.2529,  -5.9912,  -0.3449]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.715167999267578\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4171,  -2.9124,  -1.9658, -12.1497,  -3.2524,  -2.5294,  -4.1813,\n",
      "          -5.0389,  -5.8918,  -0.4139]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.41389980912208557\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.1582,  -3.7458,  -2.3999, -12.4817,  -4.2092,  -1.0797,  -4.1025,\n",
      "          -5.3118,  -6.2651,  -0.6794]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.745847225189209\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.1345,  -4.0862,  -3.1675, -13.0890,  -5.3903,  -0.3286,  -4.3517,\n",
      "          -5.8695,  -6.9111,  -1.6114]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.390341758728027\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.9760,  -4.3672,  -3.8526, -13.5980,  -5.6697,  -0.1363,  -4.5476,\n",
      "          -6.3359,  -7.4556,  -2.5642]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.33592414855957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.2542,  -4.1499,  -4.0060, -13.5768,  -5.4442,  -0.1130,  -4.2520,\n",
      "          -5.5414,  -7.4668,  -3.0012]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.4442009925842285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.9701,  -3.4310,  -3.6231, -13.0228,  -3.9657,  -0.1976,  -3.4612,\n",
      "          -4.2940,  -6.9425,  -2.8976]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.1975988894701004\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.8940,  -2.9872,  -3.4783, -12.7038,  -2.8282,  -0.3248,  -2.9515,\n",
      "          -3.3606,  -6.6508,  -3.0260]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.650783061981201\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.6658,  -2.4647,  -3.2113, -12.2565,  -1.6880,  -0.7960,  -2.3702,\n",
      "          -2.3857,  -5.4898,  -3.0186]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.0185821056365967\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.7293,  -2.3258,  -3.2704, -12.1228,  -1.0682,  -1.8117,  -2.1832,\n",
      "          -1.8447,  -4.7163,  -2.5583]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  12.122831344604492\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.9189,  -2.4049,  -3.4845, -11.3802,  -0.8987,  -2.9753,  -2.2283,\n",
      "          -1.6065,  -4.1587,  -2.3346]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.334629535675049\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.1295,  -2.5824,  -3.7404, -10.7513,  -1.0895,  -4.0996,  -2.3864,\n",
      "          -1.5799,  -3.7079,  -1.4913]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.7078840732574463\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.3613,  -2.8400,  -4.0310, -10.2271,  -1.5540,  -5.1659,  -2.6373,\n",
      "          -1.7502,  -2.6264,  -0.9443]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.637300491333008\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.6446, -3.1896, -4.3806, -9.8296, -2.2045, -6.2048, -2.2688, -2.1064,\n",
      "         -1.7805, -0.8206]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.2044694423675537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.9432, -3.5782, -4.7483, -9.5150, -2.1704, -7.1851, -2.0548, -2.5605,\n",
      "         -1.1867, -1.0853]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.1866719722747803\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.5475,  -4.2841,  -5.4214,  -9.5673,  -2.5601,  -8.4038,  -2.2899,\n",
      "          -3.3620,  -0.4768,  -1.9143]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.421418190002441\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.0535,  -4.8918,  -5.2354,  -9.5762,  -2.9303,  -9.4632,  -2.5364,\n",
      "          -4.0712,  -0.2582,  -2.7341]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.25817257165908813\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.7385,  -5.6739,  -5.3013,  -9.8135,  -3.5327, -10.6466,  -3.0448,\n",
      "          -4.9517,  -0.1232,  -3.7507]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.951745510101318\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.8252,  -5.8506,  -4.8342,  -9.4972,  -3.5668, -11.1821,  -3.0068,\n",
      "          -4.4810,  -0.1229,  -4.1537]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.0067968368530273\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.4472,  -5.5557,  -3.9636,  -8.7563,  -3.1625, -11.2082,  -1.8329,\n",
      "          -3.6094,  -0.3139,  -4.0725]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.555698871612549\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.0644,  -4.5130,  -3.1516,  -8.0469,  -2.7877, -11.1894,  -0.8487,\n",
      "          -2.8021,  -0.9760,  -3.9699]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.9760116338729858\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.0760,  -3.9384,  -2.8091,  -7.7645,  -2.8523, -11.5287,  -0.6269,\n",
      "          -2.4762,  -1.4719,  -4.2481]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.8091392517089844\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.0214,  -3.3702,  -1.7265,  -7.4455,  -2.8885, -11.7692,  -0.7463,\n",
      "          -2.1798,  -2.0208,  -4.4443]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.7463444471359253\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.2804,  -3.1921,  -1.1944,  -7.4669,  -3.2708, -12.2939,  -0.7840,\n",
      "          -2.3047,  -2.9200,  -4.9381]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.9199910163879395\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.4254,  -2.9739,  -0.8564,  -7.3983,  -3.5553, -12.6782,  -1.0577,\n",
      "          -2.4028,  -2.9504,  -5.3000]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.555250644683838\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.4113,  -2.6705,  -0.7286,  -7.1923,  -2.9427, -12.8796,  -1.4088,\n",
      "          -2.4134,  -2.8711,  -5.4849]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  11.411251068115234\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.4522,  -2.2808,  -0.8106,  -6.8398,  -2.2627, -12.8933,  -1.7329,\n",
      "          -2.3216,  -2.6734,  -5.4870]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.673431634902954\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.5793,  -1.9961,  -1.2106,  -6.5138,  -1.7187, -12.8962,  -2.1424,\n",
      "          -2.3023,  -1.8098,  -5.4827]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.4827046394348145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.8676,  -1.9148,  -1.8700,  -6.2958,  -1.4369, -12.9733,  -2.6699,\n",
      "          -2.4335,  -1.2255,  -4.7983]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.798258304595947\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.2512,  -1.9749,  -2.6045,  -6.1252,  -1.3847, -13.0670,  -3.2190,\n",
      "          -2.6409,  -0.9371,  -3.4607]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  13.067049980163574\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.6340,  -2.0695,  -3.2594,  -5.9108,  -1.4622, -12.3673,  -3.6799,\n",
      "          -2.8183,  -0.8999,  -2.2175]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.8999360799789429\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.3647,  -2.5344,  -4.1644,  -6.0061,  -1.9910, -12.0234,  -4.3993,\n",
      "          -3.3086,  -0.7217,  -1.4665]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.399253845214844\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0752,  -2.9644,  -4.9436,  -6.0462,  -2.5216, -11.6662,  -4.2887,\n",
      "          -3.7297,  -0.8666,  -0.9172]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.7296783924102783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.7019,  -3.2765,  -5.5373,  -5.9708,  -2.9461, -11.2312,  -4.0856,\n",
      "          -3.2720,  -1.1887,  -0.6114]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.085600852966309\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.1714,  -3.3903,  -5.8797,  -5.7096,  -3.1724, -10.6442,  -3.0047,\n",
      "          -2.6926,  -1.5043,  -0.5503]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.5043482780456543\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6914,  -3.5140,  -6.1862,  -5.4731,  -3.4035, -10.1118,  -2.0630,\n",
      "          -2.2172,  -1.2203,  -0.9260]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  10.111784934997559\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2689, -3.6544, -6.4708, -5.2702, -3.6436, -8.9203, -1.3130, -1.8768,\n",
      "         -1.1852, -1.5692]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.8767683506011963\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1038, -4.0116, -6.9397, -5.3030, -4.0908, -8.0589, -1.0420, -1.1561,\n",
      "         -1.5864, -2.5168]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.5167737007141113\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0141, -4.4008, -7.4167, -5.3904, -4.5601, -7.3376, -1.1049, -0.7943,\n",
      "         -2.1501, -2.7305]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.1500754356384277\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8414, -4.6633, -7.7497, -5.3755, -4.8935, -6.5914, -1.3018, -0.7057,\n",
      "         -1.9208, -2.8747]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.893465518951416\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4741, -4.6888, -7.8319, -5.1477, -4.2335, -5.7025, -1.4560, -0.7728,\n",
      "         -1.6023, -2.8292]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.4560270309448242\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1691, -4.7354, -7.9231, -4.9639, -3.6669, -4.9213, -1.0625, -1.1908,\n",
      "         -1.4780, -2.8494]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.169149398803711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0631, -4.7213, -7.9429, -4.7411, -3.1132, -4.1606, -0.8928, -1.7288,\n",
      "         -1.4684, -2.8486]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.113223075866699\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1288, -4.7404, -7.9861, -4.5724, -1.9296, -3.5119, -1.0579, -2.3695,\n",
      "         -1.6516, -2.9167]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.740449905395508\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5505, -4.1902, -8.1952, -4.5983, -1.1419, -3.1193, -1.6247, -3.1854,\n",
      "         -2.1251, -3.1886]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.1854143142700195\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3401, -3.8502, -8.5279, -4.7735, -0.8149, -2.9420, -2.4201, -3.3553,\n",
      "         -2.7822, -3.6088]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.7821500301361084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2895, -3.4937, -8.7615, -4.8717, -0.7843, -2.7543, -3.1338, -3.4679,\n",
      "         -2.6289, -3.9414]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.1337947845458984\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2996, -3.0353, -8.8119, -4.8059, -0.9366, -2.4715, -2.9319, -3.4322,\n",
      "         -2.3829, -4.0956]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.4714906215667725\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5014, -2.6376, -8.8368, -4.7324, -1.3446, -1.5353, -2.7675, -3.4033,\n",
      "         -2.2075, -4.2264]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.403296709060669\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9624, -2.4376, -8.9641, -4.7777, -2.0106, -0.9528, -2.7690, -2.7712,\n",
      "         -2.2337, -4.4599]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.0105552673339844\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5773, -2.4123, -9.1686, -4.9148, -2.0552, -0.7971, -2.9050, -2.3377,\n",
      "         -2.4246, -4.7687]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.768682479858398\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0656, -2.3315, -9.2278, -4.9189, -2.0655, -0.8577, -2.9416, -1.8935,\n",
      "         -2.5356, -4.1744]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.535614252090454\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5000, -2.2892, -9.2393, -4.8863, -2.1271, -1.1765, -2.9705, -1.5624,\n",
      "         -1.9289, -3.6089]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.9704713821411133\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9388, -2.3508, -9.2736, -4.8867, -2.2950, -1.7102, -2.3436, -1.4426,\n",
      "         -1.5114, -3.1440]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.7101653814315796\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4473, -2.5755, -9.4028, -4.9911, -2.6193, -1.6970, -1.9457, -1.6070,\n",
      "         -1.3930, -2.8561]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.6193299293518066\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8934, -2.8137, -9.4981, -5.0692, -2.2021, -1.7962, -1.6683, -1.8815,\n",
      "         -1.4445, -2.6191]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.893360137939453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4542, -3.0103, -9.5212, -5.0817, -1.8458, -1.9425, -1.4905, -2.1784,\n",
      "         -1.5987, -2.3980]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.5986671447753906\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1551, -3.3115, -9.6294, -5.1851, -1.7294, -2.2649, -1.5786, -2.6165,\n",
      "         -1.2492, -2.3548]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.3114984035491943\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8462, -2.8119, -9.6751, -5.2307, -1.7044, -2.5784, -1.7535, -3.0131,\n",
      "         -1.0896, -2.3359]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.8462061882019043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7364, -2.3367, -9.6463, -5.2060, -1.7470, -2.8456, -1.9648, -3.3366,\n",
      "         -1.1185, -2.3220]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.964760422706604\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8701, -2.0634, -9.7028, -5.2703, -1.9972, -3.2105, -1.6236, -3.7365,\n",
      "         -1.4624, -2.4661]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.4624019861221313\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3857, -2.0876, -9.9292, -5.5077, -2.4987, -3.7438, -1.6326, -4.2897,\n",
      "         -1.3940, -2.8356]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.507744789123535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0803,  -2.1373, -10.0684,  -4.8875,  -2.9468,  -4.1763,  -1.7154,\n",
      "          -4.7333,  -1.4462,  -3.1480]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.733250617980957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9465,  -2.1461, -10.0698,  -4.2108,  -3.2653,  -4.4530,  -1.7944,\n",
      "          -4.2772,  -1.5389,  -3.3378]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.210750579833984\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0024, -2.1150, -9.9445, -2.7196, -3.4540, -4.5841, -1.8576, -3.7502,\n",
      "         -1.6503, -3.4092]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.0024347305297852\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8296,  -2.4476, -10.1022,  -1.6981,  -3.9179,  -4.9799,  -2.2965,\n",
      "          -3.5635,  -2.1594,  -3.7689]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.2964892387390137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0951,  -2.8930, -10.3253,  -1.0004,  -4.4316,  -5.4224,  -2.1312,\n",
      "          -3.4973,  -2.7821,  -4.1915]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  10.32533073425293\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5643, -3.3050, -9.7280, -0.6254, -4.8725, -5.7937, -2.0365, -3.4296,\n",
      "         -3.3570, -4.5531]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.036489486694336\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1192, -3.6731, -9.1597, -0.6696, -5.2448, -6.0997, -1.3034, -3.3622,\n",
      "         -3.8694, -4.8562]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.673089027404785\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6396, -3.2032, -8.5750, -1.0300, -5.5110, -6.3039, -0.7636, -3.2540,\n",
      "         -4.2729, -5.0621]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.511045455932617\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0664, -2.7130, -7.9512, -1.5313, -4.9120, -6.3917, -0.5117, -3.0877,\n",
      "         -4.5489, -5.1549]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.154850006103516\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2911, -2.1252, -7.1937, -1.9530, -4.1821, -6.2760, -0.5148, -2.7757,\n",
      "         -4.6090, -4.2886]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.608993053436279\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3629, -1.5255, -6.3526, -2.2822, -3.3766, -6.0136, -0.7816, -2.3814,\n",
      "         -3.7893, -3.3595]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.78934645652771\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5047, -1.1983, -5.6467, -2.7072, -2.7267, -5.8291, -1.3960, -2.1447,\n",
      "         -2.4014, -2.5992]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.1447460651397705\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9542, -1.4274, -5.3120, -3.4396, -2.4886, -5.9634, -2.4229, -1.5778,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -1.5150, -2.2693]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.5149831771850586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8482, -2.2874, -5.4886, -4.5981, -2.8103, -6.5605, -3.8848, -1.6941,\n",
      "         -0.6341, -2.5249]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.8848226070404053\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.7673, -3.2458, -5.7588, -5.7570, -3.2528, -7.2072, -4.6130, -2.0426,\n",
      "         -0.3301, -2.9238]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.757012367248535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2956, -3.8361, -5.7027, -5.7309, -3.3783, -7.4882, -4.9739, -2.1505,\n",
      "         -0.2701, -3.0221]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.730914115905762\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3667, -3.9777, -5.2487, -4.5404, -3.1107, -7.3356, -4.8977, -1.9277,\n",
      "         -0.3553, -2.7415]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.741464614868164\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2609, -3.9482, -4.6728, -3.3054, -2.7318, -7.0275, -4.6632, -1.6636,\n",
      "         -0.7596, -1.6092]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.3053958415985107\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4195, -4.1885, -4.4139, -1.7153, -2.6918, -7.0031, -4.7112, -1.8185,\n",
      "         -1.7087, -0.9938]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.715341567993164\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.3442, -5.1967, -4.9706, -0.4453, -3.4869, -7.7624, -5.5413, -2.8586,\n",
      "         -3.4728, -1.5009]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.5009071826934814\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.6074, -6.5389, -5.9073, -0.2212, -4.6558, -8.8764, -6.7216, -4.2677,\n",
      "         -5.5135, -1.8007]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.267693042755127\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.3271, -7.3306, -6.3350, -0.2115, -5.2976, -9.4618, -7.3673, -4.3895,\n",
      "         -6.9360, -1.7777]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.936036109924316\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.4821, -7.5508, -6.2283, -0.3221, -5.3860, -9.4957, -7.4561, -4.0151,\n",
      "         -7.0106, -1.3918]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.550830364227295\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.2727, -6.6511, -5.7848, -0.6184, -5.1202, -9.1774, -7.1875, -3.3424,\n",
      "         -6.7293, -0.8835]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.784793853759766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.9090, -5.6668, -4.4410, -1.1148, -4.7100, -8.7157, -6.7710, -2.5875,\n",
      "         -6.3017, -0.5634]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.710043430328369\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.4516, -4.6528, -3.1100, -1.6781, -3.4703, -8.1699, -6.2666, -1.8333,\n",
      "         -5.7879, -0.5750]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.109959602355957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.2008, -3.9079, -1.3404, -2.4869, -2.5381, -7.8396, -5.9748, -1.4335,\n",
      "         -5.4884, -1.1706]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.3403980731964111\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.0574, -4.3344, -0.2657, -4.3600, -2.8399, -8.6246, -6.7959, -2.3322,\n",
      "         -6.3038, -3.0228]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  9.057398796081543\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.2435, -4.9279, -0.0895, -6.2559, -3.3551, -9.5313, -7.7358, -3.4130,\n",
      "         -7.2389, -4.9272]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.412970542907715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.8742, -4.9308, -0.0956, -7.4276, -3.3081, -9.8108, -8.0455, -3.1349,\n",
      "         -7.5446, -6.1105]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.308065176010132\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.0203, -4.4173, -0.2719, -7.9618, -2.0272, -9.5411, -7.8032, -2.3951,\n",
      "         -7.2988, -6.6563]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  8.02031421661377\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4022, -3.8939, -0.9375, -8.3728, -0.9019, -9.2281, -7.5150, -1.7261,\n",
      "         -7.0077, -7.0786]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.402229309082031\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4521, -3.7159, -2.1116, -9.0213, -0.4699, -9.2245, -7.5341, -1.5334,\n",
      "         -7.0243, -7.7376]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.452062129974365\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9481, -3.5836, -3.2702, -9.6149, -0.5566, -9.2308, -7.5612, -1.5290,\n",
      "         -7.0495, -8.3409]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.5566486120223999\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5813,  -4.2627,  -5.1197, -10.9268,  -1.0942, -10.0139,  -8.3633,\n",
      "          -2.4626,  -7.8502,  -9.6617]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.262664318084717\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.1586,  -4.5071,  -7.1617, -12.4802,  -2.1996, -11.0912,  -9.4578,\n",
      "          -3.7384,  -8.9434, -11.2232]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  11.223167419433594\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.0808,  -4.3746,  -8.6402, -13.5181,  -2.9168, -11.7003, -10.0825,\n",
      "          -4.5439,  -9.5671, -11.5110]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.08082064241170883\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.0433,  -4.3574, -10.0643, -14.5453,  -3.6954, -12.3414, -10.7376,\n",
      "          -5.3698, -10.2213, -11.8628]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.22131633758545\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.0561,  -3.6583, -10.6536, -14.7772,  -3.7220, -12.2256, -10.6345,\n",
      "          -5.4238,  -9.4034, -11.4865]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  10.653593063354492\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.1533,  -2.4098,  -9.7847, -14.3476,  -3.1256, -11.4830,  -9.9032,\n",
      "          -4.8372,  -8.0285, -10.5092]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  11.482954978942871\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6129,  -1.0721,  -8.7215, -13.6797,  -2.3404,  -9.7970,  -8.9638,\n",
      "          -4.0340,  -6.5097,  -9.3482]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  9.348188400268555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7348,  -0.4213,  -8.0603, -13.3746,  -2.0014,  -8.5751,  -8.4141,\n",
      "          -3.6200,  -5.4393,  -7.8461]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.001384735107422\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0437,  -0.4923,  -7.6293, -13.2639,  -1.2154,  -7.6391,  -8.0835,\n",
      "          -3.4313,  -4.6426,  -6.6580]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.492306649684906\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5422,  -0.5474,  -7.5249, -13.4476,  -1.0121,  -7.0799,  -8.0693,\n",
      "          -3.5687,  -4.2155,  -5.8724]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.542206764221191\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8436,  -0.7423,  -7.1428, -13.3245,  -0.8114,  -6.2885,  -7.7683,\n",
      "          -3.4249,  -3.5530,  -4.8786]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.8113874793052673\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3048,  -1.4579,  -6.9832, -13.3975,  -0.4007,  -5.7610,  -7.6813,\n",
      "          -3.5035,  -3.1607,  -4.1732]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.4579256772994995\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6524,  -1.4549,  -6.7686, -13.3917,  -0.4577,  -5.2168,  -7.5318,\n",
      "          -3.5251,  -2.7663,  -3.4782]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.7663309574127197\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8005,  -1.4592,  -6.4086, -13.2189,  -0.8106,  -4.5632,  -7.2299,\n",
      "          -3.3989,  -1.5746,  -2.7081]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  13.21890640258789\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.0649,  -1.7657,  -6.2145, -12.4329,  -1.5865,  -4.1110,  -7.0874,\n",
      "          -3.4388,  -0.7784,  -2.1938]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.7784150838851929\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8965,  -2.7615,  -6.6330, -12.3169,  -3.0287,  -4.3078,  -7.5514,\n",
      "          -4.0906,  -0.2675,  -2.4068]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.7614903450012207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.4921,  -2.8032,  -6.8567, -12.0583,  -4.2091,  -4.3408,  -7.8156,\n",
      "          -4.5358,  -0.2012,  -2.5128]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.492059707641602\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8150,  -2.4340,  -6.6071, -11.3736,  -4.8312,  -3.9283,  -7.6018,\n",
      "          -4.4928,  -0.2723,  -2.2178]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.4339990615844727\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.0275,  -1.2446,  -6.2047, -10.5783,  -5.2188,  -3.3928,  -7.2310,\n",
      "          -4.2838,  -0.6979,  -1.8560]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  10.578329086303711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4952, -0.5633, -6.0189, -9.2821, -5.7468, -3.1105, -7.0726, -4.2810,\n",
      "         -1.6087, -1.8238]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.072646141052246\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0138, -0.3685, -5.8482, -8.1096, -6.2193, -2.8841, -6.2056, -4.2835,\n",
      "         -2.5655, -1.9119]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2.884139060974121\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3839, -0.5052, -5.4952, -6.8525, -6.4449, -1.7812, -5.2248, -4.0946,\n",
      "         -3.2803, -1.9020]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.9020215272903442\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9337, -1.1825, -5.2880, -5.8289, -6.7567, -1.0202, -4.4529, -4.0444,\n",
      "         -4.0582, -1.3557]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.1824848651885986\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7793, -1.5135, -5.3415, -5.1455, -7.2745, -0.8379, -4.0025, -4.2486,\n",
      "         -5.0071, -1.2951]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.274529933929443\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4686, -1.7854, -5.2041, -4.3454, -6.8079, -0.8047, -3.4209, -4.2540,\n",
      "         -5.6773, -1.2588]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.8046647310256958\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3868, -2.3285, -5.2587, -3.8088, -6.5626, -0.5404, -3.0948, -4.4436,\n",
      "         -6.4572, -1.6153]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.386770725250244\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4132, -2.7244, -5.1465, -3.1771, -6.1774, -0.5673, -2.6686, -4.4577,\n",
      "         -6.9953, -1.9215]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.724404811859131\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5492, -2.3333, -4.9944, -2.5845, -5.7766, -0.9539, -2.2793, -4.4237,\n",
      "         -7.4250, -2.2526]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.2793021202087402\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1336, -2.2535, -5.0633, -2.3088, -5.6185, -1.7863, -1.4834, -4.6026,\n",
      "         -8.0130, -2.8311]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.1335805654525757\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6649, -2.6792, -5.5502, -2.5563, -5.8989, -3.0794, -1.3504, -5.1913,\n",
      "         -8.9627, -3.8168]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.550164222717285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5392, -3.0181, -5.1314, -2.7429, -6.0581, -4.1824, -1.3222, -5.6302,\n",
      "         -9.7227, -4.6257]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.018075942993164\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6368,  -2.3896,  -4.5265,  -2.7276,  -5.9709,  -4.9545,  -1.2568,\n",
      "          -5.7958, -10.1747,  -5.1292]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.954495906829834\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9262,  -1.6918,  -3.7905,  -2.5641,  -5.6947,  -4.7172,  -1.2036,\n",
      "          -5.7477, -10.3823,  -5.3876]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.382250785827637\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4147, -1.1274, -3.0730, -2.4036, -5.3765, -4.4381, -1.3001, -5.6348,\n",
      "         -9.7837, -5.5517]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.438110828399658\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0254, -0.8451, -2.4492, -2.3149, -5.0802, -3.4495, -1.5704, -5.5226,\n",
      "         -9.2315, -5.6893]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.522584438323975\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6238, -0.8562, -1.9021, -2.2588, -4.7665, -2.5310, -1.9121, -4.6224,\n",
      "         -8.6828, -5.7642]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.9121246337890625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2907, -1.2524, -1.5971, -2.3611, -4.5633, -1.8354, -1.6778, -3.8922,\n",
      "         -8.2618, -5.9070]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.2523777484893799\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0918, -1.2545, -1.6500, -2.6975, -4.5604, -1.4983, -1.7736, -3.4223,\n",
      "         -8.0551, -6.2099]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.2544506788253784\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9658, -0.8711, -1.9851, -3.1920, -4.7057, -1.4991, -2.1221, -3.1636,\n",
      "         -8.0093, -6.6242]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.965817451477051\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8805, -0.7157, -2.2743, -3.5505, -4.7251, -1.5457, -2.4042, -2.8444,\n",
      "         -7.8501, -6.8802]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.7250823974609375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6213, -0.7468, -2.4255, -3.7073, -3.8157, -1.5562, -2.5352, -2.4125,\n",
      "         -7.5189, -6.9234]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.707282543182373\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2614, -0.9886, -2.4957, -2.9696, -2.8792, -1.5867, -2.5763, -1.9571,\n",
      "         -7.0870, -6.8290]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.9885519742965698\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1486, -0.9457, -2.8230, -2.5451, -2.2785, -1.9652, -2.8689, -1.8539,\n",
      "         -6.8994, -6.9455]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.2784676551818848\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1547, -1.2877, -3.2592, -2.3185, -1.1674, -2.5049, -3.2691, -1.9749,\n",
      "         -6.8269, -7.1469]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.318464517593384\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4374, -2.0631, -3.9467, -1.6949, -0.6641, -3.3162, -3.9222, -2.4535,\n",
      "         -7.0276, -7.5941]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.0630502700805664\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7518, -2.1725, -4.6317, -1.3242, -0.6454, -4.1244, -4.5755, -3.0003,\n",
      "         -7.2599, -8.0480]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.1724865436553955\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9541, -1.5383, -5.1685, -1.1056, -0.9313, -4.7766, -5.0839, -3.4428,\n",
      "         -7.3822, -8.3696]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.442795753479004\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0676, -1.0500, -5.5823, -1.0868, -1.4073, -5.2961, -5.4721, -3.0388,\n",
      "         -7.4187, -8.5853]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.58533763885498\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0700, -0.7612, -5.8533, -1.2221, -1.9133, -5.6631, -5.7201, -2.6066,\n",
      "         -7.3474, -7.9119]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.663100242614746\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9071, -0.6722, -5.9297, -1.3983, -2.3088, -5.0901, -5.7761, -2.1030,\n",
      "         -7.1139, -7.1359]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.9297003746032715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5745, -0.7723, -5.0391, -1.5534, -2.5472, -4.3869, -5.6371, -1.5499,\n",
      "         -6.7126, -6.2462]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.5534021854400635\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3370, -1.2527, -4.2963, -1.1470, -2.8743, -3.8171, -5.5687, -1.2658,\n",
      "         -6.4063, -5.5006]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.8171253204345703\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1096, -1.8698, -3.6145, -0.9990, -3.1875, -2.5650, -5.4865, -1.1990,\n",
      "         -6.1082, -4.8089]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.8089447021484375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9327, -2.5529, -3.0364, -1.1605, -3.5155, -1.5091, -5.4306, -1.3810,\n",
      "         -5.8566, -3.4480]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.43064546585083\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9343, -3.3709, -2.6990, -1.6898, -3.9790, -0.8667, -4.8055, -1.8801,\n",
      "         -5.7782, -2.3928]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.3927836418151855\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2566, -4.4384, -2.7529, -2.6125, -4.7163, -0.9028, -4.5544, -2.7505,\n",
      "         -6.0157, -1.0622]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.5543599128723145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8475, -5.6982, -3.1404, -3.7890, -5.6767, -1.5226, -3.9064, -3.8722,\n",
      "         -6.5211, -0.4171]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.5225801467895508\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4080, -6.8576, -3.5452, -4.8881, -6.5666, -1.5309, -3.3598, -4.9205,\n",
      "         -6.9998, -0.3604]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.857569217681885\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5611, -6.8170, -3.5769, -5.5283, -7.0138, -1.3416, -2.5376, -5.5148,\n",
      "         -7.0764, -0.4831]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.5376155376434326\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6612, -6.7407, -3.5864, -6.0674, -7.3766, -1.3221, -1.0967, -6.0125,\n",
      "         -7.1054, -1.0192]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.661246299743652\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3233, -7.0040, -3.9475, -6.8856, -8.0349, -1.8308, -0.3714, -6.7935,\n",
      "         -7.4631, -2.1055]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.03490161895752\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9824, -7.2014, -4.2473, -7.5829, -7.8417, -2.3660, -0.1757, -7.4575,\n",
      "         -7.7455, -3.1354]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.247336387634277\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2543, -6.9534, -3.3319, -7.7849, -7.2416, -2.4904, -0.1760, -7.6294,\n",
      "         -7.5736, -3.6694]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.3318681716918945\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3173, -6.4385, -1.4787, -7.6748, -6.4095, -2.3709, -0.4835, -7.4923,\n",
      "         -7.1271, -3.8774]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.4787064790725708\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4873, -6.9622, -0.2090, -8.5622, -6.6476, -3.3180, -2.1861, -8.3555,\n",
      "         -7.7117, -5.0665]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.1860623359680176\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0381, -7.8087, -0.0644, -9.7357, -7.2372, -4.5717, -3.4576, -9.5072,\n",
      "         -8.6127, -6.5162]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.516219139099121\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9436,  -7.9675,  -0.0474, -10.1887,  -7.1649,  -5.1043,  -4.0213,\n",
      "          -9.9405,  -8.8203,  -6.4621]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.164902210235596\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1977, -7.4350, -0.0798, -9.9209, -5.6820, -4.9128, -3.8660, -9.6551,\n",
      "         -8.3317, -5.7389]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.655078887939453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0092, -6.4078, -0.2560, -9.1316, -3.8010, -4.1976, -3.1930, -8.0937,\n",
      "         -7.3437, -4.5419]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.197570323944092\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0539, -5.4964, -1.0074, -8.4334, -2.1363, -2.8434, -2.6286, -6.7004,\n",
      "         -6.4670, -3.4846]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.1363253593444824\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2422, -5.4604, -2.7397, -8.5865, -0.7667, -2.4484, -2.9536, -6.2283,\n",
      "         -6.4603, -3.3372]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.7666535973548889\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6547, -6.4531, -5.3704, -9.7466, -0.1597, -3.1781, -4.3057, -6.8267,\n",
      "         -7.4774, -4.2535]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.305671215057373\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8011,  -7.1688,  -7.5633, -10.6117,  -0.0691,  -3.6862,  -4.6397,\n",
      "          -7.1869,  -8.2143,  -4.9099]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.06912367790937424\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.9454,  -7.9087,  -9.6333, -11.4858,  -0.0330,  -4.2572,  -5.0423,\n",
      "          -7.6068,  -8.9729,  -5.6015]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.908659934997559\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3007,  -7.1641, -10.8168, -11.5923,  -0.0365,  -4.1011,  -4.7289,\n",
      "          -7.3047,  -8.9756,  -5.5465]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.300695896148682\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2019,  -5.8364, -11.2248, -11.0305,  -0.0905,  -3.3151,  -3.7953,\n",
      "          -6.3755,  -8.3204,  -4.8422]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.3150978088378906\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8895,  -4.3087, -11.2580, -10.1903,  -0.4716,  -1.5678,  -2.6363,\n",
      "          -5.2057,  -7.3963,  -3.8797]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.6362509727478027\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3543,  -3.5470, -11.8919, -10.0378,  -1.8734,  -0.7514,  -1.5367,\n",
      "          -4.7606,  -7.1687,  -3.6327]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.873444676399231\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3631,  -3.3001, -12.8808, -10.3186,  -2.9315,  -0.7801,  -1.1179,\n",
      "          -4.7843,  -7.3823,  -3.8485]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  10.31860637664795\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3088,  -2.9707, -13.6371,  -9.6709,  -3.7890,  -1.0074,  -0.8396,\n",
      "          -4.6778,  -7.4409,  -3.9248]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.3087573051452637\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5209,  -2.6590, -14.2655,  -9.0351,  -4.5250,  -1.4266,  -0.8441,\n",
      "          -4.5363,  -7.4415,  -3.9558]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.4265787601470947\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0765,  -2.5279, -14.9295,  -8.5608,  -5.2939,  -1.3463,  -1.2523,\n",
      "          -4.5153,  -7.5406,  -4.0965]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.560832023620605\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8296,  -2.3615, -15.4206,  -7.2659,  -5.8831,  -1.3573,  -1.7164,\n",
      "          -4.3978,  -7.5234,  -4.1290]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.523426055908203\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7682,  -2.1090, -15.6910,  -5.9285,  -6.2438,  -1.3833,  -2.0904,\n",
      "          -4.1295,  -6.6079,  -3.9986]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.7681508660316467\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4996,  -2.1661, -16.1297,  -4.9215,  -6.7654,  -1.7853,  -2.7105,\n",
      "          -4.0954,  -5.9797,  -4.0905]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.921480178833008\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4993,  -2.0812, -16.3043,  -3.0428,  -7.0153,  -2.0494,  -3.0958,\n",
      "          -3.8569,  -5.1954,  -3.9655]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.0428054332733154\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1568,  -2.2933, -16.6583,  -0.8321,  -7.4379,  -2.5783,  -3.6718,\n",
      "          -3.8551,  -4.6900,  -4.0642]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.6718015670776367\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9533,  -3.5243, -17.9428,  -0.1389,  -8.7846,  -4.0757,  -4.4615,\n",
      "          -4.8353,  -5.2073,  -5.1319]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.2072577476501465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4819,  -4.5257, -18.9707,  -0.0490,  -9.8686,  -5.3079,  -5.0520,\n",
      "          -5.5953,  -4.8227,  -5.9691]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.052040100097656\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.2382,  -4.8065, -19.2674,  -0.0595, -10.2158,  -5.7921,  -4.2514,\n",
      "          -5.6536,  -3.8534,  -6.0961]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.059520553797483444\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.9910,  -5.1332, -19.6025,  -0.0933, -10.5964,  -6.2982,  -3.6083,\n",
      "          -5.7766,  -3.0638,  -6.2799]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.133203029632568\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.1617,  -4.1878, -19.3950,  -0.2989, -10.4300,  -6.2462,  -2.5393,\n",
      "          -5.3807,  -1.8777,  -5.9378]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.187819480895996\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.3508,  -2.6522, -19.2420,  -1.0723, -10.3139,  -6.2346,  -1.6665,\n",
      "          -5.0614,  -0.9549,  -5.6655]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.0722752809524536\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.9876,  -1.7862, -19.5694,  -1.7396, -10.6746,  -6.6907,  -1.4800,\n",
      "          -5.2439,  -0.8700,  -5.8881]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.2438788414001465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.5447,  -1.1122, -19.8472,  -2.4550, -10.9825,  -7.0854,  -1.4568,\n",
      "          -4.6327,  -1.0820,  -6.0738]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.0819928646087646\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.2213,  -0.9208, -20.2719,  -3.3380, -11.4342,  -7.6159,  -1.7760,\n",
      "          -4.2643,  -0.9662,  -6.4172]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.337991237640381\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.6567,  -0.8660, -20.4802,  -3.2369, -11.6668,  -7.9198,  -2.0097,\n",
      "          -3.7692,  -0.9649,  -6.5535]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  8.65666389465332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.0532,  -0.8909, -20.4340,  -2.9415, -11.6427,  -7.9601,  -2.0817,\n",
      "          -3.1072,  -1.0073,  -6.4437]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.8908585906028748\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.6423,  -0.6142, -20.5247,  -2.8472, -11.7531,  -8.1289,  -2.3675,\n",
      "          -2.6776,  -1.4433,  -6.4783]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.8472301959991455\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.1619,  -0.6499, -20.4957,  -1.9507, -11.7419,  -8.1704,  -2.5809,\n",
      "          -2.2325,  -1.8970,  -6.4000]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  20.495718002319336\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6590,  -0.9920, -19.6364,  -1.1783, -11.6609,  -8.1370,  -2.7560,\n",
      "          -1.8429,  -2.3437,  -6.2597]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  11.660853385925293\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.2209,  -1.5843, -18.8763,  -0.7261, -10.8657,  -8.1210,  -2.9728,\n",
      "          -1.6270,  -2.8297,  -6.1487]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.148715972900391\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.7240,  -2.1633, -18.0880,  -0.5755, -10.0456,  -8.0028,  -3.1006,\n",
      "          -1.4792,  -3.2064,  -5.1805]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.2064151763916016\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0820,  -2.5717, -17.1811,  -0.6611,  -9.1103,  -7.6997,  -3.0507,\n",
      "          -1.3234,  -2.6496,  -4.1160]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  7.699707984924316\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3330,  -2.8195, -16.1888,  -0.9457,  -8.0924,  -6.5155,  -2.8639,\n",
      "          -1.2113,  -2.0238,  -2.9943]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.5155134201049805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6447,  -3.0625, -15.2714,  -1.4664,  -7.1522,  -4.6963,  -2.7127,\n",
      "          -1.3145,  -1.5326,  -1.9988]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.062486171722412\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1860,  -2.7250, -14.5865,  -2.2477,  -6.4473,  -3.2060,  -2.7650,\n",
      "          -1.7542,  -1.3885,  -1.3475]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.3474599123001099\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2533,  -2.9176, -14.4184,  -3.4785,  -6.2624,  -2.3424,  -3.3058,\n",
      "          -2.7312,  -1.8888,  -0.6437]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.2532594203948975\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6972,  -3.2457, -14.3822,  -4.7249,  -6.2125,  -1.7505,  -3.9342,\n",
      "          -3.7762,  -2.5646,  -0.5282]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.564556121826172\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1619,  -3.4836, -14.2636,  -5.7680,  -6.0831,  -1.2591,  -4.4281,\n",
      "          -4.6488,  -2.4161,  -0.7894]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.767996311187744\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6843,  -3.6369, -14.0736,  -5.8810,  -5.8849,  -0.9420,  -4.7981,\n",
      "          -5.3587,  -2.2639,  -1.2882]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.2638754844665527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4392,  -3.8376, -13.9458,  -6.0281,  -5.7519,  -0.9862,  -5.1805,\n",
      "          -6.0448,  -1.5223,  -1.9912]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.751855373382568\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3797,  -4.0142, -13.8109,  -6.1426,  -4.8787,  -1.2800,  -5.5092,\n",
      "          -6.6447,  -0.9928,  -2.7088]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.9928180575370789\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8574,  -4.5258, -14.0287,  -6.5865,  -4.4373,  -2.0879,  -6.1472,\n",
      "          -7.5251,  -0.4010,  -3.7452]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.0879430770874023\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3470,  -4.9345, -14.1651,  -6.9276,  -3.9888,  -2.1131,  -6.6636,\n",
      "          -8.2586,  -0.2936,  -4.6367]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.663597583770752\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4809,  -4.9280, -13.9079,  -6.8555,  -3.2186,  -1.8443,  -6.0337,\n",
      "          -8.5394,  -0.3553,  -5.0671]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  13.907940864562988\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3700,  -4.6320, -12.6168,  -6.4959,  -2.2592,  -1.4227,  -5.1728,\n",
      "          -8.4969,  -0.6195,  -5.1640]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.163971424102783\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2877,  -4.3186, -11.4001,  -6.1193,  -1.4185,  -1.1659,  -4.3477,\n",
      "          -8.4049,  -1.1899,  -4.4367]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.119261741638184\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3544,  -4.1094, -10.3678,  -5.1033,  -0.9037,  -1.2262,  -3.6771,\n",
      "          -8.3854,  -1.9852,  -3.8540]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.9037134051322937\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8809, -4.3268, -9.8319, -4.5866, -0.3950, -1.8893, -3.4852, -8.7618,\n",
      "         -3.1940, -3.7393]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.586648941040039\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2643, -4.3987, -9.2159, -3.2588, -0.3010, -2.4637, -3.2008, -8.9673,\n",
      "         -4.1783, -3.5206]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.967300415039062\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3763, -4.2099, -8.3986, -1.8289, -0.4984, -2.7807, -2.7113, -8.1203,\n",
      "         -4.8132, -3.0836]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.711273670196533\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6913, -4.2387, -7.8508, -0.8482, -1.3099, -3.2997, -1.7916, -7.5459,\n",
      "         -5.5787, -2.9132]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.8481950759887695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7560, -5.0374, -8.1199, -0.3056, -3.0007, -4.5562, -1.8447, -7.7910,\n",
      "         -7.0328, -3.5632]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.119869232177734\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5784, -5.6183, -7.4567, -0.2202, -4.4168, -5.5523, -1.8628, -7.8690,\n",
      "         -8.1998, -4.0273]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.416807174682617\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8781, -5.7002, -6.4162, -0.2915, -4.5208, -6.0084, -1.5464, -7.4957,\n",
      "         -8.8070, -4.0151]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.87810754776001\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0133, -5.4055, -5.1095, -0.5335, -4.2514, -6.0499, -1.0432, -6.7891,\n",
      "         -8.9830, -3.6469]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.013321876525879\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3200, -4.9831, -3.7771, -1.0206, -3.8589, -5.9287, -0.6821, -5.9933,\n",
      "         -8.9812, -3.1750]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.777118444442749\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9150, -4.7000, -1.9278, -1.8154, -3.6132, -5.9137, -0.8110, -5.3708,\n",
      "         -9.0719, -2.8744]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.9277634620666504\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6451,  -5.3347,  -0.5002,  -3.5335,  -4.2947,  -6.7851,  -2.1277,\n",
      "          -5.6968, -10.0366,  -3.5299]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.1276650428771973\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0771,  -6.4376,  -0.2062,  -5.6298,  -5.4461,  -8.0984,  -3.2101,\n",
      "          -6.5207, -11.4330,  -4.6705]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.437567710876465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1608,  -6.2953,  -0.1606,  -7.1193,  -6.0852,  -8.8804,  -3.8129,\n",
      "          -6.8630, -12.2897,  -5.3040]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.085205078125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7875,  -5.6315,  -0.2278,  -7.9245,  -5.3926,  -9.0481,  -3.8348,\n",
      "          -6.6352, -12.5245,  -5.3418]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.8347842693328857\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1956,  -4.6538,  -0.5049,  -8.2662,  -4.3897,  -8.8155,  -2.7738,\n",
      "          -6.0476, -12.3522,  -4.9954]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.26618766784668\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8214,  -3.7076,  -1.1352,  -7.7659,  -3.4230,  -8.5339,  -1.7908,\n",
      "          -5.4481, -12.1250,  -4.6168]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.135156273841858\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0496,  -3.1033,  -1.4202,  -7.5452,  -2.8059,  -8.5101,  -1.2541,\n",
      "          -5.1411, -12.1499,  -4.5130]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.510099411010742\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4686,  -2.5388,  -1.8050,  -7.2935,  -2.2412,  -7.6982,  -0.9209,\n",
      "          -4.8158, -12.1189,  -4.3746]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.815846920013428\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9874,  -2.0546,  -2.2410,  -7.0332,  -1.7767,  -6.9333,  -0.8707,\n",
      "          -3.7241, -12.0569,  -4.2255]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.9874125719070435\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8420,  -1.7598,  -2.7602,  -6.8460,  -1.5293,  -6.2917,  -1.1702,\n",
      "          -2.8061, -12.0477,  -4.1491]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.291714668273926\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8045,  -1.5941,  -3.2481,  -6.6510,  -1.4384,  -4.9555,  -1.6337,\n",
      "          -1.9990, -12.0121,  -4.0653]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.955486297607422\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9218,  -1.6207,  -3.7424,  -6.5022,  -1.5568,  -3.0559,  -2.2159,\n",
      "          -1.4026, -12.0058,  -4.0288]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.502154350280762\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2724,  -1.9242,  -4.3389,  -5.7702,  -1.9517,  -1.5134,  -2.9515,\n",
      "          -1.1893, -12.1336,  -4.1432]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.770221710205078\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9756,  -2.6143,  -5.1948,  -4.6955,  -2.7207,  -0.5947,  -3.9599,\n",
      "          -1.5414, -12.5576,  -4.5673]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.19476318359375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7539,  -3.3961,  -5.3227,  -3.8406,  -3.5679,  -0.2790,  -4.9880,\n",
      "          -2.1303, -13.0457,  -5.0636]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.8406190872192383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2332,  -3.8854,  -5.2020,  -2.1241,  -4.1120,  -0.3093,  -5.6790,\n",
      "          -2.5129, -13.2456,  -5.2758]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  13.24563217163086\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7059,  -4.3712,  -5.1276,  -0.6956,  -4.6440,  -0.9019,  -6.3338,\n",
      "          -2.9502, -12.7287,  -5.5009]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.6955859661102295\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.1812,  -5.8609,  -6.1078,  -0.0890,  -6.1730,  -2.7738,  -7.9675,\n",
      "          -4.4272, -13.3061,  -6.7495]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.08895712345838547\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.0408e+00, -7.7339e+00, -7.5216e+00, -1.0287e-02, -8.0809e+00,\n",
      "         -5.0345e+00, -9.9683e+00, -6.2961e+00, -1.4355e+01, -8.4043e+00]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.521631240844727\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.0556e+00, -8.7609e+00, -7.3863e+00, -3.4182e-03, -9.1391e+00,\n",
      "         -6.4149e+00, -1.1110e+01, -7.3204e+00, -1.4640e+01, -9.2346e+00]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  14.640430450439453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.2528e+00, -8.9690e+00, -6.5482e+00, -3.3580e-03, -9.3754e+00,\n",
      "         -6.9424e+00, -1.1422e+01, -7.5265e+00, -1.3457e+01, -9.2656e+00]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.375372886657715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.7191e+00, -8.4452e+00, -5.0832e+00, -9.2587e-03, -8.1404e+00,\n",
      "         -6.7069e+00, -1.0991e+01, -7.0012e+00, -1.1680e+01, -8.5823e+00]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.140405654907227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5740, -7.3091, -3.1041, -0.0578, -5.6334, -5.8311, -9.9381, -5.8644,\n",
      "         -9.4154, -7.3026]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.574045181274414\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5264, -6.0333, -1.1024, -0.5184, -3.1252, -4.7913, -8.7371, -4.5896,\n",
      "         -7.1228, -5.8974]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.791301250457764\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5435, -5.7442, -0.4076, -2.2138, -1.7568, -3.9889, -8.5136, -4.3075,\n",
      "         -5.9170, -5.4922]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.916971683502197\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0068, -5.8264, -0.6215, -4.1588, -0.9915, -3.6200, -8.6527, -4.4041,\n",
      "         -4.4522, -5.4707]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.826449394226074\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5293, -5.1529, -1.2083, -5.9132, -0.5668, -3.2993, -8.7700, -4.4926,\n",
      "         -3.1335, -5.4466]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.5292773246765137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3578, -4.5464, -1.9560, -7.4907, -0.5964, -3.0331, -8.8715, -4.5766,\n",
      "         -1.9734, -5.4239]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.423867702484131\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4972, -4.1303, -2.8575, -9.0337, -1.1485, -2.9507, -9.0851, -4.7825,\n",
      "         -1.1517, -4.7532]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.03371524810791\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0864, -3.9610, -3.9058, -9.8981, -2.0712, -3.1082, -9.4710, -5.1679,\n",
      "         -0.8348, -4.3494]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.0864332914352417\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5274,  -4.1363,  -5.1786, -10.9902,  -3.3081,  -3.5964, -10.1322,\n",
      "          -5.8331,  -1.1782,  -4.3095]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.833065986633301\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3288,  -4.1609,  -6.1837, -11.8284,  -4.3035,  -3.9109, -10.5825,\n",
      "          -5.5122,  -1.5654,  -4.1388]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  11.828374862670898\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3184,  -3.8160,  -6.7118, -11.4914,  -4.8312,  -3.8301, -10.6094,\n",
      "          -4.8479,  -1.6871,  -3.6189]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  11.491366386413574\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4780,  -3.1401,  -6.8067, -10.0982,  -4.9308,  -3.3912, -10.2517,\n",
      "          -3.8742,  -1.5491,  -2.7899]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.3912482261657715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0988, -2.4222, -6.8250, -8.6745, -4.9777, -2.0967, -9.7552, -2.9238,\n",
      "         -1.3872, -1.9419]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.098848581314087\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4181, -2.2512, -7.1809, -7.8317, -5.3455, -1.4814, -9.7455, -2.4746,\n",
      "         -1.8730, -1.7072]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.8317060470581055\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8951, -2.1827, -7.5090, -6.3760, -5.6873, -1.1007, -9.7439, -2.1426,\n",
      "         -2.4292, -1.6442]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.508967399597168\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3817, -2.1488, -6.9967, -5.0100, -5.9411, -0.9445, -9.6862, -1.8787,\n",
      "         -2.9378, -1.6817]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.010000228881836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7976, -2.1131, -6.4440, -2.9921, -6.0795, -0.9957, -9.5423, -1.6681,\n",
      "         -3.3423, -1.7683]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.6680724620819092\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4932, -2.4463, -6.2226, -1.4855, -6.4809, -1.5865, -9.6878, -1.1231,\n",
      "         -4.0073, -2.2544]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.480947494506836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4920,  -3.1602,  -6.3741,  -0.6383,  -6.4582,  -2.6172, -10.1682,\n",
      "          -1.2348,  -4.9687,  -3.1234]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  10.168225288391113\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4659, -3.9009, -6.5779, -0.3152, -6.5049, -3.6647, -9.9452, -1.6275,\n",
      "         -5.9055, -4.0062]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.905529499053955\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0401, -4.2770, -6.4564, -0.2335, -6.2420, -4.3206, -9.4385, -1.8279,\n",
      "         -5.7177, -4.5094]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.827858328819275\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3097, -4.3767, -6.0988, -0.4673, -5.7574, -4.6718, -8.7329, -1.1082,\n",
      "         -5.3017, -4.7218]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.301697254180908\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4096, -4.3317, -5.6344, -0.9731, -5.1792, -4.8506, -7.9534, -0.5722,\n",
      "         -4.0642, -4.7758]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.409557819366455\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6085, -4.1652, -5.0831, -1.5576, -4.5269, -4.8816, -7.1161, -0.3910,\n",
      "         -2.8265, -4.6953]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.695319175720215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7128, -3.8498, -4.4142, -2.0545, -3.7704, -4.7379, -6.1855, -0.5731,\n",
      "         -1.5778, -3.6727]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.712782859802246\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2985, -3.7181, -3.9573, -2.7283, -3.2424, -4.7513, -5.4853, -1.3077,\n",
      "         -0.7393, -2.9080]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.242366313934326\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3129, -3.8779, -3.8205, -3.6411, -2.3228, -5.0299, -5.1180, -2.4380,\n",
      "         -0.5905, -2.5222]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.4380083084106445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5894, -4.1267, -3.8033, -4.5709, -1.6561, -5.3749, -4.8810, -2.8385,\n",
      "         -0.9469, -2.3267]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.374912261962891\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1437, -4.4148, -3.8566, -5.4675, -1.2480, -5.0088, -4.7250, -3.2962,\n",
      "         -1.6002, -2.2789]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.2479623556137085\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2772, -4.9778, -4.2151, -6.5723, -0.6534, -4.9786, -4.8856, -4.0314,\n",
      "         -2.6290, -2.6103]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.6290199756622314\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5584, -5.4408, -4.4999, -7.5190, -0.4510, -4.9073, -4.9864, -4.6579,\n",
      "         -2.8348, -2.9170]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.44084358215332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6677, -4.8095, -4.4622, -8.0692, -0.4331, -4.5459, -4.7796, -4.9268,\n",
      "         -2.7600, -2.9328]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.932833433151245\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6722, -4.0109, -4.2008, -8.3288, -0.6547, -3.9921, -4.3633, -4.9384,\n",
      "         -2.5021, -1.9737]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.93841552734375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7833, -3.2708, -3.9422, -8.5282, -1.1986, -3.4723, -3.9632, -4.1502,\n",
      "         -2.2945, -1.1838]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.1986362934112549\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2328, -2.8554, -3.9466, -8.9304, -1.4002, -3.2496, -3.8392, -3.6750,\n",
      "         -2.4030, -0.9336]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.4030086994171143\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6832, -2.4892, -3.9300, -9.2575, -1.7263, -3.0423, -3.7081, -3.2315,\n",
      "         -1.8096, -0.9794]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.9300284385681152\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1070, -2.1884, -3.1411, -9.5186, -2.1163, -2.8573, -3.5744, -2.8290,\n",
      "         -1.3599, -1.2796]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.574416160583496\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5504, -2.0296, -2.4914, -9.7818, -2.5833, -2.7608, -2.7769, -2.5401,\n",
      "         -1.1681, -1.7943]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.583341360092163\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0339,  -2.0477,  -2.0314, -10.0813,  -2.3919,  -2.7829,  -2.1665,\n",
      "          -2.4032,  -1.2822,  -2.4497]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.7828807830810547\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5373,  -2.2157,  -1.7711, -10.4058,  -2.3409,  -2.1703,  -1.7547,\n",
      "          -2.4043,  -1.6398,  -3.1618]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.1703097820281982\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1834,  -2.6336,  -1.8502, -10.8826,  -2.5497,  -1.1585,  -1.6943,\n",
      "          -2.6596,  -2.2864,  -4.0207]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.8501542806625366\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.0251,  -3.3195,  -1.5415, -11.5676,  -3.0502,  -0.7328,  -2.0291,\n",
      "          -3.1991,  -3.1977,  -5.0638]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  11.567623138427734\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6997,  -3.8793,  -1.3402, -11.3925,  -3.4503,  -0.6159,  -2.3411,\n",
      "          -3.6313,  -3.9626,  -5.9228]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.9228363037109375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0774,  -4.1682,  -1.1260, -11.0042,  -3.6030,  -0.6746,  -2.4613,\n",
      "          -3.8102,  -4.4345,  -5.6883]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.077362060546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4131,  -4.1913,  -0.9294, -10.4058,  -3.5118,  -0.8502,  -2.3830,\n",
      "          -3.7398,  -4.6193,  -5.2310]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.413079738616943\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8473, -4.0048, -0.8317, -9.6482, -3.2327, -1.1008, -2.1609, -3.4759,\n",
      "         -4.5741, -4.6047]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.604691505432129\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3035, -3.7107, -0.9321, -8.8263, -2.8704, -1.4288, -1.9051, -3.1225,\n",
      "         -4.4010, -3.1349]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.3034586906433105\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3986, -3.6678, -1.5226, -8.2896, -2.7889, -2.1021, -1.9866, -3.0417,\n",
      "         -4.4574, -2.0485]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.1020901203155518\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5373, -4.3168, -2.8872, -8.4749, -3.4289, -2.7358, -2.8283, -3.6743,\n",
      "         -5.1850, -1.8387]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.8283379077911377\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.3282, -5.0383, -4.2850, -8.7689, -4.1559, -3.4805, -3.0280, -4.3906,\n",
      "         -5.9713, -1.9001]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.480534076690674\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.3606, -5.3733, -5.2346, -8.7143, -4.5026, -3.1283, -2.9236, -4.7257,\n",
      "         -6.3616, -1.7521]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.36160945892334\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5728, -5.3409, -5.7561, -8.3275, -4.4852, -2.5052, -2.5309, -4.6966,\n",
      "         -5.6530, -1.4158]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.5728380084037781\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6152, -5.4923, -6.4051, -8.1563, -4.6548, -2.1804, -2.4123, -4.8546,\n",
      "         -5.1944, -1.4786]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.492269992828369\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8246, -4.6459, -6.7589, -7.7707, -4.5826, -1.7382, -2.1390, -4.7710,\n",
      "         -4.5536, -1.4803]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.5536322593688965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2354, -3.7867, -6.9742, -7.3194, -4.4210, -1.3635, -1.8744, -4.5982,\n",
      "         -3.1606, -1.5545]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.8744374513626099\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0100, -3.2184, -7.3570, -7.1018, -4.4725, -1.4002, -1.2090, -4.6386,\n",
      "         -2.1250, -1.9737]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.1249561309814453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1715, -3.1010, -8.0662, -7.2705, -4.8913, -1.9764, -1.1910, -5.0466,\n",
      "         -0.9258, -2.8233]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.100973129272461\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5503, -2.5803, -9.0068, -7.7245, -5.5756, -2.8977, -1.6976, -5.7206,\n",
      "         -0.4335, -3.9361]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.43346282839775085\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.2402,  -2.6089, -10.2942,  -8.5741,  -6.6350,  -4.2078,  -2.7274,\n",
      "          -6.7704,  -0.1780,  -5.3939]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.63500452041626\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.3722,  -2.2988, -11.0624,  -8.9481,  -6.4657,  -5.0072,  -3.3111,\n",
      "          -7.3255,  -0.1606,  -6.3188]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.1605626493692398\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4990,  -2.2022, -11.8611,  -9.3919,  -6.4213,  -5.8389,  -3.9702,\n",
      "          -7.9329,  -0.1454,  -7.2602]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.260190963745117\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.9971,  -1.6819, -12.0637,  -9.2750,  -5.8659,  -6.0733,  -4.0609,\n",
      "          -7.9635,  -0.2358,  -6.8139]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  12.063655853271484\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.0847,  -0.9925, -11.1271,  -8.8086,  -5.0067,  -5.9249,  -3.7940,\n",
      "          -7.6301,  -0.5202,  -6.0518]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.630130767822266\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.0298,  -0.5174, -10.1499,  -8.2549,  -4.1041,  -5.6594,  -3.4362,\n",
      "          -6.4193,  -1.0660,  -5.2335]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.1041107177734375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.8631, -0.4209, -9.1526, -7.6392, -2.4561, -5.3056, -3.0202, -5.2129,\n",
      "         -1.6856, -4.3835]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.456103801727295\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.0380, -1.1515, -8.5796, -7.4100, -0.6339, -5.3155, -3.0061, -4.4557,\n",
      "         -2.7006, -3.9527]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.579630851745605\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.9454, -2.7965, -8.0603, -7.9539, -0.1312, -6.0777, -3.7794, -4.5326,\n",
      "         -4.4124, -4.3295]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.060271263122559\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.5083,  -4.0694,  -6.5913,  -8.1896,  -0.0649,  -6.5116,  -4.2381,\n",
      "          -4.3561,  -5.7083,  -4.4248]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.708282470703125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.4229,  -4.6362,  -4.6772,  -7.8098,  -0.0930,  -6.3111,  -4.0695,\n",
      "          -3.6148,  -5.5690,  -3.9276]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.3110833168029785\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.8823, -4.6902, -2.4970, -7.0044, -0.3115, -4.9390, -3.4665, -2.5046,\n",
      "         -4.9827, -3.0317]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.938968658447266\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.6915, -5.0417, -0.8917, -6.5757, -1.3302, -3.2808, -3.2422, -1.8645,\n",
      "         -4.7554, -2.5583]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.2807915210723877\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.2703,  -6.1137,  -0.5062,  -6.9413,  -3.1884,  -1.8464,  -3.8195,\n",
      "          -2.1597,  -5.3075,  -2.9431]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.113675594329834\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.9705,  -6.5061,  -0.7925,  -7.4501,  -5.0704,  -0.8482,  -4.5344,\n",
      "          -2.6945,  -5.9872,  -3.5097]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.534420967102051\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.6895,  -6.9490,  -1.4793,  -7.9972,  -6.8581,  -0.3486,  -4.5436,\n",
      "          -3.3172,  -6.6895,  -4.1318]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.85813045501709\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.1241,  -7.1357,  -2.0561,  -8.2772,  -7.5319,  -0.1977,  -4.3467,\n",
      "          -3.6935,  -7.1099,  -4.4915]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.277186393737793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.0558,  -6.8448,  -2.2121,  -7.3542,  -7.6793,  -0.1948,  -3.7192,\n",
      "          -3.5921,  -7.0294,  -4.3646]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.212103843688965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.6826,  -6.2719,  -1.3719,  -6.2120,  -7.5008,  -0.4720,  -2.8603,\n",
      "          -3.2107,  -6.6459,  -3.9486]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  11.682602882385254\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.5654,  -5.7277,  -0.7758,  -5.1549,  -7.3105,  -1.1386,  -2.0989,\n",
      "          -2.8689,  -6.2717,  -3.5593]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.271675109863281\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.6171, -5.2977, -0.6421, -4.2650, -7.1974, -2.0263, -1.5608, -2.6633,\n",
      "         -5.2800, -3.2887]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  9.61709213256836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.9384, -4.8354, -0.8366, -3.3946, -7.0171, -2.8413, -1.1510, -2.4538,\n",
      "         -4.3117, -2.9952]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.311695098876953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3897, -4.3877, -1.2985, -2.5977, -6.8180, -3.5798, -0.9763, -2.2952,\n",
      "         -2.7027, -2.7328]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.295201301574707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2209, -4.2185, -2.1432, -2.1581, -6.8642, -4.4894, -1.3193, -1.6737,\n",
      "         -1.5261, -2.7722]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.6737146377563477\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6547, -4.5594, -3.4738, -2.3274, -7.3887, -5.7988, -2.3061, -0.9648,\n",
      "         -1.1037, -3.3388]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.4738359451293945\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2471, -4.9694, -4.0398, -2.6450, -7.9565, -7.0752, -3.3627, -0.7190,\n",
      "         -1.0549, -3.9720]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.247087001800537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9638, -5.1607, -4.3795, -2.7990, -8.2848, -8.0419, -4.1564, -0.6944,\n",
      "         -1.0759, -4.3738]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.160664081573486\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6879, -4.4257, -4.5357, -2.8224, -8.4217, -8.7537, -4.7236, -0.9019,\n",
      "         -1.1787, -4.5865]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.1786525249481201\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9508, -4.0463, -4.9578, -3.1597, -8.8185, -9.6682, -5.5143, -1.6775,\n",
      "         -1.0522, -5.0595]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.6774578094482422\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6787,  -3.8200,  -5.4453,  -3.5961,  -9.2782, -10.5939,  -6.3314,\n",
      "          -1.8461,  -1.2890,  -5.5925]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.2889697551727295\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7994,  -3.6189,  -5.8737,  -3.9950,  -9.6783, -11.4136,  -7.0547,\n",
      "          -2.1066,  -0.9743,  -6.0616]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.061635971069336\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0319,  -3.2460,  -6.0494,  -4.1554,  -9.8265, -11.9397,  -7.4945,\n",
      "          -2.2234,  -0.7471,  -5.4894]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.4893951416015625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2966,  -2.7289,  -5.9988,  -4.1005,  -9.7493, -12.2027,  -7.6803,\n",
      "          -2.2021,  -0.6683,  -3.9893]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  12.202703475952148\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5783,  -2.1517,  -5.7943,  -3.9022,  -9.5191, -11.5569,  -7.6872,\n",
      "          -2.1079,  -0.7999,  -2.4920]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.794296741485596\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0421,  -1.7759,  -4.9212,  -3.7944,  -9.3680, -11.0314,  -7.7498,\n",
      "          -2.1737,  -1.2928,  -1.2646]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.1736533641815186\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8710,  -1.8798,  -4.4547,  -4.0278,  -9.5462, -10.8726,  -8.1208,\n",
      "          -1.8596,  -2.2455,  -0.6945]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.8709826469421387\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9118,  -2.0883,  -4.0429,  -4.2504,  -9.7064, -10.7292,  -8.4547,\n",
      "          -1.6972,  -3.1780,  -0.5714]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.0428900718688965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7855,  -2.1663,  -2.7388,  -4.2578,  -9.6472, -10.3966,  -8.5521,\n",
      "          -1.4896,  -3.8438,  -0.6977]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.785529613494873\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9665,  -2.3147,  -1.6042,  -4.2661,  -9.5854, -10.0886,  -8.6314,\n",
      "          -1.4690,  -4.4500,  -1.1906]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.45004940032959\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5174, -2.7074, -0.9169, -4.4681, -9.7141, -9.9956, -8.8872, -1.8132,\n",
      "         -4.4782, -2.0554]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.468112468719482\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3378, -3.1733, -0.6583, -3.9983, -9.8919, -9.9736, -9.1795, -2.3116,\n",
      "         -4.5734, -2.9957]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.995725631713867\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2268, -3.4801, -0.6669, -3.4439, -9.9074, -9.8094, -9.2982, -2.6927,\n",
      "         -4.5219, -2.9569]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  9.298213958740234\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1107, -3.5455, -0.8227, -2.7335, -9.6873, -9.4273, -8.4342, -2.8543,\n",
      "         -4.2490, -2.7282]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.434202194213867\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0872, -3.4625, -1.1258, -1.9771, -9.3253, -8.9196, -6.7615, -2.8808,\n",
      "         -3.8497, -2.4094]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.9771183729171753\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5017, -3.5967, -1.8249, -0.8612, -9.1846, -8.6476, -5.4413, -3.1334,\n",
      "         -3.6903, -2.3772]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.824873685836792\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3260, -4.0238, -2.1148, -0.4470, -9.3433, -8.6883, -4.5410, -3.6802,\n",
      "         -3.8499, -2.7059]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.8499298095703125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9773, -4.2582, -2.3018, -0.3714, -9.3227, -8.5613, -3.5745, -4.0285,\n",
      "         -3.1373, -2.8902]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.3018150329589844\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4471, -4.3256, -1.6487, -0.6446, -9.1496, -8.2926, -2.5703, -4.2016,\n",
      "         -2.3718, -2.9450]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.201555252075195\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9363, -4.4388, -1.2455, -1.3095, -9.0363, -8.0932, -1.7647, -3.6343,\n",
      "         -1.7911, -3.0777]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.093218803405762\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5089, -4.6672, -1.2132, -2.2194, -9.0519, -7.3083, -1.2829, -3.2615,\n",
      "         -1.5039, -3.3507]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.308268070220947\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0129, -4.8601, -1.3845, -3.0969, -9.0461, -5.8642, -1.0333, -2.9356,\n",
      "         -1.3830, -3.6039]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.046080589294434\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3505, -4.9187, -1.6032, -3.7986, -8.1901, -4.4448, -0.9494, -2.5623,\n",
      "         -1.3310, -3.7321]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.6031882762908936\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6869, -5.0058, -1.2374, -4.4753, -7.4483, -3.2040, -1.1873, -2.3150,\n",
      "         -1.5003, -3.8951]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.68693733215332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2024, -5.0448, -1.0782, -5.0483, -6.7362, -2.0713, -1.5813, -2.1245,\n",
      "         -1.7664, -4.0132]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.044760227203369\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8100, -4.3643, -1.2261, -5.6086, -6.1356, -1.1823, -2.1273, -2.0856,\n",
      "         -2.1672, -4.1734]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.608635425567627\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5275, -3.8261, -1.6411, -5.4607, -5.6611, -0.6683, -2.7714, -2.2122,\n",
      "         -2.6742, -4.3945]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.6411468982696533\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3181, -3.3950, -1.4558, -5.3675, -5.2734, -0.6130, -3.4345, -2.4484,\n",
      "         -3.2166, -4.6403]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.318118095397949\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2064, -2.8402, -1.2691, -5.0950, -4.7361, -0.7621, -3.8634, -2.5363,\n",
      "         -3.5416, -4.6772]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.5363457202911377\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2115, -2.3614, -1.2847, -4.8301, -4.2348, -1.2089, -4.2412, -1.8760,\n",
      "         -3.8310, -4.6938]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.830082893371582\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4842, -2.0891, -1.5901, -3.9686, -3.8811, -1.9134, -4.6792, -1.4875,\n",
      "         -4.1942, -4.8031]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.9685590267181396\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1111, -2.0515, -2.1289, -2.6086, -3.6910, -2.7675, -5.1937, -1.4265,\n",
      "         -4.6452, -5.0213]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.1110963821411133\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6601, -2.4975, -3.0840, -1.8186, -3.9201, -3.9639, -6.0431, -1.9402,\n",
      "         -5.4402, -5.6048]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.9200587272644043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6567, -2.9805, -3.9963, -1.2417, -3.4291, -5.0735, -6.8282, -2.5329,\n",
      "         -6.1776, -6.1516]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.151638507843018\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9199, -3.3358, -4.7132, -0.8107, -2.8924, -5.9588, -7.4176, -3.0100,\n",
      "         -6.7248, -5.7450]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.713151454925537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3128, -3.5434, -4.4870, -0.6012, -2.3103, -6.6185, -7.8094, -3.3387,\n",
      "         -7.0789, -5.2419]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.487048149108887\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6982, -3.5849, -3.3910, -0.6365, -1.6911, -7.0458, -7.9948, -3.4945,\n",
      "         -7.2308, -4.6253]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.045799255371094\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0807, -3.5433, -2.3287, -0.9456, -1.1686, -6.6083, -8.0620, -3.5585,\n",
      "         -7.2680, -3.9777]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.268031597137451\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5456, -3.5559, -1.4716, -1.5286, -0.9537, -6.2432, -8.1506, -3.6661,\n",
      "         -6.6173, -3.4371]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.4716352224349976\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4215, -3.9881, -0.5355, -2.6073, -1.4415, -6.3149, -8.6297, -4.1821,\n",
      "         -6.4313, -3.3746]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.4215052127838135\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6152, -4.5138, -0.2454, -3.7535, -2.1763, -6.5031, -9.1835, -4.7809,\n",
      "         -6.3873, -3.4674]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.753547430038452\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4640, -4.6502, -0.2125, -3.7427, -2.5758, -6.3283, -9.3369, -4.9813,\n",
      "         -6.0034, -3.2301]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.21246162056922913\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4770, -4.9062, -0.1686, -3.8758, -3.1171, -6.2980, -9.6010, -5.2929,\n",
      "         -5.7854, -3.1734]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.297961235046387\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0147, -4.6455, -0.2492, -3.5135, -3.1403, -5.0556, -9.3420, -5.0807,\n",
      "         -5.0945, -2.6584]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.5134994983673096\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3634, -4.1468, -0.6167, -2.2270, -2.9215, -3.6700, -8.8374, -4.6230,\n",
      "         -4.2053, -1.9782]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.146805763244629\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0434, -3.1421, -1.5360, -1.3419, -2.9608, -2.6374, -8.5799, -4.4153,\n",
      "         -3.6120, -1.6713]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.9607644081115723\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1649, -2.5840, -2.8338, -1.0443, -2.6142, -2.0729, -8.6618, -4.5514,\n",
      "         -3.4107, -1.8564]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.0442739725112915\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7024, -2.4820, -4.3882, -0.6598, -2.6987, -1.9982, -9.0786, -5.0251,\n",
      "         -3.5959, -2.4889]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.702408790588379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4334, -2.3918, -5.7345, -0.6185, -2.7617, -1.9665, -9.3916, -5.3944,\n",
      "         -3.7199, -3.0614]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.6184895038604736\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4486, -2.5731, -7.1417, -0.4470, -3.0572, -2.2315, -9.8659, -5.9229,\n",
      "         -4.0414, -3.8063]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.057194709777832\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2928,  -2.5613,  -8.1760,  -0.5129,  -2.3939,  -2.3143, -10.0597,\n",
      "          -6.1676,  -4.1101,  -4.2611]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.292752742767334\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4229,  -2.5428,  -9.0405,  -0.9289,  -1.7964,  -2.3933, -10.1672,\n",
      "          -6.3225,  -4.1166,  -4.6148]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  10.167180061340332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8931, -2.6618, -9.8944, -1.6581, -1.4551, -2.6058, -9.5957, -6.5387,\n",
      "         -4.2095, -5.0164]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.538663864135742\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6978,  -2.8017, -10.6426,  -2.4288,  -1.2977,  -2.8299,  -9.0603,\n",
      "          -5.9316,  -4.2831,  -5.3625]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.36246395111084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7058,  -2.7909, -11.1329,  -3.0016,  -1.1726,  -2.8909,  -8.3949,\n",
      "          -5.2035,  -4.1758,  -4.7073]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.8909013271331787\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9174,  -2.6686, -11.4148,  -3.3931,  -1.1268,  -2.1040,  -7.6363,\n",
      "          -4.3927,  -3.9306,  -3.9649]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.9648728370666504\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3674,  -2.5772, -11.6340,  -3.7348,  -1.2881,  -1.4489,  -6.9189,\n",
      "          -3.6375,  -3.6893,  -2.4956]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.2880589962005615\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2766,  -2.8696, -12.1478,  -4.3758,  -1.2196,  -1.3450,  -6.5900,\n",
      "          -3.2945,  -3.8063,  -1.5536]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.5535582304000854\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6180,  -3.6234, -13.0574,  -5.4088,  -1.8208,  -1.8867,  -6.7418,\n",
      "          -3.4616,  -4.3746,  -0.5389]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.8867322206497192\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0555,  -4.5326, -14.0863,  -6.5521,  -2.6903,  -1.9728,  -7.0892,\n",
      "          -3.8465,  -5.1053,  -0.2927]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.055521488189697\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.2499,  -4.9931, -14.6462,  -7.2160,  -3.1564,  -1.7840,  -7.0360,\n",
      "          -3.8433,  -5.4010,  -0.2878]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  14.646188735961914\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0110,  -4.9951, -14.0009,  -7.3966,  -3.1894,  -1.3175,  -6.5711,\n",
      "          -3.4395,  -5.2528,  -0.4490]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  14.000883102416992\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5523,  -4.7537, -12.4452,  -7.3111,  -3.0008,  -0.8422,  -5.9049,\n",
      "          -2.8526,  -4.8746,  -0.8403]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  12.445230484008789\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0360,  -4.4318, -10.2125,  -7.1236,  -2.7563,  -0.6138,  -5.1960,\n",
      "          -2.2583,  -4.4284,  -1.4155]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  10.212540626525879\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4597, -4.0269, -7.3621, -6.8310, -2.4585, -0.6738, -4.4376, -1.6811,\n",
      "         -3.9111, -1.9974]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.459740161895752\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2093, -3.6556, -4.7752, -6.5478, -2.2326, -1.0740, -3.7429, -1.2873,\n",
      "         -3.4391, -2.6062]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.2325663566589355\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4440, -3.6212, -2.7320, -6.5739, -1.6554, -1.9601, -3.4152, -1.4298,\n",
      "         -3.3174, -3.4916]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.9600523710250854\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3218, -4.0043, -1.3326, -6.9918, -1.6690, -2.5310, -3.5382, -2.1398,\n",
      "         -3.6274, -4.7060]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.538175106048584\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7200, -4.6756, -0.5759, -7.6809, -2.1311, -3.4144, -3.2365, -3.1839,\n",
      "         -4.2379, -6.1187]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.23789119720459\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2333, -5.3104, -0.3258, -8.3249, -2.6574, -4.2567, -3.0173, -4.1798,\n",
      "         -4.1001, -7.4157]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.179834365844727\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4724, -5.5838, -0.3211, -8.6029, -2.8806, -4.7234, -2.5545, -4.0001,\n",
      "         -3.6860, -8.2821]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.4723517894744873\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7753, -5.5923, -0.5994, -8.6128, -2.8822, -4.9095, -1.9554, -3.6121,\n",
      "         -3.0905, -8.8219]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.592340469360352\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2388, -4.7981, -1.2118, -8.5888, -2.8915, -5.0492, -1.4886, -3.2507,\n",
      "         -2.5541, -9.2749]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.2118451595306396\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1517, -4.2725, -1.4401, -8.7505, -3.1238, -5.3628, -1.4204, -3.1390,\n",
      "         -2.3104, -9.8661]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.1389989852905273\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2270,  -3.7319,  -1.7378,  -8.8180,  -3.2871,  -5.5705,  -1.4618,\n",
      "          -2.2124,  -2.0845, -10.3204]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.737838864326477\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6012,  -3.3547,  -1.5050,  -8.9702,  -3.5529,  -5.8515,  -1.7638,\n",
      "          -1.5550,  -2.0623, -10.8207]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.0622739791870117\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1919,  -3.1479,  -1.5604,  -9.2131,  -3.9189,  -6.2123,  -2.2699,\n",
      "          -1.2343,  -1.5189, -11.3770]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.1478633880615234\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8360,  -2.2566,  -1.7914,  -9.4620,  -4.2934,  -6.5689,  -2.8331,\n",
      "          -1.2037,  -1.2179, -11.9082]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.833146095275879\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4658,  -1.5413,  -2.1259,  -9.6929,  -4.6473,  -6.8977,  -2.6428,\n",
      "          -1.4180,  -1.1670, -12.3931]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.647256851196289\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0201,  -1.0265,  -2.4770,  -9.8651,  -4.2037,  -7.1586,  -2.4888,\n",
      "          -1.7648,  -1.3101, -12.7940]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.158648490905762\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4470,  -0.7539,  -2.7682,  -9.9348,  -3.7298,  -6.5877,  -2.3268,\n",
      "          -2.1259,  -1.5482, -13.0696]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  13.069598197937012\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6678,  -0.6987,  -2.9033,  -9.8253,  -3.1485,  -5.9024,  -2.0816,\n",
      "          -2.3723,  -1.7439, -12.3654]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.6987079381942749\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0883,  -0.4767,  -3.2792,  -9.9415,  -2.8711,  -5.5018,  -2.1689,\n",
      "          -2.8820,  -2.2609, -11.9460]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.279160261154175\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.2424,  -0.5253,  -2.6971,  -9.8171,  -2.4340,  -4.9151,  -2.1041,\n",
      "          -3.1560,  -2.5728, -11.3394]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.242425441741943\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4474,  -0.8202,  -2.0189,  -9.5027,  -1.9024,  -4.1897,  -1.9346,\n",
      "          -3.2337,  -2.7064, -10.5906]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.233691453933716\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7573, -1.4402, -1.5207, -9.2368, -1.5505, -3.5645, -1.9074, -2.5679,\n",
      "         -2.8921, -9.9336]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.5678672790527344\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3469, -2.3739, -1.4231, -9.1914, -1.5836, -3.2160, -2.1880, -1.4442,\n",
      "         -3.2934, -9.5359]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.2159857749938965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2139, -3.4968, -1.7190, -9.3612, -1.9749, -2.4221, -2.7355, -0.8271,\n",
      "         -3.8923, -9.3885]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.8270801305770874\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6325,  -5.0401,  -2.6232, -10.0230,  -2.9382,  -2.2802,  -3.7860,\n",
      "          -0.3433,  -4.9552,  -9.7647]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.34326454997062683\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4771,  -6.8829,  -3.9377, -11.0671,  -4.2928,  -2.6743,  -5.1971,\n",
      "          -0.1299,  -6.3656, -10.5516]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  10.55164623260498\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7343,  -8.0314,  -4.6237, -11.4956,  -5.0109,  -2.5671,  -5.9602,\n",
      "          -0.1118,  -7.1251,  -9.9707]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  9.970714569091797\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3782,  -8.4716,  -4.6543, -11.2873,  -5.0683,  -1.9319,  -6.0552,\n",
      "          -0.1946,  -7.2154,  -8.0823]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.082287788391113\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6741,  -8.4756,  -4.2962, -10.7071,  -4.7320,  -1.0720,  -5.7498,\n",
      "          -0.5107,  -6.9047,  -5.2245]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.224460601806641\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1523,  -8.5728,  -4.0768, -10.2781,  -4.5290,  -0.6384,  -5.5706,\n",
      "          -1.3497,  -6.7190,  -1.9893]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.989258050918579\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4327, -10.3793,  -5.6104, -11.6106,  -6.0731,  -2.3480,  -7.1310,\n",
      "          -4.0236,  -8.2716,  -0.1420]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  11.610623359680176\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4539e+00, -1.2865e+01, -7.8533e+00, -1.2949e+01, -8.3245e+00,\n",
      "         -4.8158e+00, -9.3960e+00, -7.3044e+00, -1.0529e+01, -1.1156e-02]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.529085159301758\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.6224e+00, -1.4451e+01, -9.2207e+00, -1.3502e+01, -9.6994e+00,\n",
      "         -6.3911e+00, -1.0783e+01, -9.6066e+00, -1.1184e+01, -2.4328e-03]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  9.220669746398926\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.9205e+00, -1.5125e+01, -8.9776e+00, -1.3245e+01, -1.0183e+01,\n",
      "         -7.0565e+00, -1.1278e+01, -1.0925e+01, -1.1020e+01, -1.4390e-03]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.920511722564697\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7000e+00, -1.4979e+01, -8.0056e+00, -1.2261e+01, -9.8656e+00,\n",
      "         -6.9032e+00, -1.0970e+01, -1.1360e+01, -1.0118e+01, -2.6991e-03]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.865594863891602\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8624e+00, -1.4107e+01, -6.3913e+00, -1.0635e+01, -8.1028e+00,\n",
      "         -6.0265e+00, -9.9532e+00, -1.1012e+01, -8.5673e+00, -1.2482e-02]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  14.10723876953125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5681, -11.9068,  -4.2935,  -8.5256,  -5.8704,  -4.5934,  -8.3926,\n",
      "         -10.0527,  -6.5256,  -0.1112]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.870419979095459\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7202, -10.0868,  -2.5759,  -6.7880,  -3.2915,  -3.4719,  -7.1491,\n",
      "          -9.3508,  -4.8497,  -1.0240]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  10.08683967590332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4268, -8.6949, -2.0955, -6.2355, -2.0079, -3.4959, -7.0412, -9.7303,\n",
      "         -4.3576, -3.1244]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.0079195499420166\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0885,  -7.8869,  -2.1971,  -6.1848,  -0.6661,  -3.9849,  -7.3902,\n",
      "         -10.5174,  -4.3692,  -5.4940]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.886930465698242\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3007,  -6.7692,  -2.7375,  -6.5094,  -0.2045,  -4.8075,  -8.0736,\n",
      "         -11.5950,  -4.7576,  -7.9995]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.757638931274414\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2033,  -5.5008,  -3.0082,  -6.5400,  -0.1244,  -5.2914,  -8.4266,\n",
      "         -12.3026,  -4.1268,  -9.9933]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.203308343887329\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8281,  -3.8802,  -2.8060,  -6.0870,  -0.2151,  -5.2491,  -8.2629,\n",
      "         -12.4582,  -3.0889, -11.3070]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.262916564941406\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2746,  -2.1775,  -2.4086,  -5.4217,  -0.6232,  -4.9558,  -7.1019,\n",
      "         -12.3392,  -1.9283, -12.2309]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.421658992767334\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1958,  -1.0752,  -2.4598,  -4.4478,  -1.7234,  -5.0409,  -6.4011,\n",
      "         -12.5761,  -1.3328, -13.4069]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.0751850605010986\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9835,  -0.3579,  -3.3447,  -4.3563,  -3.6205,  -5.8991,  -6.5481,\n",
      "         -13.5662,  -1.7650, -15.2428]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.9834723472595215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9656,  -0.2169,  -4.1356,  -4.2517,  -5.3168,  -6.6425,  -6.6502,\n",
      "         -14.4265,  -2.2473, -16.8645]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.316823959350586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5340,  -0.2511,  -4.4060,  -3.7144,  -5.6659,  -6.8594,  -6.2898,\n",
      "         -14.7478,  -2.3049, -17.8715]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.533958911895752\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2375,  -0.6359,  -4.4215,  -3.0115,  -5.7458,  -6.8187,  -5.7297,\n",
      "         -14.8002,  -2.1926, -18.5414]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  18.541406631469727\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4888,  -1.5898,  -4.6506,  -2.6205,  -6.0266,  -6.9893,  -5.4343,\n",
      "         -15.0538,  -2.3790, -18.6000]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.65060567855835\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3008,  -2.6407,  -4.1778,  -2.3585,  -6.3184,  -7.1808,  -5.2089,\n",
      "         -15.3195,  -2.6515, -18.6900]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  18.68996238708496\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3613,  -3.3309,  -3.4529,  -1.8810,  -6.2723,  -7.0436,  -4.6998,\n",
      "         -15.2485,  -2.6381, -17.7156]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.8810049295425415\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9162,  -3.9737,  -2.8171,  -0.8326,  -6.2262,  -6.9148,  -4.2424,\n",
      "         -15.1787,  -2.6722, -16.8324]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.8325671553611755\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4301,  -5.2905,  -3.0116,  -0.2047,  -6.9099,  -7.5232,  -4.5651,\n",
      "         -15.8395,  -3.4770, -16.7607]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.56511116027832\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7397,  -6.3624,  -3.1047,  -0.1123,  -7.4086,  -7.9538,  -3.9912,\n",
      "         -16.3169,  -4.1065, -16.5785]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.408560276031494\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4230,  -6.8157,  -2.7078,  -0.1601,  -6.6198,  -7.8285,  -2.9752,\n",
      "         -16.2335,  -4.1722, -15.9012]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.16012893617153168\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1833,  -7.3610,  -2.5349,  -0.2329,  -6.0467,  -7.8523,  -2.2352,\n",
      "         -16.2947,  -4.3788, -15.4275]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.378765106201172\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5554,  -7.5358,  -2.1202,  -0.5505,  -5.2157,  -7.5574,  -1.3331,\n",
      "         -16.0331,  -3.5290, -14.6844]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  14.684388160705566\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.9033,  -7.7036,  -1.8438,  -1.2594,  -4.4813,  -7.3021,  -0.7305,\n",
      "         -15.8076,  -2.7952, -13.2821]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.481313705444336\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.2576,  -7.8942,  -1.7489,  -2.1402,  -3.1459,  -7.1119,  -0.5916,\n",
      "         -15.6436,  -2.2180, -12.0586]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.2179741859436035\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6910,  -8.1790,  -1.9026,  -3.1306,  -2.0873,  -7.0540,  -0.9975,\n",
      "         -15.6088,  -1.1650, -11.0697]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.90255868434906\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.4110,  -8.7646,  -1.7529,  -4.3828,  -1.5529,  -7.3315,  -1.9704,\n",
      "         -15.9064,  -0.7727, -10.5081]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.5528770685195923\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.3270,  -9.5591,  -2.0108,  -5.7864,  -0.7711,  -7.8490,  -3.2188,\n",
      "         -16.4415,  -1.0222, -10.2695]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.022214651107788\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.3639, -10.4866,  -2.5521,  -7.2645,  -0.6141,  -8.5272,  -4.5853,\n",
      "         -17.1353,  -0.9951, -10.2667]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.585291862487793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.0272, -11.0513,  -2.8256,  -8.3255,  -0.5936,  -8.8676,  -4.7967,\n",
      "         -17.4896,  -0.9686,  -9.9938]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  17.48955535888672\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.3021, -11.2373,  -2.7924,  -8.9586,  -0.6512,  -8.8517,  -4.6707,\n",
      "         -16.7046,  -0.8976,  -9.4255]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  11.237312316894531\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.2411, -10.3336,  -2.4985,  -9.2203,  -0.7703,  -8.5290,  -4.2559,\n",
      "         -15.6892,  -0.8206,  -8.6053]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.5289888381958\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.9163,  -9.2500,  -2.0237,  -9.1862,  -0.9406,  -7.2357,  -3.6231,\n",
      "         -14.5050,  -0.8001,  -7.5970]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.9406132698059082\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.7052,  -8.3557,  -1.7736,  -9.2369,  -0.7357,  -6.1530,  -3.1549,\n",
      "         -13.5200,  -1.1881,  -6.7709]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  9.70524787902832\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.6101,  -7.3767,  -1.4979,  -9.1087,  -0.7218,  -5.0058,  -2.5916,\n",
      "         -12.4592,  -1.5842,  -5.8539]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.721763551235199\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.8268,  -6.6984,  -1.6150,  -9.1961,  -0.5418,  -4.1803,  -2.3437,\n",
      "         -11.7067,  -2.2920,  -5.2331]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.196134567260742\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.9122,  -5.8790,  -1.6556,  -8.3448,  -0.5879,  -3.2388,  -1.9836,\n",
      "         -10.8196,  -2.7932,  -4.4685]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.5879132747650146\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.2906,  -5.3444,  -2.0322,  -7.7795,  -0.5110,  -2.6209,  -1.9645,\n",
      "         -10.2220,  -3.4900,  -3.9898]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.0321998596191406\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6248, -4.7594, -1.6314, -7.1634, -0.7645, -2.0107, -1.9460, -9.5765,\n",
      "         -4.0323, -3.4653]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.4653046131134033\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0139, -4.2251, -1.3986, -6.5952, -1.3122, -1.5457, -2.0236, -8.9813,\n",
      "         -4.5195, -2.2554]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.519489765167236\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5807, -3.8672, -1.4803, -6.1965, -2.1102, -1.3959, -2.3055, -8.5575,\n",
      "         -4.3515, -1.3563]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.4803160429000854\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4380, -3.8009, -1.2333, -6.0789, -3.1557, -1.6831, -2.8748, -8.4159,\n",
      "         -4.4495, -0.9796]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.8748443126678467\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2699, -3.7099, -1.1738, -5.9263, -4.0793, -2.0302, -2.6248, -8.2402,\n",
      "         -4.4978, -0.8732]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  4.26987886428833\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2369, -3.4851, -1.1829, -5.6291, -4.7615, -2.2777, -2.2928, -7.9205,\n",
      "         -4.3877, -0.9283]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.4850640296936035\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2567, -2.4640, -1.3345, -5.2853, -5.3032, -2.4974, -1.9914, -7.5542,\n",
      "         -4.2189, -1.1946]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.2567408084869385\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9994, -1.8852, -1.9375, -5.2550, -6.0702, -3.0315, -2.0988, -7.5003,\n",
      "         -4.3531, -1.9364]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.8851983547210693\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6369, -1.2205, -3.0857, -5.7322, -7.2632, -4.0488, -2.7890, -7.9530,\n",
      "         -4.9840, -3.2129]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.732242584228516\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6988, -0.8492, -4.1547, -5.4462, -8.3398, -4.9795, -3.4589, -8.3627,\n",
      "         -5.5589, -4.3943]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.55891227722168\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8924, -0.6167, -4.9042, -4.9671, -9.0849, -5.5981, -3.8614, -8.5072,\n",
      "         -5.1310, -5.2429]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.904191017150879\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0675, -0.5212, -4.5610, -4.2432, -9.4583, -5.8603, -3.9422, -8.3400,\n",
      "         -4.4524, -5.7133]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.713346481323242\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1585, -0.5696, -3.9426, -3.2847, -9.4776, -5.7815, -3.7126, -7.8725,\n",
      "         -3.5328, -5.0737]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.9425830841064453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3038, -0.8774, -2.5138, -2.2836, -9.3300, -5.5478, -3.3595, -7.2869,\n",
      "         -2.5609, -4.3374]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.286924839019775\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8057, -1.6432, -1.4592, -1.6293, -9.3708, -5.5138, -3.2413, -6.1475,\n",
      "         -1.9152, -3.8577]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.9152164459228516\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8242, -2.9263, -1.1244, -1.6286, -9.8543, -5.9329, -3.6114, -5.5698,\n",
      "         -1.1648, -3.8882]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.611448287963867\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8924,  -4.2303,  -1.1657,  -1.8777, -10.3976,  -6.4202,  -3.3159,\n",
      "          -5.1606,  -0.8230,  -4.0390]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.1656931638717651\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.9826,  -5.5289,  -0.8201,  -2.3259, -11.0002,  -6.9735,  -3.1905,\n",
      "          -4.9099,  -0.9466,  -4.3012]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.528931140899658\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.7835,  -5.7545,  -0.6414,  -2.6145, -11.3571,  -7.2868,  -2.9231,\n",
      "          -4.5043,  -1.1530,  -4.3619]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.286782264709473\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.2635,  -5.7165,  -0.6167,  -2.6839, -11.4350,  -6.5864,  -2.4795,\n",
      "          -3.9043,  -1.3235,  -4.1825]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.182456016540527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4979,  -5.4856,  -0.7840,  -2.5966, -11.3060,  -5.7575,  -1.9445,\n",
      "          -3.1807,  -1.4705,  -3.0869]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.75753116607666\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6621,  -5.2328,  -1.2150,  -2.5240, -11.1418,  -4.2312,  -1.5231,\n",
      "          -2.5139,  -1.7210,  -2.0865]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.0864787101745605\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.1666,  -5.3650,  -2.1723,  -2.8725, -11.3497,  -3.2232,  -1.6649,\n",
      "          -2.3332,  -2.4318,  -0.8912]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.8911765813827515\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4720,  -6.3381,  -3.9669,  -4.0778, -12.3876,  -3.1955,  -2.7868,\n",
      "          -3.0978,  -3.9860,  -0.2283]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.0977542400360107\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.5670,  -7.1350,  -5.5159,  -5.0948, -13.2414,  -3.1200,  -3.7630,\n",
      "          -2.9545,  -5.3183,  -0.1455]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.7629899978637695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.0721,  -7.3723,  -6.4325,  -5.5341, -13.5292,  -2.6037,  -3.4214,\n",
      "          -2.3856,  -6.0406,  -0.2323]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.6036810874938965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.3426,  -7.4021,  -7.0749,  -5.7482, -13.6042,  -1.2757,  -2.9542,\n",
      "          -1.7615,  -6.5084,  -0.7120]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.5084075927734375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.8628,  -7.7060,  -7.9305,  -6.2199, -13.9482,  -0.5622,  -2.8495,\n",
      "          -1.6116,  -6.4827,  -1.7822]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.930477142333984\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.3589,  -8.0076,  -8.0073,  -6.6737, -14.2857,  -0.3676,  -2.8268,\n",
      "          -1.6617,  -6.4884,  -2.8978]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.6617084741592407\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.7210,  -8.1948,  -7.9920,  -6.9987, -14.5049,  -0.6168,  -2.7666,\n",
      "          -0.9858,  -6.4099,  -3.8584]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.998705863952637\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.9162,  -8.2328,  -7.8476,  -6.4355, -14.5714,  -1.1059,  -2.6292,\n",
      "          -0.5401,  -6.2096,  -4.6081]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.232772827148438\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.8763,  -7.2923,  -7.5022,  -5.7139, -14.4157,  -1.5732,  -2.3445,\n",
      "          -0.3814,  -5.8149,  -5.0749]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.814936637878418\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.5049,  -6.1105,  -6.8560,  -4.7310, -13.9399,  -1.8105,  -1.8254,\n",
      "          -0.4381,  -4.4052,  -5.1644]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.8253756761550903\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.2199,  -5.0974,  -6.3245,  -3.9018, -13.5610,  -2.1936,  -0.7725,\n",
      "          -1.0427,  -3.1942,  -5.2987]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.194178581237793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.2819,  -4.5085,  -6.1657,  -3.4884, -13.5384,  -2.9391,  -0.4929,\n",
      "          -2.1810,  -1.7348,  -5.7420]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.488379716873169\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.5599,  -4.2086,  -6.2463,  -2.6377, -13.7402,  -3.8714,  -0.9254,\n",
      "          -3.5166,  -0.7700,  -6.3656]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.516578435897827\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.9804,  -4.1201,  -6.4906,  -2.0936, -14.0921,  -4.8964,  -1.7843,\n",
      "          -4.1279,  -0.4055,  -7.0987]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.40547409653663635\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.7373,  -4.4310,  -7.0898,  -2.0713, -14.7871,  -6.2031,  -3.0628,\n",
      "          -5.0691,  -0.2158,  -8.1375]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  12.737272262573242\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.2973,  -4.3332,  -7.2431,  -1.7558, -15.0262,  -6.9944,  -3.8626,\n",
      "          -5.5347,  -0.2391,  -8.6864]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.68644905090332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.4990,  -3.8530,  -6.9797,  -1.1950, -14.8394,  -7.3056,  -4.1966,\n",
      "          -5.5551,  -0.4228,  -8.0379]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  11.499011993408203\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.8268,  -3.2132,  -6.5195,  -0.6860, -14.4475,  -7.3626,  -4.2851,\n",
      "          -5.3527,  -0.8329,  -7.2305]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  14.44753646850586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.1763,  -2.5230,  -5.9614,  -0.4482, -13.2208,  -7.2697,  -4.2305,\n",
      "          -5.0295,  -1.3681,  -6.3592]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.368058443069458\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6298,  -1.9022,  -5.4001,  -0.6356, -12.0556,  -7.1260,  -4.1318,\n",
      "          -4.6830,  -1.2547,  -5.5154]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.131818771362305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0959,  -1.3149,  -4.7559,  -1.0447, -10.8642,  -6.8549,  -3.1562,\n",
      "          -4.2360,  -1.2141,  -4.6163]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.616335868835449\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7358, -1.0078, -4.1985, -1.6838, -9.8080, -6.6283, -2.3265, -3.8615,\n",
      "         -1.4062, -3.0934]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.8614559173583984\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6789, -1.1603, -3.8579, -2.5439, -9.0072, -6.5755, -1.8034, -2.9103,\n",
      "         -1.9045, -1.9059]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.857886791229248\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0458, -1.8050, -3.1114, -3.6435, -8.5545, -6.7972, -1.7253, -2.3646,\n",
      "         -2.7279, -1.2148]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.797225475311279\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7266, -2.6671, -2.6273, -4.8085, -8.3029, -6.4165, -1.9455, -2.1025,\n",
      "         -3.6721, -0.9679]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.6670608520507812\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5693, -2.7314, -2.2430, -5.8628, -8.0758, -6.0741, -2.2513, -1.9613,\n",
      "         -4.5397, -1.0259]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.862811088562012\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4663, -2.7244, -1.8594, -5.9738, -7.7571, -5.6530, -2.4918, -1.8295,\n",
      "         -5.2142, -1.2286]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.859416127204895\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6480, -2.8729, -1.0096, -6.1803, -7.5751, -5.3811, -2.8758, -1.9410,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -5.9302, -1.7321]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.381143569946289\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0111, -3.1076, -0.5661, -6.4256, -7.4695, -4.4645, -3.3221, -2.2116,\n",
      "         -6.6347, -2.3742]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.011054277420044\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6594, -3.3106, -0.5349, -6.6052, -7.3323, -3.6050, -3.7090, -2.4985,\n",
      "         -7.2275, -2.9787]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.6593762636184692\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8105, -3.5806, -0.9889, -6.8273, -7.2687, -2.9105, -4.1353, -2.8806,\n",
      "         -7.8213, -3.6201]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.8805758953094482\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4746, -3.9475, -1.7683, -7.1306, -7.3144, -2.4276, -4.6337, -2.5901,\n",
      "         -8.4588, -4.3200]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.590067148208618\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5912, -4.2560, -2.5566, -7.3676, -7.3194, -2.0211, -5.0534, -1.5751,\n",
      "         -8.9963, -4.9234]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.92340087890625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1070, -4.5511, -3.3289, -7.5880, -7.3309, -1.7592, -5.4426, -0.8288,\n",
      "         -9.4869, -4.7388]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.8288053870201111\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3537,  -5.3658,  -4.5911,  -8.3277,  -7.8826,  -2.1911,  -6.3372,\n",
      "          -0.2614, -10.4696,  -5.1199]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.1910951137542725\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4288,  -5.9862,  -5.6182,  -8.8770,  -8.2628,  -1.8115,  -7.0273,\n",
      "          -0.2332, -11.2376,  -5.3506]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.986169815063477\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0127,  -5.3759,  -6.1377,  -8.9638,  -8.1973,  -1.1818,  -7.2413,\n",
      "          -0.4132, -11.5212,  -5.1538]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  11.521245956420898\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3248,  -4.6029,  -6.3802,  -8.8152,  -7.9117,  -0.6137,  -7.2078,\n",
      "          -0.8585, -10.8313,  -4.7541]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.8585332036018372\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7056,  -4.0047,  -6.6898,  -8.7716,  -7.7449,  -0.5901,  -7.2682,\n",
      "          -0.9046, -10.3002,  -4.4906]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.7448835372924805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7202, -3.1449, -6.6346, -8.3975, -6.5263, -0.6407, -6.9882, -0.9229,\n",
      "         -9.4870, -3.9266]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.9228771924972534\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8379, -2.5017, -6.6839, -8.1588, -5.5282, -1.1702, -6.8349, -0.5730,\n",
      "         -8.8528, -3.5315]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.170214295387268\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9681, -2.0036, -6.7476, -7.9625, -4.6507, -1.1589, -6.7160, -0.7099,\n",
      "         -8.3003, -3.2158]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.1589176654815674\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1807, -1.7483, -6.8960, -7.8762, -3.9578, -0.7369, -6.7001, -1.3008,\n",
      "         -7.8931, -3.0515]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.7368748188018799\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.7419, -2.0173, -7.3960, -8.1644, -3.7136, -0.3418, -7.0523, -2.4076,\n",
      "         -7.8924, -3.3042]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.3042097091674805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0529, -2.1646, -7.6500, -8.2275, -3.3149, -0.3090, -7.1735, -3.2767,\n",
      "         -7.6953, -2.6229]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.052886009216309\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2944, -2.0774, -7.5714, -7.9767, -2.6749, -0.5065, -6.9754, -3.7806,\n",
      "         -7.2104, -1.7554]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.571374893188477\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5375, -2.0173, -6.6987, -7.6736, -2.0718, -1.0445, -6.7202, -4.1744,\n",
      "         -6.6968, -1.0246]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.698694229125977\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9266, -2.1278, -5.2573, -7.4638, -1.6845, -1.8474, -6.5542, -4.6037,\n",
      "         -6.2980, -0.6953]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.127838611602783\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4278, -1.5902, -4.0000, -7.3121, -1.5093, -2.7219, -6.4426, -5.0348,\n",
      "         -5.9770, -0.8047]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.5901916027069092\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2351, -0.7330, -3.1138, -7.4088, -1.7474, -3.7899, -6.5761, -5.6607,\n",
      "         -5.9225, -1.4664]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.576086044311523\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1937, -0.4313, -2.4511, -7.5995, -2.1935, -4.8713, -6.0373, -6.3302,\n",
      "         -5.9787, -2.3360]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.599501609802246\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9989, -0.4670, -1.7291, -6.8550, -2.4900, -5.6631, -5.3664, -6.7469,\n",
      "         -5.8435, -3.0031]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.46696001291275024\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0951, -0.4503, -1.4423, -6.4203, -3.0531, -6.6136, -5.0007, -7.3580,\n",
      "         -5.9588, -3.8754]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.0951085090637207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2500, -0.6862, -1.1216, -5.7965, -3.3615, -7.2369, -4.4431, -7.6752,\n",
      "         -5.8309, -4.4428]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.1215994358062744\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7935, -1.5079, -0.5736, -5.4644, -3.8923, -8.0261, -4.1773, -8.1886,\n",
      "         -5.9453, -5.1897]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.892260789871216\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4863, -2.3976, -0.4696, -5.1503, -3.6291, -8.7188, -3.9315, -8.6329,\n",
      "         -6.0320, -5.8483]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.031985759735107\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1513, -3.0437, -0.6030, -4.6476, -3.1877, -9.1186, -3.5012, -8.8091,\n",
      "         -5.1662, -6.2195]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.0437352657318115\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9227, -2.7433, -0.9583, -4.0432, -2.6618, -9.3200, -2.9780, -8.8091,\n",
      "         -4.2320, -6.3964]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.231975078582764\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9475, -2.4609, -1.4938, -3.4513, -2.1793, -9.4408, -2.4854, -8.7487,\n",
      "         -2.6235, -6.4964]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.44078254699707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3815, -2.3994, -2.2660, -3.0696, -1.9566, -8.9464, -2.2339, -8.8228,\n",
      "         -1.3551, -6.7158]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.3551137447357178\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6401, -3.1225, -3.8264, -3.4961, -2.6253, -9.0802, -2.8383, -9.6457,\n",
      "         -0.3554, -7.6449]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.644899845123291\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9745,  -3.9364,  -5.2986,  -4.0101,  -3.3613,  -9.4515,  -3.5228,\n",
      "         -10.4738,  -0.1348,  -7.8493]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.361349582672119\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7882,  -4.2523,  -6.1314,  -4.0265,  -2.8343,  -9.4697,  -3.6920,\n",
      "         -10.7463,  -0.1357,  -7.5949]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.594933986663818\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0248,  -4.0661,  -6.4572,  -3.5934,  -1.9632,  -8.9107,  -3.4112,\n",
      "         -10.5438,  -0.2594,  -6.1602]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.066145896911621\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0327,  -2.9477,  -6.5508,  -3.0192,  -1.0798,  -8.1896,  -2.9803,\n",
      "         -10.1583,  -0.7123,  -4.6634]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  10.158296585083008\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1841, -2.1196, -6.7755, -2.6774, -0.6741, -7.6798, -2.7707, -9.1765,\n",
      "         -1.6080, -3.4620]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.6080195903778076\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4660, -1.6064, -7.1202, -2.5616, -0.8258, -7.3626, -2.7716, -8.4339,\n",
      "         -1.9849, -2.5448]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.5615925788879395\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.7634, -1.3367, -7.4717, -1.8219, -1.3251, -7.1179, -2.8611, -7.8059,\n",
      "         -2.4624, -1.8175]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.3367372751235962\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3614, -0.8649, -8.1164, -1.6022, -2.2981, -7.2260, -3.3136, -7.5686,\n",
      "         -3.2809, -1.6107]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.8649387359619141\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.3051, -0.4080, -9.1011, -1.9560, -3.6521, -7.7278, -4.1530, -7.7592,\n",
      "         -4.4486, -1.9763]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.652143716812134\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.9537, -0.2981, -9.7863, -2.1767, -3.9520, -7.9783, -4.7194, -7.7295,\n",
      "         -5.3067, -2.2066]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.719362258911133\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.1307, -0.3514, -9.9960, -2.0514, -3.8288, -7.7969, -4.0603, -7.2959,\n",
      "         -5.6757, -2.0882]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.295889377593994\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.9511, -0.5884, -9.8456, -1.6936, -3.3946, -7.2945, -3.1407, -5.7953,\n",
      "         -5.6712, -1.7342]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.140707015991211\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.7908, -1.2189, -9.7114, -1.5077, -3.0296, -6.8439, -1.5837, -4.4477,\n",
      "         -5.6708, -1.5476]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  7.790802001953125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.2434, -2.3404, -9.9230, -1.8352, -3.0687, -6.7713, -0.6712, -3.5756,\n",
      "         -6.0052, -1.8697]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.835167407989502\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.9732,  -3.6447, -10.3357,  -1.7356,  -3.3603,  -6.9288,  -0.4637,\n",
      "          -3.0341,  -6.5302,  -2.4962]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.9731950759887695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.7715,  -4.6104, -10.4788,  -1.5467,  -3.4200,  -6.8430,  -0.5297,\n",
      "          -2.3553,  -6.7756,  -2.8931]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.771499156951904\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7740,  -5.2951, -10.4154,  -1.3404,  -3.3055,  -6.5741,  -0.8460,\n",
      "          -1.6252,  -6.8050,  -3.0993]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.340430498123169\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2679,  -6.1912, -10.6342,  -0.8902,  -3.5053,  -6.6088,  -1.7337,\n",
      "          -1.3963,  -7.1081,  -3.5944]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.594362735748291\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1801,  -7.1924, -11.0238,  -0.9782,  -3.9000,  -6.8337,  -2.8603,\n",
      "          -1.5748,  -7.5743,  -3.5110]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.9781860113143921\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7750,  -8.4440, -11.7243,  -0.9511,  -4.6199,  -7.3866,  -4.2681,\n",
      "          -2.2457,  -8.3440,  -3.8075]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.38659143447876\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5873,  -9.4109, -12.1947,  -1.0492,  -5.1151,  -6.9905,  -5.3862,\n",
      "          -2.7716,  -8.8769,  -3.9308]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.5872552394866943\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2928, -10.4802, -12.8168,  -1.5920,  -5.7640,  -6.8330,  -6.5950,\n",
      "          -3.4923,  -9.5554,  -4.2548]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  9.555440902709961\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2177, -11.0876, -13.0215,  -1.8742,  -5.9951,  -6.3365,  -7.3291,\n",
      "          -3.8094,  -9.0963,  -4.2017]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.995141983032227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2656, -11.1646, -12.7360,  -1.7706,  -4.9984,  -5.4208,  -7.5207,\n",
      "          -3.6423,  -8.2130,  -3.6950]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.7705754041671753\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7133, -11.0831, -12.3280,  -0.9202,  -3.9549,  -4.4485,  -7.5427,\n",
      "          -3.3612,  -7.2669,  -3.1063]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  11.083086967468262\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5347, -10.3198, -12.0241,  -0.5090,  -3.0930,  -3.6453,  -7.6266,\n",
      "          -3.1987,  -6.4790,  -2.6731]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  12.024103164672852\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3729,  -9.5750, -10.9645,  -0.5193,  -2.2928,  -2.8837,  -7.6449,\n",
      "          -3.0266,  -5.7131,  -2.2768]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.372922420501709\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4312, -8.8677, -9.9738, -0.9246, -1.6101, -2.2024, -7.6251, -2.8727,\n",
      "         -4.9892, -1.9596]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.4312195777893066\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9374, -8.3439, -9.1947, -1.6908, -1.2559, -1.7835, -7.7207, -2.8912,\n",
      "         -4.4552, -1.8919]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.6908067464828491\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7095, -7.9852, -8.6059, -1.8986, -1.2601, -1.6429, -7.9198, -3.0638,\n",
      "         -4.0954, -2.0560]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.095368385314941\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5431, -7.5706, -7.9841, -2.1027, -1.3815, -1.5674, -8.0077, -3.1639,\n",
      "         -2.9780, -2.2072]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.984124660491943\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4927, -7.1428, -6.6442, -2.3203, -1.6213, -1.5983, -8.0321, -3.2322,\n",
      "         -1.9534, -2.3705]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.5983041524887085\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7973, -6.9457, -5.6261, -2.7753, -2.1708, -1.2256, -8.2419, -3.5119,\n",
      "         -1.3197, -2.7747]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.3196972608566284\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5399, -7.1176, -5.0606, -3.5790, -3.0986, -1.4550, -8.7796, -4.1359,\n",
      "         -0.5759, -3.5339]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.09858775138855\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2857, -7.2930, -4.5761, -4.3431, -3.2485, -1.8536, -9.2840, -4.7302,\n",
      "         -0.3284, -4.2594]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.7302165031433105\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6678, -7.1349, -3.8307, -4.7240, -3.0956, -2.0115, -9.4217, -4.1763,\n",
      "         -0.3030, -4.6066]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.606626987457275\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6870, -6.6499, -2.8320, -4.7302, -2.6479, -1.9090, -9.2025, -3.3462,\n",
      "         -0.4619, -3.8379]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.730219841003418\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6097, -6.1013, -1.8628, -3.9018, -2.1842, -1.8132, -8.8923, -2.5133,\n",
      "         -0.9390, -3.0489]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.892326354980469\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7150, -5.7643, -1.2588, -3.3259, -2.0052, -2.0027, -8.0003, -1.9819,\n",
      "         -1.8012, -2.5292]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.5291919708251953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0495, -5.6853, -1.1443, -3.0554, -2.1654, -2.4949, -7.4192, -1.8328,\n",
      "         -2.9168, -1.6008]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.1653642654418945\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5262, -5.7796, -1.4365, -3.0090, -1.8201, -3.1620, -7.0594, -1.9862,\n",
      "         -4.1226, -1.0777]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.526202201843262\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2155, -5.8430, -1.8493, -2.9793, -1.6047, -3.7702, -6.7121, -2.2077,\n",
      "         -5.1962, -0.8360]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.843016147613525\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8101, -5.0110, -2.1996, -2.8532, -1.4226, -4.1985, -6.2641, -2.3565,\n",
      "         -6.0305, -0.8040]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.2640509605407715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2919, -4.0978, -2.4269, -2.6125, -1.2673, -4.4262, -4.9286, -2.3955,\n",
      "         -6.6143, -0.9383]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.4269020557403564\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8117, -3.2474, -1.9256, -2.4087, -1.2945, -4.5995, -3.6910, -2.4613,\n",
      "         -7.1005, -1.3090]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.59953498840332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4446, -2.5329, -1.6021, -2.3126, -1.5427, -4.0458, -2.6175, -2.6090,\n",
      "         -7.5606, -1.8648]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.542738437652588\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3991, -2.1719, -1.6801, -2.5205, -1.4090, -3.7823, -1.9291, -3.0218,\n",
      "         -8.1976, -2.7025]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.19758129119873\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4346, -1.9436, -1.8967, -2.7769, -1.4791, -3.5724, -1.4314, -3.4422,\n",
      "         -8.0692, -3.5172]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.8967275619506836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6024, -1.9188, -1.5454, -3.1256, -1.7822, -3.4765, -1.2392, -3.9182,\n",
      "         -8.0262, -4.3452]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.602384328842163\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0649, -1.9888, -1.3653, -3.4527, -2.1602, -3.3940, -1.2697, -4.3434,\n",
      "         -7.9687, -5.0815]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.0648727416992188\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0636, -2.2663, -1.4998, -3.8811, -2.6962, -3.4552, -1.6236, -4.8471,\n",
      "         -8.0278, -5.8597]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.623560905456543\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6426, -2.8259, -2.0145, -4.5131, -3.4597, -3.7649, -1.5579, -5.5380,\n",
      "         -8.3125, -6.7939]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.31248950958252\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5016, -3.2329, -2.4333, -4.9482, -4.0285, -3.9189, -1.5184, -6.0213,\n",
      "         -7.7179, -7.4939]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.433295249938965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6061, -3.4242, -1.9420, -5.1401, -4.3487, -3.8672, -1.4456, -6.2533,\n",
      "         -6.9777, -7.9195]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.140139102935791\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8919, -3.4205, -1.4032, -4.3863, -4.4458, -3.6354, -1.3601, -6.2630,\n",
      "         -6.1111, -8.1024]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.635441541671753\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3801, -3.3782, -1.0330, -3.6528, -4.4782, -2.6442, -1.4161, -6.2095,\n",
      "         -5.2686, -8.2035]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.268558502197266\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9947, -3.3602, -0.9526, -3.0054, -4.5099, -1.7983, -1.6468, -6.1570,\n",
      "         -3.8015, -8.2889]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.8014936447143555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7704, -3.4947, -1.2846, -2.5829, -4.6708, -1.2833, -2.1266, -6.2356,\n",
      "         -1.9188, -8.4902]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.494690418243408\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9319, -3.2981, -2.2028, -2.6756, -5.2407, -1.4425, -3.0681, -6.7260,\n",
      "         -0.7452, -9.0897]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.7452409863471985\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8358,  -3.9928,  -3.9536,  -3.6534,  -6.6016,  -2.6045,  -4.7955,\n",
      "          -8.0123,  -0.1630, -10.4734]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.795531749725342\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.3768,  -4.4569,  -5.3687,  -4.3772,  -7.6525,  -3.5300,  -5.4143,\n",
      "          -8.9954,  -0.0659, -11.5439]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.529956340789795\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.2066,  -4.3254,  -6.0880,  -4.4799,  -8.0409,  -3.0893,  -5.4167,\n",
      "          -9.3224,  -0.0807, -11.9496]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.089332103729248\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.5140,  -3.7770,  -6.2975,  -4.1408,  -7.9509,  -1.5538,  -4.9823,\n",
      "          -9.1770,  -0.3006, -11.8749]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.3005726933479309\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.2100,  -3.7196,  -6.9064,  -4.2660,  -8.2891,  -0.7456,  -5.0153,\n",
      "          -9.4651,  -0.7356, -12.2267]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.906377792358398\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.8059,  -3.6554,  -6.6969,  -4.3582,  -8.5630,  -0.3364,  -5.0193,\n",
      "          -9.6938,  -1.4318, -12.5126]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.431797742843628\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.2092,  -3.4840,  -6.3758,  -4.3172,  -8.6764,  -0.3595,  -4.8946,\n",
      "          -9.7663,  -1.3923, -12.6366]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  10.209160804748535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.4737,  -2.9762,  -5.7111,  -3.9134,  -8.4019,  -0.5146,  -4.4113,\n",
      "          -9.4550,  -1.1537, -12.3716]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.913418769836426\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.6020,  -2.3484,  -4.9057,  -2.6237,  -7.9455,  -0.8814,  -3.7760,\n",
      "          -8.9653,  -0.9500, -11.9236]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.77604603767395\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.8687,  -1.9072,  -4.2371,  -1.5667,  -7.5861,  -1.5653,  -2.5084,\n",
      "          -8.5758,  -1.0882, -11.5715]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.5861310958862305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.4407,  -1.8553,  -3.8778,  -1.0001,  -6.7537,  -2.5661,  -1.6614,\n",
      "          -8.4574,  -1.6801, -11.4867]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.7537126541137695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.1739,  -2.0460,  -3.6874,  -0.8775,  -5.3875,  -3.6416,  -1.1622,\n",
      "          -8.4691,  -2.4615, -11.5284]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.8774530291557312\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.1903,  -2.5722,  -3.7903,  -0.5959,  -4.4167,  -4.8852,  -1.2085,\n",
      "          -8.7358,  -3.4808, -11.8220]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.885247707366943\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.9998,  -2.8987,  -3.6937,  -0.5400,  -3.3457,  -5.0715,  -1.2732,\n",
      "          -8.7705,  -4.2145, -11.8808]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.214517593383789\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.5950,  -3.0008,  -3.3909,  -0.6813,  -2.1734,  -5.0099,  -1.3118,\n",
      "          -8.5678,  -3.9511, -11.6996]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.56775951385498\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.1704,  -3.0697,  -3.0817,  -1.1162,  -1.1409,  -4.8982,  -1.4917,\n",
      "          -7.5342,  -3.6663, -11.4755]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.170442581176758\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1857,  -3.2835,  -2.9532,  -1.8630,  -0.5643,  -4.9194,  -1.9424,\n",
      "          -6.7203,  -3.5441, -11.3901]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.185712814331055\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5251,  -3.4421,  -2.8129,  -2.5860,  -0.4033,  -4.8811,  -2.3954,\n",
      "          -5.9256,  -3.3915, -11.2504]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.4032772183418274\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3530,  -3.9114,  -3.0325,  -3.5940,  -0.3151,  -5.1543,  -3.1752,\n",
      "          -5.5143,  -3.5797, -11.4267]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  11.426738739013672\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1814,  -4.1648,  -3.0810,  -4.3373,  -0.5900,  -5.2200,  -3.7249,\n",
      "          -4.9624,  -3.5841, -10.6490]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.219959259033203\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4600,  -4.5173,  -3.2707,  -5.1286,  -1.3583,  -4.6658,  -4.3509,\n",
      "          -4.5836,  -3.7200, -10.0612]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.35085391998291\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.2469, -4.8251, -3.4512, -5.8275, -2.2215, -4.1556, -4.1394, -4.2324,\n",
      "         -3.8413, -9.5139]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.825064659118652\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.2725, -4.0007, -3.2939, -6.1158, -2.7357, -3.3645, -3.6181, -3.5846,\n",
      "         -3.6224, -8.6779]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.677887916564941\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5441, -2.9768, -2.8838, -6.0814, -2.9509, -2.3817, -2.8735, -2.7277,\n",
      "         -3.1485, -6.8818]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.148458480834961\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3231, -2.2142, -2.6760, -6.1725, -3.3037, -1.6847, -2.3668, -2.1283,\n",
      "         -2.1726, -5.3856]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.1726436614990234\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6645, -2.0608, -2.9892, -6.7060, -4.0984, -1.6427, -2.4322, -2.1330,\n",
      "         -1.1274, -4.4916]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.1330268383026123\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2395, -2.3375, -3.6254, -7.5045, -5.1437, -2.0636, -2.8758, -1.7573,\n",
      "         -0.7298, -4.0124]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.239477634429932\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8895, -2.5992, -4.1568, -8.1628, -6.0279, -2.4742, -3.2571, -1.4943,\n",
      "         -0.6473, -3.5332]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.889536380767822\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5813, -2.7048, -4.4597, -8.5687, -6.6389, -2.7186, -3.4431, -1.2483,\n",
      "         -0.7511, -2.9366]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.581341743469238\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4456, -2.6924, -4.5823, -8.7757, -7.0314, -2.8283, -3.4764, -1.0956,\n",
      "         -1.0146, -2.2807]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.280712604522705\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5586, -2.8463, -4.8134, -9.0754, -7.4986, -3.0836, -3.6433, -1.3361,\n",
      "         -1.6173, -1.1317]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.5586447715759277\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4661, -3.3846, -5.3826, -9.7004, -8.2749, -3.7022, -4.1689, -2.1159,\n",
      "         -2.6534, -0.6946]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.65342116355896\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8169,  -4.0666,  -6.0698, -10.4346,  -9.1454,  -4.4486,  -4.8253,\n",
      "          -3.0849,  -3.1098,  -0.8473]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.0848982334136963\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4841,  -4.6325,  -6.6290, -11.0345,  -9.8681,  -5.0680,  -5.3613,\n",
      "          -3.1411,  -3.4905,  -1.2451]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.629010200500488\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3652,  -4.8945,  -6.1438, -11.3195, -10.2637,  -5.3752,  -5.5923,\n",
      "          -2.9707,  -3.5993,  -1.5639]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.263689041137695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3985,  -4.7867,  -5.3591, -11.2268,  -9.5299,  -5.3059,  -5.4539,\n",
      "          -2.5084,  -3.3670,  -1.6585]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.3985253572463989\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3444,  -4.8439,  -4.8036, -11.2910,  -9.0169,  -5.3949,  -5.4803,\n",
      "          -2.3043,  -3.3295,  -2.0342]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.016926765441895\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4560,  -4.5629,  -3.9711, -11.0104,  -7.4812,  -5.1399,  -5.1689,\n",
      "          -1.8609,  -2.9823,  -2.1322]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.9823029041290283\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8685,  -4.1849,  -3.1022, -10.6248,  -5.9656,  -4.7815,  -4.7598,\n",
      "          -1.4517,  -1.8769,  -2.1763]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.9656476974487305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6567,  -3.9787,  -2.4753, -10.3999,  -3.9944,  -4.5874,  -4.5204,\n",
      "          -1.3909,  -1.1104,  -2.4237]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.9786624908447266\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6881,  -3.2274,  -2.1602, -10.3849,  -2.4204,  -4.6076,  -4.5007,\n",
      "          -1.7206,  -0.8368,  -2.9005]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.900521755218506\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8508,  -2.7676,  -2.1477, -10.5577,  -1.2546,  -4.8194,  -4.6778,\n",
      "          -2.3454,  -1.0777,  -2.8063]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.1476945877075195\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1967,  -2.6857,  -1.7718, -10.9971,  -0.6990,  -5.2999,  -5.1284,\n",
      "          -3.2677,  -1.8150,  -3.0507]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.6856701374053955\n",
      "torch.Size([1, 1, 40])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -6.4753,  -1.9634,  -1.6210, -11.4556,  -0.6278,  -5.7990,  -5.6014,\n",
      "          -4.1912,  -2.6548,  -3.3689]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.9634063243865967\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.7799,  -0.8131,  -1.7830, -12.0207,  -1.1086,  -6.4030,  -6.1825,\n",
      "          -5.1870,  -3.6122,  -3.8336]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.1085994243621826\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.2901,  -0.4517,  -2.3875, -12.8646,  -1.3850,  -7.2830,  -7.0423,\n",
      "          -6.4232,  -4.8281,  -4.6032]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.042279243469238\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.3799,  -0.3429,  -2.7294, -13.3544,  -1.5477,  -7.8059,  -6.7759,\n",
      "          -7.2675,  -5.6585,  -5.0337]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.5477172136306763\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.1828,  -0.6070,  -2.9068, -13.6170,  -0.9399,  -8.0986,  -6.3584,\n",
      "          -7.8499,  -6.2302,  -5.2477]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.8498711585998535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.7369,  -1.0898,  -2.9380, -13.6847,  -0.5102,  -8.1936,  -5.8150,\n",
      "          -7.4133,  -6.5776,  -5.2756]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  11.73692512512207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.3065,  -1.5561,  -2.7815, -13.5219,  -0.3395,  -8.0557,  -5.1044,\n",
      "          -6.7971,  -6.6677,  -5.0810]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  13.521947860717773\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.5655,  -1.7827,  -2.3328, -12.2822,  -0.3524,  -7.5783,  -4.1157,\n",
      "          -5.8896,  -6.3963,  -4.5569]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.556885242462158\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.6191,  -1.8353,  -1.7211, -10.8867,  -0.5964,  -6.8696,  -2.9589,\n",
      "          -4.7955,  -5.8738,  -3.0642]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  9.619135856628418\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.1104, -2.0488, -1.3473, -9.6751, -1.2613, -6.2772, -2.0023, -3.8618,\n",
      "         -5.4504, -1.8000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.8000173568725586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.3573, -2.9444, -1.8078, -9.1894, -2.6713, -6.3504, -1.8507, -3.6429,\n",
      "         -5.6773, -0.6444]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.642947196960449\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.9970, -4.1083, -2.6609, -9.0695, -4.3088, -6.7351, -2.1532, -2.9955,\n",
      "         -6.2015, -0.3149]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.3088154792785645\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4274, -4.9231, -3.2349, -8.7159, -4.8161, -6.8366, -2.2698, -2.2062,\n",
      "         -6.4292, -0.3184]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.2061991691589355\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9102, -5.6569, -3.7755, -8.3922, -5.2732, -6.9233, -2.4493, -0.7924,\n",
      "         -6.6298, -0.8578]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.7754688262939453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8046, -6.6785, -3.8990, -8.4590, -6.0469, -7.3603, -3.0362, -0.2352,\n",
      "         -7.1697, -2.0171]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.8046040534973145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7850, -7.3727, -3.7985, -8.2926, -6.5185, -7.5276, -3.3751, -0.1297,\n",
      "         -7.4296, -2.9334]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.784968852996826\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6676, -7.4886, -3.2148, -7.6333, -6.4346, -7.1690, -3.1972, -0.2132,\n",
      "         -7.1544, -3.2884]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.2147774696350098\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8679, -7.6517, -2.0430, -7.0983, -6.4185, -6.9049, -3.1270, -0.9757,\n",
      "         -6.9654, -3.6942]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.904947280883789\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.2982, -8.5552, -1.8394, -7.3734, -7.1615, -6.6826, -3.8541, -2.7121,\n",
      "         -7.5522, -4.8345]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.712085247039795\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.2563, -9.3195, -1.7236, -7.5722, -7.7816, -6.4339, -4.4760, -3.4958,\n",
      "         -8.0315, -5.8178]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.4338507652282715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.3574, -9.6061, -1.3489, -7.3499, -7.9387, -5.0728, -4.6430, -3.8234,\n",
      "         -8.0616, -6.3037]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.061649322509766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6359, -9.5649, -0.9033, -6.8508, -7.7810, -3.5526, -4.5016, -3.8361,\n",
      "         -7.0892, -6.4433]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.6358941197395325\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7162, -9.6853, -0.9577, -6.5597, -7.7968, -2.3623, -4.5404, -4.0218,\n",
      "         -6.3716, -6.7276]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.0217742919921875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0285, -9.6939, -1.1890, -6.1987, -7.7115, -1.2604, -4.4838, -3.3263,\n",
      "         -5.6268, -6.8848]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.1890242099761963\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8442, -9.9878, -1.1717, -6.1613, -7.9211, -0.7644, -4.7276, -3.0140,\n",
      "         -5.2447, -7.3131]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.8442347049713135\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9748, -10.2348,  -1.3660,  -6.1114,  -8.0923,  -0.6451,  -4.9364,\n",
      "          -2.7531,  -4.8866,  -7.6815]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.6450997591018677\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3840, -10.6524,  -1.9237,  -6.2635,  -8.4421,  -0.3815,  -5.3253,\n",
      "          -2.7630,  -4.7647,  -8.2089]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.263462543487549\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5126, -10.7246,  -2.2292,  -5.3540,  -8.4531,  -0.3453,  -5.3752,\n",
      "          -2.5169,  -4.3569,  -8.3800]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.453117370605469\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3372, -10.4420,  -2.2359,  -4.1911,  -7.3858,  -0.4872,  -5.0763,\n",
      "          -2.0105,  -3.6513,  -8.1868]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.235931396484375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1910, -10.1321,  -1.5302,  -3.0996,  -6.3696,  -1.0111,  -4.7565,\n",
      "          -1.6032,  -2.9785,  -7.9574]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.099644184112549\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3513, -10.0672,  -1.2678,  -1.6245,  -5.6700,  -1.9645,  -4.6895,\n",
      "          -1.6072,  -2.6228,  -7.9654]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.6227827072143555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9280, -10.3749,  -1.6041,  -0.8088,  -5.4087,  -3.2923,  -5.0023,\n",
      "          -2.1327,  -2.0184,  -8.3389]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.338881492614746\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6008, -10.7683,  -2.1707,  -0.5219,  -5.2928,  -4.6316,  -5.4056,\n",
      "          -2.8145,  -1.6838,  -8.0428]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.6316237449646\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0495, -10.9462,  -2.5884,  -0.5282,  -5.0159,  -4.9301,  -5.5960,\n",
      "          -3.2989,  -1.3366,  -7.6002]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.01594352722168\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2271, -10.8680,  -2.7812,  -0.7323,  -3.8055,  -4.9657,  -5.5318,\n",
      "          -3.5253,  -0.9701,  -6.9635]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  10.867961883544922\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2319, -9.8648, -2.8351, -1.1064, -2.5664, -4.8374, -5.3117, -3.5867,\n",
      "         -0.7410, -6.2255]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.837442398071289\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1926, -8.9078, -2.8730, -1.6342, -1.4530, -3.9409, -5.0637, -3.6099,\n",
      "         -0.8155, -5.5088]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.5087738037109375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2693, -8.1476, -3.0502, -2.3554, -0.7227, -3.2492, -4.9469, -3.7535,\n",
      "         -1.2944, -4.2226]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.147592544555664\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3951, -6.7479, -3.2916, -3.1220, -0.4666, -2.7019, -4.8942, -3.9480,\n",
      "         -1.9647, -3.1224]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.9479503631591797\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4083, -5.3797, -3.4276, -3.7363, -0.5844, -2.1495, -4.7438, -3.2503,\n",
      "         -2.5580, -2.0558]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.0558316707611084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7226, -4.4452, -3.8680, -4.6010, -1.3898, -2.0315, -4.9093, -2.9461,\n",
      "         -3.4405, -0.7419]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.440539598464966\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4006, -4.0015, -4.6687, -5.7760, -2.6852, -2.4105, -5.4529, -3.1020,\n",
      "         -3.9435, -0.3037]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.001473903656006\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8272, -2.6695, -5.2095, -6.6491, -3.7141, -2.6305, -5.7585, -3.0902,\n",
      "         -4.2228, -0.2727]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.090190887451172\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0440, -1.3536, -5.5311, -7.2669, -4.4889, -2.7122, -5.8669, -2.1705,\n",
      "         -4.3152, -0.6411]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.488934516906738\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4866, -0.6120, -6.0694, -8.0695, -4.7115, -3.0803, -6.2124, -1.6767,\n",
      "         -4.6535, -1.6089]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.486575603485107\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2583, -0.4305, -6.6272, -8.8638, -4.9899, -3.5170, -6.5965, -1.4488,\n",
      "         -5.0362, -2.7001]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.036215782165527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.7910, -0.5000, -6.8673, -9.3160, -4.9824, -3.6689, -6.6803, -1.1630,\n",
      "         -4.4225, -3.4694]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.5000439286231995\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5182, -0.4090, -7.2302, -9.8692, -5.1265, -3.9705, -6.9027, -1.2945,\n",
      "         -4.0241, -4.3313]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.4089546203613281\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4451,  -0.2411,  -7.7272, -10.5371,  -5.4304,  -4.4256,  -7.2735,\n",
      "          -1.7956,  -3.8477,  -5.2868]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  10.537120819091797\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9340, -0.2400, -7.7269, -9.9468, -5.2589, -4.3960, -7.1596, -1.9276,\n",
      "         -3.2555, -5.7027]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.159614562988281\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0449, -0.4009, -7.2929, -8.9813, -4.6742, -3.9444, -5.8375, -1.7255,\n",
      "         -2.3152, -5.6457]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.837516784667969\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1046, -0.8994, -6.7506, -7.9600, -4.0027, -3.4002, -3.7181, -1.5301,\n",
      "         -1.3859, -5.4450]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.7180614471435547\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6520, -2.0181, -6.6260, -7.4034, -3.7740, -3.2974, -1.4178, -1.8853,\n",
      "         -1.0874, -5.6303]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.018141031265259\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1287, -3.2017, -7.3494, -7.7373, -4.4195, -4.0670, -0.3706, -3.1579,\n",
      "         -1.8897, -6.6345]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.419524669647217\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7508, -4.4604, -8.1634, -8.2005, -4.4444, -4.9347, -0.1304, -4.4991,\n",
      "         -2.8805, -7.7019]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.7019171714782715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8289, -5.1040, -8.3981, -8.1192, -3.9769, -5.2229, -0.0997, -5.2169,\n",
      "         -3.3135, -7.4210]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.119200706481934\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3094, -5.0830, -8.0045, -6.7004, -2.9644, -4.8812, -0.1673, -5.2624,\n",
      "         -3.1238, -6.5632]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.262414932250977\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4842, -4.6856, -7.2671, -5.0405, -1.7070, -4.1960, -0.4956, -4.1457,\n",
      "         -2.6008, -5.4088]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.49556905031204224\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2121, -4.7471, -7.0161, -3.9631, -1.1195, -4.0025, -0.9017, -3.5648,\n",
      "         -2.5944, -4.7850]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.002548694610596\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0526, -4.8175, -6.7991, -3.0154, -0.8368, -3.1117, -1.5880, -3.0721,\n",
      "         -2.6497, -4.2379]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.1116621494293213\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1073, -4.9950, -6.7125, -2.3065, -1.0057, -1.7167, -2.4713, -2.7725,\n",
      "         -2.8571, -3.8640]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.3064751625061035\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6220, -5.5398, -7.0152, -1.3826, -1.8039, -0.9727, -3.7116, -2.9311,\n",
      "         -3.4642, -3.9227]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.015203475952148\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3554, -6.2520, -6.7648, -0.9556, -2.8613, -0.8003, -5.0661, -3.3341,\n",
      "         -4.2516, -4.2090]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.764827251434326\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9222, -6.7766, -5.6853, -0.7384, -3.7369, -0.8577, -6.1724, -3.6066,\n",
      "         -4.8525, -4.3597]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.7384018898010254\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6445, -7.4478, -4.9138, -0.3547, -4.7407, -1.4194, -7.3682, -4.0711,\n",
      "         -5.5970, -4.7029]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.368162631988525\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0201, -7.7710, -3.9428, -0.2477, -5.3694, -1.8216, -7.3915, -4.2210,\n",
      "         -5.9885, -4.7371]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.369380474090576\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9515, -7.6509, -2.6715, -0.3164, -4.7984, -1.8913, -7.0015, -3.9561,\n",
      "         -5.9313, -4.3630]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.931314468383789\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6770, -7.3254, -1.3601, -0.6965, -4.0724, -1.8473, -6.4332, -3.5146,\n",
      "         -4.9592, -3.8179]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.8472778797149658\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7617, -7.3581, -0.6949, -1.7300, -3.7563, -1.5131, -6.2480, -3.4656,\n",
      "         -4.4140, -3.6687]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.761670112609863\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2075, -7.4569, -0.5351, -2.8599, -3.5577, -1.4430, -6.1517, -3.5148,\n",
      "         -4.0005, -3.6224]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.207521915435791\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8396, -7.3674, -0.6458, -3.7407, -3.2207, -1.3745, -5.8877, -3.4035,\n",
      "         -3.4622, -3.4218]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.887715816497803\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5794, -7.2179, -1.0634, -4.4819, -2.8769, -1.4294, -4.8149, -3.2599,\n",
      "         -2.9302, -3.1962]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.429375410079956\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9348, -7.4289, -2.0395, -5.5027, -2.9535, -1.2652, -4.2002, -3.5056,\n",
      "         -2.8339, -3.3688]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.200195789337158\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6939, -7.6824, -3.0777, -6.4881, -3.1237, -1.3876, -2.9589, -3.8136,\n",
      "         -2.8518, -3.6132]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.488101005554199\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7485, -7.8314, -3.9670, -6.5585, -3.2293, -1.6013, -1.8010, -4.0284,\n",
      "         -2.8289, -3.7736]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.8289475440979004\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2025, -8.0382, -4.8542, -6.6953, -3.4258, -2.0143, -0.9576, -4.3082,\n",
      "         -2.2184, -4.0078]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.854223728179932\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9091, -8.3117, -5.0052, -6.9064, -3.7134, -2.5710, -0.5796, -4.6577,\n",
      "         -1.8322, -4.3193]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.657703876495361\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5213, -8.4299, -5.0178, -6.9690, -3.8620, -3.0002, -0.5403, -4.0702,\n",
      "         -1.4691, -4.4815]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.8619823455810547\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9277, -8.3352, -4.8328, -6.8247, -3.0807, -3.2221, -0.7492, -3.3532,\n",
      "         -1.1032, -4.4348]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.824733257293701\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2088, -8.1275, -4.5494, -5.8391, -2.2881, -3.3285, -1.1755, -2.6123,\n",
      "         -0.8853, -4.2790]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.12746810913086\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4579, -7.1464, -4.2698, -4.9214, -1.6160, -3.4185, -1.7626, -1.9702,\n",
      "         -0.9476, -4.1169]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.418452024459839\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7497, -6.3087, -4.0735, -4.1456, -1.2012, -2.8340, -2.4676, -1.5463,\n",
      "         -1.3221, -4.0283]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.8339741230010986\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1286, -5.6555, -4.0090, -3.5582, -1.1468, -1.7205, -3.2668, -1.4310,\n",
      "         -1.9469, -4.0616]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.720492959022522\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9270, -5.5158, -4.4102, -3.4962, -1.7757, -0.5676, -4.4616, -1.9602,\n",
      "         -3.0560, -4.5505]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.5675954818725586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5396, -6.2816, -5.6691, -4.3512, -3.3541, -0.1032, -6.4348, -3.4355,\n",
      "         -4.9765, -5.8872]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.434798240661621\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.6848, -6.6647, -6.4972, -4.8226, -4.4930, -0.0381, -7.1394, -4.4812,\n",
      "         -6.4027, -6.7850]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.664678573608398\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.0708, -5.6061, -6.5985, -4.6075, -4.8812, -0.0345, -7.1289, -4.7862,\n",
      "         -7.0427, -6.9487]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.9487152099609375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.7645, -4.0017, -6.0367, -3.7671, -4.5823, -0.0752, -6.4660, -4.4134,\n",
      "         -6.9655, -5.6908]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.466038703918457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0372, -2.1190, -5.0807, -2.5755, -3.8687, -0.3259, -4.6587, -3.6353,\n",
      "         -6.4448, -4.1088]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.635298013687134\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7465, -0.8789, -4.5882, -1.9223, -3.6051, -1.4318, -3.4020, -2.5366,\n",
      "         -6.3407, -3.0602]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.746527671813965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3145, -0.6134, -4.6866, -1.9765, -3.9221, -3.1336, -2.8302, -2.1435,\n",
      "         -6.7826, -2.6857]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.830166816711426\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9795, -0.8396, -4.8348, -2.1805, -4.2748, -4.7500, -1.6569, -1.9341,\n",
      "         -7.2342, -2.4526]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2.180453300476074\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8513, -1.5434, -5.1459, -1.8824, -4.7742, -6.3835, -0.9168, -2.0303,\n",
      "         -7.8129, -2.4792]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.383508682250977\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.7850, -2.3868, -5.4775, -1.7732, -5.2773, -7.1804, -0.6014, -2.2669,\n",
      "         -8.3814, -2.6135]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.6135106086730957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6256, -3.1143, -5.6773, -1.6983, -5.6322, -7.7968, -0.6316, -2.4592,\n",
      "         -8.7917, -1.9367]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.6315877437591553\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.7048, -4.0233, -6.0799, -1.9858, -6.1744, -8.5721, -0.5243, -2.9195,\n",
      "         -9.3813, -1.6559]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.0233354568481445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5325, -3.8487, -6.1982, -2.1000, -6.4184, -9.0246, -0.6303, -3.1304,\n",
      "         -9.6665, -1.3008]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  9.666458129882812\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1537, -3.4811, -6.0798, -2.0668, -6.4128, -9.2056, -0.9018, -3.1282,\n",
      "         -8.9881, -0.9595]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.988086700439453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6426, -2.9995, -5.8009, -1.9563, -6.2349, -9.1947, -1.2787, -2.9865,\n",
      "         -7.4996, -0.7664]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.986454963684082\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0943, -2.5087, -5.4570, -1.8662, -5.9812, -9.0899, -1.7334, -2.0208,\n",
      "         -6.0647, -0.8468]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.7333742380142212\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7132, -2.2294, -5.2513, -2.0002, -5.8555, -9.0965, -1.6205, -1.3559,\n",
      "         -4.8751, -1.3420]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.229409694671631\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5319, -1.4463, -5.2147, -2.3654, -5.8890, -9.2471, -1.8127, -1.1035,\n",
      "         -3.9539, -2.1287]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.888991832733154\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4345, -0.9649, -5.2309, -2.8088, -5.2319, -9.4280, -2.1540, -1.1809,\n",
      "         -3.1831, -2.9717]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.1539769172668457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3926, -0.8435, -5.2724, -3.2756, -4.6671, -9.6138, -1.8180, -1.5137,\n",
      "         -2.5412, -3.7922]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.8434515595436096\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6355,  -0.5594,  -5.5703,  -3.9806,  -4.4220, -10.0378,  -1.8944,\n",
      "          -2.2422,  -2.2756,  -4.8047]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.24221134185791\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7538,  -0.6178,  -5.7224,  -4.5103,  -4.0912, -10.3006,  -1.9575,\n",
      "          -2.0805,  -1.9903,  -5.6036]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.603589057922363\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6639,  -0.8649,  -5.6486,  -4.7822,  -3.5924, -10.3242,  -1.9075,\n",
      "          -1.8191,  -1.6170,  -5.3596]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.663940906524658\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8095,  -1.3221,  -5.5015,  -4.9500,  -3.0803, -10.2622,  -1.8910,\n",
      "          -1.6271,  -1.3383,  -5.0601]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.338295578956604\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3166,  -2.1690,  -5.6061,  -5.3402,  -2.8869, -10.4402,  -2.2239,\n",
      "          -1.8416,  -0.7995,  -5.0291]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  10.44020938873291\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9326, -3.0079, -5.6928, -5.6850, -2.7435, -9.8696, -2.5950, -2.1483,\n",
      "         -0.6225, -4.9959]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.869636535644531\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5286, -3.6396, -5.6124, -5.8370, -2.5010, -8.4795, -2.8246, -2.3548,\n",
      "         -0.6818, -4.8101]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.836987018585205\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1590, -4.0687, -5.3831, -5.0756, -2.1833, -7.0681, -2.9164, -2.4553,\n",
      "         -0.9326, -4.4893]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.9325788021087646\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1790, -4.5981, -5.3102, -4.5247, -2.1105, -5.9279, -3.1701, -2.7429,\n",
      "         -0.8597, -4.3389]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.310154438018799\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2329, -4.9000, -4.3168, -3.8542, -1.9520, -4.7208, -3.2478, -2.8699,\n",
      "         -0.9105, -4.0310]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.2328519821166992\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8785, -5.2774, -3.5321, -3.3660, -2.0139, -3.7400, -3.4470, -3.1285,\n",
      "         -1.3397, -3.8668]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.277398109436035\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7982, -4.8081, -2.7918, -2.8964, -2.1126, -2.8183, -3.5949, -3.3401,\n",
      "         -1.8553, -3.6792]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.8963828086853027\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0928, -4.4396, -2.2192, -1.8245, -2.3388, -2.0793, -3.7968, -3.6064,\n",
      "         -2.4780, -3.5773]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.439600467681885\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7701, -3.5397, -1.9599, -1.1533, -2.7886, -1.6788, -4.1704, -4.0422,\n",
      "         -3.2728, -3.6814]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.9598963260650635\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7456, -2.9961, -1.3294, -1.0274, -3.4841, -1.6975, -4.7635, -4.6933,\n",
      "         -4.2601, -4.0391]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.6975061893463135\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8203, -2.6951, -1.1107, -1.3296, -4.2838, -1.2785, -5.4547, -5.4376,\n",
      "         -5.3099, -4.5252]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.820302724838257\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0243, -2.4047, -1.0904, -1.7271, -4.9438, -1.0315, -6.0101, -6.0410,\n",
      "         -6.1885, -4.9009]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.010123252868652\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0680, -2.0588, -1.1712, -2.0640, -5.3909, -0.9131, -5.6031, -6.4337,\n",
      "         -6.8285, -5.0922]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.092236042022705\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9497, -1.6738, -1.3063, -2.2915, -5.6271, -0.9254, -5.0695, -6.6187,\n",
      "         -7.2358, -4.3459]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.6186723709106445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7055, -1.3174, -1.4793, -2.4197, -5.6911, -1.0700, -4.4424, -5.8509,\n",
      "         -7.4517, -3.5322]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.4792819023132324\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5781, -1.2739, -1.1323, -2.6763, -5.8263, -1.5219, -3.9617, -5.2370,\n",
      "         -7.7217, -2.8968]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.5780842304229736\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7311, -1.3998, -1.0147, -2.9122, -5.9042, -2.0396, -3.4972, -4.6422,\n",
      "         -7.9190, -2.3201]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.9121744632720947\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0183, -1.7033, -1.1835, -2.4287, -5.9802, -2.6032, -3.1058, -4.1180,\n",
      "         -8.1008, -1.8789]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.1057956218719482\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5579, -2.2017, -1.6518, -2.1461, -6.1381, -3.2516, -2.1209, -3.7464,\n",
      "         -8.3523, -1.6845]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.352291107177734\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3881, -2.8299, -2.3125, -2.0739, -6.3777, -3.9591, -1.4204, -3.5261,\n",
      "         -7.9660, -1.7454]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.4204065799713135\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7784, -3.8069, -3.3482, -2.4686, -6.9614, -4.9767, -0.5867, -3.7175,\n",
      "         -7.9851, -2.2989]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.717484474182129\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3092, -4.7633, -4.3670, -2.9465, -7.5476, -5.9578, -0.3161, -3.1875,\n",
      "         -8.0624, -2.9331]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.30924654006958\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9154, -5.3949, -5.0577, -3.1796, -7.8397, -6.6069, -0.3857, -2.5064,\n",
      "         -7.8961, -3.3082]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.3082103729248047\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4516, -5.7538, -5.4712, -3.2070, -7.8898, -6.9793, -0.7456, -1.7438,\n",
      "         -7.5334, -2.7060]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.9792656898498535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1994, -6.0795, -5.8467, -3.2618, -7.9352, -6.5944, -1.4252, -1.1942,\n",
      "         -7.2072, -2.2141]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.2141177654266357\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3514, -6.5406, -6.3533, -3.5058, -8.1426, -6.4151, -2.3836, -1.1030,\n",
      "         -7.0802, -1.2692]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.2692278623580933\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1761, -7.4621, -7.3158, -4.2528, -8.8346, -6.7598, -3.8208, -1.7860,\n",
      "         -7.4715, -0.3862]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.3861728608608246\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7205,  -9.0137,  -8.9044,  -5.6575, -10.1794,  -7.7925,  -5.8529,\n",
      "          -3.2539,  -8.5458,  -0.0727]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.07268980145454407\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4039, -10.6867, -10.6108,  -7.2006, -11.6660,  -8.9985,  -7.9607,\n",
      "          -4.8817,  -9.7889,  -0.0135]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  10.6107816696167\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2253e+00, -1.1495e+01, -1.0700e+01, -7.8930e+00, -1.2307e+01,\n",
      "         -9.3867e+00, -9.1611e+00, -5.6556e+00, -1.0211e+01, -6.1316e-03]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  7.8930182456970215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2307e+00, -1.1488e+01, -1.0046e+01, -7.0406e+00, -1.2148e+01,\n",
      "         -9.0009e+00, -9.5067e+00, -5.6198e+00, -9.8549e+00, -6.8012e-03]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  12.148487091064453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5099, -10.7545,  -8.7287,  -5.5466, -10.5334,  -7.9264,  -9.0907,\n",
      "          -4.8632,  -8.8074,  -0.0166]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.533408164978027\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1958, -9.4260, -6.8752, -3.5363, -7.6718, -6.2912, -8.0484, -3.5201,\n",
      "         -7.1965, -0.0815]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.196499347686768\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7874, -7.9940, -4.9712, -1.5118, -4.8595, -4.5843, -6.8742, -2.0982,\n",
      "         -4.8009, -0.5785]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.99395751953125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3808, -6.7636, -4.0798, -0.6704, -3.1509, -3.8727, -6.6356, -1.7322,\n",
      "         -3.4676, -2.2545]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.635641098022461\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4755, -6.0518, -3.6851, -0.6873, -2.0393, -3.6421, -6.0648, -1.9370,\n",
      "         -2.6844, -4.2361]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.6873126029968262\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9755, -5.7677, -3.7035, -0.6892, -1.4903, -3.8085, -5.9075, -2.5898,\n",
      "         -2.3827, -6.3862]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.808479070663452\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3696, -5.4219, -3.6463, -0.9703, -1.0713, -3.1608, -5.6756, -3.1444,\n",
      "         -2.0843, -8.2312]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.369576930999756\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9804, -5.0544, -3.5549, -1.4445, -0.8896, -2.5488, -5.4099, -3.6183,\n",
      "         -1.8448, -9.8333]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.054360389709473\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5940,  -3.9010,  -3.4221,  -1.9741,  -0.9598,  -1.9822,  -5.1021,\n",
      "          -3.9943,  -1.6698, -11.2040]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.422126293182373\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3011,  -2.8798,  -2.5803,  -2.5559,  -1.3099,  -1.5737,  -4.8316,\n",
      "          -4.3495,  -1.6485, -12.4405]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.831625938415527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1789,  -2.0733,  -1.9495,  -3.2078,  -1.8962,  -1.4261,  -3.9156,\n",
      "          -4.7500,  -1.8368, -13.6244]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  13.624363899230957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2272,  -1.5205,  -1.5663,  -3.9028,  -2.6138,  -1.5450,  -3.1837,\n",
      "          -5.1955,  -2.1980, -14.0275]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.227156639099121\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7506,  -1.2997,  -1.4891,  -4.6547,  -3.4256,  -1.9173,  -2.6669,\n",
      "          -5.7120,  -2.7135, -14.5016]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.712045669555664\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4185,  -1.2818,  -1.5629,  -5.3128,  -4.1549,  -2.3329,  -2.2277,\n",
      "          -5.3660,  -3.1991, -14.9025]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.154932022094727\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2210,  -1.4063,  -1.7167,  -5.8391,  -4.0090,  -2.7073,  -1.8432,\n",
      "          -4.9881,  -3.5954, -15.1936]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.988124847412109\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1582,  -1.6105,  -1.8962,  -6.2214,  -3.7972,  -2.9990,  -1.5222,\n",
      "          -3.7778,  -3.8781, -15.3618]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.878124237060547\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2563,  -1.8781,  -2.1028,  -6.4992,  -3.5552,  -3.2298,  -1.3294,\n",
      "          -2.6379,  -3.3664, -15.4454]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.5552477836608887\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5639,  -2.2529,  -2.3983,  -6.7682,  -2.6366,  -3.4840,  -1.3726,\n",
      "          -1.6854,  -2.9479, -15.5384]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  15.538382530212402\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0883,  -2.7693,  -2.8317,  -7.1103,  -1.9615,  -3.8343,  -1.7011,\n",
      "          -1.0723,  -2.7076, -14.9846]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  14.984597206115723\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6942,  -3.3277,  -3.3122,  -7.4648,  -1.5037,  -4.2112,  -2.1801,\n",
      "          -0.8349,  -2.5845, -13.8008]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.5036805868148804\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4846,  -4.0549,  -3.9693,  -7.9815,  -0.7147,  -4.7584,  -2.8934,\n",
      "          -1.1587,  -2.7246, -12.9318]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.484644889831543\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5231,  -4.7367,  -4.5890,  -8.4608,  -0.3806,  -5.2712,  -3.5913,\n",
      "          -1.7103,  -2.9113, -12.1631]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.591305732727051\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3160,  -5.0946,  -4.8921,  -8.6299,  -0.3226,  -5.4740,  -3.2257,\n",
      "          -2.0861,  -2.8556, -11.2083]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.086097240447998\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9213,  -5.1877,  -4.9367,  -8.5485,  -0.5700,  -5.4257,  -2.6924,\n",
      "          -1.5043,  -2.6127, -10.1146]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.936695098876953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5021, -5.1739, -4.1282, -8.3733, -1.1065, -5.2836, -2.1611, -1.0524,\n",
      "         -2.3445, -9.0279]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.1065452098846436\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3443, -5.3274, -3.5739, -8.3774, -1.2578, -5.3209, -1.9309, -1.0802,\n",
      "         -2.3332, -8.2111]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.211057662963867\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1257, -5.3248, -2.9513, -8.2368, -1.4584, -5.2136, -1.6882, -1.2263,\n",
      "         -2.2479, -6.6010]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.324820518493652\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9280, -4.4798, -2.3446, -8.0248, -1.7245, -5.0354, -1.5232, -1.5017,\n",
      "         -2.1613, -5.0667]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.5231748819351196\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0410, -3.9153, -2.0582, -8.0221, -2.2831, -5.0676, -0.9752, -2.1117,\n",
      "         -2.3536, -3.8775]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.877547264099121\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3120, -3.4991, -1.9735, -8.0969, -2.9380, -5.1781, -0.8419, -2.8327,\n",
      "         -2.6718, -2.1718]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.671823501586914\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8519, -3.3730, -2.2275, -8.3900, -3.7924, -5.5074, -1.2709, -3.7537,\n",
      "         -2.5178, -0.9449]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.227499485015869\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7061, -3.6126, -2.1131, -8.9812, -4.9054, -6.1339, -2.1946, -4.9283,\n",
      "         -2.7638, -0.4522]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.7637939453125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4163, -3.7724, -2.0245, -9.4372, -5.8365, -6.6231, -3.0336, -5.9153,\n",
      "         -2.2419, -0.3983]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.43716049194336\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8027, -3.6721, -1.7823, -8.8391, -6.4155, -6.8029, -3.5634, -6.5444,\n",
      "         -1.5860, -0.5786]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.6721348762512207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0564, -2.7425, -1.5906, -8.2005, -6.8379, -6.8655, -3.9618, -7.0120,\n",
      "         -1.0415, -1.0493]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.961782217025757\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2999, -1.9648, -1.5818, -7.6362, -7.2296, -6.9332, -3.5950, -7.4442,\n",
      "         -0.8137, -1.7387]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.933185577392578\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4778, -1.3262, -1.6838, -7.0836, -7.5380, -6.2207, -3.2404, -7.7890,\n",
      "         -0.8799, -2.4426]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.0836381912231445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5686, -0.8807, -1.8428, -5.7711, -7.7436, -5.5082, -2.8780, -8.0273,\n",
      "         -1.1628, -3.0674]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.743558883666992\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5366, -0.6784, -1.9888, -4.4751, -7.0751, -4.7531, -2.4774, -8.1258,\n",
      "         -1.5239, -3.5476]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.4774153232574463\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4834, -0.8544, -2.1961, -3.2894, -6.4465, -4.0522, -1.4054, -8.1874,\n",
      "         -1.9771, -3.9738]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.1961188316345215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6375, -1.5347, -1.9130, -2.4486, -6.0808, -3.6328, -0.8228, -8.4423,\n",
      "         -2.6831, -4.5704]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.4486231803894043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0030, -2.5350, -1.9932, -1.2388, -5.9773, -3.4987, -0.8509, -8.8960,\n",
      "         -3.5918, -5.3393]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.238823413848877\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0042, -4.1663, -2.8381, -0.2952, -6.5563, -4.0704, -1.8658, -9.9751,\n",
      "         -5.1000, -6.7055]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.100015163421631\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.0006,  -5.7412,  -3.7372,  -0.0953,  -7.1729,  -4.6918,  -2.9895,\n",
      "         -11.0410,  -5.8424,  -8.0308]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.691840171813965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.3801,  -6.6439,  -4.0468,  -0.0726,  -7.2108,  -4.0122,  -3.5211,\n",
      "         -11.4829,  -5.9951,  -8.7066]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.07264967262744904\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.7871,  -7.5228,  -4.4038,  -0.0655,  -7.3105,  -3.4784,  -4.0869,\n",
      "         -11.9459,  -6.1994,  -9.3802]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.06545758992433548\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.2102,  -8.3711,  -4.7910,  -0.0687,  -7.4573,  -3.0768,  -4.6655,\n",
      "         -12.4193,  -6.4414, -10.0434]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.665510654449463\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.9947,  -8.5386,  -4.5493,  -0.1645,  -6.9934,  -2.1523,  -3.8503,\n",
      "         -12.2490,  -6.0638, -10.0441]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.538623809814453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4789,  -7.6070,  -4.0178,  -0.5517,  -6.2544,  -1.0828,  -2.8102,\n",
      "         -11.7738,  -5.4036,  -9.7228]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.607049942016602\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.1536,  -6.1533,  -3.6919,  -1.4614,  -5.7295,  -0.5065,  -2.0577,\n",
      "         -11.4851,  -4.9514,  -9.5727]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  8.153631210327148\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.1701,  -4.8700,  -3.4413,  -2.4748,  -5.2834,  -0.4516,  -1.4996,\n",
      "         -11.2491,  -4.5734,  -9.4616]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.45155805349349976\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.5501,  -3.9852,  -3.5049,  -3.7143,  -5.1504,  -0.4019,  -1.4289,\n",
      "         -11.3017,  -4.5054,  -9.6267]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  11.301700592041016\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6918,  -2.9016,  -3.2839,  -4.5474,  -4.7341,  -0.5438,  -1.2433,\n",
      "         -10.2593,  -4.1512,  -9.4745]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.901646852493286\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9187, -1.2131, -3.1105, -5.3027, -4.3630, -1.0909, -1.2890, -9.3180,\n",
      "         -3.8407, -9.3348]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.0909079313278198\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7862, -0.4757, -3.5465, -6.5448, -4.5967, -1.6577, -2.0944, -9.0289,\n",
      "         -4.1350, -9.7674]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.134953498840332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6428,  -0.2516,  -3.9310,  -7.6345,  -4.7846,  -2.2767,  -2.8818,\n",
      "          -8.7387,  -3.6677, -10.1271]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.634456157684326\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1365,  -0.2514,  -3.9079,  -7.4944,  -4.5759,  -2.5246,  -3.2485,\n",
      "          -8.0933,  -2.8811, -10.0668]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.9078619480133057\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3533, -0.4953, -2.8085, -7.0299, -4.0569, -2.4674, -3.2691, -7.1736,\n",
      "         -1.8740, -9.6737]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.4673666954040527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7823, -1.2798, -1.9734, -6.7215, -3.7116, -1.8593, -3.4253, -6.4552,\n",
      "         -1.1861, -9.4291]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.721535682678223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5271, -2.4088, -1.5408, -5.9270, -3.6333, -1.6394, -3.8048, -6.0241,\n",
      "         -0.9996, -9.4234]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.804795503616333\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3589, -3.4969, -1.3173, -5.2176, -3.5867, -1.5866, -3.4189, -5.6421,\n",
      "         -1.0989, -9.4224]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.586590051651001\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3637, -4.5879, -1.4068, -4.6712, -3.6538, -1.0507, -3.1843, -5.3892,\n",
      "         -1.5149, -9.5100]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.4067727327346802\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5788, -5.7210, -1.0611, -4.3291, -3.8765, -0.9651, -3.1471, -5.3082,\n",
      "         -2.1896, -9.7321]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.147125244140625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7470, -6.6637, -0.9309, -3.9507, -4.0125, -1.0842, -2.3215, -5.1591,\n",
      "         -2.7972, -9.8520]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.3214869499206543\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0446,  -7.6135,  -1.2108,  -3.7240,  -4.2484,  -1.5365,  -1.0111,\n",
      "          -5.1294,  -3.4879, -10.0599]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  10.059905052185059\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6157, -8.7380, -1.9563, -3.8065, -4.7405, -2.3687, -0.3710, -5.3762,\n",
      "         -4.4007, -9.7790]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.738049507141113\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0351, -8.8848, -2.6199, -3.7829, -5.0757, -3.0716, -0.1938, -5.4879,\n",
      "         -5.1171, -9.4117]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.487912654876709\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9754, -8.5669, -2.8223, -3.3282, -4.9322, -3.2882, -0.1946, -4.3515,\n",
      "         -5.3164, -8.6310]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.630955696105957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4991, -7.8448, -2.6133, -2.5091, -4.3723, -3.0742, -0.3660, -2.9024,\n",
      "         -5.0633, -6.7591]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.7591471672058105\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0267, -7.1296, -2.4151, -1.7660, -3.8121, -2.8497, -0.9644, -1.5754,\n",
      "         -4.7744, -4.2814]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.5754116773605347\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4900, -7.4485, -3.1182, -2.0470, -4.1522, -3.5577, -2.6973, -0.4833,\n",
      "         -5.2406, -2.7825]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.557734489440918\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1792, -7.8900, -4.0685, -2.6727, -4.7441, -3.7254, -4.4947, -0.3624,\n",
      "         -6.0334, -1.8596]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.0334296226501465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6484, -8.1253, -4.7746, -3.1246, -5.1211, -3.7313, -5.9588, -0.6401,\n",
      "         -5.8698, -0.9804]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.774598598480225\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0531, -8.3126, -4.6370, -3.5392, -5.4404, -3.7293, -7.2544, -1.2801,\n",
      "         -5.6997, -0.4397]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.440358638763428\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2577, -8.3171, -4.3560, -3.7695, -4.8194, -3.5805, -8.2572, -1.9105,\n",
      "         -5.3846, -0.2615]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.9105013608932495\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1836, -8.0591, -3.8503, -3.7316, -4.0036, -3.2044, -8.8980, -1.5460,\n",
      "         -4.8417, -0.4021]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.85030198097229\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9282, -7.6264, -2.4524, -3.5088, -3.0557, -2.6885, -9.2729, -1.1809,\n",
      "         -4.1511, -0.8247]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.151073455810547\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9404, -7.4150, -1.3851, -3.4638, -2.2187, -2.4059, -9.7701, -1.2440,\n",
      "         -2.9595, -1.7627]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.2187466621398926\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.2613,  -7.5906,  -1.0359,  -3.8551,  -1.3687,  -2.6285, -10.5961,\n",
      "          -1.9173,  -2.3412,  -3.0290]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.590624809265137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6877,  -7.1323,  -1.1222,  -4.3568,  -0.9270,  -3.0152, -11.4735,\n",
      "          -2.7726,  -1.9870,  -4.3383]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.6876912117004395\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.2718,  -6.6411,  -1.3658,  -4.7389,  -0.7459,  -3.3199, -12.1846,\n",
      "          -3.5128,  -1.6872,  -5.4477]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  12.184588432312012\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7174,  -6.0162,  -1.5935,  -4.9059,  -0.7531,  -3.4371, -11.9017,\n",
      "          -4.0191,  -1.3662,  -6.2663]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.437107801437378\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0632,  -5.2939,  -1.7899,  -4.9004,  -0.9492,  -2.6784, -11.4856,\n",
      "          -4.3277,  -1.0985,  -6.8433]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  11.485594749450684\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3681,  -4.5288,  -1.9739,  -4.7824,  -1.2954,  -1.9265, -10.2581,\n",
      "          -4.4975,  -0.9779,  -7.2452]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.497452259063721\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7289, -3.8096, -2.2059, -4.6441, -1.7727, -1.3170, -9.1146, -3.8359,\n",
      "         -1.1003, -7.5694]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.809638023376465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2446, -2.4746, -2.5417, -4.5707, -2.3731, -1.0070, -8.1289, -3.3010,\n",
      "         -1.4928, -7.9056]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.4746320247650146\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2111, -0.9176, -3.2293, -4.8380, -3.3090, -1.3192, -7.5674, -3.1741,\n",
      "         -2.3330, -8.5345]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.5674028396606445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7339, -0.2886, -4.3517, -5.5581, -4.6525, -2.2679, -6.8046, -3.5660,\n",
      "         -3.6325, -9.5743]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.804589748382568\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1173,  -0.1491,  -5.2375,  -6.0748,  -5.7348,  -3.0629,  -5.2582,\n",
      "          -3.8066,  -4.6871, -10.3761]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.14913558959960938\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6622,  -0.0879,  -6.2068,  -6.7094,  -6.8794,  -3.9805,  -4.0371,\n",
      "          -4.2083,  -5.8110, -11.2658]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  11.265806198120117\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6231,  -0.1673,  -6.5326,  -6.7332,  -7.3623,  -4.2717,  -2.4020,\n",
      "          -4.0331,  -6.2766, -10.7856]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.276576995849609\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4488,  -0.7075,  -6.6686,  -6.5971,  -7.6392,  -4.3857,  -0.8374,\n",
      "          -3.7309,  -5.8212, -10.1947]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.6391777992248535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7758,  -2.0196,  -7.2529,  -6.9364,  -7.6028,  -4.9583,  -0.2072,\n",
      "          -3.9384,  -5.8741, -10.1235]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.93841552734375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9673, -3.1797, -7.6600, -7.1230, -7.4508, -5.3593, -0.1158, -3.2381,\n",
      "         -5.8041, -9.9398]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.9672675132751465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9685, -3.7957, -7.5673, -6.8321, -6.8548, -5.2643, -0.2232, -2.1786,\n",
      "         -5.2837, -9.3149]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.567311763763428\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9178, -4.1784, -6.5407, -6.3823, -6.1302, -4.9939, -0.7113, -1.1248,\n",
      "         -4.6301, -8.5636]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.993936538696289\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3163, -4.7724, -5.8553, -6.2165, -5.7173, -4.2653, -1.7445, -0.6685,\n",
      "         -4.2865, -8.1251]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.7445402145385742\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0513, -5.3954, -5.3222, -6.1505, -5.4299, -3.7013, -2.1556, -0.7412,\n",
      "         -4.0688, -7.8124]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.7411994934082031\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2234, -6.1168, -5.0028, -6.2497, -5.3313, -3.3684, -2.7667, -0.5538,\n",
      "         -4.0421, -7.6881]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.331336975097656\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3159, -6.4918, -4.4441, -6.0643, -4.2262, -2.8176, -3.0864, -0.5585,\n",
      "         -3.7545, -7.3003]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.444121360778809\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3821, -6.6190, -2.9870, -5.6875, -3.0302, -2.1534, -3.1958, -0.7975,\n",
      "         -3.3007, -6.7400]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.687463283538818\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6890, -6.7994, -1.7778, -4.6705, -2.0542, -1.7049, -3.3889, -1.4287,\n",
      "         -2.9835, -6.3012]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.688966155052185\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7420, -7.3319, -1.1855, -4.1309, -1.6401, -1.8028, -3.9564, -2.5531,\n",
      "         -3.1034, -6.2767]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.331899166107178\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9596, -7.1106, -0.9255, -3.6999, -1.4548, -2.0541, -4.5242, -3.6692,\n",
      "         -3.2866, -6.2987]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.4548417329788208\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3905, -7.0446, -1.1228, -3.4629, -0.8509, -2.5066, -5.1761, -4.8268,\n",
      "         -3.6112, -6.4527]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.044572353363037\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7663, -6.1684, -1.4669, -3.1943, -0.5468, -2.8951, -5.6887, -5.7969,\n",
      "         -3.8444, -6.5139]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.766334056854248\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2514, -5.2065, -1.7760, -2.8085, -0.5293, -3.1107, -5.9781, -6.4983,\n",
      "         -3.8952, -6.3955]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.8951964378356934\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6756, -4.1559, -1.9934, -2.3177, -0.7625, -3.1490, -6.0521, -6.9426,\n",
      "         -3.0481, -6.1018]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.9934086799621582\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3726, -3.3015, -1.6186, -2.0294, -1.3984, -3.2948, -6.2005, -7.4234,\n",
      "         -2.3994, -5.9189]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.3015222549438477\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4124, -1.9524, -1.5592, -1.9971, -2.2832, -3.5823, -6.4646, -7.9858,\n",
      "         -2.0096, -5.8852]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.0096006393432617\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9361, -1.1539, -1.9752, -2.3809, -3.4670, -4.1728, -7.0148, -8.8039,\n",
      "         -1.3496, -6.1682]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.172801494598389\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6622, -0.8185, -2.6043, -2.9458, -4.7062, -4.1354, -7.6611, -9.6908,\n",
      "         -1.0918, -6.5748]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.706230163574219\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2518,  -0.7279,  -3.1115,  -3.3789,  -4.9704,  -3.9985,  -8.1285,\n",
      "         -10.3745,  -0.9860,  -6.8270]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.7279427647590637\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9763,  -0.4305,  -3.7672,  -3.9600,  -5.3789,  -4.0541,  -8.7150,\n",
      "         -11.1556,  -1.3241,  -7.2203]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.054144859313965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3658,  -0.3669,  -4.0987,  -4.2210,  -5.4737,  -3.1140,  -8.9669,\n",
      "         -11.5827,  -1.5433,  -7.2987]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.36686351895332336\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.9148,  -0.2721,  -4.5987,  -4.6562,  -5.7512,  -2.4889,  -9.3827,\n",
      "         -12.1562,  -2.0830,  -7.5587]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.914809703826904\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3406,  -0.3991,  -4.7074,  -4.7060,  -5.6543,  -1.6373,  -9.4082,\n",
      "         -12.3235,  -2.3094,  -7.4441]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.340639591217041\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9744,  -0.8671,  -4.6730,  -4.6185,  -5.4306,  -0.8732,  -9.2920,\n",
      "         -12.3350,  -2.4456,  -7.2023]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.8670634627342224\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0451,  -1.1259,  -4.9131,  -4.8112,  -5.4964,  -0.7538,  -9.4516,\n",
      "         -12.6095,  -2.8946,  -7.2491]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.7538127303123474\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5623,  -1.8575,  -5.3954,  -5.2513,  -5.8193,  -0.5215,  -9.8558,\n",
      "         -13.1172,  -3.5992,  -7.5523]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.395408630371094\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1185,  -2.4704,  -4.9194,  -5.4911,  -5.9517,  -0.5844, -10.0593,\n",
      "         -13.4138,  -4.0929,  -7.6652]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.09285831451416\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7575,  -2.8869,  -4.2986,  -5.5125,  -5.8752,  -0.8486, -10.0450,\n",
      "         -13.4833,  -3.6329,  -7.5696]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.875238418579102\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5729,  -3.1046,  -3.5516,  -5.3366,  -4.8690,  -1.1990,  -9.8339,\n",
      "         -13.3476,  -3.0395,  -7.2857]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.336579322814941\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6165,  -3.1368,  -2.7038,  -4.2347,  -3.7719,  -1.5367,  -9.4470,\n",
      "         -13.0287,  -2.3427,  -6.8337]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  9.447037696838379\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9764,  -3.1298,  -1.9229,  -3.1853,  -2.7330,  -1.9290,  -8.2988,\n",
      "         -12.6734,  -1.7163,  -6.3595]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.9228599071502686\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9396,  -3.5238,  -0.9466,  -2.6395,  -2.2139,  -2.7559,  -7.6332,\n",
      "         -12.7217,  -1.6495,  -6.3019]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.75588321685791\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1607,  -4.1504,  -0.6099,  -2.4517,  -2.0777,  -3.0687,  -7.2843,\n",
      "         -13.0152,  -1.9777,  -6.5015]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.1606812477111816\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4404,  -4.5982,  -0.5876,  -2.2194,  -1.9201,  -3.2562,  -6.8426,\n",
      "         -13.1515,  -2.2448,  -6.5543]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.842591285705566\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4834,  -4.7769,  -0.7528,  -1.8600,  -1.6552,  -3.2210,  -5.4854,\n",
      "         -13.0422,  -2.3296,  -6.3710]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.3295674324035645\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4946,  -4.8944,  -1.2051,  -1.6038,  -1.5092,  -3.1686,  -4.2167,\n",
      "         -12.8942,  -1.7075,  -6.1575]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.7075191736221313\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7797,  -5.2590,  -2.0902,  -1.7777,  -1.7953,  -3.4053,  -3.3384,\n",
      "         -13.0143,  -0.8153,  -6.2202]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.7776601314544678\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2989,  -5.8371,  -3.2260,  -1.5562,  -2.4224,  -3.8884,  -2.8193,\n",
      "         -13.3682,  -0.5753,  -6.5240]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.8884239196777344\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6446,  -6.2283,  -4.1470,  -1.3838,  -2.9217,  -3.4818,  -2.2640,\n",
      "         -13.5555,  -0.6308,  -6.6672]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  13.555461883544922\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7885,  -6.4075,  -4.8139,  -1.2424,  -3.2369,  -2.9635,  -1.6657,\n",
      "         -12.7599,  -0.8870,  -6.6226]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.407548904418945\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8339,  -5.7424,  -5.3303,  -1.2417,  -3.4599,  -2.4441,  -1.1753,\n",
      "         -11.9534,  -1.3219,  -6.4934]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.493378162384033\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8185,  -5.0838,  -5.7369,  -1.3960,  -3.6221,  -1.9773,  -0.8979,\n",
      "         -11.1651,  -1.8420,  -5.5705]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.736910343170166\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7069,  -4.3919,  -5.2502,  -1.6173,  -3.6845,  -1.5540,  -0.8430,\n",
      "         -10.3517,  -2.3201,  -4.6389]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.6388702392578125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5143, -3.6791, -4.7171, -1.8669, -3.6608, -1.2276, -1.0097, -9.5207,\n",
      "         -2.7222, -2.9678]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.6607766151428223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4100, -3.1173, -4.3051, -2.2691, -2.9749, -1.2077, -1.4875, -8.8336,\n",
      "         -3.1926, -1.5626]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.19260835647583\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6025, -2.9217, -4.2219, -2.9868, -2.6731, -1.6845, -2.3607, -8.4928,\n",
      "         -3.2070, -0.7311]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.6730589866638184\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9551, -2.9573, -4.3299, -3.8428, -1.8839, -2.4205, -3.3880, -8.3579,\n",
      "         -3.4207, -0.5128]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.357889175415039\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1737, -2.9239, -4.3332, -4.5259, -1.1823, -3.0439, -4.2339, -7.3454,\n",
      "         -3.5327, -0.6577]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.333191394805908\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2917, -2.8505, -3.5147, -5.0661, -0.6951, -3.5568, -4.9232, -6.3510,\n",
      "         -3.5713, -1.0894]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.06605339050293\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2927, -2.7184, -2.6912, -4.6959, -0.5183, -3.9307, -5.4404, -5.3483,\n",
      "         -3.5174, -1.6189]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.3482818603515625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1367, -2.4877, -1.8399, -4.2088, -0.6398, -4.1210, -5.7488, -3.5060,\n",
      "         -3.3295, -2.0821]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.839881181716919\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3167, -2.6578, -0.7625, -4.0976, -1.4554, -4.6204, -6.3449, -2.1869,\n",
      "         -3.5021, -2.9079]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.62044095993042\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8487, -3.2292, -0.5082, -4.3762, -2.7288, -4.7163, -7.2494, -1.4539,\n",
      "         -4.0455, -4.0584]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.5082085132598877\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7174, -4.1607, -0.3697, -5.0242, -4.3115, -5.1967, -8.4520, -1.3657,\n",
      "         -4.9350, -5.4949]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.717441558837891\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4416, -4.6761, -0.4269, -5.2777, -5.4115, -5.2984, -9.2000, -1.1525,\n",
      "         -5.4061, -6.4564]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.441570281982422\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1235, -4.7950, -0.6129, -5.1577, -6.0533, -5.0415, -9.5216, -0.8575,\n",
      "         -5.4815, -6.9714]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.04145622253418\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6641, -4.6314, -0.9064, -4.7771, -6.3562, -3.8145, -9.5344, -0.6491,\n",
      "         -5.2755, -7.1589]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.275472640991211\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1993, -4.3222, -1.3018, -4.2716, -6.4610, -2.5565, -9.3768, -0.7033,\n",
      "         -4.2087, -7.1592]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.5564584732055664\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3009, -4.3941, -2.2005, -4.1675, -6.8971, -1.1003, -9.5755, -1.4811,\n",
      "         -3.5994, -7.5006]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.4811241626739502\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2773,  -5.0565,  -3.6806,  -4.6738,  -7.8789,  -0.6184, -10.3429,\n",
      "          -2.1619,  -3.6586,  -8.3968]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.277292251586914\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8667,  -5.7874,  -5.1618,  -5.2665,  -8.8930,  -0.7045, -11.1636,\n",
      "          -2.9949,  -3.8602,  -9.3337]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  11.163626670837402\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5965,  -6.2436,  -6.2957,  -5.5999,  -9.6021,  -0.9351, -10.9626,\n",
      "          -3.5801,  -3.8525,  -9.9732]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.8525404930114746\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4972,  -6.4024,  -7.0646,  -5.6494,  -9.9871,  -1.1726, -10.5281,\n",
      "          -3.8755,  -2.8941, -10.2956]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.064647197723389\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5931,  -6.2938,  -6.7593,  -5.4438, -10.0811,  -1.3571,  -9.8841,\n",
      "          -3.9050,  -1.8178, -10.3332]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.759328365325928\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0069,  -6.1277,  -5.6760,  -5.1924, -10.0961,  -1.6393,  -9.2345,\n",
      "          -3.8777,  -0.8952, -10.2973]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.676037311553955\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7132,  -6.0509,  -4.0402,  -5.0412, -10.1808,  -2.1047,  -8.7208,\n",
      "          -3.9405,  -0.4281, -10.3362]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.1046576499938965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4399,  -5.9447,  -2.5413,  -4.8712, -10.2182,  -1.8506,  -8.2195,\n",
      "          -3.9735,  -0.4346, -10.3324]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  10.332423210144043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0967,  -5.7907,  -1.1894,  -4.6636, -10.1916,  -1.6748,  -7.7080,\n",
      "          -3.9578,  -0.8419,  -9.5224]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  9.522429466247559\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9766,  -5.9103,  -0.4531,  -4.7397, -10.4236,  -1.9074,  -7.5037,\n",
      "          -4.2146,  -1.7714,  -8.3086]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.7713855504989624\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8260,  -6.0634,  -0.3034,  -4.8584, -10.6760,  -2.2674,  -7.3636,\n",
      "          -4.5009,  -2.0591,  -7.2592]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.059131383895874\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3308,  -5.9374,  -0.4467,  -4.7055, -10.6376,  -2.4007,  -6.9722,\n",
      "          -4.5018,  -1.4327,  -6.0491]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.937373161315918\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5904,  -4.8817,  -0.8468,  -4.3760, -10.4045,  -2.3875,  -6.4219,\n",
      "          -4.3128,  -0.8396,  -4.7626]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.3875057697296143\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8505,  -3.9605,  -1.5454,  -4.1127, -10.2184,  -1.7446,  -5.9513,\n",
      "          -4.1770,  -0.6361,  -3.6343]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.21835994720459\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0537, -3.1121, -2.2978, -3.8548, -9.2718, -1.2584, -5.4963, -4.0336,\n",
      "         -0.7951, -2.6048]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.854769706726074\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2811, -2.4241, -3.0920, -2.9243, -8.4623, -1.0681, -5.1324, -3.9612,\n",
      "         -1.3010, -1.7756]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.4241108894348145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7265, -1.3671, -4.0798, -2.3663, -7.9727, -1.3835, -5.0484, -4.1504,\n",
      "         -2.1889, -1.3945]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.726500034332275\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6004, -0.7991, -5.1755, -2.1289, -7.7260, -2.0419, -5.1713, -4.5271,\n",
      "         -3.2617, -1.4302]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.128908395767212\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5948, -0.7298, -6.2733, -1.3579, -7.6111, -2.8352, -5.3931, -4.9817,\n",
      "         -4.3618, -1.7477]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.393104553222656\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5335, -0.9690, -7.2059, -0.8010, -7.4508, -3.5347, -4.8008, -5.3393,\n",
      "         -5.3042, -2.1063]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.205927848815918\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3475, -1.3347, -7.1776, -0.5074, -7.1750, -4.0537, -4.1417, -5.5332,\n",
      "         -6.0245, -2.3882]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.533233642578125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9218, -1.6003, -6.8932, -0.4383, -6.6678, -4.2742, -3.3005, -4.6621,\n",
      "         -6.4154, -2.4511]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.415440559387207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2572, -1.7064, -6.3547, -0.5788, -5.9288, -4.1996, -2.2871, -3.6020,\n",
      "         -5.7745, -2.2890]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.2889657020568848\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7021, -1.9765, -5.9106, -1.1662, -5.3050, -4.1828, -1.4894, -2.7085,\n",
      "         -5.2391, -1.5122]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.9765193462371826\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4806, -1.8501, -5.7844, -2.2009, -5.0187, -4.4504, -1.2097, -2.2282,\n",
      "         -5.0325, -1.2488]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.8500831127166748\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4421, -1.2653, -5.8260, -3.3689, -4.9187, -4.8528, -1.3316, -2.0339,\n",
      "         -5.0039, -1.3783]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.918688774108887\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3796, -0.9114, -5.8291, -4.4101, -4.0516, -5.1842, -1.6005, -1.9259,\n",
      "         -4.9465, -1.6463]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.9258915185928345\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3931, -0.9514, -5.8949, -5.4177, -3.3446, -5.5476, -2.0529, -1.2165,\n",
      "         -4.9607, -2.0921]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.2164654731750488\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8189, -1.6780, -6.3607, -6.7328, -3.1390, -6.2822, -2.9599, -0.4302,\n",
      "         -5.3830, -2.9902]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.43023425340652466\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8639, -3.1263, -7.4372, -8.5738, -3.6420, -7.6008, -4.4708, -0.1036,\n",
      "         -6.4224, -4.4922]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.641977310180664\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3722, -4.0282, -7.9723, -9.7969, -2.9367, -8.3537, -5.4051, -0.0868,\n",
      "         -6.9247, -5.4183]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.9366607666015625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4289,  -4.4514,  -8.0521, -10.4962,  -1.2005,  -8.6297,  -5.8475,\n",
      "          -0.3879,  -6.9755,  -5.8533]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.428920745849609\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.1435,  -5.2262,  -8.5094, -11.5109,  -0.2465,  -9.2635,  -6.6332,\n",
      "          -1.5731,  -7.4070,  -6.6324]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.2465001344680786\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6935,  -6.7334,  -9.7268, -13.2302,  -0.0309, -10.6398,  -8.1471,\n",
      "          -3.6075,  -8.6015,  -8.1403]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.7333807945251465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6400e+00, -6.8013e+00, -1.0273e+01, -1.4229e+01, -1.0252e-02,\n",
      "         -1.1329e+01, -8.9608e+00, -4.9109e+00, -9.1276e+00, -8.9487e+00]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.960834503173828\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8789e+00, -6.1495e+00, -1.0052e+01, -1.4414e+01, -1.0196e-02,\n",
      "         -1.1236e+01, -8.2383e+00, -5.3764e+00, -8.8875e+00, -8.9629e+00]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.878890037536621\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7783,  -4.8663,  -9.1544, -13.8829,  -0.0392, -10.4551,  -6.8902,\n",
      "          -5.1015,  -7.9737,  -8.2779]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.778273582458496\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9732,  -3.5014,  -8.1314, -13.1896,  -0.5513,  -9.5364,  -5.4619,\n",
      "          -4.6435,  -6.9359,  -7.4463]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.973203182220459\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.0495,  -4.3413,  -9.2569, -14.6119,  -3.4789, -10.7557,  -6.2254,\n",
      "          -6.2853,  -8.0487,  -8.7444]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.225407600402832\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.8935e-03, -5.2112e+00, -1.0374e+01, -1.5997e+01, -6.2415e+00,\n",
      "         -1.1958e+01, -6.2808e+00, -7.8689e+00, -9.1548e+00, -1.0017e+01]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  10.017263412475586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.0779e-03, -5.3225e+00, -1.0705e+01, -1.6567e+01, -8.0546e+00,\n",
      "         -1.2364e+01, -5.6562e+00, -8.6193e+00, -9.4750e+00, -9.7397e+00]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  12.363886833190918\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.0219,  -4.7339, -10.3097, -16.3890,  -8.9950, -11.3106,  -4.4039,\n",
      "          -8.6027,  -9.0709,  -8.7972]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.021878784522414207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.0527,  -4.2451,  -9.9887, -16.2630,  -9.8766, -10.3968,  -3.3199,\n",
      "          -8.6226,  -8.7417,  -7.9834]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.0526629276573658\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.1151,  -3.8868,  -9.7709, -16.2208, -10.7416,  -9.6452,  -2.4418,\n",
      "          -8.7118,  -8.5167,  -7.3220]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.741642951965332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3839,  -3.1600,  -9.1553, -15.7632, -10.3660,  -8.5490,  -1.2960,\n",
      "          -8.3727,  -7.8946,  -6.3075]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  15.763228416442871\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1492,  -2.5785,  -8.6427, -14.6345, -10.0693,  -7.6036,  -0.5088,\n",
      "          -8.1092,  -7.3764,  -5.4369]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.5785369873046875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2248,  -1.5324,  -8.3433, -13.7803,  -9.9643,  -6.9148,  -0.4074,\n",
      "          -8.0343,  -7.0723,  -4.8183]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.914754867553711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2452,  -0.7260,  -8.0492, -12.9865,  -9.8451,  -5.5463,  -0.7829,\n",
      "          -7.9424,  -6.7744,  -4.2427]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.942376136779785\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1779,  -0.3450,  -7.7708, -12.2578,  -9.7239,  -4.3031,  -1.4444,\n",
      "          -7.0626,  -6.4931,  -3.7213]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.303053379058838\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8465,  -0.3440,  -7.3382, -11.4194,  -9.4327,  -2.2911,  -2.0319,\n",
      "          -6.0888,  -6.0587,  -3.0877]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  11.419382095336914\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6012,  -1.0130,  -7.0963, -10.0570,  -9.3176,  -0.6997,  -2.8049,\n",
      "          -5.3608,  -5.8163,  -2.6986]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.360802173614502\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8428, -2.4426, -7.4385, -9.3898, -9.7735, -0.1869, -4.1052, -4.4904,\n",
      "         -6.1596, -2.9583]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.186879500746727\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4210,  -4.2535,  -8.2064,  -9.2484, -10.6434,  -0.0612,  -5.7476,\n",
      "          -4.1747,  -6.9297,  -3.6905]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  8.421043395996094\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.5683,  -5.3326,  -8.3360,  -8.5590, -10.8646,  -0.0675,  -6.6668,\n",
      "          -3.3404,  -7.0617,  -3.8065]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.8064863681793213\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.1783,  -5.7850,  -7.9301,  -7.4156, -10.5411,  -0.2232,  -6.9727,\n",
      "          -2.0939,  -6.6584,  -2.6553]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.658396244049072\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.7578,  -6.1252,  -7.4954,  -6.3170, -10.1803,  -0.8669,  -7.1794,\n",
      "          -0.9985,  -5.5085,  -1.6019]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.179351329803467\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.7034,  -6.7572,  -7.4284,  -5.6530, -10.1794,  -2.0715,  -6.9490,\n",
      "          -0.6244,  -4.8000,  -1.1287]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.757169246673584\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.5999,  -6.5317,  -7.3135,  -5.0029, -10.1237,  -3.1916,  -6.6873,\n",
      "          -0.6512,  -4.1130,  -0.8904]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.1916310787200928\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.2705, -6.0932, -6.9741, -4.1861, -9.8370, -3.2733, -6.2161, -0.8455,\n",
      "         -3.2696, -0.7473]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.8455392718315125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0641, -5.7898, -6.7588, -3.5519, -9.6687, -3.4637, -5.8830, -0.6647,\n",
      "         -2.6273, -1.0631]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.789818286895752\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6788, -4.5833, -6.3658, -2.8025, -9.3170, -3.4574, -5.3851, -0.7024,\n",
      "         -1.9008, -1.4061]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.678760528564453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5421, -3.4230, -5.9318, -2.0924, -8.9191, -3.3930, -4.8586, -1.0401,\n",
      "         -1.2729, -1.8171]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.931784152984619\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5892, -2.4701, -4.8637, -1.6147, -8.6286, -3.4269, -4.4582, -1.6867,\n",
      "         -0.9772, -2.3769]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.458209991455078\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8117, -1.7476, -3.9811, -1.4094, -8.4406, -3.5541, -3.4417, -2.4863,\n",
      "         -1.0553, -3.0239]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.554140329360962\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1934, -1.2917, -3.2664, -1.4766, -8.3375, -3.0388, -2.6162, -3.3372,\n",
      "         -1.4424, -3.7092]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.0388002395629883\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7833, -1.2014, -2.7689, -1.8285, -8.3624, -2.0146, -2.0443, -4.2486,\n",
      "         -2.0787, -4.4622]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.078721523284912\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6326, -1.5165, -2.5425, -2.4423, -8.5597, -1.3622, -1.7997, -5.2551,\n",
      "         -2.1957, -5.3235]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.7997068166732788\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7455, -2.1595, -2.5950, -3.2587, -8.9348, -1.1550, -1.1625, -6.3629,\n",
      "         -2.5785, -6.3001]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.745482921600342\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2361, -2.8756, -2.7501, -4.0751, -9.3246, -1.2454, -0.8717, -7.4136,\n",
      "         -3.0296, -7.2328]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.7500672340393066\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8038, -3.5125, -2.1419, -4.7737, -9.6261, -1.4829, -0.8691, -8.3108,\n",
      "         -3.4212, -8.0238]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.626148223876953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4375, -4.0141, -1.5881, -5.3152, -9.0659, -1.7648, -1.0820, -9.0248,\n",
      "         -3.7033, -8.6423]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.703310966491699\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2319, -4.4346, -1.1977, -5.7621, -8.5169, -2.0964, -1.4791, -9.6234,\n",
      "         -3.2123, -9.1549]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.51693344116211\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1682,  -4.7361,  -0.9861,  -6.0810,  -7.2039,  -2.3970,  -1.9186,\n",
      "         -10.0766,  -2.7133,  -9.5306]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.736108779907227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1998,  -4.1443,  -0.9426,  -6.2380,  -5.8903,  -2.6008,  -2.2908,\n",
      "         -10.3528,  -2.1797,  -9.7371]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.6007602214813232\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3719,  -3.5528,  -1.1242,  -6.3106,  -4.6391,  -2.0529,  -2.6303,\n",
      "         -10.5312,  -1.7101,  -9.8527]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.630303382873535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7232,  -3.0575,  -1.5467,  -6.3936,  -3.5358,  -1.6675,  -2.2679,\n",
      "         -10.7082,  -1.4337,  -9.9732]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  10.708168029785156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1787,  -2.6584,  -2.0984,  -6.4818,  -2.5760,  -1.4673,  -2.0299,\n",
      "         -10.0982,  -1.3685, -10.0939]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.368477463722229\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8907,  -2.5722,  -2.9083,  -6.7838,  -1.9893,  -1.6730,  -2.1338,\n",
      "          -9.7704,  -0.9958, -10.4241]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.770416259765625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5446,  -2.5243,  -3.6517,  -7.0300,  -1.5352,  -1.9655,  -2.2878,\n",
      "          -8.6732,  -0.8989, -10.6947]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.8989382982254028\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3724,  -2.7587,  -4.5589,  -7.4707,  -1.5038,  -2.5473,  -2.7197,\n",
      "          -7.9038,  -0.6049, -11.1567]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.5473098754882812\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.9846,  -2.8745,  -5.2416,  -7.7258,  -1.4974,  -2.2717,  -3.0151,\n",
      "          -7.0691,  -0.5902, -11.4307]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.98457670211792\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5923,  -2.7837,  -5.6234,  -7.7190,  -1.4201,  -1.8602,  -3.0803,\n",
      "          -6.0813,  -0.7372, -11.4405]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.8601715564727783\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2986,  -2.8001,  -6.0223,  -7.7657,  -1.5814,  -0.9425,  -3.2255,\n",
      "          -5.2460,  -1.2645, -11.5018]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.9424705505371094\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6262,  -3.4422,  -6.9657,  -8.3903,  -2.4608,  -0.2661,  -3.9678,\n",
      "          -5.0802,  -2.5237, -12.1393]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.5236659049987793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8711,  -3.9872,  -7.7589,  -8.8960,  -3.2589,  -0.1459,  -4.5933,\n",
      "          -4.8789,  -2.9413, -12.6564]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.9413411617279053\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6565,  -4.0510,  -8.0328,  -8.9109,  -3.5653,  -0.2097,  -4.7234,\n",
      "          -4.2629,  -2.2024, -12.6814]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.656537055969238\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4384,  -3.7982,  -7.9566,  -8.6012,  -3.5389,  -0.5159,  -4.5238,\n",
      "          -3.3960,  -1.2925, -12.3807]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.956559658050537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4091,  -3.6320,  -7.1833,  -8.3672,  -3.5815,  -1.2566,  -4.3971,\n",
      "          -2.6864,  -0.7139, -12.1548]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.397063255310059\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6625,  -3.6185,  -6.6040,  -8.2732,  -3.7570,  -2.2405,  -3.6704,\n",
      "          -2.2171,  -0.6583, -12.0679]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.6184780597686768\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1454,  -2.9062,  -6.1038,  -8.2092,  -3.9526,  -3.2219,  -3.0553,\n",
      "          -1.9001,  -0.9971, -12.0100]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  12.00997543334961\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9107,  -2.3104,  -5.6600,  -8.1568,  -4.1481,  -4.1388,  -2.5412,\n",
      "          -1.7366,  -1.5696, -11.2049]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.1480913162231445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9587,  -1.8210,  -5.2367,  -8.0834,  -3.5695,  -4.9493,  -2.1101,\n",
      "          -1.7008,  -2.2068, -10.4536]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.2068142890930176\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2785, -1.5047, -4.8640, -8.0221, -3.0739, -5.6886, -1.8160, -1.8159,\n",
      "         -2.1510, -9.7817]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.8640456199646\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7088, -1.3293, -3.7324, -7.9118, -2.6065, -6.3015, -1.6161, -1.9915,\n",
      "         -2.1281, -9.1214]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.911847114562988\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1821, -1.3249, -2.6887, -7.0008, -2.1976, -6.8121, -1.5404, -2.2139,\n",
      "         -2.1495, -8.4843]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.1495165824890137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7796, -1.6090, -1.8908, -6.2722, -2.0027, -7.3636, -1.7218, -2.5909,\n",
      "         -1.6329, -8.0017]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.7795910835266113\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7325, -2.0946, -1.3670, -5.6990, -2.0087, -7.9423, -2.0988, -3.0705,\n",
      "         -1.3879, -7.6491]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.7324557304382324\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0672, -2.6608, -1.1237, -5.2230, -2.1509, -8.5011, -2.5666, -3.5763,\n",
      "         -1.3818, -7.3693]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.369303226470947\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5041, -3.1690, -1.0948, -4.7451, -2.3118, -8.9509, -2.9912, -4.0003,\n",
      "         -1.5012, -6.3084]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.000288009643555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0892, -3.5927, -1.2542, -4.2563, -2.4651, -9.2910, -3.3456, -3.5480,\n",
      "         -1.7017, -5.2893]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.701737403869629\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9990, -4.0401, -1.6567, -3.8725, -2.7115, -9.6426, -3.7362, -3.2086,\n",
      "         -1.3478, -4.4209]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.040063381195068\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0946, -3.6303, -2.0785, -3.4594, -2.8991, -9.8757, -4.0221, -2.8511,\n",
      "         -1.1297, -3.5644]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.0946438312530518\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8578,  -3.4281,  -2.6993,  -3.2589,  -3.2561, -10.2329,  -4.4400,\n",
      "          -2.7216,  -1.3096,  -2.9619]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  10.232866287231445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8263, -3.1523, -3.1908, -2.9902, -3.4884, -9.7276, -4.7073, -2.5386,\n",
      "         -1.5450, -2.3408]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.9902095794677734\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0723, -2.9010, -3.6297, -1.9832, -3.6858, -9.2381, -4.9200, -2.4011,\n",
      "         -1.8736, -1.8201]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.401108980178833\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6942, -2.8745, -4.2038, -1.3414, -4.0410, -8.9563, -5.2760, -1.7265,\n",
      "         -2.4374, -1.6334]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.7264721393585205\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7350, -3.2436, -5.0830, -1.3162, -4.7250, -9.0537, -5.9514, -0.8321,\n",
      "         -3.3580, -1.9647]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.358022689819336\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8136, -3.7005, -5.9750, -1.5960, -5.4433, -9.2372, -6.6571, -0.4622,\n",
      "         -3.5982, -2.4654]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.6571197509765625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5447, -3.8745, -6.5243, -1.7484, -5.8373, -9.1466, -6.2956, -0.3642,\n",
      "         -3.5780, -2.7251]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.29561185836792\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8301, -3.6663, -6.6397, -1.6394, -5.8140, -8.6847, -4.8547, -0.4352,\n",
      "         -3.1993, -2.6284]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.43522757291793823\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2601, -3.6651, -6.9118, -1.8584, -5.9626, -8.4363, -3.7303, -0.3926,\n",
      "         -3.0545, -2.7637]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.260149002075195\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6362, -3.3752, -6.8498, -1.8680, -5.7904, -7.9049, -2.4277, -0.5694,\n",
      "         -2.6496, -2.6257]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.375216245651245\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0833, -2.4000, -6.7969, -1.9980, -5.6398, -7.4288, -1.3221, -1.1679,\n",
      "         -2.3373, -2.5588]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.558800220489502\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9096, -1.9013, -7.0623, -2.5320, -5.8190, -7.3126, -0.8362, -2.2594,\n",
      "         -2.4369, -2.1088]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.108778238296509\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9780, -1.7739, -7.5127, -3.2849, -6.1933, -7.4193, -0.9303, -3.5337,\n",
      "         -2.7993, -1.2501]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.419282913208008\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0803, -1.8126, -7.9460, -4.0193, -6.5593, -6.8340, -1.3340, -4.7312,\n",
      "         -3.1962, -0.7217]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.7217204570770264\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5910, -2.3754, -8.7431, -5.1011, -7.2966, -6.7144, -2.2990, -6.2230,\n",
      "         -3.9894, -0.2641]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.98941707611084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7938, -2.6870, -9.1967, -5.8157, -7.6967, -6.3433, -2.9780, -7.3035,\n",
      "         -3.7436, -0.1707]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  9.196732521057129\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4737, -2.5097, -8.3437, -5.9529, -7.5488, -5.5019, -3.1185, -7.7686,\n",
      "         -3.0305, -0.2145]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.548849582672119\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7892, -2.0062, -7.1715, -5.6742, -6.2655, -4.3428, -2.8735, -7.7833,\n",
      "         -2.0183, -0.4557]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.018296241760254\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4335, -1.8975, -6.3611, -5.6705, -5.3559, -3.5530, -2.9393, -8.0415,\n",
      "         -0.7392, -1.3923]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.7391623258590698\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0866, -2.8617, -6.5832, -6.6203, -5.4909, -3.8126, -3.9883, -9.2248,\n",
      "         -0.1694, -3.3724]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.08662748336792\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8198,  -3.6124,  -6.6241,  -7.3165,  -5.4553,  -3.9020,  -4.7865,\n",
      "         -10.1302,  -0.0947,  -5.0211]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.901992082595825\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0877,  -3.8012,  -6.1545,  -7.4365,  -4.9192,  -2.7809,  -5.0040,\n",
      "         -10.4382,  -0.1615,  -6.0033]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.91918420791626\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1635,  -3.6905,  -5.4361,  -7.2478,  -3.4016,  -1.5181,  -4.9077,\n",
      "         -10.4183,  -0.5212,  -6.5924]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.4015750885009766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7657,  -3.9625,  -5.1454,  -7.4315,  -1.6747,  -0.8898,  -5.1794,\n",
      "         -10.7533,  -1.6135,  -7.4768]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.431463718414307\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0118,  -4.7049,  -5.3713,  -7.3058,  -0.7424,  -1.0994,  -5.9115,\n",
      "         -11.5383,  -3.2199,  -8.7569]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.75687026977539\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4308,  -5.4827,  -5.6809,  -7.2958,  -0.3599,  -1.6276,  -6.6754,\n",
      "         -12.3479,  -4.7972,  -9.2590]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.295806884765625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5932,  -5.9090,  -5.6850,  -6.2412,  -0.2568,  -1.9654,  -7.0869,\n",
      "         -12.7995,  -5.9460,  -9.4339]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  9.433924674987793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3547,  -5.8571,  -5.2535,  -4.8553,  -0.2988,  -1.9315,  -7.0203,\n",
      "         -12.7685,  -6.5445,  -8.4062]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.253482341766357\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8603,  -5.4656,  -3.7688,  -3.2664,  -0.5364,  -1.6570,  -6.6141,\n",
      "         -12.3935,  -6.7374,  -7.1340]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.46557092666626\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5227,  -4.3675,  -2.4465,  -1.8623,  -1.1776,  -1.5427,  -6.2464,\n",
      "         -12.0531,  -6.9092,  -5.9862]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  12.053115844726562\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7054,  -3.7200,  -1.6530,  -1.0499,  -2.3135,  -1.9237,  -6.2487,\n",
      "         -11.2999,  -7.3964,  -5.2864]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.653004765510559\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4620,  -3.6181,  -0.7947,  -1.0522,  -3.8725,  -2.8339,  -6.7153,\n",
      "         -11.0848,  -8.2987,  -5.1231]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.298694610595703\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2706,  -3.6131,  -0.4295,  -1.3909,  -5.3583,  -3.7620,  -7.2030,\n",
      "         -10.9579,  -8.4744,  -5.0473]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.203012943267822\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7627,  -3.3659,  -0.3279,  -1.6253,  -6.4367,  -4.3514,  -6.6358,\n",
      "         -10.5806,  -8.3698,  -4.7209]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.3658528327941895\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8968, -2.1004, -0.4516, -1.6629, -7.0835, -4.5658, -5.8005, -9.9153,\n",
      "         -7.9502, -4.1080]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.1080427169799805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9853, -1.0054, -0.9926, -1.7966, -7.6197, -4.7195, -5.0039, -9.2697,\n",
      "         -7.5259, -2.7756]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.0054142475128174\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8242, -0.2952, -2.5029, -2.7912, -8.8490, -5.6103, -5.0375, -9.4342,\n",
      "         -7.8902, -2.3684]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.29518455266952515\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.2206,  -0.1012,  -4.5595,  -4.3696, -10.5912,  -7.0503,  -5.7079,\n",
      "         -10.2178,  -8.8538,  -2.7071]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.707937240600586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.9763,  -0.0974,  -5.9160,  -5.2976, -11.6569,  -7.8445,  -5.0702,\n",
      "         -10.4203,  -9.2184,  -2.5589]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  9.21841812133789\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0833,  -0.1919,  -6.5654,  -5.5628, -12.0424,  -7.9857,  -3.9265,\n",
      "         -10.0284,  -8.2715,  -1.9092]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.271456718444824\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8395,  -0.5443,  -6.8105,  -5.4640, -12.0488,  -7.7724,  -2.5706,\n",
      "          -9.3349,  -6.3817,  -1.0946]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.810476303100586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6984,  -1.3658,  -6.3592,  -5.4559, -12.1323,  -7.6583,  -1.4842,\n",
      "          -8.7882,  -4.7590,  -0.6898]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.759029388427734\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.7453,  -2.4663,  -6.1271,  -5.6251, -12.3805,  -7.7290,  -0.8477,\n",
      "          -8.4691,  -2.7838,  -0.8740]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.7838072776794434\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.2249,  -3.9562,  -6.3562,  -6.2166, -13.0405,  -8.2294,  -1.0298,\n",
      "          -8.6184,  -0.7947,  -1.7886]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.229384422302246\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4818,  -6.1366,  -7.3884,  -7.5754, -14.4594,  -8.7901,  -2.2839,\n",
      "          -9.5775,  -0.1439,  -3.5619]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.2839467525482178\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.5307,  -8.0185,  -8.2353,  -8.7164, -15.6540,  -9.2121,  -2.6641,\n",
      "         -10.3582,  -0.0798,  -5.0969]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.212071418762207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.9025,  -9.1405,  -8.4253,  -9.1710, -16.1569,  -8.3091,  -2.4851,\n",
      "         -10.4884,  -0.0908,  -5.9109]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.09077605605125427\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.2902, -10.2039,  -8.6495,  -9.6336, -16.6627,  -7.5492,  -2.4389,\n",
      "         -10.6586,  -0.0936,  -6.6989]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.633556365966797\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.0796, -10.6017,  -8.2917,  -8.7147, -16.5584,  -6.3055,  -1.9022,\n",
      "         -10.2521,  -0.1656,  -6.8495]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  16.55835723876953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.4856, -10.5555,  -7.5653,  -7.4831, -15.3178,  -4.7825,  -1.1253,\n",
      "          -9.4817,  -0.4088,  -6.5816]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  9.485564231872559\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.1189, -10.3967,  -6.7944,  -6.2573, -14.0835,  -3.2999,  -0.5497,\n",
      "          -8.6708,  -0.9664,  -6.2242]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.224155426025391\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8486, -10.2137,  -6.0611,  -5.1150, -12.9322,  -1.9511,  -0.4193,\n",
      "          -7.9008,  -1.6896,  -5.1139]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  10.213730812072754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.7189,  -9.3230,  -5.4161,  -4.1046, -11.9089,  -0.8517,  -0.8017,\n",
      "          -7.2212,  -2.4813,  -4.1321]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.801691472530365\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0834,  -8.9003,  -5.2180,  -3.5869, -11.3668,  -0.5460,  -1.1159,\n",
      "          -6.9892,  -3.6311,  -3.6395]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.5869147777557373\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3646,  -8.3689,  -4.8927,  -2.2190, -10.7278,  -0.5331,  -1.4903,\n",
      "          -6.6301,  -4.5337,  -3.0646]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.0646214485168457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7943,  -7.9583,  -4.6732,  -1.1391, -10.2202,  -1.0071,  -2.0619,\n",
      "          -6.3756,  -5.4216,  -1.9035]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.0619163513183594\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6487,  -7.9406,  -4.8344,  -0.7667, -10.1149,  -2.0457,  -2.2815,\n",
      "          -6.4995,  -6.5761,  -1.3213]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.499514579772949\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5223,  -7.9111,  -4.9717,  -0.7774, -10.0062,  -3.0592,  -2.5408,\n",
      "          -5.8137,  -7.6026,  -0.9827]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.059174060821533\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2594, -7.7145, -4.9302, -0.9722, -9.7381, -3.1212, -2.6623, -5.0282,\n",
      "         -8.3571, -0.7876]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.2593793869018555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1626, -7.3645, -4.7251, -1.2667, -9.3235, -3.0351, -2.6500, -4.1528,\n",
      "         -8.8634, -0.7786]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.364518165588379\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2077, -6.2632, -4.4974, -1.6999, -8.9006, -2.9422, -2.6415, -3.3272,\n",
      "         -9.2697, -1.0635]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.263213157653809\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6619, -4.6415, -4.4009, -2.3313, -8.6199, -2.9961, -2.7868, -2.7120,\n",
      "         -9.7357, -1.6777]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.400853157043457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5440,  -3.1926,  -3.5748,  -2.9794,  -8.3716,  -3.0846,  -2.9675,\n",
      "          -2.2148, -10.1597,  -2.3746]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.2147603034973145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9756,  -2.0412,  -2.9751,  -3.7253,  -8.2712,  -3.3199,  -3.2914,\n",
      "          -1.1927, -10.6646,  -3.1947]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.2914280891418457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9180,  -1.3848,  -2.7567,  -4.7000,  -8.4642,  -3.8420,  -3.1547,\n",
      "          -0.7951, -11.4032,  -4.2489]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.8420040607452393\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9154,  -1.0232,  -2.6376,  -5.6244,  -8.6677,  -3.6577,  -3.0983,\n",
      "          -0.8326, -12.1055,  -5.2569]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.9153871536254883\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0043,  -0.8266,  -2.4820,  -6.3351,  -8.7490,  -3.3816,  -2.9664,\n",
      "          -1.0803, -12.6191,  -6.0258]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.080345630645752\n",
      "torch.Size([1, 1, 40])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -3.1893,  -1.0424,  -2.4591,  -7.0417,  -8.8764,  -3.2242,  -2.9459,\n",
      "          -0.8528, -13.1439,  -6.7942]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.794218063354492\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1774,  -1.2882,  -2.2951,  -7.4706,  -8.7832,  -2.9029,  -2.7583,\n",
      "          -0.7736, -13.4085,  -6.5306]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.1773581504821777\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3366,  -1.5638,  -2.0748,  -7.7086,  -8.5508,  -2.5039,  -2.4878,\n",
      "          -0.9144, -13.4981,  -6.1457]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.5039312839508057\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7044,  -2.0221,  -2.0275,  -7.9794,  -8.3978,  -1.5496,  -2.3619,\n",
      "          -1.4103, -13.6349,  -5.8570]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  13.634933471679688\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4037,  -2.6713,  -2.2234,  -8.3626,  -8.3993,  -0.9801,  -2.4574,\n",
      "          -2.1865, -13.2040,  -5.7380]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.4573590755462646\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3849,  -3.3838,  -2.5588,  -8.7848,  -8.4778,  -0.8113,  -1.9446,\n",
      "          -3.0504, -12.8930,  -5.7104]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.710414886474609\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4344,  -3.9386,  -2.8075,  -9.0533,  -8.4368,  -0.8632,  -1.4769,\n",
      "          -3.7534, -12.5011,  -4.8320]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  12.50107479095459\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5121,  -4.3160,  -2.9405,  -9.1586,  -8.2634,  -1.0727,  -1.0881,\n",
      "          -4.2682, -11.3220,  -3.9103]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.0880801677703857\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9910,  -4.9176,  -3.3522,  -9.5055,  -8.3595,  -1.7561,  -0.5007,\n",
      "          -4.9947, -10.5123,  -3.3473]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.917601108551025\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4289, -4.6370, -3.6589, -9.7272, -8.3555, -2.4034, -0.3292, -5.5635,\n",
      "         -9.6925, -2.7759]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.32916349172592163\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1247,  -4.6301,  -4.1931, -10.1655,  -8.5908,  -3.2892,  -0.2065,\n",
      "          -6.3174,  -9.1930,  -2.5465]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.5907564163208\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3503,  -4.1987,  -4.2534, -10.1279,  -7.6213,  -3.6810,  -0.2635,\n",
      "          -6.5654,  -8.3110,  -1.9662]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.198747158050537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2706, -2.7809, -4.0105, -9.7862, -6.4408, -3.7439, -0.5709, -6.4818,\n",
      "         -7.2090, -1.2403]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.4408063888549805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2661, -1.5898, -3.8458, -9.5187, -4.6751, -3.8574, -1.3016, -6.4480,\n",
      "         -6.2574, -0.8430]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.447959899902344\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4790, -0.8569, -3.9033, -9.4676, -3.2819, -4.1645, -2.3488, -5.8249,\n",
      "         -5.5916, -0.9965]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.9033358097076416\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7852, -0.6012, -3.3052, -9.5141, -2.1478, -4.5444, -3.4542, -5.3586,\n",
      "         -5.0871, -1.5027]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.514137268066406\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0691, -0.7652, -2.7864, -8.7690, -1.2060, -4.8861, -4.4649, -4.9344,\n",
      "         -4.6290, -2.1167]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.069111347198486\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6846, -1.3153, -2.4276, -8.1597, -0.6438, -5.2609, -5.4451, -4.6197,\n",
      "         -4.2850, -2.8211]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.8211143016815186\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3285, -1.9796, -2.1437, -7.5837, -0.5031, -5.5743, -6.3031, -4.3163,\n",
      "         -3.9571, -2.7247]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.5031133890151978\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2902, -2.9359, -2.2337, -7.3221, -0.3378, -6.1161, -7.3339, -4.3104,\n",
      "         -3.9319, -2.9436]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.9358632564544678\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9765, -2.7964, -2.0903, -6.7813, -0.4162, -6.2996, -7.9568, -4.0098,\n",
      "         -3.6170, -2.8742]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.781322002410889\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4527, -2.4376, -1.7771, -5.2423, -0.7000, -6.1884, -8.2401, -3.4755,\n",
      "         -3.0744, -2.5760]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.4376096725463867\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1073, -1.5138, -1.6884, -3.9255, -1.3895, -6.1546, -8.5603, -3.0836,\n",
      "         -2.6828, -2.4290]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.9254722595214844\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1123, -1.0717, -1.9779, -2.2141, -2.4249, -6.3548, -9.0778, -2.9957,\n",
      "         -2.6069, -2.5916]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.6068673133850098\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5181, -1.2383, -2.6584, -1.0724, -3.7378, -6.8509, -9.8586, -3.2706,\n",
      "         -2.2099, -3.1087]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.2705793380737305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1780,  -1.8368,  -3.5614,  -0.5471,  -5.1747,  -7.5353, -10.7985,\n",
      "          -3.0019,  -2.1657,  -3.8446]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  10.798539161682129\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6898,  -2.3797,  -4.2837,  -0.4109,  -6.3604,  -8.0397, -10.7954,\n",
      "          -2.6867,  -2.0933,  -4.4109]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.3796675205230713\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9401,  -1.9791,  -4.7162,  -0.5731,  -7.2011,  -8.2657, -10.5643,\n",
      "          -2.2278,  -1.8855,  -4.7015]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.9790863990783691\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2077,  -1.0222,  -5.1407,  -1.1824,  -7.9868,  -8.4976, -10.3843,\n",
      "          -1.9273,  -1.8322,  -4.9982]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  10.384326934814453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5875, -0.5506, -5.6557, -2.0957, -8.8228, -8.8348, -9.6180, -1.8991,\n",
      "         -2.0240, -5.3987]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.834811210632324\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8089, -0.4170, -5.9940, -2.8850, -9.4477, -8.2950, -8.8000, -1.8633,\n",
      "         -2.1607, -5.6347]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.447675704956055\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7066, -0.4670, -5.9931, -3.3314, -8.9562, -7.5016, -7.7560, -1.6453,\n",
      "         -2.0566, -5.5424]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.706558704376221\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6353, -0.6957, -5.7246, -3.4914, -8.2441, -6.5180, -6.5467, -1.3310,\n",
      "         -1.7824, -5.1926]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.3309671878814697\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8826, -1.4547, -5.6783, -3.8520, -7.7961, -5.8263, -5.6517, -0.6639,\n",
      "         -1.8458, -5.0748]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.67825984954834\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2544, -2.3165, -4.8876, -4.2028, -7.4026, -5.2152, -4.8580, -0.4764,\n",
      "         -2.0227, -4.9830]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.3164570331573486\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6286, -2.3035, -4.0460, -4.3948, -6.9133, -4.5334, -4.0136, -0.6578,\n",
      "         -2.1389, -4.7701]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.394786834716797\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1154, -2.2735, -3.2111, -3.7136, -6.3830, -3.8367, -3.1762, -1.1349,\n",
      "         -2.2353, -4.4943]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.273512363433838\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0166, -1.7280, -2.6183, -3.2473, -6.0351, -3.3533, -2.5812, -1.9437,\n",
      "         -2.5253, -4.3828]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.618265151977539\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3534, -1.5313, -1.5486, -3.0239, -5.8901, -3.1094, -2.2677, -2.9502,\n",
      "         -3.0087, -4.4581]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.5486007928848267\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3672, -2.0353, -0.5171, -3.3857, -6.2869, -3.4473, -2.5871, -4.4228,\n",
      "         -4.0039, -5.0601]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.060098171234131\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5211, -2.7571, -0.2153, -3.9113, -6.8195, -3.9482, -3.1040, -5.9321,\n",
      "         -5.0866, -5.0302]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.911343574523926\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2140, -3.0854, -0.1870, -3.2635, -6.9324, -4.0458, -3.2352, -6.9258,\n",
      "         -5.6985, -4.6409]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.0458245277404785\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4115, -2.9770, -0.3494, -2.2725, -6.5978, -2.9927, -2.9454, -7.3843,\n",
      "         -5.8148, -3.8605]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.9927167892456055\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6202, -2.9383, -1.0469, -1.4818, -6.3197, -1.3905, -2.7454, -7.8199,\n",
      "         -5.9438, -3.1957]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.481808066368103\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5450, -3.6715, -2.6680, -0.9070, -6.8004, -0.8557, -3.3426, -8.9421,\n",
      "         -6.7915, -3.3577]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.6679866313934326\n",
      "torch.Size([1, 1, 40])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -6.4773,  -4.4468,  -3.5238,  -0.7971,  -7.3308,  -0.7753,  -4.0032,\n",
      "         -10.0495,  -7.6524,  -3.6264]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.62644362449646\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0714,  -4.9069,  -4.0700,  -0.7984,  -7.5624,  -0.7859,  -4.3651,\n",
      "         -10.8002,  -8.1814,  -2.8938]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.906880855560303\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.3550,  -4.3535,  -4.3226,  -0.8934,  -7.5194,  -0.8691,  -4.4483,\n",
      "         -11.2242,  -8.4060,  -2.0236]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.8934124112129211\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.7806,  -4.0342,  -4.7298,  -0.6955,  -7.6508,  -1.4132,  -4.7017,\n",
      "         -11.7758,  -8.7781,  -1.5090]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.5090001821517944\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.3446,  -3.9399,  -5.2836,  -1.0805,  -7.9500,  -2.2573,  -5.1172,\n",
      "         -12.4529,  -9.2938,  -0.6449]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  12.452936172485352\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.8819,  -3.8983,  -5.8154,  -1.7166,  -8.2489,  -3.1214,  -5.5249,\n",
      "         -12.3076,  -9.7875,  -0.2897]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.1213889122009277\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.0682,  -3.5779,  -5.9989,  -2.1295,  -8.2207,  -2.9193,  -5.5975,\n",
      "         -11.8792,  -9.9345,  -0.2325]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.23247383534908295\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.3793,  -3.4528,  -6.3091,  -2.7357,  -8.3386,  -2.9188,  -5.8087,\n",
      "         -11.6366, -10.2101,  -0.1692]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  9.379256248474121\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4335,  -2.8570,  -6.0838,  -2.8253,  -7.9390,  -2.4510,  -5.4952,\n",
      "         -10.9122,  -9.9523,  -0.2357]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  10.912193298339844\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.2162, -1.9961, -5.5168, -2.5857, -7.2136, -1.7253, -4.8500, -9.1147,\n",
      "         -9.3542, -0.5156]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.725325584411621\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3778, -1.5764, -5.2665, -2.6850, -6.8181, -0.7441, -4.5321, -7.7536,\n",
      "         -9.0731, -1.4668]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.466810941696167\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9164, -1.6404, -5.3373, -3.1191, -6.7552, -0.4914, -4.5461, -6.8205,\n",
      "         -9.1122, -2.0426]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.337296962738037\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2582, -1.5937, -4.4092, -3.2994, -6.4548, -0.4545, -4.3220, -5.7365,\n",
      "         -8.9030, -2.4126]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.32204008102417\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4124, -1.4419, -3.3258, -3.2333, -5.9285, -0.6147, -3.1315, -4.5061,\n",
      "         -8.4577, -2.5553]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.50607967376709\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6305, -1.4473, -2.3481, -3.1750, -5.4276, -1.1130, -2.0627, -2.6015,\n",
      "         -8.0279, -2.7123]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.6015031337738037\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5765, -2.2535, -2.1706, -3.7857, -5.6109, -2.4256, -1.8258, -0.8039,\n",
      "         -8.2721, -3.5340]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.170586347579956\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3187, -3.8261, -2.1187, -5.1238, -6.5493, -4.4409, -2.5027, -0.3048,\n",
      "         -9.2627, -5.0661]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.549289226531982\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8059, -5.0671, -1.9713, -6.1423, -6.4513, -6.0731, -2.9821, -0.2388,\n",
      "         -9.9640, -6.2596]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.067132472991943\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8075,  -5.0216,  -1.5002,  -6.6183,  -5.9213,  -7.1016,  -3.0087,\n",
      "          -0.3469, -10.1527,  -6.8928]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.6183319091796875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4985,  -4.6688,  -0.9270,  -5.9618,  -5.1297,  -7.7118,  -2.7528,\n",
      "          -0.6729, -10.0061,  -7.1473]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.147305488586426\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0910, -4.2208, -0.5706, -5.2355, -4.2841, -8.1244, -2.4326, -1.2220,\n",
      "         -9.7369, -6.4972]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.124430656433105\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5751, -3.6669, -0.5122, -4.4244, -3.3720, -7.6234, -2.0486, -1.7820,\n",
      "         -9.3335, -5.7517]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.751712322235107\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9775, -3.0332, -0.7542, -3.5499, -2.4232, -7.0192, -1.6453, -2.2626,\n",
      "         -8.8169, -4.1920]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.7542436122894287\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7769, -2.7982, -0.8758, -3.0852, -1.9365, -6.7765, -1.7266, -3.0763,\n",
      "         -8.6525, -3.0994]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.798175811767578\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6855, -1.9524, -1.3405, -2.7460, -1.6513, -6.6027, -1.9764, -3.8886,\n",
      "         -8.5486, -2.1929]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.3405433893203735\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9034, -1.5443, -1.4575, -2.7409, -1.7903, -6.6980, -2.5554, -4.8867,\n",
      "         -8.7060, -1.7101]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.740878105163574\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1772, -1.3689, -1.7744, -2.0561, -2.0795, -6.8224, -3.1723, -5.8290,\n",
      "         -8.8855, -1.4469]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.828957557678223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4255, -1.3665, -2.1579, -1.5094, -2.4060, -6.9068, -3.7307, -5.8785,\n",
      "         -9.0188, -1.3557]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.3664757013320923\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8168, -0.9709, -2.7336, -1.3311, -2.9123, -7.1275, -4.3954, -6.0694,\n",
      "         -9.2830, -1.6085]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.6084932088851929\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2310, -0.9342, -3.3464, -1.4196, -3.4552, -7.3726, -5.0490, -6.2888,\n",
      "         -9.5668, -1.2911]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.4552104473114014\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4699, -1.0402, -3.7800, -1.5406, -3.0676, -7.4491, -5.4978, -6.3433,\n",
      "         -9.6777, -1.0640]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.4491376876831055\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5111, -1.2085, -4.0053, -1.6322, -2.5715, -6.6264, -5.7227, -6.2115,\n",
      "         -9.5955, -0.9325]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.722725868225098\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3840, -1.4032, -4.0495, -1.6927, -2.0102, -5.7142, -5.0092, -5.9220,\n",
      "         -9.3492, -0.9325]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.714180946350098\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1517, -1.6289, -3.9754, -1.7618, -1.4791, -4.0625, -4.2448, -5.5365,\n",
      "         -9.0006, -1.0961]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.9754109382629395\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9390, -1.9589, -3.1603, -1.9413, -1.1582, -2.5725, -3.5522, -5.1775,\n",
      "         -8.6718, -1.4752]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.9413223266601562\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9804, -2.5765, -2.6767, -1.6626, -1.3255, -1.5036, -3.1686, -5.0773,\n",
      "         -8.5946, -2.2041]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.594596862792969\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1904, -3.3466, -2.4517, -1.7163, -1.8359, -0.8579, -3.0137, -5.1509,\n",
      "         -7.9722, -3.1010]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.972245216369629\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3991, -4.0741, -2.3221, -1.9113, -2.4248, -0.5861, -2.9195, -5.2303,\n",
      "         -6.7137, -3.9505]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.399093151092529\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6991, -4.5726, -2.1097, -2.0316, -2.8530, -0.5669, -2.7059, -5.1369,\n",
      "         -5.4123, -4.5607]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.1097288131713867\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0551, -4.9972, -1.2319, -2.2091, -3.2506, -0.9194, -2.5320, -5.0257,\n",
      "         -4.2119, -5.0862]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.2318720817565918\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0086, -5.8835, -0.4146, -2.9524, -4.1371, -2.0178, -2.9338, -5.4298,\n",
      "         -3.6406, -6.0631]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.6406188011169434\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0957, -6.7767, -0.2650, -3.7549, -5.0404, -3.1940, -3.4286, -5.8900,\n",
      "         -2.5327, -7.0376]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.1939809322357178\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9906, -7.3652, -0.4843, -4.2791, -5.6422, -3.3573, -3.6818, -6.0901,\n",
      "         -1.3749, -7.6991]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.3572888374328613\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9956, -7.9587, -1.2015, -4.8247, -6.2498, -2.8883, -3.9917, -6.3350,\n",
      "         -0.5748, -8.3581]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.824713230133057\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0935, -8.5502, -2.1269, -4.6105, -6.8553, -2.5621, -4.3414, -6.6137,\n",
      "         -0.3111, -9.0086]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.0935163497924805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2704, -8.8654, -2.8311, -4.2077, -7.1838, -2.1051, -4.4486, -6.6483,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -0.3753, -9.3769]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  9.376885414123535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4212, -8.9661, -3.3257, -3.6732, -7.2969, -1.5963, -4.3707, -6.4972,\n",
      "         -0.7351, -8.7842]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.784161567687988\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8708, -9.0954, -3.8362, -3.2499, -7.4378, -1.3196, -4.3485, -6.4008,\n",
      "         -1.4356, -7.5535]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.3195571899414062\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9218, -9.4536, -4.5535, -3.1402, -7.8067, -0.7965, -4.5798, -6.5569,\n",
      "         -2.4760, -6.6874]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.55689001083374\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1592, -9.6782, -5.1094, -2.9769, -8.0414, -0.5454, -4.6979, -5.8260,\n",
      "         -3.3742, -5.8106]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.8105573654174805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3631, -9.6423, -5.3762, -2.6307, -8.0147, -0.4889, -4.5729, -4.9320,\n",
      "         -3.9691, -4.0532]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  9.642326354980469\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5286, -8.6798, -5.4158, -2.1704, -7.7867, -0.6645, -4.2640, -3.9284,\n",
      "         -4.3140, -2.2794]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.6644930243492126\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2313, -8.2091, -5.8506, -2.2397, -7.9777, -0.8771, -4.3923, -3.4359,\n",
      "         -5.0299, -1.1534]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.209123611450195\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0881, -7.2099, -6.3901, -2.5300, -8.2957, -1.5064, -4.6630, -3.1631,\n",
      "         -5.8250, -0.5180]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.529967784881592\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8900, -6.3079, -6.8743, -2.0812, -8.5794, -2.2257, -4.9109, -2.9475,\n",
      "         -6.5401, -0.3821]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.540147304534912\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3689, -5.2389, -7.0530, -1.5149, -8.5770, -2.6913, -4.8817, -2.5361,\n",
      "         -6.2192, -0.5032]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.053040027618408\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6369, -4.1077, -6.2984, -1.0017, -8.4025, -2.9857, -4.6887, -2.0548,\n",
      "         -5.7591, -0.8829]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.10769510269165\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8776, -2.3744, -5.6126, -0.8142, -8.2378, -3.2787, -4.5141, -1.7133,\n",
      "         -5.3394, -1.5200]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.278656482696533\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2784, -1.0594, -5.1762, -1.1642, -8.2682, -3.0444, -4.5437, -1.7246,\n",
      "         -5.1433, -2.4324]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.143276691436768\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9385, -0.4217, -5.0829, -2.0145, -8.5913, -3.1624, -4.8738, -2.1688,\n",
      "         -4.5620, -3.6139]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.873789310455322\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4672, -0.2544, -4.9359, -2.8151, -8.8147, -3.2307, -4.3565, -2.5903,\n",
      "         -3.9784, -4.6299]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.2306509017944336\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6284, -0.3467, -4.4929, -3.2660, -8.7000, -2.3043, -3.5843, -2.7122,\n",
      "         -3.1500, -5.2360]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.712177038192749\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6875, -0.8505, -4.0152, -3.6143, -8.5097, -1.4530, -2.8228, -2.0091,\n",
      "         -2.3473, -5.6986]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.8227787017822266\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0250, -1.8942, -3.8819, -4.2321, -8.6220, -1.1337, -1.7163, -1.7636,\n",
      "         -1.9754, -6.4010]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.71627938747406\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.8529, -3.4654, -4.3007, -5.3230, -9.2466, -1.5952, -0.6322, -2.1992,\n",
      "         -2.2620, -7.5581]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.852947235107422\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.0706,  -5.1054,  -4.8906,  -6.5117, -10.0118,  -2.3556,  -0.2582,\n",
      "          -2.8803,  -2.7963,  -8.8031]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.8802542686462402\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.9881,  -6.3077,  -5.1485,  -7.3044, -10.4220,  -2.8279,  -0.2219,\n",
      "          -2.4840,  -3.0418,  -9.6454]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.9880690574646\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.7532,  -6.9568,  -4.9502,  -7.5838, -10.3565,  -2.8598,  -0.3521,\n",
      "          -1.7569,  -2.8617,  -9.9691]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.8617169857025146\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4895,  -7.3893,  -4.6244,  -7.6833, -10.1451,  -2.7761,  -0.8394,\n",
      "          -1.0835,  -1.8822, -10.1080]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.8394466638565063\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6352,  -8.0599,  -4.6190,  -8.0538, -10.2353,  -3.0252,  -1.1358,\n",
      "          -1.0202,  -1.3883, -10.5138]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.235307693481445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7422,  -8.5331,  -4.4906,  -8.2569,  -9.4197,  -3.1527,  -1.5104,\n",
      "          -1.1117,  -0.9889, -10.7483]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.1117491722106934\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0993,  -9.1034,  -4.5274,  -8.5839,  -8.8293,  -3.4415,  -2.1558,\n",
      "          -0.8188,  -1.0361, -11.1035]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.8187602162361145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8317,  -9.8953,  -4.8470,  -9.1568,  -8.5761,  -4.0024,  -3.1014,\n",
      "          -0.4017,  -1.6074, -11.7017]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.156846046447754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4005, -10.3752,  -4.9074,  -8.6684,  -8.1151,  -4.2871,  -3.7531,\n",
      "          -0.3107,  -2.0301, -12.0071]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.907370090484619\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7187, -10.4476,  -3.8613,  -7.8690,  -7.3404,  -4.1934,  -3.9977,\n",
      "          -0.4340,  -2.1438, -11.9224]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.8613028526306152\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1135, -10.3905,  -2.0719,  -7.0272,  -6.5211,  -3.9974,  -4.1093,\n",
      "          -0.9203,  -2.2067, -11.7239]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.521089553833008\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1089, -10.6395,  -0.8548,  -6.5703,  -5.3218,  -4.1342,  -4.5224,\n",
      "          -1.9643,  -2.6415, -11.8454]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.85480135679245\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1964, -11.7144,  -0.1839,  -7.0105,  -5.0963,  -5.1193,  -5.7531,\n",
      "          -3.8629,  -3.9341, -12.8056]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.862917900085449\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1319, -12.5572,  -0.0755,  -7.2825,  -4.7728,  -5.8855,  -6.7387,\n",
      "          -4.6929,  -4.9868, -13.5450]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.885540008544922\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4158, -12.7258,  -0.0754,  -6.9377,  -3.8977,  -5.2836,  -7.0367,\n",
      "          -4.8571,  -5.3493, -13.6206]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.8976593017578125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1978, -12.3800,  -0.2607,  -6.1303,  -1.8677,  -4.2475,  -6.8080,\n",
      "          -4.5131,  -5.1813, -13.1910]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  13.190984725952148\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3212, -12.3583,  -1.2823,  -5.6946,  -0.4475,  -3.6143,  -6.8926,\n",
      "          -4.5016,  -5.3238, -12.3544]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  12.354364395141602\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9271, -12.8071,  -2.8742,  -5.7733,  -0.1264,  -3.5314,  -7.4379,\n",
      "          -4.9680,  -5.9239, -11.3355]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.9270572662353516\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3669, -12.8221,  -3.9601,  -5.4574,  -0.1199,  -3.0883,  -7.5402,\n",
      "          -5.0043,  -6.0770, -10.0290]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  10.028989791870117\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3756, -12.3235,  -4.4398,  -4.6641,  -0.2736,  -2.2093,  -7.1207,\n",
      "          -4.5299,  -5.7044,  -7.6109]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.1206841468811035\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4049, -11.7286,  -4.7344,  -3.8111,  -0.8394,  -1.3492,  -5.8512,\n",
      "          -3.9651,  -5.2252,  -5.2878]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.349191427230835\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2808, -11.7635,  -5.5768,  -3.6309,  -2.2452,  -0.6243,  -5.2808,\n",
      "          -4.0417,  -5.3683,  -3.7704]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.368289470672607\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5037, -11.9264,  -6.4697,  -3.6205,  -3.7225,  -0.4806,  -4.9025,\n",
      "          -4.2558,  -4.9227,  -2.5524]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.25576639175415\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7721, -11.9792,  -7.1805,  -3.5372,  -4.9767,  -0.6922,  -4.4739,\n",
      "          -3.5971,  -4.4311,  -1.4184]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.4311394691467285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2027, -12.1965,  -7.9312,  -3.5284,  -6.2195,  -1.4174,  -4.3361,\n",
      "          -3.0717,  -3.2597,  -0.6585]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.2026710510253906\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1080, -12.4666,  -8.7318,  -3.7327,  -7.4626,  -2.2994,  -4.2359,\n",
      "          -2.8245,  -2.4979,  -0.5151]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.462630748748779\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9630, -12.5614,  -9.3044,  -3.7869,  -7.6754,  -3.0157,  -4.0081,\n",
      "          -2.4991,  -1.7218,  -0.6768]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  9.304360389709473\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8687, -12.5804,  -9.0155,  -3.7869,  -7.8010,  -3.6288,  -3.7502,\n",
      "          -2.2029,  -1.0831,  -1.1290]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.1289758682250977\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0591, -12.7602,  -8.9181,  -3.9673,  -8.0772,  -4.3622,  -3.6983,\n",
      "          -2.1838,  -0.9104,  -1.2021]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  12.760236740112305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1381, -12.0091,  -8.6449,  -3.9588,  -8.1404,  -4.8460,  -3.4845,\n",
      "          -2.0675,  -0.8540,  -1.3025]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.3025463819503784\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3382, -11.3755,  -8.4417,  -4.0087,  -8.2402,  -5.3299,  -3.3576,\n",
      "          -2.1029,  -1.1471,  -0.9025]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.338169574737549\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8069, -10.7527,  -8.2067,  -4.0156,  -8.2781,  -5.7168,  -3.2173,\n",
      "          -2.1765,  -1.5833,  -0.7871]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.5833055973052979\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4504, -10.1941,  -7.9975,  -4.0380,  -8.3146,  -6.0697,  -3.1231,\n",
      "          -2.3323,  -1.4161,  -1.0183]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.997485160827637\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1724, -9.5631, -6.9465, -3.9440, -8.2197, -6.2610, -2.9434, -2.4194,\n",
      "         -1.3089, -1.3626]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.172424077987671\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6188, -9.1943, -6.2002, -4.0737, -8.3336, -6.6340, -3.0204, -2.7656,\n",
      "         -1.6024, -2.0590]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.602410078048706\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5526, -8.9019, -5.5694, -4.2435, -8.4761, -7.0105, -3.1660, -3.1656,\n",
      "         -1.3428, -2.8192]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.3428465127944946\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9787, -8.7058, -5.0712, -4.4746, -8.6717, -7.4172, -3.3959, -3.6254,\n",
      "         -0.6568, -3.6144]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.9787066578865051\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0455, -8.6664, -4.7642, -4.8287, -8.9849, -7.9208, -3.7652, -4.1970,\n",
      "         -0.5415, -4.4873]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.666385650634766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0505, -7.5938, -4.1834, -4.8431, -8.9563, -8.0639, -3.8044, -4.4127,\n",
      "         -0.5365, -4.9708]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.95632553100586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9946, -6.3140, -3.3573, -4.5479, -7.8600, -7.8786, -3.5421, -4.3019,\n",
      "         -0.6282, -5.0969]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.096892356872559\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9766, -4.9268, -2.4029, -4.0541, -6.6368, -7.4758, -3.0916, -3.9763,\n",
      "         -0.8487, -4.2460]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.475797176361084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1607, -3.6099, -1.5374, -3.5501, -5.4635, -6.3341, -2.6471, -3.6248,\n",
      "         -1.2741, -3.4173]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.46347188949585\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6789, -2.5690, -1.0420, -3.2440, -3.7835, -5.4326, -2.4255, -3.4540,\n",
      "         -1.9784, -2.8203]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.6789050102233887\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8032, -1.9372, -1.1060, -3.2485, -2.5375, -4.8734, -2.5422, -3.5743,\n",
      "         -2.9592, -2.5758]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.1059503555297852\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3364, -1.7752, -0.9716, -3.5848, -1.7770, -4.6770, -3.0085, -4.0060,\n",
      "         -4.1805, -2.7132]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.677000522613525\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8805, -1.7470, -1.1238, -3.9033, -1.2139, -3.7975, -3.4595, -4.4029,\n",
      "         -5.2850, -2.8794]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.402885437011719\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3685, -1.8062, -1.4578, -4.1632, -0.8887, -2.9785, -3.8466, -3.9540,\n",
      "         -6.2403, -3.0275]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.163198471069336\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7526, -1.8992, -1.8500, -3.5463, -0.8263, -2.1967, -4.1311, -3.4843,\n",
      "         -7.0217, -3.1162]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.1967005729675293\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2440, -2.2209, -2.4476, -3.1419, -1.2290, -0.9981, -4.5278, -3.2135,\n",
      "         -7.8543, -3.3569]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.1418628692626953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9946, -2.8875, -3.3472, -2.3316, -2.1100, -0.4764, -5.1909, -3.2985,\n",
      "         -8.9021, -3.8970]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.1100211143493652\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.7060, -3.5592, -4.2140, -1.7084, -2.2712, -0.4750, -5.8229, -3.4342,\n",
      "         -9.8763, -4.4289]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.822915554046631\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.1540,  -3.9898,  -4.8103,  -1.0937,  -2.2990,  -0.7158,  -5.4443,\n",
      "          -3.3863, -10.5585,  -4.7215]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.7157828211784363\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.7146,  -4.5467,  -5.5089,  -0.9575,  -2.5552,  -0.7295,  -5.2622,\n",
      "          -3.5250, -11.3284,  -5.1472]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.508913993835449\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.9540,  -4.7897,  -5.1365,  -0.8684,  -2.5783,  -0.8141,  -4.8359,\n",
      "          -3.4065, -11.7554,  -5.2685]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.5782933235168457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0022,  -4.8466,  -4.6375,  -0.9473,  -1.7367,  -1.0328,  -4.2900,\n",
      "          -3.1574, -11.9719,  -5.2135]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.9473434686660767\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.2628,  -5.1200,  -4.4117,  -0.7577,  -1.3278,  -1.6958,  -4.0252,\n",
      "          -3.1826, -12.3833,  -5.3845]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.6957733631134033\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.4615,  -5.3343,  -4.1810,  -0.9158,  -1.1226,  -1.6836,  -3.7640,\n",
      "          -3.2011, -12.7175,  -5.5054]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.461543083190918\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.7155,  -5.3328,  -3.7866,  -1.1715,  -0.9847,  -1.6047,  -3.3484,\n",
      "          -3.0514, -12.8204,  -5.4194]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.6046593189239502\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.0796,  -5.3701,  -3.4833,  -1.6779,  -1.1763,  -1.0101,  -3.0358,\n",
      "          -2.9885, -12.9482,  -5.3803]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.079617500305176\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7451,  -5.3663,  -3.1921,  -2.2384,  -1.5399,  -0.6887,  -2.7499,\n",
      "          -2.9301, -13.0224,  -5.3077]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.307725429534912\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4355,  -5.2521,  -2.8461,  -2.7119,  -1.9141,  -0.6360,  -2.4266,\n",
      "          -2.8049, -12.9751,  -4.3962]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.711945056915283\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2332,  -5.1067,  -2.5309,  -2.3646,  -2.3155,  -0.9115,  -2.1561,\n",
      "          -2.6927, -12.8860,  -3.5381]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.364637851715088\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4329,  -5.1847,  -2.5106,  -1.5559,  -2.9558,  -1.6444,  -2.2048,\n",
      "          -2.8489, -13.0103,  -2.9913]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.6444483995437622\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1439,  -5.5173,  -2.8107,  -1.2492,  -3.8297,  -1.9987,  -2.5905,\n",
      "          -3.2929, -13.3804,  -2.7942]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.2928895950317383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0630,  -5.7677,  -3.0734,  -1.1431,  -4.5809,  -2.3601,  -2.9425,\n",
      "          -2.8928, -13.6616,  -2.6096]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.892843246459961\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1937,  -5.9479,  -3.2967,  -1.2469,  -5.2176,  -2.7039,  -3.2521,\n",
      "          -1.7572, -13.8674,  -2.4501]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.7038612365722656\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6232,  -6.2040,  -3.6171,  -1.6546,  -5.8868,  -2.4556,  -3.6522,\n",
      "          -0.9599, -14.1445,  -2.4620]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.617079019546509\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2081,  -6.4909,  -3.2407,  -2.2246,  -6.5463,  -2.3466,  -4.0869,\n",
      "          -0.5935, -14.4488,  -2.5905]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.5934527516365051\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1746,  -7.1103,  -3.2907,  -3.1815,  -7.5012,  -2.6750,  -4.8511,\n",
      "          -0.2781, -15.0828,  -3.1214]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.290656328201294\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7823,  -7.3757,  -2.3350,  -3.7824,  -8.0685,  -2.7257,  -5.2521,\n",
      "          -0.2870, -15.3607,  -3.3391]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.3391149044036865\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0979,  -7.3669,  -1.2977,  -4.0929,  -8.3314,  -2.5689,  -5.3691,\n",
      "          -0.6248, -15.3627,  -2.5770]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.568864345550537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5513,  -7.5167,  -0.7225,  -4.5426,  -8.7254,  -1.9433,  -5.6351,\n",
      "          -1.4972, -15.5217,  -2.1038]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.7224575281143188\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4930,  -8.1776,  -0.3518,  -5.4816,  -9.6061,  -2.0054,  -6.4031,\n",
      "          -2.9804, -16.1906,  -2.2934]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.351797491312027\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.7044,  -9.1334,  -0.1602,  -6.6907, -10.7596,  -2.5154,  -7.4563,\n",
      "          -4.7155, -17.1534,  -2.8990]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.704423904418945\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.5940,  -9.5191,  -0.1420,  -7.3055, -11.3232,  -2.5559,  -7.9301,\n",
      "          -5.8098, -17.5453,  -3.0098]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.5558969974517822\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.0716,  -9.4427,  -0.3390,  -7.4357, -11.4069,  -1.5292,  -7.9332,\n",
      "          -6.3735, -17.4743,  -2.7222]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.071618556976318\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7918,  -9.2850,  -0.9485,  -7.4645, -11.3935,  -0.6665,  -7.8474,\n",
      "          -6.7937, -17.3216,  -2.4229]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.793697357177734\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7294,  -9.2272,  -1.8644,  -7.5750, -11.4655,  -0.3306,  -7.8545,\n",
      "          -6.4869, -17.2680,  -2.3029]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  11.465453147888184\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5907,  -8.9758,  -2.6031,  -7.4755, -10.5747,  -0.3270,  -7.6617,\n",
      "          -6.0124, -17.0204,  -2.0692]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.069215774536133\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5947,  -8.7244,  -3.2976,  -7.3613,  -9.7476,  -0.7973,  -7.4635,\n",
      "          -5.5621, -16.7725,  -1.1899]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.4635114669799805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0355,  -8.6886,  -4.1403,  -7.4493,  -9.1933,  -1.7223,  -6.7138,\n",
      "          -5.3498, -16.7396,  -0.8129]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.8129223585128784\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1796,  -9.0464,  -5.3008,  -7.9190,  -9.0842,  -3.0687,  -6.4296,\n",
      "          -5.5523, -17.0999,  -0.4540]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  9.04643726348877\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2921,  -8.3877,  -6.1091,  -8.1018,  -8.7456,  -4.0729,  -5.9346,\n",
      "          -5.4973, -17.1840,  -0.3587]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.3586549460887909\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7502,  -7.9524,  -6.9962,  -8.4243,  -8.5985,  -5.1466,  -5.6485,\n",
      "          -5.6085, -17.4173,  -0.2088]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.146580696105957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8212,  -7.0931,  -7.3280,  -8.2473,  -7.9986,  -4.9564,  -4.9259,\n",
      "          -5.2439, -17.1598,  -0.2027]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  17.159799575805664\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5236,  -5.8409,  -7.1483,  -7.6091,  -6.9796,  -4.3109,  -3.8018,\n",
      "          -4.4406, -15.7342,  -0.3155]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.148292541503906\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1299,  -4.4316,  -5.9689,  -6.7509,  -5.7789,  -3.4552,  -2.5228,\n",
      "          -3.4425, -14.1665,  -0.6647]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.778911113739014\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0830,  -3.2446,  -4.9820,  -6.0522,  -4.0187,  -2.7796,  -1.5056,\n",
      "          -2.6415, -12.8281,  -1.4269]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.4269421100616455\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6378,  -2.5561,  -4.4497,  -5.7763,  -2.7986,  -2.5656,  -1.1108,\n",
      "          -2.3267, -11.9743,  -1.9072]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.449735641479492\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3884,  -2.1038,  -3.3593,  -5.6402,  -1.8560,  -2.5360,  -1.1170,\n",
      "          -2.2286, -11.3154,  -2.5578]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.3592658042907715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3181,  -1.9743,  -1.8649,  -5.7076,  -1.3127,  -2.7514,  -1.5598,\n",
      "          -2.4105, -10.9093,  -3.3874]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.312677025794983\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7176,  -2.4970,  -1.1682,  -6.3068,  -0.8085,  -3.5255,  -2.6553,\n",
      "          -3.1796, -11.0795,  -4.6949]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.1682331562042236\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4377,  -3.4823,  -0.4954,  -7.3013,  -1.1452,  -4.6964,  -4.1489,\n",
      "          -4.3578, -11.6863,  -6.3325]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.332484722137451\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.9108,  -4.3155,  -0.2575,  -8.1203,  -1.6119,  -5.6802,  -5.4289,\n",
      "          -5.3516, -12.1557,  -7.0008]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.315504550933838\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.8473,  -3.9434,  -0.2156,  -8.4678,  -1.7926,  -6.1781,  -6.1947,\n",
      "          -5.8600, -12.1881,  -7.2130]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.178116321563721\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.2200,  -3.1519,  -0.2912,  -8.3102,  -1.6105,  -5.4647,  -6.4151,\n",
      "          -5.8492, -11.7466,  -6.9339]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.933925151824951\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.2122,  -2.1276,  -0.5550,  -7.8250,  -1.2540,  -4.4818,  -6.2713,\n",
      "          -5.4983, -11.0056,  -5.6140]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.271324634552002\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.1442,  -1.2327,  -1.1449,  -7.3274,  -1.0877,  -3.5435,  -5.3170,\n",
      "          -5.1245, -10.2773,  -4.3672]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.543525218963623\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.2390, -0.7995, -2.0612, -7.0357, -1.3484, -2.1853, -4.6173, -4.9484,\n",
      "         -9.7775, -3.4095]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.1852869987487793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.7310, -1.1501, -3.3847, -7.1804, -2.1860, -0.7602, -4.4015, -5.2020,\n",
      "         -9.7340, -2.9778]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.401459693908691\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.6261,  -2.1529,  -5.0531,  -7.7633,  -3.4772,  -0.2521,  -3.9082,\n",
      "          -5.8866, -10.1470,  -3.0782]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.14700984954834\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.2644,  -2.9744,  -6.3922,  -8.1207,  -4.4955,  -0.1632,  -3.3116,\n",
      "          -6.3375,  -9.6340,  -3.0344]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  9.633955955505371\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.4119,  -3.3249,  -7.1720,  -8.0156,  -4.9936,  -0.2397,  -2.3749,\n",
      "          -6.3176,  -8.0325,  -2.6026]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  11.41188907623291\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.5503,  -3.4026,  -7.6100,  -7.6565,  -5.1826,  -0.5823,  -1.3378,\n",
      "          -6.0364,  -6.3261,  -2.0033]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  10.55029296875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.1306, -3.5778, -8.0854, -7.4141, -5.4376, -1.3529, -0.6848, -5.8656,\n",
      "         -4.8713, -1.6424]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.437635898590088\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.8742, -3.7784, -8.5356, -7.2182, -4.9353, -2.2455, -0.5035, -5.7360,\n",
      "         -3.5888, -1.4806]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.874238967895508\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8477, -3.8006, -8.7657, -6.8670, -4.3131, -2.9464, -0.6252, -5.4464,\n",
      "         -2.2783, -1.3254]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.325399398803711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2463, -4.0586, -9.1944, -6.7729, -3.9842, -3.8347, -1.3627, -5.4103,\n",
      "         -1.3931, -0.8718]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.9842262268066406\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9757, -4.4648, -9.7414, -6.8501, -3.1109, -4.8104, -2.3823, -5.5422,\n",
      "         -0.9353, -0.9291]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.9756579399108887\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3241,  -5.0130, -10.4078,  -7.0942,  -2.5319,  -5.8684,  -3.5446,\n",
      "          -5.8379,  -0.9786,  -1.4419]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.9785670638084412\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6205,  -6.1023, -11.5988,  -7.9055,  -2.6612,  -7.4139,  -5.2040,\n",
      "          -6.6972,  -1.1615,  -2.6667]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.203955173492432\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3601,  -7.0682, -12.6545,  -8.6196,  -2.8138,  -8.7892,  -5.9234,\n",
      "          -7.4553,  -1.5340,  -3.8035]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.068236827850342\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3087,  -6.8718, -13.2835,  -8.9412,  -2.6747,  -9.7061,  -6.2516,\n",
      "          -7.8168,  -1.7024,  -4.5218]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  13.283498764038086\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3963,  -6.3002, -12.7290,  -8.8353,  -2.2061, -10.1363,  -6.1531,\n",
      "          -7.7470,  -1.5893,  -4.7810]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.83534049987793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6655,  -5.4939, -11.9366,  -7.6578,  -1.5743, -10.2307,  -5.7730,\n",
      "          -7.3916,  -1.3408,  -4.7275]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.3408019542694092\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4350,  -4.9293, -11.3816,  -6.7563,  -1.3203, -10.4741,  -5.5915,\n",
      "          -7.2304,  -0.7464,  -4.8442]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.4350273609161377\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6599,  -4.5068, -10.9622,  -6.0258,  -1.3738, -10.7738,  -5.5113,\n",
      "          -7.1663,  -0.6313,  -5.0355]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  10.962204933166504\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7366,  -3.8722,  -9.6007,  -5.1077,  -1.3511, -10.7814,  -5.1800,\n",
      "          -6.8469,  -0.6459,  -4.9502]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.645882248878479\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0772,  -3.4616,  -8.5200,  -4.4311,  -1.6715, -10.9335,  -5.0311,\n",
      "          -6.7054,  -0.4637,  -5.0239]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.431065559387207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2340,  -2.8755,  -7.3072,  -2.8058,  -1.8622, -10.8305,  -4.6622,\n",
      "          -6.3390,  -0.5091,  -4.8551]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  10.830533027648926\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3962, -2.3339, -6.1597, -1.3341, -2.0956, -9.9938, -4.2814, -5.9546,\n",
      "         -0.9225, -4.6530]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.9225053787231445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0640, -2.3750, -5.5842, -0.6731, -2.8550, -9.6966, -4.4052, -6.0668,\n",
      "         -1.3204, -4.9343]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.6730551719665527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2147, -2.9973, -5.5845, -0.2086, -4.0982, -9.9448, -5.0418, -6.6854,\n",
      "         -2.3848, -5.7085]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.685426712036133\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9489, -3.2825, -5.2750, -0.1184, -4.9177, -9.8558, -5.3075, -6.1489,\n",
      "         -3.0964, -6.0957]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.85576343536377\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0250, -2.9773, -4.4098, -0.1437, -5.0710, -8.5004, -4.9603, -5.0772,\n",
      "         -3.1793, -5.8557]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.1792850494384766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6521, -2.2944, -3.1934, -0.3951, -4.7676, -6.8338, -4.2069, -3.6710,\n",
      "         -2.1242, -5.1956]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.670990228652954\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4673, -1.8992, -2.2720, -1.2885, -4.6450, -5.4780, -3.6840, -1.7915,\n",
      "         -1.4033, -4.7494]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.2885299921035767\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9552, -2.3016, -2.1633, -2.1725, -5.1880, -4.9062, -3.8784, -0.8754,\n",
      "         -1.5754, -5.0001]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.000102519989014\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5096, -2.8489, -2.2589, -3.1669, -5.7911, -4.5062, -4.1793, -0.4860,\n",
      "         -1.9877, -4.6083]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.509598731994629\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0855, -3.1790, -2.2148, -3.8890, -6.1303, -3.9475, -4.2557, -0.4092,\n",
      "         -2.2504, -4.0565]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.214775323867798\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5365, -3.3359, -1.3576, -4.3836, -6.2658, -3.2860, -4.1638, -0.6849,\n",
      "         -2.3904, -3.4008]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.68487948179245\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3233, -3.7775, -1.0460, -5.1121, -6.6628, -2.9897, -4.3665, -0.8210,\n",
      "         -2.8554, -3.1083]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.3664774894714355\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9791, -4.0304, -0.8586, -5.6110, -6.8594, -2.5957, -3.6328, -1.1234,\n",
      "         -3.1533, -2.7159]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.611028671264648\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5536, -4.1425, -0.8683, -5.1553, -6.9082, -2.1634, -2.8634, -1.5191,\n",
      "         -3.3230, -2.2820]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.8682721257209778\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4253, -4.4897, -0.6905, -4.9836, -7.1872, -2.0876, -2.4485, -2.2796,\n",
      "         -3.7359, -2.2006]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.08758807182312\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3284, -4.8059, -0.8889, -4.8295, -7.4341, -1.4121, -2.1361, -3.0391,\n",
      "         -4.1199, -2.2037]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.434077262878418\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2338, -5.0635, -1.3318, -4.6637, -6.8636, -0.9384, -1.9119, -3.7269,\n",
      "         -4.4440, -2.2544]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.3318092823028564\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2674, -5.3907, -1.2883, -4.6121, -6.4411, -0.8719, -1.9137, -4.4555,\n",
      "         -4.8346, -2.4676]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.44106388092041\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1406, -5.5040, -1.2637, -4.3888, -5.1225, -0.9151, -1.8435, -4.9359,\n",
      "         -5.0074, -2.5373]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.1405704021453857\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2239, -5.4953, -1.3321, -4.0834, -3.8259, -1.1156, -1.7878, -5.2601,\n",
      "         -5.0539, -2.5443]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.115628957748413\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6598, -5.6739, -1.7680, -4.0050, -2.8583, -1.0170, -2.0492, -5.7396,\n",
      "         -5.2838, -2.7919]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.858280658721924\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4126, -5.9610, -2.4075, -4.0723, -1.4025, -1.3004, -2.5070, -6.2975,\n",
      "         -5.6181, -3.1836]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.4024693965911865\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1462, -7.0021, -3.8292, -4.9268, -0.3077, -2.5235, -3.7624, -7.5819,\n",
      "         -6.7023, -4.3475]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.1461925506591797\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4270, -8.1948, -5.3796, -5.9564, -0.1335, -3.9346, -5.1651, -8.9934,\n",
      "         -7.9340, -5.6596]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.934014797210693\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2394, -8.7650, -6.2750, -6.3815, -0.1325, -4.7146, -5.9286, -9.7604,\n",
      "         -7.8234, -6.3396]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.2394254207611084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0792,  -8.9261,  -6.7302,  -6.4132,  -0.4355,  -5.0707,  -6.2658,\n",
      "         -10.0988,  -7.3718,  -6.6009]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.070713520050049\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3516,  -9.1442,  -7.2140,  -6.5160,  -1.2640,  -4.7813,  -6.6438,\n",
      "         -10.4765,  -7.0385,  -6.9101]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.643799781799316\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.1425,  -9.2814,  -7.5908,  -6.5505,  -2.1615,  -4.4672,  -6.1593,\n",
      "         -10.7573,  -6.6797,  -7.1300]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.46715784072876\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.1399,  -8.9704,  -7.4959,  -6.1480,  -2.6211,  -3.0741,  -5.2900,\n",
      "         -10.5755,  -5.9228,  -6.8939]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.1479573249816895\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3952,  -8.3296,  -7.0500,  -4.6472,  -2.7284,  -1.4905,  -4.1502,\n",
      "         -10.0510,  -4.8825,  -6.3213]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.64718770980835\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3948, -8.0446, -6.9409, -2.8222, -3.1657, -0.5108, -3.4278, -9.8705,\n",
      "         -4.2428, -6.0987]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.1656761169433594\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8680,  -8.1851,  -7.2403,  -1.6222,  -3.2397,  -0.4372,  -3.1992,\n",
      "         -10.1051,  -4.0742,  -6.2970]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.185140609741211\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2965,  -7.6173,  -7.5720,  -0.7566,  -3.3971,  -0.8744,  -3.0862,\n",
      "         -10.3778,  -3.9961,  -6.5384]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.571977138519287\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6171,  -7.1308,  -7.1697,  -0.3669,  -3.5882,  -1.5776,  -3.0439,\n",
      "         -10.6479,  -3.9634,  -6.7814]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.169707298278809\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.5411,  -6.4257,  -5.8199,  -0.2864,  -3.5133,  -2.0844,  -2.7748,\n",
      "         -10.6234,  -3.6800,  -6.7333]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.0844242572784424\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0853,  -5.5031,  -4.3178,  -0.5056,  -3.1793,  -1.6526,  -2.2916,\n",
      "         -10.3126,  -3.1541,  -6.4021]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  10.312618255615234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.4568, -4.5563, -2.8556, -1.0488, -2.7904, -1.2754, -1.8151, -9.1312,\n",
      "         -2.5920, -5.9858]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.7904183864593506\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.0039, -3.9240, -1.7929, -2.0202, -1.9531, -1.3388, -1.7235, -8.2798,\n",
      "         -2.3522, -5.8252]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.3387677669525146\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.8566, -3.7292, -1.3163, -3.3571, -1.6646, -1.2518, -2.1381, -7.8729,\n",
      "         -2.5644, -6.0424]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.3570573329925537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.6182, -3.5658, -1.0751, -3.8070, -1.5396, -1.3623, -2.5958, -7.5006,\n",
      "         -2.8047, -6.2335]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.233450889587402\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.1699,  -3.3061,  -0.9711,  -4.0952,  -1.4529,  -1.5025,  -2.9314,\n",
      "          -7.0317,  -2.9306,  -5.5320]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.095213413238525\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.5181,  -2.9514,  -1.0030,  -3.4505,  -1.4008,  -1.6320,  -3.1260,\n",
      "          -6.4616,  -2.9339,  -4.7547]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.125964641571045\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.7404,  -2.5803,  -1.2058,  -2.8030,  -1.4462,  -1.7908,  -2.4743,\n",
      "          -5.8581,  -2.8839,  -3.9698]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.205849051475525\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.1037,  -2.4670,  -1.0444,  -2.4296,  -1.8260,  -2.2108,  -2.1155,\n",
      "          -5.4800,  -3.0424,  -3.4403]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.0423974990844727\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.4108,  -2.4095,  -1.1336,  -2.1411,  -2.2681,  -2.6440,  -1.8650,\n",
      "          -5.1229,  -2.4789,  -2.9672]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.6439807415008545\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.6929,  -2.4316,  -1.4519,  -1.9772,  -2.7490,  -2.4049,  -1.7641,\n",
      "          -4.8115,  -2.0374,  -2.5849]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.0373520851135254\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.0918,  -2.6632,  -2.0527,  -2.0809,  -3.3748,  -2.3960,  -1.9499,\n",
      "          -4.6823,  -1.1609,  -2.4416]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.949906349182129\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.6468,  -3.1207,  -2.8824,  -2.4662,  -4.1596,  -2.6461,  -1.6549,\n",
      "          -4.7692,  -0.7929,  -2.5730]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.120739221572876\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.0909,  -2.7511,  -3.6145,  -2.8228,  -4.8225,  -2.8640,  -1.4804,\n",
      "          -4.7984,  -0.7315,  -2.6925]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.863996982574463\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.3659,  -2.3417,  -4.1681,  -3.0647,  -5.3003,  -2.2932,  -1.3729,\n",
      "          -4.7062,  -0.8969,  -2.7255]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.168097496032715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.5166,  -1.9493,  -3.8575,  -3.2217,  -5.6375,  -1.7511,  -1.3739,\n",
      "          -4.5335,  -1.2417,  -2.7071]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.7511374950408936\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.8334,  -1.8852,  -3.7740,  -3.5748,  -6.1248,  -0.8833,  -1.7501,\n",
      "          -4.5675,  -1.9406,  -2.9213]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.940595030784607\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.2782,  -2.1025,  -3.8751,  -4.0739,  -6.7249,  -0.5431,  -2.3819,\n",
      "          -4.7658,  -2.1146,  -3.3139]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  14.278229713439941\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.7728,  -2.2028,  -3.7928,  -4.3483,  -7.0778,  -0.4438,  -2.8336,\n",
      "          -4.7629,  -2.1695,  -3.5062]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.169466733932495\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.1629,  -2.2224,  -3.5802,  -4.4504,  -7.2415,  -0.6351,  -3.1306,\n",
      "          -4.6122,  -1.4309,  -3.5470]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.222426176071167\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.6410,  -1.5906,  -3.4362,  -4.5788,  -7.4167,  -1.1939,  -3.4590,\n",
      "          -4.5117,  -0.9644,  -3.6325]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  12.641048431396484\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.4609,  -1.1799,  -3.3334,  -4.7058,  -7.5784,  -1.9060,  -3.7824,\n",
      "          -4.4333,  -0.8205,  -3.7328]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.8204782605171204\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.6356,  -1.2808,  -3.5040,  -5.0645,  -7.9617,  -2.8854,  -4.3286,\n",
      "          -4.6095,  -0.5285,  -4.0783]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.8854198455810547\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.6833, -1.3734, -3.4702, -5.1832, -8.0980, -2.9167, -4.6213, -4.5667,\n",
      "         -0.4777, -4.1929]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.192856311798096\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.5294, -1.3526, -3.1659, -4.9980, -7.9245, -2.6852, -4.5960, -4.2401,\n",
      "         -0.5779, -3.2657]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.3526098728179932\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5526, -0.8334, -2.9846, -4.8986, -7.8307, -2.5851, -4.6432, -4.0195,\n",
      "         -1.1295, -2.5214]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.898606300354004\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6622, -0.6841, -2.8469, -4.0318, -7.7353, -2.5347, -4.6818, -3.8239,\n",
      "         -1.8451, -1.8998]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.8238677978515625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8106, -0.8809, -2.7143, -3.2143, -7.5990, -2.4925, -4.6731, -2.8254,\n",
      "         -2.5513, -1.4010]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.5512759685516357\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0888, -1.4143, -2.6859, -2.5520, -7.5195, -2.5535, -4.7153, -2.0160,\n",
      "         -2.5717, -1.1785]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.6858513355255127\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5431, -2.1782, -2.0846, -2.1157, -7.5481, -2.7610, -4.8601, -1.4921,\n",
      "         -2.7442, -1.3075]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.7441837787628174\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1461, -3.0386, -1.7200, -1.9026, -7.6610, -3.0775, -5.0831, -1.2848,\n",
      "         -2.3219, -1.7121]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.038562774658203\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7976, -3.0893, -1.5193, -1.8238, -7.7607, -3.3914, -5.2864, -1.3144,\n",
      "         -2.0089, -2.2088]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.008903980255127\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5792, -3.2486, -1.5765, -1.9569, -7.9299, -3.7762, -5.5525, -1.6325,\n",
      "         -1.1943, -2.8172]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.776244640350342\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4511, -3.4700, -1.8266, -2.2347, -8.1313, -3.5080, -5.8438, -2.1219,\n",
      "         -0.7241, -3.4583]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.121889114379883\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3459, -3.6801, -2.1558, -2.5548, -8.3000, -3.2741, -6.0956, -1.8554,\n",
      "         -0.6315, -4.0464]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.631488561630249\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4841, -4.0959, -2.7438, -3.1108, -8.6596, -3.2966, -6.5316, -1.9462,\n",
      "         -0.4245, -4.7965]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.4245421588420868\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8654, -4.7176, -3.5548, -3.8808, -9.2183, -3.5768, -7.1600, -2.3753,\n",
      "         -0.2285, -5.7129]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.5547807216644287\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8384, -4.8989, -3.1953, -4.2047, -9.3361, -3.4627, -7.3411, -2.4497,\n",
      "         -0.2299, -6.1551]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.1952991485595703\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4965, -4.7345, -1.8478, -4.1747, -9.1091, -3.0481, -7.1716, -2.2516,\n",
      "         -0.4582, -6.2218]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.73453426361084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2746, -3.9023, -0.8124, -4.2238, -8.9688, -2.7711, -7.0835, -2.2203,\n",
      "         -1.1724, -6.3473]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.7710671424865723\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3695, -3.4356, -0.4683, -4.5467, -9.1099, -2.1535, -7.2723, -2.5453,\n",
      "         -2.3006, -6.7291]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.109928131103516\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3823, -2.9421, -0.5131, -4.7483, -8.3841, -1.5788, -7.3453, -2.8024,\n",
      "         -3.2896, -6.9763]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.802441120147705\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3252, -2.4445, -0.8913, -4.8433, -7.6375, -1.1081, -7.3184, -2.2004,\n",
      "         -4.1132, -7.1064]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.2003872394561768\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4684, -2.2306, -1.6956, -5.1035, -7.1341, -1.0771, -7.4633, -1.1309,\n",
      "         -5.0349, -7.3927]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.134093284606934\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7769, -2.2762, -2.7089, -5.4996, -6.0874, -1.4375, -7.7511, -0.5786,\n",
      "         -6.0264, -7.8080]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.807979583740234\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9478, -2.2716, -3.5459, -5.7360, -5.0233, -1.7999, -7.8872, -0.3984,\n",
      "         -6.7976, -7.3097]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.9477968215942383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0893, -2.0412, -4.0161, -5.6470, -3.7657, -1.9342, -7.7058, -0.4577,\n",
      "         -7.1884, -6.5572]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2.0412354469299316\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3246, -1.1523, -4.4278, -5.5451, -2.6261, -2.1287, -7.5181, -0.9805,\n",
      "         -7.5163, -5.8560]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.6261191368103027\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0612, -0.9452, -5.1618, -5.8109, -1.2601, -2.7394, -7.7041, -2.0985,\n",
      "         -8.1665, -5.5814]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.161803722381592\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2309, -1.3671, -5.4202, -6.3675, -0.5587, -3.6481, -8.1868, -3.5159,\n",
      "         -9.0670, -5.6518]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.420192718505859\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4196, -1.8976, -4.8979, -6.8281, -0.3165, -4.4422, -8.5798, -4.7736,\n",
      "         -9.8361, -5.6760]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.773563385009766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3045,  -2.1392,  -4.0836,  -6.8944,  -0.2969,  -4.8159,  -8.5846,\n",
      "          -4.7807, -10.1793,  -5.3509]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.780682563781738\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9009,  -2.0735,  -2.9902,  -6.5826,  -0.4633,  -4.7857,  -8.2167,\n",
      "          -3.6456, -10.1162,  -4.6896]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.9008688926696777\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0053,  -2.1913,  -2.1237,  -6.3849,  -1.1647,  -4.8462,  -7.9676,\n",
      "          -2.7256, -10.1413,  -4.1830]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.123690128326416\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8811,  -2.7997,  -1.1323,  -6.6260,  -2.4471,  -5.3238,  -8.1614,\n",
      "          -2.3659, -10.5818,  -4.1560]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.4470667839050293\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2481,  -3.5730,  -0.6504,  -7.0236,  -3.0966,  -5.9366,  -8.5156,\n",
      "          -2.2944, -11.1579,  -4.3230]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.023613929748535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6503,  -4.1552,  -0.4554,  -6.4676,  -3.5799,  -6.3549,  -8.6993,\n",
      "          -2.1730, -11.5412,  -4.3479]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.467552661895752\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8753,  -4.4155,  -0.4579,  -4.9193,  -3.7599,  -6.4568,  -8.5889,\n",
      "          -1.8763, -11.6105,  -4.1042]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  11.610535621643066\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9293,  -4.3996,  -0.6526,  -3.2716,  -3.6801,  -6.2903,  -8.2303,\n",
      "          -1.4690, -10.7051,  -3.6379]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.70511531829834\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0284, -4.3403, -1.1446, -1.7628, -3.5726, -6.0872, -7.8532, -1.2268,\n",
      "         -9.1318, -3.1833]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.572634696960449\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4661, -4.5500, -2.0680, -0.7910, -3.0047, -6.1592, -7.7673, -1.4902,\n",
      "         -7.9684, -3.0586]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.550001621246338\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0785, -4.1467, -3.1466, -0.4257, -2.6871, -6.3824, -7.8471, -2.0596,\n",
      "         -7.0780, -3.1386]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.1465766429901123\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4708, -3.6031, -3.2405, -0.4116, -2.2593, -6.3920, -7.7268, -2.4790,\n",
      "         -6.0844, -3.0509]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.391973972320557\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5672, -2.8547, -3.0737, -0.6324, -1.6726, -5.4391, -7.3394, -2.6426,\n",
      "         -4.9118, -2.7283]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.911829948425293\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6191, -2.1691, -2.9010, -1.1861, -1.2290, -4.5287, -6.9358, -2.7900,\n",
      "         -3.1039, -2.4317]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.900984287261963\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9070, -1.8601, -2.2949, -2.1424, -1.2695, -3.9380, -6.7948, -3.1924,\n",
      "         -1.7293, -2.4529]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.794836521148682\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4484, -1.9674, -2.0884, -3.3620, -1.7831, -3.6871, -6.1526, -3.8544,\n",
      "         -0.8845, -2.8047]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.884454607963562\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5243, -2.7497, -2.5704, -5.0667, -2.9508, -4.0581, -6.1557, -5.0469,\n",
      "         -0.2910, -3.7471]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.058140277862549\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3771, -3.3839, -2.9400, -6.4878, -3.9225, -3.6040, -6.0414, -6.0068,\n",
      "         -0.1661, -4.4946]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.487827301025391\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6948, -3.5292, -2.8591, -6.5418, -4.3608, -2.7622, -5.4888, -6.4217,\n",
      "         -0.1983, -4.7248]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.724842071533203\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6193, -3.3198, -2.4646, -6.2290, -4.4026, -1.6848, -4.6321, -6.4340,\n",
      "         -0.4393, -3.8208]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.63206672668457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5819, -3.1883, -2.1995, -5.9784, -4.4789, -0.8711, -3.1177, -6.4760,\n",
      "         -1.1359, -3.0529]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.188307046890259\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8053, -2.5999, -2.2959, -6.0109, -4.8121, -0.6806, -2.0448, -6.7710,\n",
      "         -2.2437, -2.6532]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.295936346054077\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.1634, -2.2824, -1.8991, -6.1981, -5.2745, -1.0111, -1.3363, -7.1938,\n",
      "         -3.4717, -2.5027]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.163393974304199\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7982, -2.1118, -1.6861, -6.4062, -5.7325, -1.5948, -0.9422, -7.6129,\n",
      "         -4.6370, -2.4669]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.612912178039551\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3983, -1.9780, -1.5544, -6.5230, -6.0756, -2.1873, -0.8210, -7.1377,\n",
      "         -5.6213, -2.4271]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.523002624511719\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8758, -1.7989, -1.4228, -5.6947, -6.2226, -2.6338, -0.8928, -6.5469,\n",
      "         -6.3466, -2.2945]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.7988723516464233\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4469, -1.0463, -1.5154, -4.9910, -6.3960, -3.1245, -1.3171, -6.0554,\n",
      "         -7.0403, -2.2909]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.990969181060791\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0757, -0.6465, -1.7672, -3.6089, -6.5653, -3.6083, -1.9207, -5.6267,\n",
      "         -7.6776, -2.3762]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.376206159591675\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7431, -0.6798, -2.1128, -2.3824, -6.7159, -4.0596, -2.5758, -5.2405,\n",
      "         -8.2489, -1.7648]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.240509510040283\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4672, -1.1096, -2.5273, -1.3661, -6.8696, -4.4950, -3.2425, -4.1371,\n",
      "         -8.7806, -1.3608]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.7806396484375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3584, -1.8767, -3.0889, -0.7789, -7.1402, -5.0260, -4.0049, -3.2873,\n",
      "         -8.6888, -1.3223]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.004854679107666\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2537, -2.6670, -3.6111, -0.5874, -7.3683, -5.4926, -3.9064, -2.5352,\n",
      "         -8.5901, -1.4730]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.6670165061950684\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0324, -2.5382, -3.9631, -0.7048, -7.4368, -5.7782, -3.6961, -1.7823,\n",
      "         -8.3639, -1.6446]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.36391830444336\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7288, -2.3646, -4.1766, -1.0726, -7.3818, -5.9203, -3.4090, -1.1185,\n",
      "         -7.3451, -1.8280]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.072596549987793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6389, -2.4449, -4.5456, -1.0644, -7.4985, -6.2160, -3.3421, -0.9418,\n",
      "         -6.5940, -2.2805]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.9417747259140015\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7736, -2.7792, -5.0820, -1.5180, -7.8006, -6.6801, -3.5061, -0.5042,\n",
      "         -6.1152, -2.9619]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.7792344093322754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7562, -2.2195, -5.4139, -1.9389, -7.9175, -6.9434, -3.5218, -0.4257,\n",
      "         -5.5301, -3.4591]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.2194666862487793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6988, -0.9906, -5.6572, -2.3694, -7.9642, -7.1224, -3.5002, -0.8039,\n",
      "         -4.9472, -3.8719]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.5001957416534424\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8922, -0.3899, -6.1058, -3.0558, -8.2334, -7.5111, -2.9516, -1.7187,\n",
      "         -4.6543, -4.4863]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.7187073230743408\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0742, -0.3500, -6.5043, -3.7030, -8.4691, -7.8544, -2.4913, -1.8978,\n",
      "         -4.3902, -5.0411]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.041131496429443\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9159, -0.5062, -6.5295, -3.9700, -8.3468, -7.8292, -1.8069, -1.8405,\n",
      "         -3.8264, -4.4539]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.529522895812988\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6201, -0.9283, -5.6702, -4.0571, -8.0690, -7.6389, -1.1509, -1.7441,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -3.1661, -3.7661]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.7441291809082031\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5417, -1.7711, -5.0671, -4.3172, -7.9874, -7.6362, -0.9757, -1.1870,\n",
      "         -2.7696, -3.3326]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.1870472431182861\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8634, -3.0279, -4.8997, -4.9327, -8.2852, -8.0052, -1.4833, -0.5211,\n",
      "         -2.8276, -3.3403]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.5210703611373901\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7172, -4.7446, -5.3031, -6.0413, -9.1024, -8.8865, -2.6663, -0.1574,\n",
      "         -3.4701, -3.9229]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.303050518035889\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1031, -5.9074, -4.5684, -6.6519, -9.4489, -9.2907, -3.3963, -0.1013,\n",
      "         -3.6812, -4.0730]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.651886940002441\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8639, -6.3653, -3.3232, -5.8433, -9.1697, -9.0635, -3.4887, -0.1539,\n",
      "         -3.2977, -3.6298]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.863945007324219\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5325, -6.3888, -1.8374, -4.7273, -8.5283, -8.4689, -3.2056, -0.4657,\n",
      "         -2.5883, -2.8608]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.727301597595215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6013, -6.6576, -0.8598, -3.2130, -8.1972, -8.1799, -3.2288, -1.4707,\n",
      "         -2.2488, -2.4581]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.2129569053649902\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2920, -7.3754, -0.7569, -1.5975, -8.3742, -8.3948, -3.7554, -3.0257,\n",
      "         -2.4923, -2.6352]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.2919955253601074\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7740, -8.4376, -1.4147, -0.7128, -8.9490, -9.0038, -4.6634, -4.8785,\n",
      "         -3.1852, -3.2646]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.949047088623047\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5697, -9.5323, -2.3186, -0.4289, -8.8484, -9.6903, -5.6264, -6.6906,\n",
      "         -3.9763, -3.9983]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.998349189758301\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3124, -10.2927,  -2.9775,  -0.4446,  -8.5326, -10.0832,  -6.2710,\n",
      "          -8.0980,  -4.4765,  -3.6904]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.9774506092071533\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0075, -10.7073,  -2.6236,  -0.6760,  -7.9782, -10.1668,  -6.5829,\n",
      "          -9.0953,  -4.6649,  -3.1619]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.58286190032959\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8018, -10.8826,  -2.1586,  -1.0720,  -7.2811, -10.0441,  -5.8844,\n",
      "          -9.7954,  -4.6431,  -2.5199]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.0720231533050537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0365, -11.1328,  -1.9146,  -1.0217,  -6.7464, -10.0259,  -5.3499,\n",
      "         -10.5182,  -4.7226,  -2.0953]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.0365445613861084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8666, -11.4480,  -1.8900,  -1.3391,  -6.3556, -10.0996,  -4.9623,\n",
      "         -11.2590,  -4.8903,  -1.8961]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.33905827999115\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0427, -11.7542,  -1.9979,  -1.0885,  -6.0274, -10.1882,  -4.6411,\n",
      "         -11.9484,  -5.0691,  -1.8531]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.0690836906433105\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2874, -11.8590,  -2.0210,  -0.9468,  -5.5628, -10.0972,  -4.1885,\n",
      "         -12.3983,  -4.3582,  -1.7623]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.188508033752441\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5701, -11.8145,  -1.9975,  -0.9737,  -5.0085,  -9.8763,  -2.8758,\n",
      "         -12.6645,  -3.5882,  -1.6721]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.9975171089172363\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0627, -11.8607,  -1.4464,  -1.3697,  -4.6008,  -9.7638,  -1.8240,\n",
      "         -12.9906,  -3.0008,  -1.8198]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.4464117288589478\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9876, -12.2910,  -0.7959,  -2.3069,  -4.6299, -10.0512,  -1.3915,\n",
      "         -13.6727,  -2.8955,  -2.4645]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.6298627853393555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9287, -12.7498,  -0.6029,  -3.2976,  -3.9785, -10.3814,  -1.2678,\n",
      "         -14.3584,  -2.9111,  -3.1811]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  10.38135814666748\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5952, -12.9677,  -0.6232,  -4.0224,  -3.2110,  -9.7892,  -1.1809,\n",
      "         -14.7806,  -2.7684,  -3.6627]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.2109572887420654\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0816, -13.0428,  -0.9012,  -4.5675,  -1.6772,  -9.1350,  -1.2213,\n",
      "         -15.0396,  -2.5632,  -3.9947]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.567462921142578\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.7291, -13.3153,  -1.6445,  -4.5142,  -0.6424,  -8.7508,  -1.6926,\n",
      "         -15.4778,  -2.6378,  -4.5126]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  15.477785110473633\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4724, -13.7187,  -2.6088,  -4.6325,  -0.2669,  -8.5629,  -2.4187,\n",
      "         -15.2620,  -2.9135,  -5.1452]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.418701648712158\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8938, -13.8328,  -3.2804,  -4.4973,  -0.2580,  -8.1448,  -2.1130,\n",
      "         -14.8187,  -2.9512,  -5.4703]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.280416488647461\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8982, -13.5598,  -2.8255,  -4.0082,  -0.4549,  -7.3928,  -1.5561,\n",
      "         -14.0436,  -2.6464,  -5.3904]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.5560933351516724\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0703, -13.4813,  -2.6254,  -3.7489,  -1.2750,  -6.8834,  -0.6096,\n",
      "         -13.5131,  -2.5895,  -5.4894]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.5895214080810547\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.4190, -13.6038,  -2.6896,  -3.7263,  -2.4161,  -6.6185,  -0.3733,\n",
      "         -13.2286,  -2.0774,  -5.7747]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.077388286590576\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.7199, -13.7005,  -2.7819,  -3.7106,  -3.4970,  -6.3673,  -0.6809,\n",
      "         -12.9587,  -0.9873,  -6.0204]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.710588216781616\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.1268, -13.9233,  -3.0448,  -3.0968,  -4.6288,  -6.2781,  -1.4852,\n",
      "         -12.8515,  -0.4048,  -6.3793]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.4852275848388672\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.5161, -14.1465,  -3.3379,  -2.6009,  -5.6779,  -6.2216,  -1.6329,\n",
      "         -12.7775,  -0.3738,  -6.7263]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.726319313049316\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.5448, -14.0255,  -3.3051,  -1.8883,  -6.3031,  -5.8502,  -1.5949,\n",
      "         -12.3889,  -0.5082,  -5.9557]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.5082443952560425\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.7435, -14.0894,  -3.4744,  -1.5338,  -7.0403,  -5.6906,  -1.8903,\n",
      "         -12.2118,  -0.5217,  -5.4365]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  14.089356422424316\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.6729, -13.1413,  -3.3992,  -1.1278,  -7.4550,  -5.2994,  -2.0234,\n",
      "         -11.8026,  -0.7012,  -4.7226]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.7011779546737671\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.7334, -12.4117,  -3.4793,  -1.1309,  -7.9530,  -5.0748,  -2.3694,\n",
      "         -11.5582,  -0.6325,  -4.2106]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.210580825805664\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.5535, -11.5202,  -3.3387,  -1.1429,  -8.1670,  -4.6423,  -2.5189,\n",
      "         -11.1035,  -0.7090,  -2.7683]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.51887845993042\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.3814, -10.7072,  -3.2273,  -1.3842,  -8.3498,  -4.2494,  -1.9324,\n",
      "         -10.6839,  -1.1127,  -1.5071]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.2272531986236572\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4562, -10.2047,  -2.6740,  -2.0203,  -8.7441,  -4.1352,  -1.7456,\n",
      "         -10.5357,  -1.9362,  -0.7696]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  10.535664558410645\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.5902, -9.8188, -2.2913, -2.7597, -9.1658, -4.1100, -1.7787, -9.6997,\n",
      "         -2.8454, -0.5246]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.699677467346191\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.5127, -9.2730, -1.8203, -3.2752, -9.3473, -3.9006, -1.7406, -7.9859,\n",
      "         -3.5067, -0.5554]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.5553734302520752\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.6387, -8.9772, -1.7069, -3.9635, -9.7063, -3.9217, -2.0374, -6.6385,\n",
      "         -4.3187, -0.4551]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.037381887435913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.5794, -8.5381, -1.5611, -4.4248, -9.8569, -3.7819, -1.4612, -5.2534,\n",
      "         -4.8865, -0.6730]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.85689640045166\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.3909, -8.0077, -1.4440, -4.7141, -9.1030, -3.5367, -0.9859, -3.8750,\n",
      "         -5.2678, -1.1201]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.714088439941406\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.1669, -7.4758, -1.4520, -4.1702, -8.3698, -3.2819, -0.7911, -2.5953,\n",
      "         -5.5604, -1.7150]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.7149850130081177\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.0356, -7.0675, -1.6960, -3.7623, -7.7799, -3.1491, -1.0348, -1.5705,\n",
      "         -5.8967, -1.6989]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.762307643890381\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.9898, -6.7727, -2.1184, -2.7333, -7.3212, -3.1318, -1.5999, -0.8799,\n",
      "         -6.2737, -1.8949]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.321243762969971\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.0052, -6.5644, -2.6409, -1.9121, -6.2151, -3.2032, -2.3204, -0.6335,\n",
      "         -6.6708, -2.2413]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.5644049644470215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.9431, -5.5448, -3.0859, -1.2077, -5.1444, -3.2200, -2.9688, -0.7432,\n",
      "         -6.9532, -2.5575]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.943061828613281\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0721, -4.5528, -3.4424, -0.7218, -4.1078, -3.1864, -3.5152, -1.1298,\n",
      "         -7.1311, -2.8240]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.107784748077393\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2284, -3.6074, -3.7260, -0.5901, -2.3804, -3.1250, -3.9701, -1.6656,\n",
      "         -7.2318, -3.0487]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.228411674499512\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8374, -2.8774, -4.0994, -0.9889, -0.9951, -3.2015, -4.4950, -2.3937,\n",
      "         -7.4237, -3.3878]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.837350368499756\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2384, -2.6390, -4.8237, -2.0037, -0.4019, -3.6753, -5.3526, -3.4958,\n",
      "         -7.9733, -4.0949]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.352618217468262\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8563, -2.5075, -5.5104, -3.0476, -0.3989, -4.1487, -5.3859, -4.5402,\n",
      "         -8.4971, -4.7731]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.5075178146362305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8380, -1.8065, -6.2432, -4.1349, -1.0098, -4.6975, -5.5309, -5.6004,\n",
      "         -9.0805, -5.5017]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  9.080465316772461\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4540, -1.5144, -7.1190, -5.3405, -2.0467, -5.4128, -5.8790, -6.7724,\n",
      "         -9.1146, -6.3755]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.04673433303833\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4805, -1.3236, -7.8136, -6.3351, -2.2353, -5.9654, -6.1001, -7.7341,\n",
      "         -9.0508, -7.0689]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.813590049743652\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6440, -1.0400, -7.4113, -6.9184, -2.1711, -6.1511, -5.9873, -8.2867,\n",
      "         -8.6798, -7.3804]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.411255836486816\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9224, -0.7996, -6.0871, -7.1915, -1.9455, -6.0669, -5.6346, -8.5316,\n",
      "         -8.0929, -7.4083]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.092885971069336\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2443, -0.7044, -4.6771, -7.2186, -1.6298, -5.7734, -5.1005, -8.5329,\n",
      "         -6.6428, -7.2146]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.77342414855957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5557, -0.8036, -3.2250, -7.0546, -1.3027, -4.6166, -4.4353, -8.3452,\n",
      "         -5.1489, -6.8518]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.054555416107178\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9334, -1.1742, -1.8888, -6.0970, -1.1541, -3.5249, -3.7884, -8.1194,\n",
      "         -3.7508, -6.4688]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.0969719886779785\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5759, -1.9380, -0.9899, -4.6854, -1.4522, -2.7592, -3.4199, -8.1128,\n",
      "         -2.7050, -6.3217]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.7050211429595947\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5650, -3.0895, -0.8003, -3.7761, -2.2502, -2.4692, -3.4682, -8.4619,\n",
      "         -1.4644, -6.5454]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.564974784851074\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9734, -4.3913, -1.1800, -3.2049, -3.2779, -2.4984, -3.7662, -9.0069,\n",
      "         -0.7405, -6.9783]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.006855010986328\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3748, -5.5927, -1.7607, -2.7408, -4.2513, -2.6027, -4.0723, -8.7469,\n",
      "         -0.4446, -7.3887]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.7606732845306396\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6439, -6.5758, -1.5927, -2.2698, -5.0370, -2.6474, -4.2595, -8.4114,\n",
      "         -0.5274, -7.6572]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.5927350521087646\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9056, -7.4745, -0.8897, -1.9357, -5.7617, -2.7502, -4.4515, -8.1218,\n",
      "         -1.0285, -7.9117]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.121847152709961\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1509, -8.2884, -0.5526, -1.7476, -6.4208, -2.8923, -4.6376, -7.1002,\n",
      "         -1.7347, -8.1454]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.892301559448242\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2628, -8.9082, -0.5441, -1.5958, -6.9023, -2.2400, -4.6994, -6.0675,\n",
      "         -2.3810, -8.2427]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.908163070678711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1851, -8.5254, -0.7653, -1.4295, -7.1544, -1.5458, -4.5800, -4.9573,\n",
      "         -2.8458, -8.1484]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.185121536254883\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3165, -8.1080, -1.2207, -1.3870, -7.3093, -0.9986, -4.4077, -3.8902,\n",
      "         -3.2324, -7.9910]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.407650947570801\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5232, -7.7116, -1.8185, -1.5156, -7.4283, -0.7454, -3.4677, -2.9241,\n",
      "         -3.5873, -7.8285]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.7453887462615967\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1587, -7.6831, -2.7998, -2.1249, -7.8641, -0.4745, -2.9737, -2.4238,\n",
      "         -4.2545, -8.0108]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.683084964752197\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7241, -6.7665, -3.5893, -2.6261, -8.1196, -0.5329, -2.4311, -1.9041,\n",
      "         -4.7280, -8.0379]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.727972507476807\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2511, -5.8123, -4.1900, -3.0023, -8.2201, -0.8694, -1.8809, -1.4212,\n",
      "         -4.3279, -7.9328]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.2511391639709473\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3056, -5.0871, -4.8735, -3.5102, -8.4427, -1.5994, -1.6354, -1.3042,\n",
      "         -4.1086, -7.9702]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.3041702508926392\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9909, -4.7776, -5.8332, -4.3288, -8.9820, -2.7378, -1.9042, -0.9778,\n",
      "         -4.2616, -8.3430]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.98204231262207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8854, -4.4121, -6.6062, -4.9828, -8.6243, -3.7154, -2.1684, -0.8802,\n",
      "         -4.3160, -8.5857]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.982756614685059\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8629, -3.8636, -7.0748, -4.5952, -8.0738, -4.3844, -2.2666, -0.8827,\n",
      "         -4.1459, -8.5759]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.074841499328613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9010, -3.1365, -6.5385, -4.0047, -7.3292, -4.7465, -2.1862, -0.9534,\n",
      "         -3.7547, -8.3181]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.9010246992111206\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6327, -2.6450, -6.1868, -3.6169, -6.7895, -5.2089, -2.3313, -1.4432,\n",
      "         -3.5493, -8.2164]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.216400146484375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6154, -2.0937, -5.7091, -3.1255, -6.1419, -5.4667, -2.3750, -1.9030,\n",
      "         -3.2220, -7.1963]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.466723442077637\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8439, -1.5421, -5.1327, -2.5674, -5.4118, -4.8468, -2.3379, -2.2830,\n",
      "         -2.8068, -6.1296]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.846813201904297\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3316, -1.1774, -4.5875, -2.0924, -4.7273, -3.5623, -2.3492, -2.6731,\n",
      "         -2.4451, -5.1405]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.0924010276794434\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1670, -1.2871, -4.3083, -1.2110, -4.3222, -2.6301, -2.6381, -3.2821,\n",
      "         -2.3851, -4.4589]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.458882808685303\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1711, -1.7636, -4.2350, -0.8098, -4.1358, -2.0099, -3.1223, -4.0277,\n",
      "         -2.5644, -3.2602]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.009862184524536\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3232, -2.5403, -4.3967, -1.0006, -4.1975, -1.0632, -3.8101, -4.9304,\n",
      "         -2.9977, -2.4276]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.3231964111328125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7931, -3.4510, -4.7026, -1.5999, -4.4160, -0.6050, -4.5981, -5.9003,\n",
      "         -3.5746, -1.8970]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.598149299621582\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1634, -4.2362, -4.9256, -2.2324, -4.5629, -0.5171, -4.4794, -6.7169,\n",
      "         -4.0550, -1.4753]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.2323718070983887\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3667, -4.8201, -4.9974, -1.9979, -4.5688, -0.7217, -4.2471, -7.3188,\n",
      "         -4.3655, -1.1365]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.5687713623046875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3829, -5.1815, -4.8964, -1.7181, -3.6607, -1.0758, -3.8787, -7.6910,\n",
      "         -4.4838, -0.9070]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.691035270690918\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2665, -5.3771, -4.6766, -1.4665, -2.7281, -1.4989, -3.4288, -7.1222,\n",
      "         -4.4641, -0.8754]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.8753701448440552\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4039, -5.7951, -4.7237, -1.6512, -2.1759, -2.2747, -3.2872, -6.8489,\n",
      "         -4.6929, -0.6390]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.6512174606323242\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5477, -6.1906, -4.7893, -1.2296, -1.7808, -3.0621, -3.2056, -6.6204,\n",
      "         -4.9222, -0.8466]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.205583095550537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6242, -6.4926, -4.7985, -1.0131, -1.4962, -3.7481, -2.3337, -6.3600,\n",
      "         -5.0780, -1.3053]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.748079299926758\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6644, -6.7343, -4.7813, -1.0585, -1.3773, -3.6499, -1.5924, -6.0954,\n",
      "         -5.1914, -1.8940]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.781287670135498\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6664, -6.9161, -4.0237, -1.3222, -1.4236, -3.5430, -1.0461, -5.8223,\n",
      "         -5.2608, -2.5024]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.822291374206543\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5985, -7.0084, -3.2820, -1.6868, -1.5743, -3.3947, -0.7545, -4.7399,\n",
      "         -5.2548, -3.0405]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.394686698913574\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4385, -6.9906, -2.5392, -2.0520, -1.7645, -2.4856, -0.7548, -3.6705,\n",
      "         -5.1514, -3.4601]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.7547956109046936\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5916, -7.2692, -2.2207, -2.7710, -2.3589, -2.0192, -0.6386, -3.0210,\n",
      "         -5.3565, -4.1560]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.6386317610740662\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0290, -7.8175, -2.3080, -3.7622, -3.2621, -1.9886, -0.4658, -2.7705,\n",
      "         -5.8412, -5.0914]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.4658088982105255\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6857, -8.5726, -2.7187, -4.9331, -4.3655, -2.3179, -0.2835, -2.8542,\n",
      "         -6.5409, -6.1995]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.317877769470215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.9719, -8.9466, -2.8296, -5.6869, -5.0626, -1.6811, -0.3967, -2.6678,\n",
      "         -6.8660, -6.8929]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.686933994293213\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.9944, -9.0477, -2.7356, -5.3833, -5.4591, -1.0016, -0.7813, -2.3175,\n",
      "         -6.9235, -7.2821]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.282069683074951\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.9706, -9.0940, -2.6527, -5.0686, -5.7747, -0.6013, -1.4354, -2.0332,\n",
      "         -6.9313, -6.8227]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.931334972381592\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8297, -9.0156, -2.5081, -4.6697, -5.9411, -0.5028, -2.0873, -1.7579,\n",
      "         -6.1090, -6.2897]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.669658660888672\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5013, -8.7428, -2.2338, -3.3710, -5.8906, -0.6326, -2.5677, -1.4406,\n",
      "         -5.1678, -5.6089]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.233827829360962\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2347, -8.5253, -1.3780, -2.2552, -5.8752, -1.1465, -3.0875, -1.3653,\n",
      "         -4.3523, -5.0267]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.87518835067749\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1605, -8.4940, -0.9517, -1.4931, -5.2728, -1.9944, -3.7551, -1.6587,\n",
      "         -3.7916, -4.6719]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.951687753200531\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5087, -8.8795, -0.5443, -1.3881, -5.1478, -3.2660, -4.7878, -2.4832,\n",
      "         -3.7162, -4.7730]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.147802829742432\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6975, -9.1008, -0.4655, -1.3540, -4.1640, -4.3117, -5.5982, -3.1640,\n",
      "         -3.5397, -4.7447]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.46552470326423645\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0570, -9.4888, -0.3184, -1.7046, -3.4785, -5.4513, -6.5195, -3.9984,\n",
      "         -3.5901, -4.9145]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.5901012420654297\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0755, -9.5325, -0.3980, -1.8504, -2.5786, -6.1747, -7.0444, -4.4581,\n",
      "         -2.6407, -4.7672]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.397994726896286\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.3180, -9.7970, -0.4614, -2.3241, -2.0505, -7.0526, -7.7428, -5.1061,\n",
      "         -2.0615, -4.8662]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.866213798522949\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.3662, -9.8646, -0.7958, -2.6533, -1.5014, -7.6732, -8.2015, -5.5237,\n",
      "         -1.4598, -4.0267]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.653282403945923\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.4454, -9.9607, -1.4523, -2.2915, -1.2100, -8.2676, -8.6500, -5.9380,\n",
      "         -1.1184, -3.3197]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.2914557456970215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.6246, -10.1549,  -2.3170,  -1.4069,  -1.2799,  -8.9105,  -9.1615,\n",
      "          -6.4207,  -1.1509,  -2.8182]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.2799453735351562\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.0337, -10.5772,  -3.4131,  -1.0399,  -1.0477,  -9.7369,  -9.8696,\n",
      "          -7.1040,  -1.6524,  -2.6598]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.6598286628723145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.3954, -10.9505,  -4.4166,  -0.9655,  -1.0956, -10.4741, -10.5003,\n",
      "          -7.7129,  -2.2332,  -1.8025]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.095630407333374\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.9145, -11.4798,  -5.5219,  -1.3748,  -0.8327, -11.3312, -11.2613,\n",
      "          -8.4548,  -3.0255,  -1.3497]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.45479965209961\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.2619, -11.8364,  -6.3999,  -1.8112,  -0.8028, -11.9828, -11.8266,\n",
      "          -8.2300,  -3.6535,  -1.0202]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  11.98283863067627\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.3645, -11.9472,  -6.9815,  -2.1153,  -0.9021, -11.6608, -12.1253,\n",
      "          -7.8176,  -4.0271,  -0.7887]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.027069091796875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.2084, -11.7984,  -7.2573,  -2.2303,  -1.0473, -11.1222, -12.1458,\n",
      "          -7.1979,  -3.4171,  -0.6788]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.197901248931885\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.8008, -11.3973,  -7.2390,  -2.1466,  -1.1739, -10.3701, -11.8971,\n",
      "          -5.6057,  -2.6239,  -0.6995]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  11.397308349609375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.2421, -10.0743,  -7.0313,  -1.9666,  -1.3279,  -9.5012, -11.4814,\n",
      "          -3.9831,  -1.7695,  -0.9046]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.9665729999542236\n",
      "torch.Size([1, 1, 40])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -7.8835,  -9.0273,  -6.9892,  -1.3092,  -1.8096,  -8.8631, -11.2514,\n",
      "          -2.6806,  -1.2656,  -1.5414]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.680605411529541\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.9061,  -8.4298,  -7.2972,  -1.2630,  -2.7113,  -8.6339, -11.3895,\n",
      "          -1.1412,  -1.3575,  -2.6231]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.429847717285156\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.3263,  -7.5263,  -7.9745,  -1.8310,  -3.9727,  -8.8271, -11.9134,\n",
      "          -0.4005,  -2.0228,  -4.0519]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.02275013923645\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.7164,  -6.7248,  -8.5963,  -2.4731,  -5.1342,  -9.0128, -12.3968,\n",
      "          -0.2608,  -2.0173,  -5.3634]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.017333984375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.8211,  -5.7572,  -8.9095,  -2.8672,  -5.9378,  -8.9333, -12.5853,\n",
      "          -0.4788,  -1.1534,  -6.3012]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.757187366485596\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.8357,  -4.0475,  -9.1119,  -3.1846,  -6.5837,  -8.7821, -12.6753,\n",
      "          -1.0685,  -0.5193,  -7.0673]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.04747200012207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.8971,  -1.8135,  -9.3423,  -3.5493,  -7.2144,  -8.6942, -12.8044,\n",
      "          -1.9097,  -0.4178,  -7.8058]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.8135467767715454\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.9910,  -0.2105, -10.5885,  -4.9376,  -8.8214,  -9.6537, -13.9592,\n",
      "          -3.8189,  -1.8302,  -9.5098]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.2105490267276764\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2365e+01, -1.1581e-02, -1.3099e+01, -7.5817e+00, -1.1657e+01,\n",
      "         -1.1906e+01, -1.6388e+01, -6.9433e+00, -4.6038e+00, -1.2433e+01]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  13.09913158416748\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3912e+01, -1.6715e-03, -1.4056e+01, -9.3730e+00, -1.3621e+01,\n",
      "         -1.3345e+01, -1.7984e+01, -9.1676e+00, -6.5186e+00, -1.4475e+01]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.167586326599121\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4554e+01, -6.6068e-04, -1.4165e+01, -1.0234e+01, -1.4637e+01,\n",
      "         -1.3888e+01, -1.8670e+01, -9.6539e+00, -7.4918e+00, -1.5562e+01]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  14.553521156311035\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3637e+01, -6.2029e-04, -1.3510e+01, -1.0256e+01, -1.4799e+01,\n",
      "         -1.3624e+01, -1.8535e+01, -9.3387e+00, -7.6154e+00, -1.5787e+01]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  18.5349063873291\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2065e+01, -1.2657e-03, -1.2173e+01, -9.5293e+00, -1.4197e+01,\n",
      "         -1.2639e+01, -1.6886e+01, -8.3077e+00, -6.9798e+00, -1.5243e+01]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  15.242959022521973\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.9108e+00, -5.1681e-03, -1.0231e+01, -8.1360e+00, -1.2917e+01,\n",
      "         -1.1014e+01, -1.4662e+01, -6.6409e+00, -5.6696e+00, -1.3250e+01]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.136022567749023\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.2695,  -0.0409,  -7.7808,  -5.4356, -11.0628,  -8.8487, -11.9588,\n",
      "          -4.4395,  -3.7907, -10.7529]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  11.0628023147583\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5736, -0.4588, -5.2566, -2.6893, -8.3215, -6.5812, -9.2062, -2.1483,\n",
      "         -1.7968, -8.1869]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  9.206243515014648\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2361, -2.3814, -4.0698, -1.3494, -6.9356, -5.6228, -7.0350, -1.2567,\n",
      "         -1.2014, -6.9589]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.958941459655762\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6799, -4.7998, -3.6323, -0.9550, -6.3074, -5.3812, -5.6994, -1.2903,\n",
      "         -1.4975, -5.7126]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.712590217590332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1924, -6.9460, -3.2197, -0.8490, -5.7054, -5.1294, -4.4618, -1.4933,\n",
      "         -1.8851, -3.8008]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.8851003646850586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9155, -8.9582, -2.9558, -1.1509, -5.2449, -4.9857, -3.4353, -1.9267,\n",
      "         -1.7111, -2.1752]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.175196886062622\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3342, -11.3287,  -3.3141,  -2.2166,  -5.3926,  -5.4197,  -3.0947,\n",
      "          -2.9869,  -2.2409,  -0.6039]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.419710159301758\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3486, -14.0286,  -4.2281,  -3.8227,  -6.0945,  -5.6752,  -3.3885,\n",
      "          -4.5454,  -3.3586,  -0.1701]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.67521858215332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9726, -16.1442,  -4.7460,  -4.9697,  -6.4125,  -4.8930,  -3.3639,\n",
      "          -5.6414,  -4.0741,  -0.1040]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.074126720428467\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9921, -17.4927,  -4.6622,  -5.4511,  -6.1437,  -3.6375,  -2.8122,\n",
      "          -6.0745,  -3.4668,  -0.1675]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  17.492660522460938\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6462, -17.5844,  -4.2162,  -5.5107,  -5.5260,  -2.1482,  -1.9851,\n",
      "          -6.0890,  -2.5648,  -0.4815]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  17.584426879882812\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5350, -17.1087,  -4.0061,  -5.7481,  -5.1537,  -1.0700,  -1.5285,\n",
      "          -6.2847,  -1.9879,  -1.4066]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.4066466093063354\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8280, -17.0517,  -4.2014,  -6.3357,  -5.1942,  -0.7119,  -1.6582,\n",
      "          -6.8336,  -1.9367,  -2.0442]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.0441904067993164\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0438, -16.9361,  -4.3238,  -6.8018,  -5.1706,  -0.6702,  -1.8596,\n",
      "          -7.2646,  -1.9284,  -1.9037]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.85960054397583\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1874, -16.7681,  -4.3798,  -7.1586,  -5.0898,  -0.9281,  -1.3189,\n",
      "          -7.5893,  -1.9601,  -1.8246]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.089776992797852\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2316, -16.5205,  -4.3427,  -7.3840,  -4.1710,  -1.3413,  -0.9442,\n",
      "          -7.7856,  -1.9921,  -1.7773]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.342741012573242\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1828, -16.1980,  -3.5004,  -7.4879,  -3.2557,  -1.7973,  -0.8106,\n",
      "          -7.8633,  -2.0180,  -1.7613]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.8106428980827332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4180, -16.1754,  -3.0315,  -7.8497,  -2.7285,  -2.5920,  -0.5257,\n",
      "          -8.2012,  -2.4034,  -2.1431]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.592043399810791\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4991, -16.0154,  -2.5042,  -8.0360,  -2.1635,  -2.5180,  -0.5897,\n",
      "          -8.3661,  -2.6748,  -2.4347]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.5180165767669678\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5063, -15.7970,  -2.0139,  -8.1298,  -1.6674,  -1.7350,  -1.0038,\n",
      "          -8.4405,  -2.8939,  -2.6885]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.667364478111267\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8166, -15.8960,  -1.9644,  -8.5102,  -0.9053,  -1.4490,  -1.9567,\n",
      "          -8.8033,  -3.4262,  -3.2636]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.426220417022705\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.2013, -16.0843,  -2.1198,  -8.9519,  -0.6239,  -1.4547,  -3.0237,\n",
      "          -9.2292,  -3.3186,  -3.9091]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.909080743789673\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3748, -16.0769,  -2.1694,  -9.1729,  -0.5980,  -1.4463,  -3.8453,\n",
      "          -9.4358,  -3.0703,  -3.5816]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.5816235542297363\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3372, -15.8729,  -2.0991,  -9.1745,  -0.7916,  -1.4060,  -4.4044,\n",
      "          -9.4246,  -2.6823,  -2.3687]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.174506187438965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.2760, -15.6582,  -2.0933,  -8.3966,  -1.2759,  -1.5103,  -4.8864,\n",
      "          -9.3836,  -2.3505,  -1.3153]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.2758878469467163\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4831, -15.7233,  -2.4353,  -7.9546,  -1.4273,  -2.0171,  -5.5847,\n",
      "          -9.6051,  -2.3777,  -0.8248]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.9545578956604\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5622, -15.6714,  -2.6960,  -6.7029,  -1.6335,  -2.4561,  -6.1058,\n",
      "          -9.6941,  -2.3576,  -0.5987]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.105847358703613\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4051, -15.3934,  -2.7483,  -5.3455,  -1.7348,  -2.6802,  -5.5676,\n",
      "          -9.5431,  -2.1754,  -0.5723]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  15.393399238586426\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0237, -14.1596,  -2.5984,  -3.8836,  -1.7154,  -2.6868,  -4.8426,\n",
      "          -9.1639,  -1.8488,  -0.7235]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.8487880229949951\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7666, -13.1298,  -2.5986,  -2.6638,  -1.9145,  -2.8218,  -4.2773,\n",
      "          -8.9039,  -1.0385,  -1.3001]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.663792133331299\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8673, -12.5284,  -2.9783,  -1.2018,  -2.5306,  -3.3109,  -4.1048,\n",
      "          -8.9957,  -0.8858,  -2.3470]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.867316246032715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5632, -12.3367,  -3.7069,  -0.4595,  -3.4951,  -4.1268,  -4.3121,\n",
      "          -9.4282,  -1.3905,  -3.7105]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.7104854583740234\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2705, -12.1375,  -4.3541,  -0.2358,  -4.3599,  -4.8462,  -4.4826,\n",
      "          -9.7912,  -1.9948,  -4.1868]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.359890937805176\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6164, -11.5570,  -4.5452,  -0.2208,  -3.9943,  -5.0984,  -4.2439,\n",
      "          -9.7170,  -2.2344,  -4.2258]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.2343854904174805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7323, -10.7190,  -4.4096,  -0.4853,  -3.3636,  -5.0144,  -3.7248,\n",
      "          -9.3348,  -1.5021,  -3.9564]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.334819793701172\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9395, -9.9189, -4.2507, -1.1322, -2.7761, -4.8980, -3.2306, -8.1723,\n",
      "         -0.9548, -3.6825]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.250736713409424\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4473, -9.3119, -3.5077, -2.0662, -2.4074, -4.9119, -2.9299, -7.2392,\n",
      "         -0.8479, -3.5679]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.9298512935638428\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2443, -8.8287, -2.9236, -3.0640, -2.2064, -4.9928, -1.9873, -6.4627,\n",
      "         -1.1177, -3.5489]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.2064273357391357\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4363, -8.5517, -2.5946, -4.1552, -1.5161, -5.2285, -1.4032, -5.9228,\n",
      "         -1.7500, -3.7112]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.55169677734375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8608, -7.6346, -2.4250, -5.2220, -1.1320, -5.5171, -1.1410, -5.5114,\n",
      "         -2.5149, -3.9481]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.132023811340332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6443, -7.0934, -2.6206, -6.4708, -0.5636, -6.0641, -1.4376, -5.4283,\n",
      "         -3.5451, -4.4600]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.6442980766296387\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5739, -6.5293, -2.7721, -7.5191, -0.4014, -6.4808, -1.8119, -5.2794,\n",
      "         -4.4158, -4.8521]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.480836391448975\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2425, -5.6972, -2.6286, -8.1382, -0.4312, -5.8282, -1.9507, -4.8241,\n",
      "         -4.8832, -4.8857]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.242483377456665\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1657, -4.8405, -2.4417, -8.5859, -0.8328, -5.1326, -2.0763, -4.3104,\n",
      "         -5.1995, -4.8117]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.8327802419662476\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7467, -4.3918, -2.6535, -9.3061, -1.0890, -4.8273, -2.6039, -4.1751,\n",
      "         -5.8051, -5.0679]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.827276706695557\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5674, -3.8398, -2.7382, -9.7975, -1.4135, -3.7007, -2.9794, -3.9081,\n",
      "         -6.1954, -5.1462]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.79747200012207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6234, -3.1523, -2.6549, -9.2913, -1.6806, -2.4970, -3.1506, -3.4768,\n",
      "         -6.3418, -5.0145]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.4767813682556152\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0627, -2.5537, -2.6197, -8.8242, -2.0488, -1.4597, -3.3268, -2.3275,\n",
      "         -6.4635, -4.8896]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.889618396759033\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9524, -2.3090, -2.8772, -8.6401, -2.7128, -0.9253, -3.7498, -1.6046,\n",
      "         -6.8106, -4.2763]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.810603141784668\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9607, -2.2638, -3.2513, -8.5756, -3.4614, -0.8241, -4.2503, -1.2106,\n",
      "         -6.5153, -3.8356]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.251281261444092\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8289, -2.2222, -2.8117, -8.4391, -4.0804, -0.9626, -4.6335, -1.0084,\n",
      "         -6.1720, -3.3762]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.633481979370117\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4814, -2.1200, -2.3140, -8.1710, -4.5050, -1.2100, -4.0618, -0.9637,\n",
      "         -5.7188, -2.8425]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.12003493309021\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1012, -1.3973, -1.9614, -7.9535, -4.9194, -1.6659, -3.5841, -1.2427,\n",
      "         -5.3369, -2.4291]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.6658968925476074\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8011, -1.0678, -1.8834, -7.8951, -5.4352, -1.6440, -3.3129, -1.8546,\n",
      "         -5.1336, -2.2596]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.6439855098724365\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5289, -1.1224, -2.0188, -7.9382, -5.9983, -1.1552, -3.1923, -2.6222,\n",
      "         -5.0501, -2.2801]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.1224007606506348\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.3608, -0.8460, -2.4127, -8.1526, -6.6825, -1.1112, -3.2910, -3.5450,\n",
      "         -5.1548, -2.5500]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.5500292778015137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.0095, -0.8154, -2.7317, -8.2450, -7.1988, -1.2011, -3.3082, -4.2976,\n",
      "         -5.1524, -2.0079]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.0079116821289062\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.6537, -1.1765, -3.1261, -8.3884, -7.7241, -1.5527, -3.4121, -5.0457,\n",
      "         -5.2142, -0.9406]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.1764841079711914\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.5244, -1.2790, -3.8037, -8.8081, -8.4879, -2.3078, -3.8217, -6.0148,\n",
      "         -5.5642, -0.5598]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.2790052890777588\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.3452,  -0.8747,  -4.4668,  -9.2228,  -9.2125,  -3.0942,  -4.2444,\n",
      "          -6.9260,  -5.9188,  -0.6773]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.244444370269775\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.8684,  -0.6038,  -4.8563,  -9.3804,  -9.6492,  -3.6181,  -3.6431,\n",
      "          -7.5314,  -6.0240,  -0.9432]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.024038314819336\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.0732,  -0.4983,  -4.9463,  -9.2560,  -9.7760,  -3.8423,  -2.8555,\n",
      "          -7.8105,  -5.1444,  -1.2040]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  11.073166847229004\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.2401,  -0.5848,  -4.7652,  -8.8767,  -9.6229,  -3.7919,  -1.9238,\n",
      "          -7.7948,  -4.0890,  -1.3933]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  10.240083694458008\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.6343, -0.9620, -4.4970, -8.4238, -9.3738, -3.6509, -1.0872, -7.6696,\n",
      "         -3.0393, -1.6357]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.423837661743164\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.2427, -1.6375, -4.3178, -7.3268, -9.2037, -3.5965, -0.6508, -7.6115,\n",
      "         -2.1823, -2.0523]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.203696250915527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9502, -2.3492, -4.1263, -6.2996, -8.2603, -3.5268, -0.6238, -7.5196,\n",
      "         -1.4510, -2.4825]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.526750087738037\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7269, -2.9990, -3.9041, -5.3145, -7.3496, -2.7218, -0.9543, -7.3758,\n",
      "         -0.8979, -2.8703]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.8978846073150635\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0329, -4.0219, -4.1198, -4.8320, -6.9309, -2.4440, -1.9516, -7.6477,\n",
      "         -0.3796, -3.6623]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.951585292816162\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3881, -4.9232, -4.2928, -4.3705, -6.5216, -2.2217, -2.1489, -7.8599,\n",
      "         -0.3667, -4.3615]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.3667297065258026\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0031, -5.9104, -4.6288, -4.1346, -6.3244, -2.2679, -2.5873, -8.2215,\n",
      "         -0.3074, -5.1709]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.587306261062622\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4150, -6.5227, -4.6599, -3.6555, -5.8695, -2.1034, -1.9881, -8.2687,\n",
      "         -0.4973, -5.6252]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.659896373748779\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8269, -6.9497, -3.8393, -3.1179, -5.3366, -1.9156, -1.4290, -8.1860,\n",
      "         -0.9735, -5.9115]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.973492443561554\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6298, -7.5467, -3.3278, -2.8787, -5.0722, -2.0617, -1.3226, -8.3235,\n",
      "         -1.1727, -6.3832]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.6297876834869385\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9532, -8.1863, -2.9951, -2.8069, -4.9404, -2.3843, -1.5345, -8.5491,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -1.6727, -6.9107]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.9951019287109375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6876, -8.8173, -2.0603, -2.8423, -4.8820, -2.7944, -1.9469, -8.8073,\n",
      "         -2.3108, -7.4414]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.794440507888794\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8169, -9.3779, -1.3037, -2.9101, -4.8274, -2.4971, -2.4210, -9.0322,\n",
      "         -2.9480, -7.9120]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.911993980407715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2280, -9.8474, -0.7852, -2.9765, -4.7490, -2.2518, -2.8813, -9.1995,\n",
      "         -3.5235, -7.5583]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.8812944889068604\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7722, -10.2256,  -0.6062,  -3.0299,  -4.6403,  -2.0601,  -2.5216,\n",
      "          -9.3056,  -4.0181,  -7.1956]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.0601229667663574\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3621, -10.5390,  -0.8150,  -3.0869,  -4.5224,  -1.2500,  -2.2326,\n",
      "          -9.3740,  -4.4489,  -6.8423]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.448933124542236\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9667, -10.8242,  -1.3279,  -3.1755,  -4.4276,  -0.7244,  -2.0581,\n",
      "          -9.4386,  -4.1394,  -6.5280]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.438623428344727\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4758, -11.0073,  -1.9088,  -3.2128,  -4.2774,  -0.5171,  -1.9260,\n",
      "          -8.6413,  -3.7983,  -6.1724]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.5170604586601257\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2080, -11.4227,  -2.7903,  -3.5271,  -4.4032,  -0.2983,  -2.1701,\n",
      "          -8.1739,  -3.7574,  -6.1042]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.527148962020874\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5757, -11.4940,  -3.3261,  -2.7815,  -4.2231,  -0.3180,  -2.1755,\n",
      "          -7.4507,  -3.4345,  -5.7418]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.741756439208984\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6244, -11.2681,  -3.5445,  -1.8663,  -3.7818,  -0.5530,  -1.9780,\n",
      "          -6.5097,  -2.8765,  -4.3879]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.6244049072265625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9127, -11.0501,  -3.7476,  -1.1433,  -3.3870,  -1.1503,  -1.8926,\n",
      "          -5.6489,  -2.3992,  -3.1633]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.1432735919952393\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8025, -11.3695,  -4.4635,  -0.4997,  -3.5729,  -2.4243,  -2.4480,\n",
      "          -5.3923,  -2.5497,  -2.6078]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.39227294921875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7288, -11.6660,  -5.1253,  -0.3830,  -3.7704,  -3.6421,  -3.0240,\n",
      "          -4.3950,  -2.7495,  -2.1711]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.171070098876953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6241, -11.8767,  -5.6694,  -0.7302,  -3.9095,  -4.7006,  -3.5240,\n",
      "          -3.4504,  -2.9185,  -1.0681]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.624138832092285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9748, -12.2358,  -6.3310,  -1.5707,  -4.2192,  -5.8295,  -4.1664,\n",
      "          -2.7939,  -3.2784,  -0.4989]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.97476863861084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7547, -12.6252,  -6.9943,  -2.5485,  -4.5754,  -6.9141,  -4.8230,\n",
      "          -2.3167,  -3.6953,  -0.5023]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.5022830963134766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1660, -13.3571,  -7.9734,  -3.8685,  -5.2851,  -8.2727,  -5.8017,\n",
      "          -2.3454,  -4.4697,  -0.5951]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.469714164733887\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7237, -13.8721,  -8.7113,  -4.9286,  -5.7841,  -9.3522,  -6.5412,\n",
      "          -2.3021,  -4.3217,  -0.9423]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.928617477416992\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5085, -14.1580,  -9.1980,  -4.9653,  -6.0578, -10.1465,  -7.0305,\n",
      "          -2.1636,  -4.0200,  -1.3649]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.020036220550537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5217, -14.1757,  -9.3966,  -4.7639,  -6.0664, -10.6220,  -7.2320,\n",
      "          -1.8892,  -2.8161,  -1.6942]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.8891963958740234\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0269, -14.2453,  -9.6292,  -4.6425,  -6.1295, -11.1039,  -7.4677,\n",
      "          -1.0338,  -1.8280,  -2.1800]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  9.629189491271973\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9174, -14.4784,  -9.2780,  -4.7107,  -6.3584, -11.7081,  -7.8507,\n",
      "          -0.7120,  -1.2225,  -2.8714]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.917381763458252\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1092, -14.7106,  -8.9842,  -4.8013,  -6.5882, -12.2747,  -8.2183,\n",
      "          -0.8279,  -0.9083,  -3.5582]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.98423957824707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1479, -14.6961,  -7.7700,  -4.6653,  -6.5726, -12.5612,  -8.3259,\n",
      "          -1.0496,  -0.6874,  -3.9740]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.974029302597046\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0356, -14.4495,  -6.4433,  -4.3163,  -6.3260, -12.5856,  -8.1894,\n",
      "          -1.2884,  -0.6107,  -3.3900]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.4433369636535645\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8005, -13.9968,  -4.2973,  -3.7813,  -5.8747, -12.3769,  -7.8360,\n",
      "          -1.4878,  -0.6947,  -2.6584]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.874667644500732\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6405, -13.5185,  -2.3042,  -3.2460,  -4.6398, -12.1184,  -7.4476,\n",
      "          -1.7727,  -1.0519,  -1.9807]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.7727469205856323\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0603, -13.5082,  -1.0025,  -3.2134,  -3.9556, -12.3061,  -7.5186,\n",
      "          -1.8015,  -2.0404,  -1.8926]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  12.306058883666992\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8680, -13.8342,  -0.4327,  -3.5494,  -3.6893, -12.1088,  -7.9182,\n",
      "          -2.2911,  -3.3576,  -2.2598]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.357567548751831\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5376, -14.0280,  -0.2920,  -3.7736,  -3.3688, -11.8314,  -8.1786,\n",
      "          -2.7110,  -3.7604,  -2.5679]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  11.831379890441895\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7858, -13.8262,  -0.3304,  -3.6163,  -2.7300, -10.5080,  -8.0369,\n",
      "          -2.7645,  -3.7632,  -2.5255]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.3304139971733093\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1817, -13.8001,  -0.3168,  -3.6505,  -2.3602,  -9.4720,  -8.0653,\n",
      "          -3.0175,  -3.9377,  -2.7023]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  13.800080299377441\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1961, -12.6725,  -0.4777,  -3.3471,  -1.7456,  -8.1857,  -7.7375,\n",
      "          -2.9299,  -3.7551,  -2.5574]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.196063041687012\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3187, -11.4970,  -0.9099,  -2.9402,  -1.1651,  -6.8674,  -7.2826,\n",
      "          -2.7325,  -3.4470,  -2.3243]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.1651239395141602\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9440, -10.8270,  -1.9777,  -3.0018,  -0.5073,  -6.0696,  -7.2619,\n",
      "          -2.9940,  -3.5806,  -2.5752]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.5072574615478516\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2123, -10.7905,  -3.6060,  -3.6613,  -0.1793,  -5.9197,  -7.8107,\n",
      "          -3.8355,  -4.2874,  -3.4244]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.6613123416900635\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1208, -10.3947,  -4.7289,  -3.1641,  -0.1578,  -5.4235,  -7.9422,\n",
      "          -4.2470,  -4.5705,  -3.8502]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.120790958404541\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9169, -9.6221, -5.3301, -2.3316, -0.3689, -4.5636, -7.6446, -4.2125,\n",
      "         -4.4166, -3.8332]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.3689481019973755\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2636, -9.2484, -6.1970, -1.9767, -0.6474, -4.1186, -7.6990, -4.5151,\n",
      "         -4.6085, -4.1559]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.2636176347732544\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4570, -9.2215, -7.2885, -2.0702, -1.6032, -4.0388, -8.0578, -5.1055,\n",
      "         -5.0979, -4.7676]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.038782596588135\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.2465, -9.2450, -8.3196, -2.2964, -2.6638, -3.3285, -8.4289, -5.6896,\n",
      "         -5.5905, -5.3724]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.372350692749023\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.2893, -8.9227, -8.9047, -2.2320, -3.3281, -2.3705, -8.4197, -5.8748,\n",
      "         -5.6933, -4.8359]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.3280506134033203\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6388, -8.3942, -9.1933, -2.0159, -2.9578, -1.3349, -8.1731, -5.8053,\n",
      "         -5.5498, -4.1203]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2.01592755317688\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5515, -8.1302, -9.6648, -1.3855, -2.8753, -0.7986, -8.1630, -5.9567,\n",
      "         -5.6350, -3.6996]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.5515236854553223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9465,  -8.0446, -10.2414,  -1.1569,  -2.9955,  -0.7833,  -8.3061,\n",
      "          -6.2470,  -5.8662,  -3.4911]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  10.24144172668457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2027, -7.7638, -9.8316, -0.9821, -2.9376, -0.8855, -8.2311, -6.3060,\n",
      "         -5.8725, -3.1220]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.9820727109909058\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6802, -7.6771, -9.6285, -0.5239, -3.0914, -1.4320, -8.3297, -6.5264,\n",
      "         -6.0459, -2.9881]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.091353416442871\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0335, -7.4725, -9.3187, -0.4267, -2.3836, -1.9645, -8.2917, -6.5991,\n",
      "         -6.0769, -2.7781]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.42665916681289673\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6294, -7.5312, -9.2823, -0.3227, -2.0583, -2.7847, -8.5003, -6.9081,\n",
      "         -6.3490, -2.8776]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  9.28232192993164\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8498, -7.2488, -8.1929, -0.4330, -1.5260, -3.2309, -8.3526, -6.8516,\n",
      "         -6.2596, -2.6734]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.192851066589355\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8261, -6.7573, -6.2581, -0.7760, -0.9730, -3.4226, -7.9820, -6.5637,\n",
      "         -5.9426, -2.3031]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.7760316133499146\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9772, -6.4720, -4.6737, -0.8397, -0.9166, -3.7746, -7.8050, -6.4620,\n",
      "         -5.8155, -2.2004]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.81552791595459\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9055, -5.9948, -3.0322, -0.9959, -0.9457, -3.8860, -7.4243, -6.1501,\n",
      "         -4.7712, -1.9687]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.9456512928009033\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0962, -5.8074, -1.8293, -1.6510, -0.7511, -4.2413, -7.3226, -6.1115,\n",
      "         -4.0773, -2.1045]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.6509872674942017\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4379, -5.7987, -1.0198, -1.7981, -1.0889, -4.7290, -7.3892, -6.2361,\n",
      "         -3.6222, -2.4753]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.6222095489501953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8065, -5.8454, -0.6035, -2.1056, -1.6987, -5.2267, -7.5019, -6.4022,\n",
      "         -2.5766, -2.9242]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.806532382965088\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3612, -5.8406, -0.5740, -2.4236, -2.3363, -5.6295, -7.5548, -6.5039,\n",
      "         -1.6399, -3.3193]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.3192663192749023\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9386, -5.8074, -0.9220, -2.7446, -2.9522, -5.9638, -7.5718, -6.5657,\n",
      "         -0.9032, -2.9268]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.9385616779327393\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8640, -5.8011, -1.5427, -3.1026, -3.5675, -6.2878, -7.6087, -6.6437,\n",
      "         -0.5489, -2.6345]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.56748366355896\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8721, -5.7317, -2.1894, -3.3923, -3.3234, -6.5148, -7.5763, -6.6489,\n",
      "         -0.5737, -2.3585]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.5736579895019531\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3787, -5.9588, -3.1395, -3.9653, -3.4179, -7.0075, -7.8348, -6.9418,\n",
      "         -0.5737, -2.4676]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.958810806274414\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9461, -5.2342, -3.8533, -4.3225, -3.3547, -7.2788, -7.8949, -7.0334,\n",
      "         -0.8001, -2.4560]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.8533482551574707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6892, -4.4341, -3.6392, -4.5023, -3.1724, -7.3720, -7.7977, -6.9649,\n",
      "         -1.1702, -2.3578]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.434137344360352\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6684, -2.8127, -3.3083, -4.5156, -2.8829, -7.2995, -7.5536, -6.7471,\n",
      "         -1.5661, -2.1830]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.5660674571990967\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1327, -1.5068, -3.1453, -4.6443, -2.7730, -7.3433, -7.4429, -6.6606,\n",
      "         -1.4708, -2.2183]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.5067678689956665\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4235, -0.3838, -3.6670, -5.4049, -3.3586, -8.0206, -7.9810, -7.2211,\n",
      "         -2.1848, -2.9685]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.981039047241211\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8835, -0.1218, -4.3880, -6.3260, -4.1450, -8.8637, -7.9067, -7.9594,\n",
      "         -3.1402, -3.9154]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.8835043907165527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0160, -0.0882, -4.5806, -6.6910, -4.3994, -9.1573, -7.3743, -8.1587,\n",
      "         -3.5654, -4.3172]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.158726692199707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5317, -0.1276, -4.1446, -6.4040, -4.0210, -8.8050, -6.2787, -6.9312,\n",
      "         -3.3517, -4.0722]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.0210280418396\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6612, -0.3630, -3.3077, -5.6909, -2.4860, -8.0321, -4.8379, -5.3709,\n",
      "         -2.7282, -3.4086]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.837882041931152\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0467, -1.2099, -2.6988, -5.1697, -1.2847, -7.4547, -2.8775, -4.0879,\n",
      "         -2.3314, -2.9541]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.0879082679748535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1383, -2.7450, -2.7497, -5.2553, -0.9620, -7.4859, -1.7074, -2.7111,\n",
      "         -2.5936, -3.1345]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.593625068664551\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6288, -4.4971, -3.1636, -5.6582, -1.2809, -7.8362, -1.1193, -1.8457,\n",
      "         -2.4967, -3.6513]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.119262456893921\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5889, -6.5488, -4.0326, -6.4892, -2.2426, -8.6176, -0.5254, -1.6568,\n",
      "         -2.9333, -4.6019]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.617612838745117\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3980, -8.3216, -4.7521, -7.1630, -3.1129, -8.5382, -0.3832, -1.5616,\n",
      "         -3.2884, -5.3897]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.389666557312012\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7901, -9.5728, -5.0609, -7.4249, -3.5845, -8.1215, -0.4477, -1.2962,\n",
      "         -3.2893, -5.0100]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  9.572803497314453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8204, -9.6220, -5.0146, -7.3322, -3.7013, -7.4175, -0.6793, -0.9443,\n",
      "         -2.9875, -4.3441]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.332236289978027\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6250, -9.4379, -4.7492, -6.2744, -3.5964, -6.5555, -1.0571, -0.7060,\n",
      "         -2.5229, -3.5257]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.0571174621582031\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5174, -9.3333, -4.5776, -5.3845, -3.5839, -5.8415, -0.9453, -0.9416,\n",
      "         -2.2227, -2.8719]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.84149169921875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2670, -9.0776, -4.2691, -4.4251, -3.4320, -4.3342, -0.9877, -1.2995,\n",
      "         -1.8676, -2.1640]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.2691192626953125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0390, -8.8346, -3.2661, -3.5572, -3.3067, -2.9733, -1.3046, -1.8235,\n",
      "         -1.6446, -1.5996]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.304626226425171\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1289, -8.8983, -2.6728, -3.0794, -3.5040, -2.0665, -1.3007, -2.7050,\n",
      "         -1.8633, -1.5250]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.6728367805480957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3711, -9.1051, -1.6192, -2.8329, -3.8538, -1.4889, -1.6596, -3.7010,\n",
      "         -2.3197, -1.7701]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.7009835243225098\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7674, -9.4604, -0.9822, -2.8240, -4.3536, -1.2975, -2.3005, -3.9963,\n",
      "         -2.9695, -2.2872]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.3005309104919434\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1890, -9.8388, -0.7374, -2.9189, -4.8720, -1.3771, -2.2329, -4.3353,\n",
      "         -3.6496, -2.8874]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2.8874199390411377\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4323, -10.0392,  -0.7214,  -2.9043,  -5.2041,  -1.4871,  -2.1152,\n",
      "          -4.5104,  -4.1400,  -2.5813]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.510372161865234\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4678, -10.0328,  -0.8702,  -2.7454,  -5.3205,  -1.5593,  -1.9166,\n",
      "          -3.7059,  -4.4061,  -2.1753]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.406113624572754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3933, -9.9176, -1.1960, -2.5410, -5.3195, -1.6637, -1.7431, -2.8913,\n",
      "         -3.8344, -1.7851]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.663704752922058\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4443, -9.9286, -1.8215, -2.5307, -5.4369, -1.2987, -1.8384, -2.3160,\n",
      "         -3.4496, -1.6739]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.6739253997802734\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6625, -10.1076,  -2.6703,  -2.7503,  -5.7151,  -1.3322,  -2.2176,\n",
      "          -2.0445,  -3.2948,  -1.1370]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.3322497606277466\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.0336, -10.4410,  -3.6567,  -3.1681,  -6.1403,  -1.0150,  -2.8164,\n",
      "          -2.0739,  -3.3539,  -1.0652]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  10.440970420837402\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2369, -9.8614, -4.4307, -3.4432, -6.3920, -0.8528, -3.2696, -2.0663,\n",
      "         -3.2991, -1.1251]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.430670738220215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2274, -9.1457, -4.2216, -3.5210, -6.4260, -0.8138, -3.5136, -1.9651,\n",
      "         -3.0822, -1.2273]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.425990581512451\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0163, -8.2972, -3.8398, -3.4093, -5.4968, -0.8873, -3.5525, -1.7801,\n",
      "         -2.7154, -1.3339]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.8873336315155029\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9662, -7.6715, -3.6497, -3.4717, -4.8013, -0.6765, -3.7482, -1.8842,\n",
      "         -2.5704, -1.7645]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.884155511856079\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9034, -7.0889, -3.4777, -3.5318, -4.1619, -0.8256, -3.9234, -1.2928,\n",
      "         -2.4748, -2.2606]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.477660894393921\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8018, -6.5179, -2.5808, -3.5608, -3.5507, -1.2211, -4.0495, -0.9287,\n",
      "         -2.4016, -2.7381]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.401624917984009\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.7638, -6.0560, -1.8788, -3.6596, -3.0734, -1.8362, -4.2280, -0.9618,\n",
      "         -1.7405, -3.2676]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.8361777067184448\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8389, -5.7489, -1.4634, -3.8749, -2.7857, -1.9042, -4.5072, -1.3982,\n",
      "         -1.3769, -3.8799]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.74888801574707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8739, -4.6946, -1.2209, -4.0498, -2.5387, -2.0356, -4.7325, -1.9501,\n",
      "         -1.1944, -4.4120]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.732539176940918\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8294, -3.6740, -1.1363, -4.1422, -2.2981, -2.1676, -4.0807, -2.4804,\n",
      "         -1.1673, -4.8220]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.080716133117676\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.7290, -2.7113, -1.2280, -4.1749, -2.0952, -2.3044, -2.6674, -2.9610,\n",
      "         -1.3016, -5.1346]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.6673624515533447\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9393, -2.1926, -1.8194, -4.5143, -2.3044, -2.7964, -0.9751, -3.7328,\n",
      "         -1.9144, -5.7190]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.9144130945205688\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7363, -2.4147, -3.0740, -5.4339, -3.1743, -3.8881, -0.3508, -5.0522,\n",
      "         -2.4657, -6.8533]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.05220365524292\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.3253, -2.5520, -4.1074, -6.1356, -3.8598, -4.7559, -0.2077, -5.3311,\n",
      "         -2.8929, -7.7459]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.1356120109558105\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.3808, -2.2587, -4.5744, -5.5400, -4.0178, -5.0682, -0.2336, -5.1107,\n",
      "         -2.8416, -8.0746]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.2587382793426514\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.1900, -1.0857, -4.7611, -4.7653, -3.9325, -5.1124, -0.6261, -4.6756,\n",
      "         -2.5955, -8.1296]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.761063098907471\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.1711, -0.4344, -4.3690, -4.2266, -4.0230, -5.3090, -1.5434, -4.4436,\n",
      "         -2.5794, -8.3317]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.5433943271636963\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.1931, -0.3703, -4.0635, -3.7910, -4.1566, -5.5279, -1.8007, -4.2823,\n",
      "         -2.6573, -8.5524]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.657344341278076\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.9498, -0.5631, -3.5370, -3.1521, -4.0251, -5.4641, -1.8957, -3.8842,\n",
      "         -1.8039, -8.4875]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.537045478820801\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7053, -1.1336, -2.3428, -2.5829, -3.8942, -5.3835, -2.0707, -3.5157,\n",
      "         -1.1261, -8.4030]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.1336058378219604\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7807, -1.4368, -1.6310, -2.4221, -4.0866, -5.6089, -2.6200, -3.5020,\n",
      "         -1.0409, -8.6219]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.780710697174072\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0643, -1.8438, -1.0877, -2.3018, -4.2300, -5.7718, -3.1280, -3.4706,\n",
      "         -1.1722, -8.7764]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.771840572357178\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3528, -2.2596, -0.7719, -2.2010, -4.3020, -5.1463, -3.5511, -3.3986,\n",
      "         -1.4420, -8.8475]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.398613929748535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6132, -2.6093, -0.7163, -2.0916, -4.2749, -4.4848, -3.8517, -2.4748,\n",
      "         -1.7505, -8.8093]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.7163140177726746\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2036, -3.2279, -0.5491, -2.3355, -4.5101, -4.1461, -4.3879, -1.9580,\n",
      "         -2.4006, -9.0240]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.146061897277832\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7040, -3.6725, -0.6698, -2.4865, -4.5883, -3.0076, -4.7383, -1.4612,\n",
      "         -2.9084, -9.0754]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.738265514373779\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2033, -4.0226, -1.0751, -2.6164, -4.5975, -1.9481, -4.2211, -1.1267,\n",
      "         -3.3353, -9.0527]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.203263998031616\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1564, -4.4655, -1.7980, -2.9029, -4.7277, -1.2089, -3.8810, -1.1938,\n",
      "         -3.8594, -9.1466]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.156367778778076\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9264, -5.2365, -2.9310, -3.5663, -5.2154, -1.1176, -3.9543, -1.8555,\n",
      "         -4.7099, -9.5949]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.5662593841552734\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3983,  -6.2204,  -4.2750,  -3.7138,  -5.9443,  -1.5518,  -4.3206,\n",
      "          -2.8594,  -5.7678, -10.2843]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.274986743927002\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2516,  -6.9387,  -4.6105,  -3.6961,  -6.4336,  -1.9231,  -4.4916,\n",
      "          -3.6393,  -6.5536, -10.7359]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.9386796951293945\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2648,  -6.4125,  -4.4907,  -3.2698,  -6.4464,  -1.9316,  -4.2253,\n",
      "          -3.9331,  -6.8331, -10.7136]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.2698423862457275\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5219,  -5.6207,  -4.0716,  -1.8431,  -6.1400,  -1.7223,  -3.6775,\n",
      "          -3.8939,  -6.7664, -10.3744]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.5219386219978333\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8118,  -5.2684,  -4.0643,  -1.0358,  -6.2236,  -2.0179,  -3.5617,\n",
      "          -4.2326,  -7.0651, -10.4269]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  10.426901817321777\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3680, -4.9237, -4.0389, -0.5457, -6.2692, -2.3468, -3.4481, -4.5177,\n",
      "         -7.3034, -9.6881]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.4481289386749268\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9383, -4.5012, -3.9109, -0.4238, -6.1942, -2.5930, -2.4842, -4.6654,\n",
      "         -7.4010, -8.9054]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.592956781387329\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4240, -3.9953, -3.6764, -0.6727, -5.9945, -2.0277, -1.5467, -4.6721,\n",
      "         -7.3555, -8.0669]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.027681589126587\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1319, -3.7588, -3.6886, -1.4852, -6.0219, -1.1142, -1.0718, -4.8909,\n",
      "         -7.5203, -7.5175]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.071780800819397\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2957, -4.0575, -4.2117, -2.8813, -6.5427, -1.0170, -0.6339, -5.5880,\n",
      "         -8.1634, -7.5174]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.542749881744385\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2212, -4.2070, -4.5610, -4.0481, -6.1130, -1.0517, -0.5156, -6.0863,\n",
      "         -8.6103, -7.3853]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.206967353820801\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.7484, -3.2992, -4.5728, -4.8017, -5.4175, -1.0185, -0.5574, -6.2266,\n",
      "         -8.7026, -6.9566]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.2991559505462646\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0539, -1.5992, -4.4193, -5.3149, -4.6231, -1.0710, -0.8622, -6.1829,\n",
      "         -8.6142, -6.3998]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.614228248596191\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6209, -0.5088, -4.5798, -6.0708, -4.2055, -1.6493, -1.7498, -6.4353,\n",
      "         -8.1105, -6.1898]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.205511093139648\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.3602, -0.2016, -4.9594, -6.9810, -3.3052, -2.5329, -2.9099, -6.8916,\n",
      "         -7.8848, -6.2300]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.891576766967773\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.7120, -0.2163, -4.9920, -7.4870, -2.2083, -3.0702, -3.6819, -6.2020,\n",
      "         -7.3675, -5.9533]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.953311920166016\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.7667, -0.5611, -4.7638, -7.6806, -1.0425, -3.3242, -4.1340, -5.3203,\n",
      "         -6.6398, -4.6891]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.766659259796143\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.2055, -1.4182, -4.6914, -7.9823, -0.3902, -3.7053, -4.6804, -4.6572,\n",
      "         -6.1125, -3.6848]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.691422462463379\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6435, -2.3109, -3.8589, -8.1969, -0.2643, -4.0086, -5.1222, -4.0104,\n",
      "         -5.5820, -2.7421]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.7420873641967773\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0615, -3.1110, -3.0474, -8.3135, -0.6599, -4.2175, -5.4477, -3.3652,\n",
      "         -5.0300, -1.1137]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.313467025756836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9845, -4.3096, -2.7962, -8.1098, -1.8551, -4.8615, -6.1896, -3.2570,\n",
      "         -4.9831, -0.3409]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.189553737640381\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9334, -5.4152, -2.6301, -7.9429, -3.0668, -5.4631, -6.1078, -3.2061,\n",
      "         -4.9621, -0.1985]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.933393955230713\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7374, -5.9963, -2.1146, -7.3752, -3.7758, -5.5901, -5.6182, -2.7747,\n",
      "         -4.5304, -0.2692]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.774657726287842\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4896, -6.3441, -1.5598, -6.6872, -4.2544, -5.5298, -5.0029, -1.4725,\n",
      "         -3.9722, -0.7273]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.002865314483643\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6535, -6.9236, -1.4763, -6.3336, -4.9613, -5.7435, -3.9566, -0.7456,\n",
      "         -3.7482, -1.7660]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.743451118469238\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0722, -7.5659, -1.6850, -6.1363, -5.7229, -5.3520, -3.1489, -0.5843,\n",
      "         -3.6830, -2.9490]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.9489588737487793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5410, -8.0441, -1.9057, -5.8597, -6.3106, -4.9022, -2.3537, -0.7764,\n",
      "         -3.5419, -3.2022]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.9022393226623535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1651, -8.4194, -2.1559, -5.5574, -6.7858, -3.7455, -1.6549, -1.2548,\n",
      "         -3.3801, -3.4051]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.6549015045166016\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3797, -9.0807, -2.7876, -5.6112, -7.5376, -3.0437, -0.7335, -2.2323,\n",
      "         -3.5821, -3.9358]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.7335487008094788\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4544, -10.3721,  -4.0967,  -6.3583,  -8.9109,  -3.1412,  -0.2050,\n",
      "          -3.8926,  -4.4800,  -5.1242]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.454420566558838\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5551, -11.3404,  -5.0928,  -6.8376,  -9.9529,  -3.0648,  -0.1574,\n",
      "          -5.2090,  -5.1019,  -6.0040]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.5550670623779297\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5602, -11.8009,  -5.5828,  -6.8588, -10.4800,  -2.6175,  -0.3529,\n",
      "          -5.9873,  -5.2550,  -6.3868]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.987283706665039\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7165, -12.1135,  -5.9246,  -6.7765, -10.8524,  -2.1640,  -0.9585,\n",
      "          -5.8026,  -5.2945,  -6.6307]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.630671977996826\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3821, -12.4617,  -6.3011,  -6.7700, -11.2546,  -1.9035,  -1.8604,\n",
      "          -5.7054,  -5.4004,  -6.1711]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  12.46172046661377\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3625, -11.8160,  -6.4229,  -6.5466, -11.3982,  -1.5555,  -2.5718,\n",
      "          -5.4020,  -5.2806,  -5.5402]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.546563148498535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5473, -10.9288,  -6.2281,  -5.2858, -11.2218,  -1.0853,  -2.9644,\n",
      "          -4.8265,  -4.8706,  -4.6694]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.547337532043457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5632, -10.2876,  -6.2117,  -4.3120, -11.2207,  -1.0580,  -3.5148,\n",
      "          -4.4724,  -4.6646,  -4.0500]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.0580320358276367\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0348,  -9.7524,  -6.2406,  -3.4874, -11.2618,  -0.6151,  -4.0750,\n",
      "          -4.2045,  -4.5281,  -3.5473]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.204501152038574\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6153,  -9.1673,  -6.1648,  -2.6648, -11.1956,  -0.4942,  -4.4892,\n",
      "          -3.0907,  -4.3098,  -3.0131]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.4942055344581604\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5893,  -8.9468,  -6.4043,  -2.2831, -11.4423,  -0.4169,  -5.1769,\n",
      "          -2.4296,  -4.4292,  -2.8750]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.42964768409729\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5287,  -8.7560,  -6.6288,  -2.0242, -11.6721,  -0.8187,  -5.8081,\n",
      "          -1.1339,  -4.5530,  -2.8006]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.8005900382995605\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6853,  -8.8735,  -7.1211,  -2.1804, -12.1682,  -1.7798,  -6.6679,\n",
      "          -0.5078,  -4.9613,  -2.3224]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.121123313903809\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6971,  -8.9430,  -6.8064,  -2.3703, -12.5785,  -2.7273,  -7.4067,\n",
      "          -0.3775,  -5.2976,  -1.9286]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.406695365905762\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.3167,  -8.7117,  -6.2298,  -2.3181, -12.6540,  -3.3326,  -7.0196,\n",
      "          -0.4998,  -5.3101,  -1.3887]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.3886990547180176\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0372,  -8.6648,  -5.8733,  -2.5071, -12.8833,  -4.0640,  -6.8329,\n",
      "          -1.2417,  -5.4862,  -0.5053]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.873251438140869\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.7419,  -8.6780,  -4.8913,  -2.7944, -13.1450,  -4.7900,  -6.7209,\n",
      "          -2.1892,  -5.7031,  -0.2158]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.677986145019531\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.0054,  -7.5781,  -3.6411,  -2.7282, -13.0094,  -5.0783,  -6.2497,\n",
      "          -2.7579,  -5.5294,  -0.1839]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.578077793121338\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.8265,  -5.4364,  -2.1178,  -2.3018, -12.4707,  -4.9258,  -5.4103,\n",
      "          -2.9028,  -4.9595,  -0.3549]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  12.470707893371582\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.7002,  -3.5457,  -0.8675,  -2.0284, -11.2499,  -4.8281,  -4.6924,\n",
      "          -3.1105,  -4.4859,  -1.0610]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.485902786254883\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.9942,  -2.2719,  -0.4523,  -2.2896, -10.5581,  -5.1532,  -4.4604,\n",
      "          -3.7395,  -3.7506,  -2.3598]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.994194030761719\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5887, -1.2631, -0.5989, -2.6637, -9.9970, -5.5119, -4.3221, -4.3863,\n",
      "         -3.1673, -3.6611]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.996967315673828\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.2658, -0.6060, -1.1680, -3.0955, -8.7683, -5.8796, -4.2495, -5.0203,\n",
      "         -2.7146, -4.8937]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.265789985656738\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2044, -0.3747, -1.8604, -3.4750, -7.6183, -6.1690, -4.1513, -5.5526,\n",
      "         -2.3112, -5.9655]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.151266574859619\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0095, -0.4336, -2.3552, -3.5997, -6.3425, -6.1904, -3.0768, -5.7943,\n",
      "         -1.7794, -6.6919]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.43359366059303284\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1743, -0.4627, -3.1050, -3.9687, -5.4310, -6.4470, -2.3802, -6.2502,\n",
      "         -1.6588, -7.5828]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.6588343381881714\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4423, -0.9618, -3.8212, -4.3242, -4.6223, -6.6880, -1.8319, -6.6710,\n",
      "         -0.9729, -8.3942]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.8318524360656738\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0801, -1.9664, -4.7555, -4.9281, -4.1754, -7.1796, -0.9780, -7.3246,\n",
      "         -0.9031, -9.3986]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.9663742780685425\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9112,  -2.3603,  -5.7267,  -5.6009,  -3.9084,  -7.7463,  -0.6179,\n",
      "          -8.0372,  -1.2576, -10.4267]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.037199020385742\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5950,  -2.5805,  -6.3997,  -6.0058,  -3.4796,  -8.0531,  -0.4981,\n",
      "          -7.6963,  -1.5790, -11.1486]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.479611873626709\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1567,  -2.6264,  -6.7987,  -6.1640,  -2.1436,  -8.1213,  -0.6411,\n",
      "          -7.1814,  -1.8096, -11.5904]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.181432723999023\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8618,  -2.7361,  -7.1739,  -6.3232,  -1.0458,  -8.1982,  -1.1822,\n",
      "          -5.9606,  -2.1510, -12.0035]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.0458347797393799\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4157,  -3.5882,  -8.2179,  -7.1736,  -0.2673,  -8.9731,  -2.6061,\n",
      "          -5.5688,  -3.2484, -13.0810]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.217897415161133\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9378,  -4.3339,  -8.3944,  -7.8979,  -0.1135,  -9.6290,  -3.9020,\n",
      "          -5.1770,  -4.2228, -14.0092]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.9020347595214844\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9088,  -4.4770,  -8.0155,  -8.0123,  -0.1202,  -9.6817,  -3.7912,\n",
      "          -4.2906,  -4.5727, -14.3071]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.01233196258545\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3711,  -4.0627,  -7.1231,  -6.8009,  -0.2490,  -9.1776,  -3.1569,\n",
      "          -2.9516,  -4.3439, -14.0238]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.062716484069824\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7804,  -2.7915,  -6.1451,  -5.5359,  -0.7798,  -8.5488,  -2.4428,\n",
      "          -1.6114,  -3.9723, -13.5937]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.6114095449447632\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1026,  -2.4223,  -5.9963,  -5.1302,  -2.3349,  -8.7131,  -2.5955,\n",
      "          -0.5164,  -4.3816, -13.9367]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.996252059936523\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7539,  -2.4268,  -5.4172,  -5.0409,  -4.0803,  -9.1327,  -3.0609,\n",
      "          -0.2657,  -5.0310, -14.5172]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.030965328216553\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0335,  -2.1423,  -4.5454,  -4.6120,  -5.3111,  -9.1571,  -3.1617,\n",
      "          -0.2799,  -4.5408, -14.6864]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.033543586730957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2651,  -1.6501,  -3.4455,  -3.9108,  -6.1007,  -8.8566,  -2.9620,\n",
      "          -0.5527,  -3.7847, -14.5162]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.910813570022583\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6584,  -1.3576,  -2.4874,  -2.5436,  -6.8227,  -8.5954,  -2.8304,\n",
      "          -1.2497,  -3.1296, -14.3722]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  14.372200012207031\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4871,  -1.5193,  -1.9200,  -1.6079,  -7.7090,  -8.5958,  -2.9918,\n",
      "          -2.3332,  -2.8069, -13.7322]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.595804214477539\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6445,  -1.9722,  -1.6608,  -1.0641,  -8.6535,  -8.0305,  -3.3211,\n",
      "          -3.5294,  -2.7062, -13.3018]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.653457641601562\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9046,  -2.4595,  -1.5413,  -0.8146,  -8.7197,  -7.4986,  -3.6218,\n",
      "          -4.6060,  -2.6409, -12.8911]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  12.891128540039062\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0899,  -2.8032,  -1.4302,  -0.7695,  -8.6213,  -6.8619,  -3.7545,\n",
      "          -5.4250,  -2.4757, -11.6219]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.7694768309593201\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5324,  -3.3423,  -1.6877,  -0.5050,  -8.7177,  -6.4742,  -4.0767,\n",
      "          -6.3508,  -2.5732, -10.6639]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.71769905090332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7219, -3.5866, -1.7858, -0.4591, -7.7817, -5.8589, -4.1124, -6.9185,\n",
      "         -2.4491, -9.5340]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.7857919931411743\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8073, -3.6935, -1.1403, -0.7640, -6.8057, -5.1734, -4.0234, -7.2969,\n",
      "         -2.2668, -8.3831]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.1402812004089355\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2672, -4.1469, -0.4089, -1.7304, -6.2664, -4.8989, -4.2956, -7.9769,\n",
      "         -2.5169, -7.6857]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.2672266960144043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9821, -4.5733, -0.2356, -2.7416, -5.7887, -4.6635, -4.5575, -8.5960,\n",
      "         -2.8074, -7.0646]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.663506507873535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4076, -4.6100, -0.2916, -3.3461, -5.0059, -3.3926, -4.4462, -8.7986,\n",
      "         -2.7579, -6.1509]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.4075565338134766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1610, -4.5851, -0.8111, -3.8520, -4.2409, -2.2070, -4.2898, -8.9159,\n",
      "         -2.6945, -5.2645]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.811086893081665\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7519, -5.0545, -1.3646, -4.8078, -4.0472, -1.7020, -4.6435, -9.5059,\n",
      "         -3.1709, -4.9545]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.3645939826965332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7962,  -5.5497,  -1.3983,  -5.7426,  -3.9538,  -1.4451,  -5.0371,\n",
      "         -10.1050,  -3.6983,  -4.7483]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.4451260566711426\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2409,  -6.0738,  -1.6805,  -6.6620,  -3.9595,  -0.7464,  -5.4718,\n",
      "         -10.7198,  -4.2667,  -4.6445]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.7463975548744202\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3330,  -7.0281,  -2.5484,  -7.9716,  -4.4598,  -0.2249,  -6.3470,\n",
      "         -11.7540,  -5.2693,  -5.0388]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.548434019088745\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2138,  -7.7145,  -2.4991,  -8.9776,  -4.7456,  -0.1513,  -6.9630,\n",
      "         -12.5118,  -6.0024,  -5.2253]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.15131770074367523\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1556,  -8.4522,  -2.6326, -10.0027,  -5.1288,  -0.1047,  -7.6376,\n",
      "         -13.3135,  -6.7837,  -5.5164]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  10.00273323059082\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4547,  -8.5563,  -2.2436,  -9.6041,  -4.9179,  -0.1417,  -7.6850,\n",
      "         -13.4749,  -6.9275,  -5.2212]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.604063034057617\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2556,  -8.1732,  -1.4922,  -8.0130,  -4.2568,  -0.3110,  -7.2512,\n",
      "         -13.1434,  -6.5809,  -4.4825]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.255566120147705\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1811,  -7.6533,  -0.8010,  -6.4053,  -3.4970,  -0.8037,  -6.6859,\n",
      "         -12.6697,  -6.0946,  -3.6506]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.650642156600952\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3469,  -7.2884,  -0.6020,  -5.0620,  -2.9389,  -1.6652,  -6.2808,\n",
      "         -12.3461,  -5.7613,  -2.2781]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.6019593477249146\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1418,  -7.4366,  -0.5761,  -4.3333,  -2.9529,  -3.0505,  -6.3937,\n",
      "         -12.5310,  -5.9398,  -1.5949]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.9528632164001465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0286,  -7.5562,  -0.9394,  -3.6729,  -2.2317,  -4.3170,  -6.4823,\n",
      "         -12.6831,  -6.0881,  -1.1172]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  12.683124542236328\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0047,  -7.6463,  -1.5269,  -3.0794,  -1.6459,  -5.4487,  -6.5453,\n",
      "         -12.0262,  -6.2053,  -0.9137]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.079420328140259\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1206,  -7.7667,  -2.2498,  -1.8650,  -1.3040,  -6.5099,  -6.6420,\n",
      "         -11.4736,  -6.3513,  -1.0692]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.351262092590332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4061,  -7.9688,  -3.0693,  -0.9822,  -1.2959,  -7.5598,  -6.8235,\n",
      "         -11.0694,  -5.8449,  -1.5589]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.5589367151260376\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8989,  -8.3209,  -4.0102,  -0.6407,  -1.6664,  -8.6755,  -7.1576,\n",
      "         -10.8753,  -5.5609,  -1.5803]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.320934295654297\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1833,  -7.6945,  -4.6706,  -0.5324,  -1.9440,  -9.4804,  -7.2593,\n",
      "         -10.5008,  -5.1082,  -1.5534]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.670614242553711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1857, -6.8466, -4.2740, -0.5942, -2.0188, -9.9213, -7.0674, -9.8795,\n",
      "         -4.4210, -1.4029]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.421015739440918\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9950,  -5.8609,  -3.7038,  -0.8428,  -1.9640, -10.0952,  -6.6721,\n",
      "          -9.0971,  -2.8589,  -1.2278]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.9950203895568848\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1774,  -5.0241,  -3.2565,  -1.4394,  -2.0702, -10.3004,  -6.3658,\n",
      "          -8.4412,  -1.5428,  -1.3372]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.4393643140792847\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8850,  -4.6364,  -3.2421,  -1.7613,  -2.6227, -10.8463,  -6.4523,\n",
      "          -8.2118,  -0.8752,  -1.9926]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.8850071430206299\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1897,  -4.4798,  -3.4423,  -2.3658,  -3.3609, -11.5230,  -6.7166,\n",
      "          -8.1907,  -0.7645,  -2.8697]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.4422836303710938\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7674,  -4.3290,  -2.9161,  -2.9624,  -4.0337, -12.1141,  -6.9373,\n",
      "          -8.1536,  -0.9870,  -3.6836]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  12.114117622375488\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5825,  -4.0595,  -2.3373,  -3.3952,  -4.5096, -11.7942,  -6.9932,\n",
      "          -7.9769,  -1.3162,  -4.2918]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.99322509765625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6195,  -3.6264,  -1.6815,  -3.6068,  -4.7432, -11.3028,  -6.0758,\n",
      "          -7.6147,  -1.6053,  -4.6463]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.6194926500320435\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5291,  -3.4689,  -1.4362,  -4.0304,  -5.1727, -11.0730,  -5.4640,\n",
      "          -7.5016,  -2.2249,  -5.1853]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.1727094650268555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6413,  -3.1152,  -1.1496,  -4.1901,  -4.5667, -10.6309,  -4.6812,\n",
      "          -7.1651,  -2.6268,  -5.4398]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.115216016769409\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9944,  -1.9552,  -0.9870,  -4.2151,  -3.8986, -10.1026,  -3.8532,\n",
      "          -6.7324,  -2.9113,  -5.5419]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.9943819046020508\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0845, -1.2466, -1.3363, -4.4792, -3.5429, -9.8573, -3.3543, -6.5741,\n",
      "         -3.4377, -5.8671]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.867147445678711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3794, -0.7915, -1.8065, -4.6940, -3.2131, -9.6049, -2.9003, -6.4011,\n",
      "         -3.9038, -5.3827]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.3794031143188477\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1755, -0.7932, -2.4204, -4.9680, -3.0203, -9.4513, -2.6073, -6.3202,\n",
      "         -4.4118, -5.0235]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.7932087182998657\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3933, -0.5646, -3.2141, -5.3974, -3.0615, -9.4905, -2.5776, -6.4263,\n",
      "         -5.0556, -4.8825]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.490497589111328\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5220, -0.5349, -3.7101, -5.5402, -2.8869, -8.5713, -2.3619, -6.2757,\n",
      "         -5.3927, -4.5138]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.51384162902832\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5487, -0.6960, -3.9268, -5.4243, -2.5249, -7.4963, -1.9927, -5.8943,\n",
      "         -5.4522, -3.1989]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.5487430095672607\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0976, -1.3064, -4.2315, -5.4188, -2.3555, -6.6241, -1.8604, -5.6484,\n",
      "         -5.6043, -2.1407]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.355450391769409\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1169, -2.2410, -4.7002, -5.6011, -1.6978, -6.0237, -2.0450, -5.6137,\n",
      "         -5.9280, -1.4594]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.02371072769165\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4362, -3.2266, -5.1937, -5.8331, -1.3102, -4.8454, -2.3758, -5.6503,\n",
      "         -6.2864, -1.0845]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.3101825714111328\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1562, -4.4038, -5.9024, -6.3045, -0.6674, -4.0502, -3.0055, -5.9463,\n",
      "         -6.8708, -1.2595]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.667357325553894\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3874, -5.9720, -7.0415, -7.2295, -0.2187, -3.8455, -4.1097, -6.7140,\n",
      "         -7.8969, -2.1279]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.845536470413208\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2623, -7.1278, -7.8096, -7.8046, -0.1685, -2.7163, -4.8584, -7.1480,\n",
      "         -8.5628, -2.7405]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.858356475830078\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6923, -7.8011, -8.1335, -7.9548, -0.3954, -1.3782, -4.4017, -7.1713,\n",
      "         -8.7945, -2.9722]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.954787254333496\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1819, -8.5034, -8.5212, -7.4286, -1.2034, -0.4471, -4.0957, -7.2887,\n",
      "         -9.0991, -3.3149]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.521188735961914\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.7310, -9.2401, -8.2594, -7.0595, -2.2615, -0.1651, -3.9370, -7.4991,\n",
      "         -9.4776, -3.7548]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.7547502517700195\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8673, -9.5431, -7.6634, -6.3672, -2.9324, -0.1481, -3.4487, -7.3286,\n",
      "         -9.4580, -3.0623]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.8673095703125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8347, -9.3833, -6.6944, -5.3125, -3.1440, -0.3048, -2.6008, -6.7428,\n",
      "         -9.0077, -2.0409]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.312482833862305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8222, -9.1511, -5.7344, -3.5247, -3.2788, -0.8726, -1.8060, -6.1279,\n",
      "         -8.5139, -1.1297]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.822235584259033\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5126, -9.2486, -5.1787, -2.2437, -3.7352, -1.9824, -1.5233, -5.8824,\n",
      "         -8.3760, -0.8567]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.2436959743499756\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8704, -9.8149, -5.1609, -0.8985, -4.6427, -3.5567, -1.9152, -6.1421,\n",
      "         -8.7304, -1.4058]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.5566675662994385\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8045, -10.7260,  -5.5500,  -0.3960,  -5.8682,  -4.6924,  -2.7825,\n",
      "          -6.7786,  -9.4508,  -2.4840]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  9.450764656066895\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7086, -11.3909,  -5.7476,  -0.2962,  -6.8183,  -5.5660,  -3.4557,\n",
      "          -7.1972,  -9.2066,  -3.3615]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  9.206633567810059\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3617, -11.5980,  -5.5363,  -0.3741,  -7.2831,  -5.9637,  -3.6946,\n",
      "          -7.1831,  -7.8635,  -3.7860]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.183139801025391\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9045, -11.4543,  -5.0187,  -0.6296,  -7.3720,  -5.9934,  -3.5987,\n",
      "          -6.0537,  -6.3241,  -3.8550]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.053711891174316\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5915, -11.1311,  -4.3634,  -1.0641,  -7.2586,  -5.8281,  -3.3396,\n",
      "          -4.0642,  -4.7455,  -3.7390]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.363417148590088\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6367, -10.7673,  -2.9949,  -1.6407,  -7.0843,  -5.6085,  -3.0610,\n",
      "          -2.2134,  -3.2576,  -3.5797]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.06099271774292\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4293, -10.8104,  -2.1690,  -2.6756,  -7.2987,  -5.7840,  -2.4464,\n",
      "          -1.0034,  -2.3168,  -3.8277]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.446396827697754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8466, -11.3799,  -2.0379,  -4.1898,  -8.0230,  -6.4749,  -1.7249,\n",
      "          -0.7328,  -2.0730,  -4.5980]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.7327854633331299\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5833, -12.3114,  -2.4320,  -5.9833,  -9.0940,  -7.5168,  -1.6308,\n",
      "          -0.5014,  -2.3648,  -5.7178]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.583258628845215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1808, -12.8998,  -2.5994,  -7.3498,  -9.8081,  -8.2049,  -1.4460,\n",
      "          -0.5185,  -2.4464,  -6.4782]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.349751949310303\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4226, -13.1293,  -2.5031,  -7.5294, -10.1509,  -8.5245,  -1.1603,\n",
      "          -0.7000,  -2.2834,  -6.8637]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.1602829694747925\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8006, -13.4931,  -2.6323,  -7.8488, -10.6168,  -8.9695,  -0.5347,\n",
      "          -1.4086,  -2.3691,  -7.3689]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.61676025390625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.0462, -13.7237,  -2.7033,  -8.0396, -10.1802,  -9.2733,  -0.3242,\n",
      "          -2.1406,  -2.4182,  -7.7272]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.1406490802764893\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.0026, -13.6649,  -2.5488,  -7.9452,  -9.5206,  -9.2805,  -0.4215,\n",
      "          -1.8438,  -2.2617,  -7.7837]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.42154911160469055\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.1170, -13.7638,  -2.6178,  -8.0123,  -9.0786,  -9.4389,  -0.3981,\n",
      "          -1.8518,  -2.3496,  -7.9867]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  13.763795852661133\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8631, -12.7439,  -2.3738,  -7.7146,  -8.3222,  -9.2231,  -0.5311,\n",
      "          -1.6229,  -2.1408,  -7.8113]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.6229009628295898\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6654, -11.8539,  -2.2489,  -7.4768,  -7.6692,  -9.0595,  -1.1285,\n",
      "          -0.8214,  -2.0712,  -7.6827]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.05949592590332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5192, -11.0828,  -2.2438,  -7.2902,  -7.1128,  -8.2360,  -1.9396,\n",
      "          -0.4707,  -2.1259,  -7.5964]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.519244194030762\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4519, -10.1701,  -2.0967,  -6.9059,  -6.3936,  -7.2783,  -2.5628,\n",
      "          -0.4226,  -2.0480,  -7.3012]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.393606662750244\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2097, -9.0587, -1.7631, -6.2711, -4.7013, -6.1269, -2.8932, -0.5973,\n",
      "         -1.7838, -6.7464]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.701280117034912\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0785, -8.0163, -1.5445, -5.6591, -2.3917, -5.0499, -3.1912, -1.1382,\n",
      "         -1.6285, -6.2059]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.659074783325195\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6421, -7.5698, -1.9933, -4.8539, -0.8731, -4.5766, -3.9829, -2.3649,\n",
      "         -2.1258, -6.2127]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.1257755756378174\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9459, -7.7251, -3.0527, -4.6918, -0.3790, -4.7145, -5.2670, -4.0992,\n",
      "         -2.4783, -6.7772]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.266950607299805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1433, -7.6860, -3.8613, -4.3733, -0.2725, -4.6658, -5.4835, -5.4945,\n",
      "         -2.6785, -7.1072]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.373283386230469\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0163, -7.2616, -4.2151, -2.9621, -0.3608, -4.2390, -5.2922, -6.3645,\n",
      "         -2.5200, -7.0153]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.215146064758301\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8160, -6.6979, -3.6411, -1.5478, -0.7813, -3.6827, -4.9416, -6.9671,\n",
      "         -2.2547, -6.7512]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.967136859893799\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9888, -6.4267, -3.3786, -0.6690, -1.7385, -3.4351, -4.8668, -6.9690,\n",
      "         -2.3289, -6.7498]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.9887735843658447\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7302, -6.3927, -3.3758, -0.4700, -2.9414, -3.4438, -5.0144, -7.1805,\n",
      "         -2.6769, -6.9584]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.941404104232788\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4309, -6.1690, -3.2034, -0.5630, -3.1175, -3.2798, -4.9580, -7.1770,\n",
      "         -2.8467, -6.9525]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.2798221111297607\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1524, -5.7875, -2.8959, -0.8893, -3.1276, -2.2736, -4.7309, -6.9929,\n",
      "         -2.8611, -6.7663]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.1275522708892822\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1456, -5.4622, -2.6748, -1.5049, -2.4381, -1.4560, -4.5490, -6.8438,\n",
      "         -2.9323, -6.6155]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.6748180389404297\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5181, -5.3217, -1.9555, -2.3736, -2.0316, -1.0333, -4.5426, -6.8594,\n",
      "         -3.1852, -6.6298]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.859439849853516\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0566, -5.2438, -1.4545, -3.2703, -1.8086, -0.9484, -4.5898, -6.1472,\n",
      "         -3.4885, -6.6887]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.9483968019485474\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8667, -5.4104, -1.4043, -4.3387, -1.9629, -0.6737, -4.8729, -5.7402,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -4.0171, -6.9754]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.975369930267334\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4621, -5.3887, -1.3608, -5.1355, -2.0319, -0.6104, -4.9585, -5.2012,\n",
      "         -4.3313, -6.3040]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.3608391284942627\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0340, -5.3857, -0.8006, -5.8704, -2.2051, -0.9482, -5.0541, -4.7331,\n",
      "         -4.6371, -5.7138]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.63710355758667\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4558, -5.2805, -0.5133, -6.4283, -2.3375, -1.4187, -5.0391, -4.2125,\n",
      "         -4.0721, -5.0790]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.4187251329421997\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7794, -5.1251, -0.6197, -6.8673, -2.4645, -1.2449, -4.9659, -3.6905,\n",
      "         -3.5113, -4.4474]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.6197417378425598\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2224, -5.1351, -0.5296, -7.4088, -2.7880, -1.4359, -5.0509, -3.3853,\n",
      "         -3.1740, -4.0331]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.385342597961426\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4291, -4.9524, -0.6745, -7.7008, -2.9293, -1.5789, -4.9362, -2.1705,\n",
      "         -2.7052, -3.4773]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.936183452606201\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6190, -4.7940, -1.1704, -7.9647, -3.0973, -1.8529, -4.0745, -1.1653,\n",
      "         -2.3333, -3.0008]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.964669227600098\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9422, -4.8072, -1.9885, -7.6048, -3.4319, -2.3594, -3.4612, -0.6508,\n",
      "         -2.2200, -2.7591]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.4318864345550537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2035, -4.7936, -2.7916, -7.2494, -2.9771, -2.8502, -2.9013, -0.5587,\n",
      "         -2.1670, -2.5577]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.901318073272705\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3712, -4.7186, -3.4897, -6.8610, -2.5368, -3.2638, -1.6096, -0.8476,\n",
      "         -2.1354, -2.3662]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.371225357055664\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9548, -4.8137, -4.2959, -6.6677, -2.3551, -3.8188, -0.7548, -1.5931,\n",
      "         -2.3505, -2.4207]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.667670726776123\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6658, -4.9896, -5.1159, -5.8357, -2.3467, -4.4182, -0.4286, -2.5052,\n",
      "         -2.6993, -2.6213]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.346735954284668\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2862, -5.0312, -5.7365, -4.9667, -1.5428, -4.8444, -0.5095, -3.2673,\n",
      "         -2.9414, -2.7352]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.286170959472656\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1087, -4.9547, -6.1787, -4.0706, -0.8598, -5.1149, -0.9203, -3.8641,\n",
      "         -3.0798, -2.7682]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.0798239707946777\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0849, -4.9157, -6.6030, -3.3008, -0.5856, -5.3871, -1.6172, -4.4422,\n",
      "         -2.5201, -2.8701]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.300795555114746\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2129, -4.9032, -7.0029, -1.9118, -0.7710, -5.6525, -2.4126, -4.9887,\n",
      "         -2.0929, -3.0220]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.0219979286193848\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7460, -5.1367, -7.6027, -1.0101, -1.5218, -6.1330, -3.4360, -5.7252,\n",
      "         -2.0388, -2.6760]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.5217515230178833\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7082, -5.6079, -8.3997, -0.7258, -1.8715, -6.8237, -4.6385, -6.6474,\n",
      "         -2.3435, -2.6732]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.607871055603027\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6357, -5.1041, -8.9479, -0.6602, -2.1313, -7.2767, -5.5590, -7.3092,\n",
      "         -2.5195, -2.5534]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.947930335998535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4866, -4.4303, -8.4977, -0.7601, -2.2288, -7.4604, -6.1661, -7.6808,\n",
      "         -2.5131, -2.2798]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.279848337173462\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4871, -3.8037, -8.0635, -1.1678, -2.3678, -7.5972, -6.6853, -7.9868,\n",
      "         -2.5386, -1.3259]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.3259094953536987\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1477, -3.7529, -8.1692, -2.2621, -3.0593, -8.2172, -7.6503, -8.7591,\n",
      "         -3.1169, -0.4106]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.059250593185425\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9327, -3.8307, -8.3701, -3.4303, -3.0788, -8.8813, -8.6252, -9.5602,\n",
      "         -3.7762, -0.1946]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.560240745544434\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2471, -3.4863, -8.1203, -4.0753, -2.6996, -9.0484, -9.0722, -9.0779,\n",
      "         -3.9560, -0.1906]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.120315551757812\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0993, -2.7404, -6.7204, -4.2095, -1.9490, -8.7398, -9.0156, -8.1845,\n",
      "         -3.6730, -0.3482]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.6729695796966553\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8586, -1.9778, -5.3205, -4.2011, -1.2387, -8.3217, -8.8245, -7.2400,\n",
      "         -2.5531, -0.8778]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.8777778744697571\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0159, -1.7292, -4.3958, -4.5371, -1.1472, -8.2778, -8.9849, -6.7225,\n",
      "         -1.9350, -1.2482]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.1472212076187134\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4064, -1.8543, -3.7853, -5.0609, -0.7710, -8.4518, -9.3427, -6.4706,\n",
      "         -1.6992, -2.0098]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.6992031335830688\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9018, -2.2063, -3.3716, -5.6570, -0.8958, -8.7283, -9.7847, -6.3648,\n",
      "         -1.0011, -2.9156]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  9.784708976745605\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3177, -2.5627, -2.9788, -6.1514, -1.2664, -8.9325, -9.3743, -6.2259,\n",
      "         -0.6006, -3.7270]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.600593626499176\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0453, -3.2859, -3.0051, -6.9416, -2.1527, -9.4598, -9.3483, -6.4458,\n",
      "         -0.2489, -4.8190]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.045291900634766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6581, -3.6445, -2.7431, -7.3326, -2.7156, -9.6134, -9.0035, -6.3236,\n",
      "         -0.1899, -5.4870]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  9.003549575805664\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8482, -3.5193, -2.0854, -7.2170, -2.8036, -9.2836, -7.4666, -5.7470,\n",
      "         -0.2797, -5.6235]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.623537540435791\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8466, -3.1415, -1.2950, -6.8257, -2.6402, -8.6990, -5.7954, -4.9424,\n",
      "         -0.6291, -4.7117]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.6290749311447144\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2738, -3.1214, -1.0675, -6.7611, -2.8330, -8.4596, -4.5797, -4.5104,\n",
      "         -0.8857, -4.1842]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.1213855743408203\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7751, -2.3141, -1.0526, -6.6461, -2.9927, -8.1865, -3.4352, -4.0723,\n",
      "         -1.3626, -3.6629]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.072256088256836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5107, -1.7245, -1.3521, -6.6051, -3.2354, -8.0024, -2.4908, -2.9798,\n",
      "         -2.0421, -3.2743]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.2743496894836426\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6039, -1.5007, -1.9788, -6.7400, -3.6541, -8.0077, -1.8743, -2.2061,\n",
      "         -2.9202, -2.3777]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.3777403831481934\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1351, -1.7709, -2.9439, -7.1635, -4.3515, -8.3137, -1.7374, -1.8959,\n",
      "         -4.0518, -1.1991]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.8958557844161987\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0855, -2.5305, -4.2370, -7.9314, -5.3752, -8.9756, -2.1344, -1.3484,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -5.4697, -0.7488]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.975592613220215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9607, -3.2617, -5.3980, -8.6095, -6.2866, -8.8462, -2.5685, -1.0425,\n",
      "         -6.7358, -0.6822]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.286599159240723\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5428, -3.7296, -6.2268, -9.0002, -6.1441, -8.5099, -2.7980, -0.8197,\n",
      "         -7.6568, -0.7788]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.729569911956787\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8171, -3.1477, -6.7169, -9.0946, -5.7598, -7.9496, -2.7935, -0.7018,\n",
      "         -8.2289, -0.9494]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.817086696624756\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0855, -2.3989, -6.9014, -8.9220, -5.1585, -7.1877, -2.5787, -0.7205,\n",
      "         -8.4866, -1.1329]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.486624717712402\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2668, -1.6219, -6.8962, -8.5946, -4.4491, -6.3300, -2.2711, -0.9398,\n",
      "         -7.8081, -1.3651]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.594558715820312\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5392, -1.0552, -6.8742, -7.5338, -3.8010, -5.5410, -2.0550, -1.4199,\n",
      "         -7.1794, -1.7457]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.0552058219909668\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3655, -0.4718, -7.2791, -7.0030, -3.6582, -5.2573, -2.3825, -2.4623,\n",
      "         -7.0379, -2.6423]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.365522623062134\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5831, -0.4530, -7.6743, -6.5558, -3.5788, -5.0356, -2.7780, -3.4968,\n",
      "         -6.9411, -3.5325]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.4967706203460693\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8959, -0.7886, -7.8988, -6.0226, -3.3964, -4.7090, -3.0502, -3.5481,\n",
      "         -6.7231, -4.2243]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.022572994232178\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5034, -1.3661, -8.0312, -4.7299, -3.1871, -4.3512, -3.2614, -3.5462,\n",
      "         -6.4575, -4.7879]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.031150817871094\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4149, -1.9068, -7.2541, -3.3993, -2.8563, -3.8650, -3.3078, -3.3935,\n",
      "         -6.0463, -5.1284]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.128437042236328\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6203, -2.3144, -6.3626, -2.0337, -2.4089, -3.2498, -3.1852, -3.0895,\n",
      "         -5.4853, -4.5025]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.3143796920776367\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3495, -2.1508, -5.7172, -1.0581, -2.2295, -2.8798, -3.2628, -3.0069,\n",
      "         -5.1395, -4.1032]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.3495323657989502\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7421, -2.3643, -5.4108, -0.7116, -2.4207, -2.8592, -3.6344, -3.2430,\n",
      "         -5.1048, -4.0283]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.7421114444732666\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4661, -2.5933, -5.1034, -0.7318, -2.6246, -2.8471, -3.9546, -3.4510,\n",
      "         -5.0433, -3.9394]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.9394330978393555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2208, -2.6931, -4.6680, -0.9459, -2.6994, -2.7146, -4.0945, -3.4996,\n",
      "         -4.8296, -2.9703]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.693138599395752\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1901, -2.0536, -4.2603, -1.4059, -2.7948, -2.6205, -4.2110, -3.5444,\n",
      "         -4.6208, -2.1133]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.190140724182129\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9225, -1.8358, -4.1642, -2.2638, -3.1873, -2.8488, -4.5881, -3.8677,\n",
      "         -4.7009, -1.6921]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.8487751483917236\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9671, -1.7600, -4.0884, -3.1133, -3.5710, -2.3793, -4.9349, -4.1745,\n",
      "         -4.7791, -1.4488]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.7600358724594116\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3594, -1.1448, -4.1110, -3.9901, -4.0163, -2.1015, -5.3313, -4.5412,\n",
      "         -4.9344, -1.4827]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.934426307678223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8722, -0.8067, -4.1180, -4.7683, -4.4056, -1.9139, -5.6669, -4.8545,\n",
      "         -4.3150, -1.6567]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.8066878914833069\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7556, -0.3954, -4.4472, -5.7863, -5.0763, -2.1615, -6.2827, -5.4536,\n",
      "         -4.0781, -2.2659]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.282713890075684\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3640, -0.3019, -4.5193, -6.4725, -5.4522, -2.2344, -5.8372, -5.7636,\n",
      "         -3.6446, -2.6588]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.4521942138671875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5536, -0.3919, -4.2090, -6.7084, -4.6615, -1.9935, -5.0551, -5.6620,\n",
      "         -2.8904, -2.6813]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.6813414096832275\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5794, -0.8150, -3.7747, -6.7561, -3.7910, -1.7088, -4.1902, -5.4076,\n",
      "         -2.0868, -1.8451]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.791013240814209\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7676, -1.6730, -3.5453, -6.9448, -2.4247, -1.7272, -3.5679, -5.3269,\n",
      "         -1.6001, -1.3542]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.4246726036071777\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3810, -3.0138, -3.7870, -7.5427, -0.9473, -2.2987, -3.4565, -5.6852,\n",
      "         -1.7389, -1.5308]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.685214042663574\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3651, -4.6807, -4.4438, -8.5042, -0.3292, -3.3081, -3.8031, -5.6607,\n",
      "         -2.4169, -2.2730]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.4168965816497803\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1738, -6.1080, -4.9631, -9.2894, -0.2285, -4.1626, -4.0517, -5.5605,\n",
      "         -2.2729, -2.9369]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.560525894165039\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4807, -6.9720, -5.0129, -9.5736, -0.3058, -4.5203, -3.8661, -4.2835,\n",
      "         -1.7966, -3.1513]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.283472061157227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5228, -7.5155, -4.8274, -9.5943, -0.6848, -4.6150, -3.4799, -2.1476,\n",
      "         -1.2553, -3.1408]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.827354907989502\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.9461, -8.3894, -4.3231, -9.9972, -1.7823, -5.0916, -3.5400, -0.6982,\n",
      "         -1.3632, -3.5478]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.323081970214844\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.7930,  -9.6417,  -3.6216, -10.8252,  -3.3600,  -5.9903,  -4.0817,\n",
      "          -0.2411,  -2.1150,  -4.4007]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.990330696105957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.3082, -10.5216,  -2.7616, -11.3230,  -4.5586,  -5.8350,  -4.3348,\n",
      "          -0.1852,  -2.6336,  -4.9301]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.334785461425781\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.3728, -10.9145,  -1.6336, -11.3718,  -5.2461,  -5.2978,  -3.4044,\n",
      "          -0.3700,  -2.7543,  -5.0127]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  8.372791290283203\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.6683, -11.2280,  -0.7193, -11.3755,  -5.8289,  -4.7773,  -2.5519,\n",
      "          -1.0215,  -2.8699,  -5.0518]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.0215436220169067\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.3226, -11.7986,  -0.5384, -11.6671,  -6.6441,  -4.6031,  -2.1327,\n",
      "          -1.4087,  -3.3044,  -5.3801]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.3043861389160156\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8111, -12.1117,  -0.5982, -11.7291,  -7.1784,  -4.2527,  -1.6458,\n",
      "          -1.7424,  -2.7817,  -5.4784]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.478385925292969\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.1833, -12.2257,  -0.8820, -11.6168,  -7.4922,  -3.7795,  -1.1880,\n",
      "          -2.0081,  -2.1889,  -4.6590]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.1880134344100952\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.9214, -12.6303,  -1.7389, -11.8177,  -8.0770,  -3.6717,  -0.5435,\n",
      "          -2.6514,  -2.0399,  -4.2302]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.230170249938965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6702, -12.9772,  -2.6204, -11.9813,  -8.5866,  -3.5756,  -0.3931,\n",
      "          -3.2671,  -1.9848,  -3.0992]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  11.981267929077148\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.2212, -13.0643,  -3.2415, -11.1507,  -8.8202,  -3.2840,  -0.5506,\n",
      "          -3.6252,  -1.8116,  -1.8890]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.221160411834717\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0979, -13.1405,  -3.8268, -10.4005,  -9.0284,  -3.0461,  -1.1317,\n",
      "          -3.9657,  -1.7745,  -0.9090]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.028368949890137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2422, -13.3529,  -4.5136,  -9.8689,  -8.6181,  -3.0100,  -2.0457,\n",
      "          -4.4306,  -2.0106,  -0.4695]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.618120193481445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3715, -13.4157,  -5.0114,  -9.2617,  -7.3843,  -2.8846,  -2.8393,\n",
      "          -4.7298,  -2.1941,  -0.4085]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.261711120605469\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4422, -13.2596,  -5.2518,  -7.7538,  -6.0611,  -2.5994,  -3.3861,\n",
      "          -4.7932,  -2.2293,  -0.6320]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.793234348297119\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7679, -13.1103,  -5.4635,  -6.3877,  -4.8627,  -2.3876,  -3.8957,\n",
      "          -4.0861,  -2.3322,  -1.2164]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.3877034187316895\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5141, -12.9938,  -5.6750,  -4.4328,  -3.8072,  -2.2811,  -4.3881,\n",
      "          -3.4801,  -2.5149,  -1.9791]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.6750359535217285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6237, -12.7952,  -5.0483,  -2.5877,  -2.7794,  -2.1654,  -4.7473,\n",
      "          -2.8640,  -2.6457,  -2.6742]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.8640146255493164\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3605, -12.8681,  -4.7405,  -1.2344,  -2.1517,  -2.3960,  -5.3293,\n",
      "          -1.8469,  -3.0680,  -3.6028]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.60284423828125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6644, -13.3894,  -4.9252,  -0.6897,  -2.1281,  -3.1251,  -6.3126,\n",
      "          -1.5063,  -3.9385,  -4.1747]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.664407730102539\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1834, -13.8758,  -5.1138,  -0.5928,  -2.2120,  -3.8304,  -7.2164,\n",
      "          -1.3852,  -4.7538,  -4.7179]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.2164154052734375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4256, -14.0588,  -5.0331,  -0.6645,  -2.1137,  -4.2263,  -7.0074,\n",
      "          -1.2113,  -5.2395,  -4.9587]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.007413387298584\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4197, -13.9762,  -4.7177,  -0.8662,  -1.8672,  -4.3460,  -5.8103,\n",
      "          -1.0336,  -5.4333,  -4.9333]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.345982074737549\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2569, -13.7207,  -4.2590,  -1.1808,  -1.5788,  -3.5587,  -4.5536,\n",
      "          -0.9626,  -5.4300,  -4.7346]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.2568564414978027\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3487, -13.4204,  -3.7861,  -1.6230,  -1.4016,  -2.8001,  -3.3597,\n",
      "          -1.1182,  -5.3600,  -4.4920]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.800081968307495\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7543, -13.3046,  -3.5314,  -2.3232,  -1.5794,  -1.5962,  -2.4660,\n",
      "          -1.6610,  -5.4552,  -4.4364]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.4659621715545654\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7566, -13.6135,  -3.7364,  -3.4400,  -2.3053,  -1.0715,  -1.3793,\n",
      "          -2.7070,  -5.9572,  -4.8082]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  13.613482475280762\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1021, -13.3497,  -4.1576,  -4.6889,  -3.2522,  -1.0654,  -0.8123,\n",
      "          -3.9188,  -6.6303,  -5.3683]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.368283271789551\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4198, -13.0308,  -4.4669,  -5.7389,  -4.0521,  -1.2272,  -0.5593,\n",
      "          -4.9437,  -7.1561,  -5.0573]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.2271816730499268\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7477, -12.7216,  -4.7316,  -6.6647,  -4.7632,  -0.8422,  -0.7453,\n",
      "          -5.8498,  -7.6079,  -4.7599]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.607893943786621\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8622, -12.2161,  -4.7494,  -7.2723,  -5.1829,  -0.5790,  -1.0470,\n",
      "          -6.4410,  -7.0427,  -4.2714]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.272300720214844\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7397, -11.4942,  -4.5050,  -6.8044,  -5.2983,  -0.4786,  -1.3189,\n",
      "          -6.7078,  -6.2677,  -3.5751]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.5750632286071777\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4603, -10.6286,  -4.0774,  -6.1683,  -5.1903,  -0.6175,  -1.5514,\n",
      "          -6.7333,  -5.3556,  -2.0191]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.355597019195557\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3835, -9.9623, -3.8179, -5.7102, -5.2103, -1.2423, -2.0352, -6.8704,\n",
      "         -3.9100, -0.8289]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  9.962268829345703\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6722, -8.8949, -3.8915, -5.5914, -5.5236, -2.3031, -2.8614, -7.2858,\n",
      "         -2.9143, -0.3702]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.894858360290527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8714, -7.0703, -3.8621, -5.3766, -5.6981, -3.2195, -3.5384, -7.5498,\n",
      "         -1.9476, -0.3548]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.37658166885376\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9293, -5.2657, -3.6886, -4.2795, -5.6953, -3.9111, -4.0078, -7.6256,\n",
      "         -1.0208, -0.6927]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.265707969665527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1027, -2.9787, -3.6334, -3.3846, -5.7781, -4.6309, -4.5270, -7.7768,\n",
      "         -0.5374, -1.4459]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.527015686035156\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4985, -1.1649, -3.8101, -2.8113, -6.0620, -5.4932, -4.4476, -8.1205,\n",
      "         -0.7438, -2.5037]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.120497703552246\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4194, -0.3105, -4.5281, -2.8825, -6.8620, -6.8152, -4.9275, -8.2106,\n",
      "         -1.8253, -4.0589]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.927520275115967\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2946, -0.1343, -5.2198, -3.0258, -7.6205, -8.0438, -4.6459, -8.3294,\n",
      "         -2.9561, -5.5092]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.620511054992676\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5896, -0.1383, -5.3499, -2.6942, -7.0622, -8.6534, -3.9027, -7.9396,\n",
      "         -3.5163, -6.3213]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.653414726257324\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3549, -0.2918, -4.9675, -1.9432, -6.0571, -7.9795, -2.7458, -7.0859,\n",
      "         -3.5397, -6.5509]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.291822612285614\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3826, -0.4757, -4.8638, -1.6097, -5.3894, -7.6084, -1.9883, -6.5535,\n",
      "         -3.8181, -6.9943]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.99427604675293\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2479, -0.9433, -4.6133, -1.2961, -4.6287, -7.1118, -1.2473, -5.9122,\n",
      "         -3.9222, -6.4965]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.2473127841949463\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5428, -2.0676, -4.8072, -1.6306, -4.3632, -7.0774, -0.4533, -5.7491,\n",
      "         -4.4429, -6.4617]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.0675950050354004\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8646, -2.4783, -5.0413, -2.1320, -4.1872, -7.1006, -0.2741, -5.6582,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -4.9740, -6.4850]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.1319501399993896\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8534, -2.6077, -4.9538, -1.6214, -3.7370, -6.8190, -0.3843, -5.2759,\n",
      "         -5.1544, -6.2040]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.15439510345459\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5819, -2.5158, -4.6168, -1.0458, -3.0859, -6.3028, -0.7329, -4.6721,\n",
      "         -4.3134, -5.6890]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.581918716430664\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5495, -2.4276, -4.2546, -0.7240, -2.4678, -5.7733, -1.3422, -4.0696,\n",
      "         -3.5001, -5.1618]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.773252964019775\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5860, -2.3726, -3.8974, -0.7544, -1.9331, -4.5394, -2.0459, -3.4986,\n",
      "         -2.7487, -4.6498]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.7487425804138184\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8578, -2.5122, -3.7100, -1.2515, -1.6792, -3.5554, -2.8962, -3.1270,\n",
      "         -1.4987, -4.3151]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.7100143432617188\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5344, -2.9893, -3.1154, -2.2030, -1.8808, -2.9806, -3.9943, -3.1167,\n",
      "         -0.8296, -4.3142]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.53444242477417\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7521, -3.6302, -2.7861, -3.3157, -2.3500, -2.6730, -5.1705, -3.3148,\n",
      "         -0.7246, -4.4968]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.7520527839660645\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7157, -4.4893, -2.7971, -4.6070, -3.1061, -2.7080, -6.4961, -3.7834,\n",
      "         -1.2515, -4.9317]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.4893479347229\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.3117, -4.6983, -3.0272, -5.9525, -3.9958, -2.9627, -7.8662, -4.3980,\n",
      "         -2.1133, -5.5039]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.503850936889648\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.2256, -4.6416, -3.0184, -6.9144, -4.5591, -2.9778, -8.8486, -4.7094,\n",
      "         -2.7273, -5.0367]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.559083938598633\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.3034, -4.1789, -2.6276, -7.3624, -3.9073, -2.6091, -9.3144, -4.5777,\n",
      "         -2.9097, -4.2018]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.201798439025879\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6545, -3.5255, -2.0806, -7.5180, -3.0872, -2.0820, -9.4857, -4.2188,\n",
      "         -2.8661, -2.4834]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.4834277629852295\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8216,  -3.4381,  -2.1591,  -8.1375,  -2.8618,  -2.1762, -10.1189,\n",
      "          -4.3859,  -3.3482,  -0.7505]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.1591312885284424\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7194,  -4.1144,  -2.3108,  -9.4264,  -3.4326,  -3.0739, -11.4201,\n",
      "          -5.2768,  -4.5393,  -0.2668]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.719416379928589\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5271,  -4.5357,  -2.3205, -10.3873,  -3.7707,  -3.7156, -12.3918,\n",
      "          -5.8831,  -5.4198,  -0.1916]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.19162705540657043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3929,  -5.0539,  -2.5322, -11.3833,  -4.2233,  -4.4419, -13.3976,\n",
      "          -6.5621,  -6.3468,  -0.1279]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  13.397639274597168\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6244,  -4.9740,  -2.2301, -11.7288,  -4.0905,  -4.5531, -12.9954,\n",
      "          -6.6231,  -6.6315,  -0.1601]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.631490707397461\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3553,  -4.4270,  -1.5569, -11.5597,  -3.5032,  -4.1806, -12.1529,\n",
      "          -6.1989,  -5.6663,  -0.3262]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  12.152914047241211\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.9027,  -3.7298,  -0.8925, -11.1939,  -2.7834,  -3.6426, -10.4296,\n",
      "          -5.6050,  -4.5862,  -0.7830]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.6049604415893555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5196,  -3.1391,  -0.6148, -10.8835,  -2.2006,  -3.1962,  -8.8969,\n",
      "          -4.3237,  -3.6402,  -1.5431]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.19621205329895\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2240,  -2.6814,  -0.8040, -10.6458,  -1.8006,  -2.1436,  -7.5585,\n",
      "          -3.2218,  -2.8495,  -2.4235]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.2217841148376465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1933,  -2.5456,  -1.5279, -10.6565,  -1.7893,  -1.5052,  -6.5786,\n",
      "          -1.7217,  -2.4054,  -3.5052]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.789331078529358\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6392,  -2.9450,  -2.8019, -11.1289,  -1.6176,  -1.5535,  -6.1600,\n",
      "          -0.9707,  -2.5352,  -4.9637]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.160009860992432\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1109,  -3.4075,  -4.0571, -11.6176,  -1.6749,  -1.8130,  -5.0994,\n",
      "          -0.6485,  -2.7744,  -6.3453]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  11.617594718933105\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3566,  -3.6655,  -5.0167, -11.1237,  -1.6836,  -1.9813,  -3.9657,\n",
      "          -0.5759,  -2.8527,  -7.4074]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  11.123722076416016\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3430, -3.6790, -5.6474, -9.6961, -1.5925, -1.9943, -2.7208, -0.7024,\n",
      "         -2.7280, -8.1259]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.125937461853027\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2377, -3.6135, -6.1214, -8.3140, -1.5664, -2.0078, -1.5529, -1.0980,\n",
      "         -2.5678, -7.9509]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.314032554626465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2617, -3.6899, -6.6648, -6.4445, -1.8146, -2.2322, -0.7756, -1.8239,\n",
      "         -2.5957, -7.9085]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.8239104747772217\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3982, -3.8887, -7.2663, -4.8735, -2.2714, -2.6230, -0.5339, -1.9472,\n",
      "         -2.7876, -7.9818]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.981837272644043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2985, -3.8574, -7.5825, -3.2387, -2.5344, -2.8016, -0.5314, -1.9412,\n",
      "         -2.7804, -7.1013]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.5825324058532715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0752, -3.7079, -6.9929, -1.6586, -2.6935, -2.8693, -0.8331, -1.9081,\n",
      "         -2.6830, -6.1718]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.075167655944824\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4131, -3.8450, -6.7160, -0.6314, -3.1409, -3.2246, -1.6838, -2.2447,\n",
      "         -2.8996, -5.5895]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.8450238704681396\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0221, -3.4278, -6.6640, -0.3005, -3.7728, -3.7699, -2.7857, -2.8252,\n",
      "         -3.3322, -5.2645]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.663982391357422\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4096, -2.8033, -5.6119, -0.2814, -4.0858, -4.0043, -3.5509, -3.1199,\n",
      "         -3.4752, -4.7023]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.550898551940918\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5765, -1.9811, -4.3618, -0.5191, -4.0749, -3.9232, -3.2042, -3.1136,\n",
      "         -3.3216, -3.8971]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.11357045173645\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9079, -1.3716, -3.2724, -1.2006, -4.1046, -3.8914, -2.9492, -2.4056,\n",
      "         -3.2371, -3.2136]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.237122058868408\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6384, -1.2399, -2.5450, -2.2631, -4.3696, -4.1033, -2.9846, -2.0625,\n",
      "         -2.6699, -2.8530]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.8529560565948486\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6768, -1.4806, -2.0887, -3.4380, -4.7588, -4.4471, -3.1954, -1.9916,\n",
      "         -2.3517, -1.9905]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.0887351036071777\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0639, -2.0866, -1.2547, -4.7376, -5.3334, -4.9830, -3.6336, -2.2495,\n",
      "         -2.3541, -1.5303]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.249473810195923\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6847, -2.9067, -0.8939, -6.0950, -6.0352, -5.6513, -4.2288, -1.9825,\n",
      "         -2.6078, -1.4530]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.651272296905518\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2103, -3.6038, -0.7868, -7.2365, -6.5863, -5.4468, -4.6931, -1.7643,\n",
      "         -2.8087, -1.4697]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.586340427398682\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5310, -4.0703, -0.8427, -8.0830, -6.1488, -5.0841, -4.9363, -1.5164,\n",
      "         -2.8529, -1.4692]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.8426807522773743\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9820, -4.6444, -0.6172, -8.9867, -5.8976, -4.9031, -5.3019, -1.6015,\n",
      "         -3.0770, -1.7761]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.9820361137390137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4604, -4.9480, -0.5887, -9.5798, -5.4528, -4.5249, -5.4141, -1.6109,\n",
      "         -3.0925, -1.9541]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.5886750221252441\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1881,  -5.4014,  -0.4122, -10.2887,  -5.2302,  -4.3669,  -5.6932,\n",
      "          -1.9462,  -3.3152,  -2.3915]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.230245590209961\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6778,  -5.5183,  -0.4429, -10.6322,  -3.9900,  -3.9390,  -5.6522,\n",
      "          -2.0620,  -3.2480,  -2.5567]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.2480413913726807\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0905,  -5.4493,  -0.7616, -10.7642,  -2.7099,  -3.3906,  -5.4407,\n",
      "          -2.0860,  -2.2930,  -2.5843]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.086010456085205\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8603,  -5.5999,  -1.5982, -11.0926,  -1.8167,  -3.1308,  -5.4630,\n",
      "          -1.6504,  -1.7179,  -2.8733]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.816678524017334\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1997,  -6.1727,  -2.9333, -11.8226,  -0.8215,  -3.3630,  -5.9206,\n",
      "          -1.8385,  -1.7684,  -3.6087]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.1996703147888184\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0896,  -6.9141,  -4.3985, -12.7040,  -0.4798,  -3.8213,  -6.5587,\n",
      "          -2.3530,  -2.1654,  -4.5146]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.514647006988525\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8716,  -7.3743,  -5.5186, -13.2896,  -0.4284,  -4.0419,  -6.9262,\n",
      "          -2.6804,  -2.4005,  -4.4067]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.374293804168701\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4773,  -6.7238,  -6.2214, -13.5081,  -0.5608,  -3.9446,  -6.9492,\n",
      "          -2.7187,  -2.3712,  -4.0096]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.949179172515869\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0744,  -5.9268,  -6.6435, -13.4926,  -0.8936,  -3.6588,  -6.0059,\n",
      "          -2.5911,  -2.2024,  -3.4528]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.0744459629058838\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5046,  -5.4775,  -7.2909, -13.7451,  -1.7647,  -3.6868,  -5.4248,\n",
      "          -2.7998,  -2.3995,  -3.2408]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.399515151977539\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4300,  -5.0799,  -7.8781, -13.9762,  -2.6806,  -3.7339,  -4.9086,\n",
      "          -3.0378,  -1.9020,  -3.0820]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.0819599628448486\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6785,  -4.5751,  -8.2556, -14.0328,  -3.4051,  -3.6424,  -4.2979,\n",
      "          -3.1372,  -1.4139,  -2.0998]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.4139313697814941\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5578,  -4.4202,  -8.8876, -14.3756,  -4.3740,  -3.8710,  -4.0500,\n",
      "          -3.5516,  -0.7034,  -1.5956]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  14.37563419342041\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5804,  -4.3695,  -9.5365, -14.0166,  -5.3357,  -4.1717,  -3.9197,\n",
      "          -4.0264,  -0.5126,  -1.3679]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.5125722289085388\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8235,  -4.6015, -10.3888, -13.9613,  -6.4732,  -4.7218,  -4.0853,\n",
      "          -4.7355,  -0.3105,  -1.6148]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.735527992248535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5912,  -4.4505, -10.7889, -13.5441,  -7.1312,  -4.8563,  -3.8797,\n",
      "          -4.2516,  -0.3072,  -1.6135]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.1311774253845215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8929,  -3.9267, -10.7524, -12.7717,  -6.5795,  -4.5862,  -3.3134,\n",
      "          -3.4298,  -0.4532,  -1.3595]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.892945766448975\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2277,  -3.2463, -10.4959, -11.8524,  -5.8601,  -4.1269,  -2.6072,\n",
      "          -2.4909,  -0.8311,  -1.0927]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.86014986038208\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6428,  -2.6669, -10.2686, -11.0284,  -4.4756,  -3.7287,  -2.0308,\n",
      "          -1.7122,  -1.4970,  -1.0984]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.475594520568848\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2765,  -2.3395, -10.2054, -10.4279,  -2.6415,  -3.5294,  -1.7525,\n",
      "          -1.2902,  -2.4037,  -1.4859]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.6415486335754395\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4648,  -2.6092, -10.6398, -10.3784,  -0.8005,  -3.8626,  -2.1243,\n",
      "          -1.6112,  -3.7782,  -2.4896]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  10.63976764678955\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3647,  -3.6159, -11.0049, -11.0416,  -0.1836,  -4.8858,  -3.2572,\n",
      "          -2.7604,  -5.7407,  -4.1611]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.1836402714252472\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.7144,  -5.0732, -11.8641, -12.1691,  -0.0348,  -6.3431,  -4.8369,\n",
      "          -4.3737,  -8.0406,  -6.2079]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.343100070953369\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.3316,  -5.7896, -12.0372, -12.5839,  -0.0162,  -6.3235,  -5.6648,\n",
      "          -5.2356,  -9.5112,  -7.4518]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.01621616631746292\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.9096e+00, -6.4580e+00, -1.2214e+01, -1.2978e+01, -8.5961e-03,\n",
      "         -6.3281e+00, -6.4338e+00, -6.0366e+00, -1.0856e+01, -8.5932e+00]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  12.978313446044922\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7104e+00, -6.3407e+00, -1.1653e+01, -1.1866e+01, -1.0886e-02,\n",
      "         -5.6131e+00, -6.4071e+00, -6.0394e+00, -1.1347e+01, -8.9008e+00]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  11.347344398498535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8264,  -5.5308, -10.4420, -10.1583,  -0.0299,  -4.2665,  -5.6788,\n",
      "          -5.3381, -10.3410,  -8.4723]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.472332954406738\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4343, -4.2064, -8.7534, -8.0227, -0.1529, -2.4660, -4.4274, -4.1122,\n",
      "         -8.8366, -6.7640]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.427411079406738\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2308, -3.0667, -7.2746, -6.1414, -0.9249, -0.9486, -2.5942, -3.0622,\n",
      "         -7.5236, -5.2681]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.2307562828063965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2317, -2.8504, -6.7179, -5.2234, -2.6815, -0.6410, -1.7745, -2.9271,\n",
      "         -7.1161, -4.6992]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.7745273113250732\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8466, -3.1373, -6.6549, -4.8382, -4.7504, -1.1879, -0.8484, -3.2838,\n",
      "         -7.1872, -4.6309]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.630916595458984\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7581, -3.5736, -6.7440, -4.6422, -6.7644, -2.0486, -0.4830, -3.7785,\n",
      "         -7.3965, -4.0006]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.000627517700195\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6611, -3.8467, -6.6837, -4.3315, -8.4375, -2.7769, -0.4787, -4.1002,\n",
      "         -7.4442, -2.5890]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.478652685880661\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0042,  -4.4028,  -6.9242,  -4.3555, -10.2381,  -3.7722,  -0.4820,\n",
      "          -4.6965,  -7.7814,  -1.6659]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.781378746032715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2947,  -4.7974,  -7.0260,  -4.2713, -11.7439,  -4.5699,  -0.8349,\n",
      "          -5.1249,  -7.2299,  -0.8553]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.0259809494018555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6105,  -5.1406,  -6.3652,  -4.1876, -13.0815,  -5.2773,  -1.4607,\n",
      "          -5.4968,  -6.7154,  -0.4136]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  13.081465721130371\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7319,  -5.2384,  -5.5557,  -3.9078, -13.3395,  -5.7023,  -1.9830,\n",
      "          -5.6191,  -6.0372,  -0.2762]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.037234783172607\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5087,  -4.9511,  -4.4502,  -3.2916, -13.1925,  -5.7081,  -2.1775,\n",
      "          -5.3526,  -4.3131,  -0.3176]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.508749008178711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5102,  -4.5609,  -3.3264,  -2.6278, -12.9232,  -5.5788,  -2.3011,\n",
      "          -4.9793,  -2.6336,  -0.7384]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.6336276531219482\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2832,  -4.7309,  -2.8543,  -2.5978, -13.1941,  -5.9784,  -3.0012,\n",
      "          -5.1618,  -0.9550,  -1.9720]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.1617937088012695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8852,  -5.4978,  -3.0786,  -3.2340, -14.0450,  -6.9472,  -4.2761,\n",
      "          -5.1704,  -0.3347,  -3.7894]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.0786449909210205\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4645,  -6.1196,  -2.5093,  -3.7646, -14.7392,  -7.7483,  -5.3625,\n",
      "          -5.1106,  -0.2326,  -5.3702]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.509331703186035\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8520,  -6.4858,  -1.1319,  -4.0645, -15.1691,  -8.2747,  -6.1491,\n",
      "          -4.8661,  -0.5281,  -6.6016]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.60164737701416\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4557,  -7.0300,  -0.3416,  -4.5608, -15.7693,  -8.9620,  -7.0722,\n",
      "          -4.8650,  -1.4396,  -7.2068]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.4395556449890137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0945,  -7.5930,  -0.2244,  -5.0879, -16.3822,  -9.6534,  -7.9764,\n",
      "          -4.9423,  -1.7736,  -7.8246]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.976434707641602\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2139,  -7.6327,  -0.2357,  -5.0995, -16.4663,  -9.8084,  -7.5689,\n",
      "          -4.5497,  -1.7308,  -7.9135]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.808367729187012\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8817,  -7.2183,  -0.3707,  -4.6641, -16.0916,  -8.7607,  -6.7518,\n",
      "          -3.7539,  -1.3715,  -7.5433]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.76068115234375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3163,  -6.5647,  -0.7122,  -3.9981, -15.4732,  -6.8051,  -5.7359,\n",
      "          -2.7742,  -0.9527,  -6.9293]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.735894203186035\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7715,  -5.9153,  -1.3135,  -3.3505, -14.8544,  -4.9831,  -4.0122,\n",
      "          -1.8782,  -0.7959,  -6.3152]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.878212571144104\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6940,  -5.7005,  -2.4179,  -3.1616, -14.6650,  -3.7153,  -2.8415,\n",
      "          -0.7895,  -1.3523,  -6.1314]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.6939539909362793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3214,  -5.8788,  -3.8463,  -3.3928, -14.8637,  -2.9608,  -2.2004,\n",
      "          -0.5274,  -2.4116,  -6.3365]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.200399398803711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1990,  -6.1840,  -5.2905,  -3.7689, -15.1850,  -2.4619,  -1.1017,\n",
      "          -0.8867,  -3.5736,  -6.6650]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.665009498596191\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3379,  -6.6295,  -6.7638,  -4.2942, -15.6434,  -2.2445,  -0.5310,\n",
      "          -1.6950,  -4.8095,  -6.4156]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.809547424316406\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4547,  -6.9538,  -8.0134,  -4.6997, -15.9784,  -2.0488,  -0.3807,\n",
      "          -2.4857,  -5.1174,  -6.1143]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.4547362327575684\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6935,  -7.0370,  -8.9292,  -4.8621, -16.0704,  -1.7579,  -0.5472,\n",
      "          -3.0518,  -5.1893,  -5.6350]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.189311981201172\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0257,  -6.9977,  -9.6391,  -4.8994, -16.0384,  -1.5081,  -1.0141,\n",
      "          -3.4831,  -4.4152,  -5.0911]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  16.03839111328125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6675,  -6.9481, -10.2634,  -4.9237, -15.2637,  -1.4312,  -1.6902,\n",
      "          -3.8800,  -3.7121,  -4.5909]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.88000750541687\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5993,  -6.7895, -10.7110,  -4.8364, -14.4515,  -1.4233,  -2.3219,\n",
      "          -3.3720,  -2.9821,  -4.0330]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.4232909679412842\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9861,  -6.7013, -11.1677,  -4.8176, -13.7739,  -0.9115,  -3.0178,\n",
      "          -2.9945,  -2.4154,  -3.5970]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.994471549987793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6360,  -6.6567, -11.6129,  -4.8407, -13.1976,  -0.7802,  -3.7148,\n",
      "          -1.9652,  -2.0042,  -3.2581]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.7147834300994873\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4045,  -6.6611, -12.0572,  -4.9110, -12.7221,  -1.0423,  -3.6563,\n",
      "          -1.1887,  -1.7758,  -3.0240]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.1887463331222534\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6145,  -7.1191, -12.9104,  -5.4330, -12.7471,  -1.9904,  -4.0760,\n",
      "          -0.4146,  -2.1469,  -3.3012]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  12.910414695739746\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7053,  -7.5139, -12.9300,  -5.8881, -12.7514,  -2.9262,  -4.4484,\n",
      "          -0.2038,  -2.5481,  -3.5590]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.448404312133789\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.2618,  -7.4377, -12.5156,  -5.8680, -12.3232,  -3.3763,  -3.6174,\n",
      "          -0.2021,  -2.5345,  -3.3796]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.868032932281494\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3261,  -6.9290, -11.7018,  -4.6516, -11.4970,  -3.3661,  -2.4484,\n",
      "          -0.3780,  -2.1396,  -2.8019]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.3661017417907715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3240,  -6.4081, -10.9055,  -3.4999, -10.6895,  -2.5835,  -1.3965,\n",
      "          -0.9892,  -1.8066,  -2.2618]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.408109188079834\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5762,  -5.4159, -10.4391,  -2.7365, -10.2131,  -2.1849,  -0.8842,\n",
      "          -2.0706,  -1.8775,  -2.1012]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.7365097999572754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.9937,  -4.7134, -10.2068,  -1.5298,  -9.9716,  -2.0961,  -0.9178,\n",
      "          -3.3271,  -2.2408,  -2.2322]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.713436603546143\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.5221,  -3.4690, -10.1483,  -0.7584,  -9.9050,  -2.2572,  -1.3959,\n",
      "          -4.6365,  -2.7967,  -2.5783]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  10.148337364196777\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0577, -2.4311, -9.4266, -0.4781, -9.9038, -2.5378, -2.0690, -5.8815,\n",
      "         -3.4005, -3.0033]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.903772354125977\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.4148, -1.4388, -8.6509, -0.5699, -9.0447, -2.7229, -2.6434, -6.8789,\n",
      "         -3.8430, -3.2960]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.4388434886932373\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.1539, -0.3765, -8.3698, -1.4972, -8.6883, -3.3549, -3.6307, -8.1950,\n",
      "         -4.6742, -4.0035]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.674215316772461\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.9862, -0.1179, -8.2833, -2.6679, -8.5341, -4.1162, -4.7059, -9.5468,\n",
      "         -4.8639, -4.8202]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.6679189205169678\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.2844,  -0.1188,  -7.7543,  -2.5671,  -7.9439,  -4.3624,  -5.2295,\n",
      "         -10.3127,  -4.5889,  -5.1101]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.588863372802734\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.9996,  -0.2463,  -6.7249,  -1.9809,  -6.8595,  -4.0402,  -5.1516,\n",
      "         -10.4491,  -3.0679,  -4.8222]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.724919319152832\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.5458,  -0.7592,  -4.8755,  -1.3597,  -5.6863,  -3.5655,  -4.8884,\n",
      "         -10.3744,  -1.5348,  -4.3712]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.3596900701522827\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.7503,  -2.1903,  -3.8288,  -0.8535,  -5.2454,  -3.7719,  -5.2699,\n",
      "         -10.9202,  -0.9246,  -4.5873]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.9246175289154053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.4503,  -4.0801,  -3.4179,  -1.2345,  -5.3680,  -4.4905,  -6.1331,\n",
      "         -11.9274,  -0.4522,  -5.3050]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.305016994476318\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.9104,  -5.6244,  -2.9014,  -1.6264,  -5.3116,  -4.9755,  -6.7416,\n",
      "         -12.6641,  -0.3210,  -5.0625]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.90142822265625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.0929,  -6.7860,  -1.5206,  -1.8956,  -5.0325,  -5.1855,  -7.0587,\n",
      "         -13.0956,  -0.4990,  -4.6169]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.895613670349121\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.4654,  -8.0409,  -0.6445,  -1.7072,  -4.9942,  -5.5869,  -7.5529,\n",
      "         -13.6923,  -1.3079,  -4.4310]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.6445074677467346\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.4681,  -9.8384,  -0.1786,  -2.3411,  -5.6320,  -6.6184,  -8.6656,\n",
      "         -14.8969,  -2.8996,  -4.9394]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  9.838388442993164\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.0989, -10.4190,  -0.0969,  -2.7122,  -5.9368,  -7.2761,  -9.3957,\n",
      "         -15.7095,  -4.1009,  -5.1303]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.130339622497559\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.1038, -10.3787,  -0.1180,  -2.5332,  -5.6502,  -7.3058,  -9.4900,\n",
      "         -15.8781,  -4.6315,  -4.0242]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.650162696838379\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.6163,  -9.8505,  -0.2856,  -1.9398,  -4.1684,  -6.8410,  -9.0830,\n",
      "         -15.5379,  -4.6244,  -2.5492]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.84100341796875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.1232,  -9.3208,  -0.9217,  -1.4596,  -2.7913,  -5.6312,  -8.6625,\n",
      "         -15.1775,  -4.5710,  -1.2232]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.7913198471069336\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.2081,  -9.3728,  -2.3090,  -1.7310,  -1.3947,  -5.0734,  -8.8128,\n",
      "         -15.3818,  -5.0593,  -0.7705]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.3090176582336426\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.6319,  -9.7670,  -3.2553,  -2.4562,  -0.6666,  -4.9231,  -9.2957,\n",
      "         -15.9132,  -5.8510,  -1.0443]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  11.631891250610352\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.2457, -10.0804,  -4.0935,  -3.1322,  -0.3467,  -4.7515,  -9.6888,\n",
      "         -16.3500,  -6.5243,  -1.5030]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.3467130661010742\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.1875, -10.6521,  -5.1496,  -4.0632,  -0.1336,  -4.8928, -10.3324,\n",
      "         -17.0328,  -7.4212,  -2.3659]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  10.332433700561523\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.6486, -10.6803,  -5.6183,  -4.4280,  -0.0970,  -4.5391,  -9.6767,\n",
      "         -17.1611,  -7.7426,  -2.7241]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  9.67667007446289\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.5752, -10.1177,  -5.4548,  -4.1774,  -0.1376,  -3.6403,  -7.7550,\n",
      "         -16.6885,  -7.4443,  -2.5058]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  16.68851661682129\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.1393,  -9.1416,  -4.8412,  -3.4939,  -0.3368,  -2.3811,  -5.5556,\n",
      "         -15.0311,  -6.7067,  -1.8988]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.3368140459060669\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.1360,  -8.5523,  -4.5839,  -3.1909,  -0.5973,  -1.6051,  -3.8675,\n",
      "         -13.8282,  -6.3329,  -1.7499]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.7498888969421387\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.3861,  -8.1747,  -4.5124,  -3.1020,  -1.3837,  -1.2081,  -2.5159,\n",
      "         -12.8979,  -6.1505,  -1.1719]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.150461196899414\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8831,  -8.0060,  -4.6271,  -3.2271,  -2.4449,  -1.2431,  -1.5304,\n",
      "         -12.2313,  -5.4299,  -1.0460]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.429937362670898\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5045,  -7.9266,  -4.8096,  -3.4420,  -3.5357,  -1.5605,  -0.8770,\n",
      "         -11.7033,  -4.1329,  -1.2581]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.809595108032227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1492,  -7.8380,  -4.2430,  -3.6423,  -4.5218,  -1.9845,  -0.5826,\n",
      "         -11.2105,  -2.9592,  -1.6367]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.9845430850982666\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8126,  -7.7377,  -3.7223,  -3.8218,  -5.3968,  -1.7064,  -0.7138,\n",
      "         -10.7460,  -1.9193,  -2.0970]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  10.745979309082031\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5018, -7.6340, -3.2572, -3.9862, -6.1743, -1.5766, -1.1834, -9.5541,\n",
      "         -1.0758, -2.5865]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.5017781257629395\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5786, -7.6163, -2.9413, -4.2237, -6.9512, -1.6878, -1.9099, -8.5562,\n",
      "         -0.6397, -3.1569]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.9413070678710938\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7536, -7.5867, -1.9643, -4.4346, -7.6375, -1.9109, -2.6606, -7.6438,\n",
      "         -0.6165, -3.6872]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.6872124671936035\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0483, -7.5517, -1.1765, -4.6248, -8.2470, -2.2124, -3.3800, -6.8138,\n",
      "         -0.9786, -3.4520]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.048333168029785\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0524, -7.7905, -0.9586, -5.0734, -9.0659, -2.8349, -4.3231, -6.3372,\n",
      "         -1.8470, -3.5329]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.3230695724487305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5583, -8.1545, -1.1865, -5.6307, -9.9521, -3.5876, -4.5836, -6.0580,\n",
      "         -2.8921, -3.7755]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.952078819274902\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.3726, -8.3254, -1.4538, -5.9782, -9.8634, -4.1288, -4.6687, -5.6513,\n",
      "         -3.7163, -3.8534]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.651309967041016\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.3648, -8.1391, -1.5218, -5.9526, -9.4432, -4.2876, -4.4119, -4.1890,\n",
      "         -4.1358, -3.5984]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.5983946323394775\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5918, -7.7034, -1.4718, -5.6635, -8.7968, -4.1727, -3.9217, -2.6157,\n",
      "         -4.2570, -2.4014]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.1727495193481445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3129, -7.4287, -1.7089, -5.5231, -8.3322, -3.4573, -3.6123, -1.3720,\n",
      "         -4.4938, -1.5061]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.612318277359009\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5314, -7.5567, -2.4272, -5.7745, -8.2888, -3.2112, -2.9853, -0.8203,\n",
      "         -5.0900, -1.2344]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.985292434692383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8010, -7.7873, -3.2525, -6.1182, -8.3648, -3.1343, -1.8346, -0.7742,\n",
      "         -5.7462, -1.3144]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.364816665649414\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9786, -8.0134, -4.0416, -6.4475, -7.7253, -3.1155, -0.9351, -1.1019,\n",
      "         -6.3576, -1.5979]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.041564464569092\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0960, -8.2693, -4.0978, -6.7973, -7.2018, -3.1836, -0.4689, -1.7019,\n",
      "         -6.9615, -2.0511]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.70186185836792\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0326, -8.4287, -4.0890, -7.0419, -6.6597, -3.2043, -0.4421, -1.5492,\n",
      "         -7.4346, -2.4806]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.43464469909668\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5614, -8.2572, -3.7780, -6.9477, -5.8574, -2.9379, -0.5783, -1.2579,\n",
      "         -6.8181, -2.6124]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.257237434387207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.8044, -7.0979, -3.2809, -6.6300, -4.9034, -2.5038, -0.8815, -0.9781,\n",
      "         -6.0303, -2.5506]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.9780685901641846\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.2742, -6.3052, -3.1108, -6.5956, -4.3005, -2.4243, -1.7105, -0.5032,\n",
      "         -5.5732, -2.8018]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  8.274153709411621\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.8454, -5.4662, -2.8632, -6.4391, -3.6409, -2.2918, -2.4640, -0.4076,\n",
      "         -5.0378, -2.9452]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.40764427185058594\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.6923, -4.9467, -2.9139, -6.5320, -3.2987, -2.4804, -3.4380, -0.3006,\n",
      "         -4.7931, -3.3450]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.4380078315734863\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.2059, -4.1356, -2.6498, -6.2680, -2.6688, -2.3636, -3.2498, -0.4156,\n",
      "         -4.2300, -3.3817]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.2498106956481934\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6014, -3.2505, -2.2957, -5.8646, -1.9850, -2.1612, -2.2069, -0.8497,\n",
      "         -3.5664, -3.2721]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.566408395767212\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2314, -2.6569, -2.2229, -5.6769, -1.6431, -2.2381, -1.5221, -1.7362,\n",
      "         -2.4371, -3.3744]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.2381339073181152\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1773, -2.4543, -2.5129, -5.7882, -1.7542, -1.9212, -1.3435, -2.9450,\n",
      "         -1.7613, -3.7688]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.788205623626709\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1700, -2.3783, -2.8723, -5.1666, -2.0206, -1.7843, -1.4145, -4.1130,\n",
      "         -1.3177, -4.1806]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.0205650329589844\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2071, -2.4240, -3.2789, -4.6535, -1.6697, -1.8280, -1.6993, -5.2194,\n",
      "         -1.1553, -4.6046]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.278947591781616\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1727, -2.4645, -2.8830, -4.1295, -1.4219, -1.9176, -2.0210, -6.1504,\n",
      "         -1.1690, -4.9244]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.924436569213867\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0407, -2.4644, -2.4641, -3.5673, -1.2722, -2.0048, -2.3055, -6.8878,\n",
      "         -1.3048, -4.3917]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.5672669410705566\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8828, -2.4896, -2.1075, -2.2817, -1.3013, -2.1428, -2.5944, -7.5119,\n",
      "         -1.5836, -3.8803]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.4895877838134766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8903, -1.9502, -2.0216, -1.3496, -1.6738, -2.5020, -3.0572, -8.2219,\n",
      "         -2.1316, -3.5823]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.582303524017334\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0602, -1.7356, -2.2007, -0.8695, -2.3071, -3.0475, -3.6697, -9.0225,\n",
      "         -2.8726, -2.7756]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.7356374263763428\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4032, -1.0962, -2.6301, -0.9455, -3.1384, -3.7624, -4.4283, -9.9318,\n",
      "         -3.7692, -2.2825]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.428288459777832\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6916,  -0.7572,  -3.0472,  -1.2887,  -3.8971,  -4.4018,  -4.3625,\n",
      "         -10.7291,  -4.5719,  -1.8905]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  10.729060173034668\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8101,  -0.6722,  -3.3147,  -1.6657,  -4.4529,  -4.8445,  -4.1705,\n",
      "         -10.5471,  -5.1600,  -1.5043]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.6656849384307861\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8683,  -0.9402,  -3.5326,  -1.3385,  -4.9126,  -5.1997,  -3.9596,\n",
      "         -10.3341,  -5.6444,  -1.2679]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.338472843170166\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0916,  -1.6527,  -3.9201,  -0.6548,  -5.5021,  -5.6938,  -3.9539,\n",
      "         -10.3124,  -6.2534,  -1.4284]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.9201231002807617\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.2554,  -2.4039,  -3.5252,  -0.3965,  -5.9980,  -6.1034,  -3.9251,\n",
      "         -10.2551,  -6.7653,  -1.7083]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.7082873582839966\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.2667,  -3.0133,  -3.0541,  -0.5374,  -6.3096,  -6.3371,  -3.7768,\n",
      "         -10.0667,  -7.0903,  -1.2331]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.233076810836792\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.4608,  -3.7834,  -2.8473,  -1.2898,  -6.7750,  -6.7324,  -3.8437,\n",
      "         -10.0805,  -7.5670,  -0.4796]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.774980068206787\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.6316,  -4.4900,  -2.6985,  -2.1711,  -6.4591,  -7.0848,  -3.9153,\n",
      "         -10.0886,  -7.9923,  -0.2431]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  10.088616371154785\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.4299, -4.7792, -2.2572, -2.6951, -5.8199, -7.0469, -3.6387, -8.9857,\n",
      "         -8.0196, -0.2379]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.779151439666748\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8768, -3.9026, -1.5634, -2.8462, -4.8747, -6.6415, -3.0370, -7.6207,\n",
      "         -7.6725, -0.4255]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.620707988739014\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2516, -3.0008, -0.9619, -2.8983, -3.9011, -6.1494, -2.4027, -5.5146,\n",
      "         -7.2324, -0.9328]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.89829683303833\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8161, -2.3533, -0.8221, -2.3552, -3.1653, -5.8340, -2.0245, -3.7472,\n",
      "         -6.9627, -1.7965]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.8160576820373535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7995, -1.9467, -1.1164, -2.0411, -2.6370, -5.6555, -1.8848, -2.2769,\n",
      "         -6.8237, -2.7960]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.0411431789398193\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2155, -2.0159, -1.9428, -1.4280, -2.5390, -5.8227, -2.1965, -1.3555,\n",
      "         -7.0247, -4.0651]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.065072059631348\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8878, -2.3685, -2.9777, -1.2443, -2.6960, -6.1629, -2.7470, -0.9080,\n",
      "         -7.3939, -4.6898]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.162889003753662\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5356, -2.6861, -3.8743, -1.2241, -2.8148, -5.6508, -3.2179, -0.7373,\n",
      "         -7.6546, -5.1868]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.654552936553955\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0322, -2.8170, -4.4890, -1.2200, -2.7582, -4.9848, -3.4640, -0.7368,\n",
      "         -6.9499, -5.4308]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.949872016906738\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4027, -2.7696, -4.8391, -1.2275, -2.5422, -4.1787, -3.4973, -0.8851,\n",
      "         -5.3777, -5.4420]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.402665615081787\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2211, -2.8232, -5.2079, -1.5030, -2.4533, -3.5121, -3.5976, -1.3769,\n",
      "         -4.0132, -5.5031]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.82322359085083\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6507, -2.4243, -5.8220, -2.1968, -2.7145, -3.2122, -3.9862, -2.2876,\n",
      "         -3.0758, -5.8390]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.9861631393432617\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5631, -2.1782, -6.4220, -2.9503, -3.0433, -3.0173, -3.6547, -3.2290,\n",
      "         -2.3103, -6.1885]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.188502788543701\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7838, -1.9283, -6.8479, -3.5527, -3.2588, -2.7629, -3.2598, -3.9909,\n",
      "         -1.5780, -5.6750]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.5779623985290527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6027, -2.1030, -7.5197, -4.4044, -3.7688, -2.8687, -3.2202, -4.9786,\n",
      "         -0.6292, -5.5026]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.103003978729248\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7127, -1.8119, -8.3512, -5.4067, -4.4711, -3.2328, -3.4403, -6.0992,\n",
      "         -0.3907, -5.5765]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.232753276824951\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5607, -1.4755, -8.9001, -6.1126, -4.9119, -2.6426, -3.4621, -6.9100,\n",
      "         -0.4694, -5.4457]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.900080680847168\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1202, -1.1238, -8.4456, -6.5251, -5.0895, -1.9397, -3.2803, -7.4160,\n",
      "         -0.7703, -5.1062]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.44558048248291\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5425, -0.9641, -7.2244, -6.8044, -5.1607, -1.3212, -3.0511, -7.7788,\n",
      "         -1.2841, -4.7115]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.0511279106140137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9291, -1.1120, -6.1237, -7.0552, -5.2275, -0.9626, -2.1399, -8.1043,\n",
      "         -1.9462, -4.3611]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.104330062866211\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2522, -1.4680, -5.1040, -7.2515, -5.2613, -0.8955, -1.3762, -7.6127,\n",
      "         -2.6160, -4.0244]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.2613348960876465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5156, -1.9342, -4.1587, -7.3973, -4.5282, -1.1093, -0.8439, -7.1390,\n",
      "         -3.2408, -3.7026]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.515580654144287\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9448, -2.3841, -3.2377, -7.4480, -3.7949, -1.4675, -0.6016, -6.6318,\n",
      "         -3.7508, -3.3495]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.631848335266113\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2866, -2.7107, -2.2873, -7.3446, -3.0018, -1.8130, -0.6386, -5.2770,\n",
      "         -4.0777, -2.9072]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.2872958183288574\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8743, -3.2263, -0.9564, -7.4223, -2.4944, -2.4165, -1.2315, -4.2311,\n",
      "         -4.5547, -2.7184]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.231537938117981\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9867, -4.1898, -0.5040, -7.9613, -2.5670, -3.4954, -1.7109, -3.7688,\n",
      "         -5.4605, -3.0643]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.768810272216797\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9957, -4.9633, -0.4266, -8.3411, -2.5832, -4.3838, -2.1699, -2.5180,\n",
      "         -6.1734, -3.3036]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.173369407653809\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8777, -5.5256, -0.6870, -8.5438, -2.5140, -5.0537, -2.5280, -1.3127,\n",
      "         -5.9489, -3.4059]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.9488525390625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9076, -6.1561, -1.4037, -8.8475, -2.6325, -5.7827, -3.0303, -0.5505,\n",
      "         -5.1465, -3.6429]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.403666615486145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0539, -6.8301, -1.6116, -9.2257, -2.8969, -6.5461, -3.6229, -0.4018,\n",
      "         -4.5328, -3.9798]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.8968615531921387\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9212, -7.1608, -1.6650, -9.2893, -2.1625, -6.9575, -3.8991, -0.4919,\n",
      "         -3.7110, -4.0195]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.711003303527832\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6870, -7.3299, -1.7196, -9.2174, -1.4567, -7.1994, -4.0336, -0.9004,\n",
      "         -2.1396, -3.9390]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.4567196369171143\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9907, -7.9789, -2.3935, -9.6489, -0.7550, -7.9141, -4.6640, -2.0676,\n",
      "         -1.3060, -4.3767]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.664017200469971\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4747,  -8.7607,  -3.2630, -10.2346,  -0.6662,  -8.7549,  -4.6980,\n",
      "          -3.4101,  -0.9486,  -4.9769]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.760683059692383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7350,  -8.5089,  -3.8895, -10.5781,  -0.7801,  -9.3283,  -4.5514,\n",
      "          -4.4598,  -0.7233,  -5.3385]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.3385233879089355\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6962,  -8.0026,  -4.1887, -10.6078,  -0.9395,  -9.5649,  -4.1476,\n",
      "          -5.1339,  -0.5917,  -4.6692]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.696183204650879\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6446,  -7.2542,  -4.1763, -10.3417,  -1.0769,  -9.4853,  -3.5028,\n",
      "          -5.4526,  -0.5801,  -3.7804]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  10.341702461242676\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4951, -6.3591, -3.9544, -9.1192, -1.2286, -9.1920, -2.7227, -5.5211,\n",
      "         -0.7515, -2.7747]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.7515398263931274\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7992, -5.8334, -4.0473, -8.2974, -1.8588, -9.2068, -2.3476, -5.8646,\n",
      "         -0.8031, -2.1930]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.8587892055511475\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3615, -5.4301, -4.2114, -7.6255, -1.8739, -9.2880, -2.1484, -6.2439,\n",
      "         -1.2401, -1.8173]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.817322015762329\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3152, -5.2305, -4.5300, -7.1810, -2.1601, -9.5215, -2.2155, -6.7471,\n",
      "         -2.0023, -1.0384]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.747100830078125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5080, -5.0930, -4.8628, -6.8194, -2.5404, -9.7698, -2.3946, -6.4905,\n",
      "         -2.8240, -0.6298]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.3945910930633545\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7720, -4.9023, -5.0963, -6.4230, -2.8690, -9.9218, -1.8139, -6.1889,\n",
      "         -3.5351, -0.5730]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.7720277309417725\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3621,  -4.6955,  -5.2702,  -6.0264,  -3.1656, -10.0179,  -1.3705,\n",
      "          -5.8781,  -4.1556,  -0.8855]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.3705213069915771\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4086,  -4.7449,  -5.6590,  -5.8997,  -3.6922, -10.3329,  -0.6514,\n",
      "          -5.8288,  -4.9542,  -1.6911]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.408625602722168\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0810,  -4.9771,  -6.1926,  -5.9687,  -4.3657, -10.7976,  -0.5694,\n",
      "          -5.9676,  -5.8594,  -2.7296]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.85939359664917\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8140,  -4.9718,  -6.4549,  -5.8131,  -4.7618, -10.9964,  -0.6924,\n",
      "          -5.8748,  -5.7347,  -3.4919]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.9718403816223145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6292,  -3.9330,  -6.4246,  -5.4077,  -4.8571, -10.9078,  -0.9033,\n",
      "          -5.5258,  -5.3571,  -3.9326]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.357134819030762\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5926,  -2.7540,  -6.1400,  -4.7874,  -4.6901, -10.5695,  -1.1321,\n",
      "          -4.9559,  -4.0445,  -4.0848]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.084822654724121\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8455,  -1.6254,  -5.7689,  -4.1191,  -4.4302, -10.1486,  -1.4584,\n",
      "          -4.3318,  -2.7589,  -3.3997]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.8454898595809937\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0329,  -1.1372,  -5.8127,  -3.9054,  -4.5806, -10.1453,  -2.2987,\n",
      "          -4.1553,  -2.0225,  -3.1824]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.032857060432434\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9556,  -1.1680,  -6.0766,  -3.9506,  -4.9458, -10.3646,  -3.3515,\n",
      "          -4.2304,  -1.6769,  -3.2387]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.23041296005249\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0327,  -1.3036,  -6.1831,  -3.8733,  -5.1471, -10.4293,  -4.1923,\n",
      "          -3.4284,  -1.3674,  -3.1847]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.032668948173523\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7729,  -1.7739,  -6.4186,  -3.9578,  -5.4708, -10.6257,  -5.0988,\n",
      "          -2.8687,  -1.4103,  -3.3040]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.7738726139068604\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8458,  -1.5274,  -6.6035,  -4.0201,  -5.7370, -10.7742,  -5.8911,\n",
      "          -2.3789,  -1.5963,  -3.4093]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.0201215744018555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0909,  -1.3412,  -6.6391,  -3.1938,  -5.8473, -10.7761,  -6.4747,\n",
      "          -1.8754,  -1.7778,  -3.3961]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.8754067420959473\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7088,  -1.5292,  -6.8258,  -2.6347,  -6.1023, -10.9315,  -7.1550,\n",
      "          -0.9443,  -2.2166,  -3.5619]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.155038833618164\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5150,  -1.9843,  -7.1132,  -2.3047,  -6.4522, -11.1899,  -7.1502,\n",
      "          -0.5156,  -2.8088,  -3.8502]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.8501639366149902\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1661,  -2.3667,  -7.2390,  -1.9505,  -6.6348, -11.2891,  -7.0129,\n",
      "          -0.4426,  -3.2519,  -3.2746]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.634774684906006\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5294,  -2.5299,  -7.0992,  -1.4868,  -5.8098, -11.1248,  -6.6363,\n",
      "          -0.6023,  -3.4252,  -2.5298]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.6023049354553223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0782,  -2.9389,  -7.1744,  -1.4430,  -5.2696, -11.1773,  -6.4985,\n",
      "          -0.6091,  -3.8052,  -2.1168]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.1167805194854736\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5487,  -3.3120,  -7.2065,  -1.5486,  -4.7509, -11.1885,  -6.3395,\n",
      "          -0.9841,  -4.1273,  -1.0806]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  11.188454627990723\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0782,  -3.7744,  -7.3342,  -1.9048,  -4.3884, -10.5366,  -6.2959,\n",
      "          -1.6981,  -4.5272,  -0.4891]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.527246952056885\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4622, -4.1112, -7.3523, -2.2423, -3.9738, -9.8523, -6.1606, -2.3799,\n",
      "         -4.0767, -0.2984]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.352339267730713\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4664, -4.0825, -6.2977, -2.2831, -3.2697, -8.8915, -5.6956, -2.7181,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -3.3386, -0.3119]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.082529544830322\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1924, -3.0158, -5.0685, -2.1171, -2.3828, -7.7455, -4.9986, -2.7909,\n",
      "         -2.4186, -0.5641]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.7455339431762695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9814, -2.1248, -3.9980, -2.0918, -1.6842, -5.9896, -4.4076, -2.9340,\n",
      "         -1.6862, -1.2270]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.6861554384231567\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2470, -1.8653, -3.4980, -2.6145, -1.6430, -4.8609, -4.3350, -3.5531,\n",
      "         -0.8915, -2.4830]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.335038185119629\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6359, -1.8973, -3.2157, -3.2873, -1.8947, -3.9964, -3.6898, -4.2778,\n",
      "         -0.6172, -3.8192]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.2872822284698486\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8809, -1.9342, -2.8828, -3.0459, -2.1247, -3.1240, -3.0194, -4.8329,\n",
      "         -0.6507, -4.9303]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.880861282348633\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2507, -1.9546, -2.4994, -2.7405, -2.2957, -2.2473, -2.3271, -5.2141,\n",
      "         -0.9312, -5.8113]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.21412992477417\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7151, -2.1106, -2.2419, -2.5429, -2.5522, -1.5662, -1.8036, -4.8430,\n",
      "         -1.4946, -6.6347]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.8036162853240967\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5196, -2.6251, -2.3680, -2.7057, -3.1212, -1.3922, -0.9999, -4.7950,\n",
      "         -2.4434, -7.6574]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.3679819107055664\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5006, -3.2936, -1.9716, -3.0526, -3.8153, -1.5737, -0.6961, -4.9070,\n",
      "         -3.5093, -8.7278]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.8153300285339355\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3760, -3.8086, -1.6003, -3.2856, -3.6012, -1.7792, -0.6737, -4.8978,\n",
      "         -4.3750, -9.5761]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.8086495399475098\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1025,  -3.3460,  -1.2426,  -3.3537,  -3.2580,  -1.9222,  -0.8575,\n",
      "          -4.7245,  -4.9930, -10.1695]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.2580039501190186\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7919,  -2.8803,  -1.0544,  -3.3655,  -2.1658,  -2.0861,  -1.2579,\n",
      "          -4.4989,  -5.4782, -10.6276]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.7919251918792725\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8533,  -2.5552,  -1.1896,  -3.4537,  -1.3177,  -2.3791,  -1.8779,\n",
      "          -4.3549,  -5.9689, -11.0910]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.555209159851074\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2465,  -1.7497,  -1.7293,  -3.7537,  -0.9479,  -2.9099,  -2.7447,\n",
      "          -4.4312,  -6.6090, -11.7046]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.9479081630706787\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1937,  -1.5751,  -2.7610,  -4.4586,  -0.5815,  -3.8460,  -3.9891,\n",
      "          -4.9254,  -7.6030, -12.6738]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.9254255294799805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1041,  -1.4542,  -3.6129,  -4.9789,  -0.5407,  -4.5820,  -5.0000,\n",
      "          -4.5081,  -8.3752, -13.4232]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.582008361816406\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8620,  -1.2752,  -4.1494,  -5.2025,  -0.6821,  -4.2410,  -5.6649,\n",
      "          -3.8902,  -8.8203, -13.8478]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  13.847773551940918\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5523,  -1.1246,  -4.4390,  -5.2032,  -0.9760,  -3.7399,  -6.0612,\n",
      "          -3.1442,  -9.0164, -13.3093]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.061241149902344\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3058,  -1.1172,  -4.5864,  -5.0859,  -1.3950,  -3.1847,  -5.5628,\n",
      "          -2.3825,  -9.0709, -12.7024]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.3950018882751465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3657,  -1.4471,  -4.8108,  -5.0694,  -1.3039,  -2.8006,  -5.2010,\n",
      "          -1.8499,  -9.2044, -12.2402]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.8006343841552734\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6153,  -1.9349,  -5.0284,  -5.0689,  -1.4304,  -1.7528,  -4.8889,\n",
      "          -1.4972,  -9.3342, -11.8335]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.7528167963027954\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3980,  -2.8986,  -5.6421,  -5.4864,  -2.1328,  -0.5994,  -5.0264,\n",
      "          -1.7599,  -9.8642, -11.8804]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.486350059509277\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4143,  -4.0540,  -6.4425,  -5.3409,  -3.0973,  -0.2229,  -5.4001,\n",
      "          -2.3701, -10.5866, -12.1677]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.442507743835449\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0119,  -4.7662,  -6.0930,  -4.8721,  -3.6574,  -0.1481,  -5.3984,\n",
      "          -2.6478, -10.8955, -12.0849]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.14812776446342468\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6810,  -5.5319,  -5.8978,  -4.5736,  -4.2986,  -0.0947,  -5.5180,\n",
      "          -3.0687, -11.2916, -12.1281]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.09474531561136246\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3741,  -6.3082,  -5.8078,  -4.3966,  -4.9696,  -0.0622,  -5.7124,\n",
      "          -3.5662, -11.7319, -12.2508]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.566208600997925\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3878,  -6.3950,  -5.1152,  -3.6330,  -4.9653,  -0.1275,  -5.2763,\n",
      "          -2.6753, -11.5148, -11.7476]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.387842655181885\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2631,  -6.0639,  -4.0856,  -2.5554,  -4.5561,  -0.4351,  -4.4768,\n",
      "          -1.5141, -10.9088, -10.8841]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.43509641289711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6563,  -6.1634,  -3.5665,  -2.0407,  -4.5911,  -0.8427,  -4.1611,\n",
      "          -1.0285, -10.7590, -10.5023]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.163437366485596\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0767,  -5.4302,  -3.0676,  -1.6255,  -4.5781,  -1.4801,  -3.8363,\n",
      "          -0.8060, -10.5719, -10.1064]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.076749324798584\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8801,  -4.7911,  -2.6703,  -1.4215,  -4.5917,  -2.2425,  -3.5775,\n",
      "          -0.9566, -10.4214,  -9.7679]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.421428680419922\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0057, -4.3143, -2.4553, -1.5164, -4.7036, -3.1008, -3.4572, -1.4707,\n",
      "         -9.6532, -9.5552]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  9.55518627166748\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5699, -3.9802, -2.4097, -1.8564, -4.8961, -3.9925, -3.4573, -2.1899,\n",
      "         -9.0466, -8.7318]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.5698970556259155\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.2418, -4.0739, -2.8143, -2.6632, -5.4550, -5.1893, -3.8606, -3.3010,\n",
      "         -8.8804, -8.3705]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.301004648208618\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.2034, -3.8569, -2.9082, -3.1292, -5.6469, -5.9567, -3.9248, -3.2680,\n",
      "         -8.4164, -7.7308]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.416446685791016\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.2998, -3.2177, -2.5725, -3.1225, -5.3621, -6.1895, -3.5372, -2.8066,\n",
      "         -6.8173, -6.6950]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2.806553840637207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7554, -2.5072, -2.1604, -2.9847, -4.9433, -6.2348, -3.0437, -1.5282,\n",
      "         -5.2122, -5.5973]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.212221622467041\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7672, -2.1934, -2.1368, -3.1626, -4.8343, -6.5399, -2.8975, -0.8011,\n",
      "         -3.3164, -4.8744]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.1367948055267334\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1092, -2.3047, -1.7769, -3.6631, -5.0496, -7.1232, -3.1142, -0.7871,\n",
      "         -1.9430, -4.5365]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.536502838134766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5014, -2.6337, -1.7281, -4.2851, -5.3996, -7.8005, -3.4937, -1.2635,\n",
      "         -0.9613, -3.6757]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.728127360343933\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0478, -3.2704, -1.3690, -5.1406, -6.0029, -8.6955, -4.1427, -2.1868,\n",
      "         -0.6386, -3.2035]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.6386319398880005\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.7948, -4.2261, -1.5845, -6.2685, -6.9009, -9.8545, -5.0919, -3.4544,\n",
      "         -0.3612, -3.1605]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.09185266494751\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.0824,  -4.8121,  -1.6427,  -6.9996,  -7.4243, -10.6121,  -4.9255,\n",
      "          -4.3334,  -0.3292,  -2.8662]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.925529479980469\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.8860,  -4.9902,  -1.4807,  -7.3028,  -7.5402, -10.9386,  -3.6911,\n",
      "          -4.7787,  -0.4629,  -2.2863]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.778714656829834\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.4235,  -4.9698,  -1.3151,  -7.3902,  -7.4589, -11.0464,  -2.4119,\n",
      "          -4.2583,  -0.8492,  -1.6511]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.3151458501815796\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.2047,  -5.2539,  -0.9291,  -7.7666,  -7.6832, -11.4407,  -1.6232,\n",
      "          -4.0974,  -1.8011,  -1.5143]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.8010756969451904\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.0301,  -5.6357,  -0.9919,  -8.2277,  -8.0075, -11.9176,  -1.1806,\n",
      "          -4.0866,  -2.1798,  -1.6713]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.635721206665039\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.6356,  -5.0697,  -1.1817,  -8.5054,  -8.1620, -12.2094,  -0.8710,\n",
      "          -3.9517,  -2.4642,  -1.8103]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.9517199993133545\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.0284,  -4.4127,  -1.4242,  -8.6033,  -8.1490, -12.3198,  -0.7487,\n",
      "          -2.9545,  -2.6290,  -1.9008]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.412661552429199\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.2635,  -2.9423,  -1.6995,  -8.5729,  -8.0188, -12.3005,  -0.8685,\n",
      "          -1.9763,  -2.7104,  -1.9713]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  13.263520240783691\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.8180,  -1.7279,  -2.1498,  -8.6145,  -7.9707, -12.3519,  -1.3541,\n",
      "          -1.2668,  -2.9003,  -2.2039]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.203906297683716\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.6942,  -1.0491,  -2.9176,  -8.9294,  -8.2049, -12.6756,  -2.2588,\n",
      "          -1.1137,  -3.3882,  -2.0505]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.3881630897521973\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.6173,  -0.7434,  -3.6832,  -9.2477,  -8.4506, -13.0017,  -3.1851,\n",
      "          -1.2534,  -3.1692,  -2.0395]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.450640678405762\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.3702,  -0.6578,  -4.2131,  -9.3565,  -7.7518, -13.1174,  -3.8718,\n",
      "          -1.4125,  -2.8243,  -1.9453]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.9452742338180542\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.0835,  -0.9161,  -4.6369,  -9.3904,  -7.0587, -13.1574,  -4.4413,\n",
      "          -1.6716,  -2.4920,  -1.1815]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.4919934272766113\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.9042,  -1.5359,  -5.1044,  -9.4998,  -6.5140, -13.2723,  -5.0417,\n",
      "          -2.1228,  -1.6168,  -0.7931]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.1227970123291016\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.8471,  -2.3643,  -5.6342,  -9.7027,  -6.1291, -13.4801,  -5.6914,\n",
      "          -1.9826,  -1.0752,  -0.8726]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.702689170837402\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.7050,  -3.0922,  -6.0233,  -9.0159,  -5.6934, -13.5766,  -6.1884,\n",
      "          -1.8675,  -0.7412,  -1.1533]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.092197895050049\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.4305,  -2.8643,  -6.2288,  -8.2510,  -5.1570, -13.5169,  -6.4907,\n",
      "          -1.7313,  -0.6347,  -1.4857]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.2287983894348145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.9591,  -2.4788,  -5.4590,  -7.3381,  -4.4541, -13.2389,  -6.5399,\n",
      "          -1.5153,  -0.6933,  -1.7232]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.338130950927734\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.3505,  -2.0120,  -4.5847,  -5.5586,  -3.6456, -12.8043,  -6.4010,\n",
      "          -1.2989,  -0.9185,  -1.8808]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.645604372024536\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.7750,  -1.6672,  -3.7775,  -3.9318,  -2.1684, -12.3856,  -6.2498,\n",
      "          -1.2782,  -1.3784,  -2.1048]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  12.385616302490234\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.4505,  -1.6957,  -3.2611,  -2.6759,  -1.1170, -11.4430,  -6.3087,\n",
      "          -1.6591,  -2.1659,  -2.5877]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.2610716819763184\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.4652,  -2.1696,  -2.4022,  -1.9053,  -0.7203, -10.9010,  -6.6699,\n",
      "          -2.4494,  -3.2637,  -3.3833]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.26371431350708\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.5617,  -2.7675,  -1.7782,  -1.4104,  -0.8080, -10.4962,  -7.0793,\n",
      "          -3.3082,  -3.6472,  -4.2074]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.8080275058746338\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.8919,  -3.5977,  -1.5830,  -1.3981,  -0.7193, -10.3751,  -7.6918,\n",
      "          -4.3519,  -4.2544,  -5.2034]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.69182014465332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.9823,  -4.1593,  -1.3504,  -1.3723,  -0.7939, -10.0589,  -7.2966,\n",
      "          -5.0942,  -4.6042,  -5.8972]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  10.058930397033691\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.8431, -4.4565, -1.1097, -1.3259, -0.9756, -8.7979, -6.7205, -5.5465,\n",
      "         -4.7058, -6.3033]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.7057881355285645\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.5205, -4.5359, -0.9367, -1.2935, -1.2211, -7.4653, -6.0056, -5.7595,\n",
      "         -3.8948, -6.4731]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.005560874938965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.0431, -4.4285, -0.8801, -1.2907, -1.4735, -6.0787, -4.4407, -5.7665,\n",
      "         -2.9919, -6.4400]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  9.043072700500488\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.7592, -4.2157, -1.0065, -1.3770, -1.7452, -4.7066, -2.9150, -5.6499,\n",
      "         -2.0894, -6.2861]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.286107063293457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6815, -4.1136, -1.4650, -1.7290, -2.1972, -3.5560, -1.6592, -5.6255,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -1.4428, -5.5067]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.6592445373535156\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3254, -4.6477, -2.6600, -2.7976, -3.3001, -3.1550, -0.5477, -6.2196,\n",
      "         -1.6424, -5.4213]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.4212565422058105\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2714, -5.4014, -4.0524, -4.0726, -4.5859, -3.0916, -0.2393, -7.0214,\n",
      "         -2.2253, -4.8972]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.23931749165058136\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5248, -6.3842, -5.6196, -5.5346, -6.0519, -3.3698, -0.1058, -8.0447,\n",
      "         -3.1279, -4.7314]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.3842058181762695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2149, -5.9588, -6.4943, -6.3151, -6.8346, -3.1073, -0.1094, -8.4272,\n",
      "         -3.4326, -4.0492]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.1072912216186523\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4981, -5.1385, -6.8439, -6.5800, -7.1010, -1.7091, -0.3300, -8.3326,\n",
      "         -3.2910, -3.0083]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.58004093170166\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9433, -4.4920, -7.2470, -6.1275, -7.4290, -0.6750, -1.1406, -8.3352,\n",
      "         -3.2775, -2.1941]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.246993541717529\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7015, -4.1711, -7.1311, -5.9744, -7.9775, -0.3833, -2.3563, -8.5904,\n",
      "         -3.5450, -1.7937]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.974358081817627\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3059, -3.7096, -6.8429, -4.8802, -8.2871, -0.4525, -3.3358, -8.6358,\n",
      "         -3.6220, -1.3682]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.305930137634277\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0292, -3.1113, -6.3823, -3.6992, -8.3644, -0.7934, -4.0420, -8.4750,\n",
      "         -3.5087, -0.9665]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.042045593261719\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9129, -2.6050, -5.9669, -2.6529, -8.4321, -1.4396, -3.9562, -8.3285,\n",
      "         -3.4261, -0.8763]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.8763176202774048\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4209, -2.6117, -6.0001, -2.1708, -8.8987, -2.6057, -4.2982, -8.6020,\n",
      "         -3.7804, -0.7810]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.4209380149841309\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6852, -2.9334, -6.2905, -2.0841, -9.5776, -3.9704, -4.8749, -9.1073,\n",
      "         -4.3744, -1.2829]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.933371067047119\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4346,  -2.5361,  -6.5971,  -2.1463, -10.2327,  -5.2571,  -5.4434,\n",
      "          -9.6060,  -4.9621,  -1.9777]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.23273754119873\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4454, -2.0038, -6.6383, -2.0573, -9.8422, -6.1838, -5.7226, -9.8193,\n",
      "         -5.2604, -2.4669]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.842232704162598\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6724, -1.3801, -6.4278, -1.8280, -8.5032, -6.7714, -5.7279, -9.7628,\n",
      "         -5.2843, -2.7199]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.4278435707092285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1290, -0.8948, -5.3913, -1.6282, -7.1793, -7.1830, -5.6168, -9.5938,\n",
      "         -5.1911, -2.8768]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.89476478099823\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1404, -0.3671, -4.8269, -1.9664, -6.3533, -7.9197, -5.8849, -9.8071,\n",
      "         -5.4767, -3.4241]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.807085037231445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9506, -0.2413, -4.1385, -2.1939, -5.4249, -8.3974, -5.9424, -9.0670,\n",
      "         -5.5510, -3.7545]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.9506499767303467\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6011, -0.3427, -3.1408, -2.0960, -4.2026, -8.4383, -5.6066, -8.0111,\n",
      "         -5.2311, -3.6792]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.67924427986145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1288, -0.7663, -2.0626, -1.8921, -2.9017, -8.2637, -5.0954, -6.8491,\n",
      "         -4.7354, -2.6990]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.901686429977417\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1217, -1.8354, -1.5168, -2.1579, -1.3649, -8.4388, -4.9717, -6.1356,\n",
      "         -4.6275, -2.1966]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.627455234527588\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6670, -3.3850, -1.6507, -2.9520, -0.6352, -9.0612, -5.3300, -5.9594,\n",
      "         -4.2846, -2.2888]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.3850131034851074\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2400, -4.0684, -1.9435, -3.7393, -0.4030, -9.6534, -5.6878, -5.8343,\n",
      "         -4.0174, -2.4764]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.068446159362793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4971, -3.6463, -2.0248, -4.1795, -0.4013, -9.8994, -5.7252, -5.4365,\n",
      "         -3.5025, -2.4185]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.179516792297363\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4601, -2.9954, -1.9042, -3.5183, -0.6032, -9.8304, -5.4706, -4.7910,\n",
      "         -2.7698, -2.1398]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.791029453277588\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3616, -2.3595, -1.8168, -2.8580, -1.0999, -9.6803, -5.1566, -3.3833,\n",
      "         -2.0672, -1.8857]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.359503746032715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5651, -1.3663, -2.1243, -2.5749, -2.0592, -9.8121, -5.1449, -2.4079,\n",
      "         -1.7923, -2.0330]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.4078729152679443\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1650,  -1.0622,  -2.8849,  -2.7754,  -3.4132, -10.3269,  -5.5348,\n",
      "          -1.2514,  -2.0607,  -2.6561]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.4131667613983154\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.9330,  -1.2681,  -3.8274,  -3.2210,  -4.1342, -11.0070,  -6.1053,\n",
      "          -0.6400,  -2.6105,  -3.4844]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.220984935760498\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5691,  -1.6068,  -4.6314,  -2.8171,  -4.7345, -11.5588,  -6.5600,\n",
      "          -0.4221,  -3.0978,  -4.1916]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.42210453748703003\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.3981,  -2.3177,  -5.6158,  -2.7532,  -5.5349, -12.3090,  -7.2238,\n",
      "          -0.2234,  -3.8224,  -5.0927]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.2238383293151855\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.7282,  -2.6153,  -6.0874,  -2.3276,  -5.8410, -12.5670,  -6.6702,\n",
      "          -0.2225,  -4.0731,  -5.4910]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.6152889728546143\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6858,  -1.8392,  -6.1733,  -1.6797,  -5.7783, -12.4588,  -5.8322,\n",
      "          -0.4742,  -3.9707,  -5.5121]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.832170486450195\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.5754,  -1.1878,  -6.1790,  -1.1680,  -5.6510, -12.2883,  -4.2769,\n",
      "          -1.0875,  -3.8189,  -5.4610]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.0874730348587036\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6853,  -1.0411,  -6.3939,  -1.1573,  -5.7472, -12.3430,  -3.0949,\n",
      "          -1.3568,  -3.9063,  -5.6262]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.393860340118408\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6564,  -1.0482,  -5.7250,  -1.2632,  -5.7074, -12.2635,  -1.9350,\n",
      "          -1.6607,  -3.8708,  -5.6489]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.656419277191162\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.9076,  -1.3254,  -5.1300,  -1.5830,  -5.6789, -12.1967,  -1.0013,\n",
      "          -2.0795,  -3.8587,  -5.6767]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.583017349243164\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4393,  -1.9806,  -4.8026,  -1.4578,  -5.8598, -12.3407,  -0.6343,\n",
      "          -2.7532,  -4.0671,  -5.9083]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.7531661987304688\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.9067,  -2.5613,  -4.3998,  -1.4115,  -5.9108, -12.3563,  -0.5787,\n",
      "          -2.5536,  -4.1531,  -6.0047]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.153107166290283\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2048,  -2.9150,  -3.8184,  -1.3311,  -5.7309, -12.1426,  -0.7111,\n",
      "          -2.2035,  -3.2932,  -5.8655]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.203503370285034\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5979,  -3.2890,  -3.3252,  -1.4780,  -5.5856, -11.9644,  -1.2035,\n",
      "          -1.2486,  -2.5600,  -5.7566]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.325221538543701\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2588,  -3.8414,  -2.3625,  -1.9745,  -5.6449, -11.9913,  -2.0536,\n",
      "          -0.7873,  -2.1428,  -5.8481]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.8414230346679688\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0561,  -3.6700,  -1.6393,  -2.6039,  -5.7755, -12.0902,  -2.9875,\n",
      "          -0.7815,  -1.9265,  -6.0072]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.6393253803253174\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1761,  -3.8030,  -0.6682,  -3.4963,  -6.1635, -12.4473,  -4.1335,\n",
      "          -1.3809,  -2.1049,  -6.4204]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.133490085601807\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4491,  -4.0742,  -0.3045,  -4.4578,  -6.6489, -12.9033,  -4.5788,\n",
      "          -2.2397,  -2.4880,  -6.9281]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.488036870956421\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5025,  -4.1156,  -0.3016,  -5.1169,  -6.8712, -13.0983,  -4.7716,\n",
      "          -2.8757,  -1.9572,  -7.1702]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.115571975708008\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2736,  -3.1107,  -0.5396,  -5.4160,  -6.7732, -12.9748,  -4.6524,\n",
      "          -3.1909,  -1.2820,  -7.0898]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.6523756980896\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0272,  -2.1716,  -1.1102,  -5.6209,  -6.6178, -12.7956,  -3.7559,\n",
      "          -3.4369,  -0.8061,  -6.9500]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.617751121520996\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8781,  -1.4495,  -1.9009,  -5.8453,  -5.7762, -12.6714,  -3.0029,\n",
      "          -3.7194,  -0.7367,  -6.8621]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.7366861701011658\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0987,  -1.2907,  -3.0356,  -6.3635,  -5.3343, -12.8734,  -2.6747,\n",
      "          -4.3054,  -0.6125,  -7.0973]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.097345352172852\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1393,  -1.1649,  -3.9011,  -6.6402,  -4.7489, -12.8641,  -2.2384,\n",
      "          -4.6518,  -0.6998,  -6.3923]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.1649090051651\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3301,  -0.6542,  -4.8177,  -7.0128,  -4.3506, -12.9782,  -2.0457,\n",
      "          -5.0932,  -1.2578,  -5.8812]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.2578470706939697\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5709,  -0.6304,  -5.6916,  -7.3918,  -4.0443, -13.1236,  -2.0092,\n",
      "          -5.5379,  -1.2884,  -5.4657]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  13.123579978942871\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5408,  -0.7434,  -6.2135,  -7.4660,  -3.5139, -12.2183,  -1.8068,\n",
      "          -5.6738,  -1.2464,  -4.8271]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.7434124946594238\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6756,  -0.5898,  -6.8254,  -7.6738,  -3.1989, -11.5436,  -1.8849,\n",
      "          -5.9391,  -1.5555,  -4.3984]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.1989035606384277\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6366,  -0.6906,  -7.1984,  -7.6823,  -2.0282, -10.7573,  -1.8874,\n",
      "          -6.0011,  -1.8067,  -3.8425]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.0011372566223145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5963,  -1.1339,  -7.5100,  -7.6657,  -1.0468, -10.0245,  -1.9755,\n",
      "          -5.2967,  -2.1261,  -3.3328]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.133924961090088\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8471, -1.2890, -8.0580, -7.9181, -0.6901, -9.6317, -2.4233, -4.9330,\n",
      "         -2.7665, -3.1668]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.631715774536133\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9094, -1.4566, -8.3725, -7.9664, -0.5610, -8.3337, -2.7121, -4.4317,\n",
      "         -3.2091, -2.8689]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.372496604919434\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7237, -1.5262, -7.6682, -7.7536, -0.6097, -6.9085, -2.7641, -3.7324,\n",
      "         -3.3801, -2.3854]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.7324042320251465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4301, -1.6082, -6.8901, -7.4181, -0.9101, -5.4817, -2.7130, -2.2423,\n",
      "         -3.4145, -1.8730]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.430088996887207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6225, -2.0007, -6.3583, -7.2846, -1.6453, -4.3682, -2.8835, -1.1468,\n",
      "         -3.6371, -1.6919]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.0007145404815674\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2705, -2.0249, -6.2025, -7.4866, -2.7714, -3.6971, -3.3998, -0.7160,\n",
      "         -4.1784, -1.9851]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.0248899459838867\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1023, -1.4699, -6.1365, -7.7418, -3.9045, -3.1847, -3.9621, -0.7607,\n",
      "         -4.7496, -2.4222]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.422227382659912\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0139, -1.1156, -6.0518, -7.9451, -4.9128, -2.7283, -4.4555, -1.1177,\n",
      "         -5.2434, -2.1244]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.945085525512695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9534, -0.9632, -5.8982, -7.2673, -5.7471, -2.2886, -4.8293, -1.6003,\n",
      "         -5.6128, -1.8642]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.6003152132034302\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0303, -1.1389, -5.7888, -6.6844, -6.5277, -1.9977, -5.1986, -1.4754,\n",
      "         -5.9750, -1.7699]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.1388568878173828\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3065, -0.8988, -5.8029, -6.2710, -7.3419, -1.9506, -5.6456, -1.6411,\n",
      "         -6.4133, -1.9197]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.6411120891571045\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6322, -0.9907, -5.8214, -5.9036, -8.0792, -2.0214, -6.0542, -1.2036,\n",
      "         -6.8127, -2.1650]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.6321654319763184\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1687, -1.2767, -5.7657, -5.5006, -8.6688, -2.1129, -6.3494, -0.9552,\n",
      "         -7.0987, -2.3953]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.1687397956848145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1544, -1.7929, -5.7681, -5.1910, -9.2501, -2.3387, -6.6668, -1.0635,\n",
      "         -7.4070, -2.7194]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.250080108642578\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5595, -2.4694, -5.8597, -5.0038, -9.1203, -2.7036, -7.0406, -1.5009,\n",
      "         -7.7722, -3.1466]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.003833770751953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.3466, -3.0453, -5.8478, -3.9646, -8.9071, -2.9874, -7.2813, -1.9614,\n",
      "         -8.0049, -3.4662]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.98744535446167\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4203, -3.3476, -5.5872, -2.7918, -8.4633, -2.2596, -7.2467, -2.2273,\n",
      "         -7.9627, -3.5249]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.524881601333618\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8622, -3.5426, -5.2518, -1.6801, -7.9602, -1.5811, -7.1125, -2.4420,\n",
      "         -7.8215, -2.7657]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.821468830108643\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7415, -3.9137, -5.1275, -0.9987, -7.6813, -1.3024, -7.1661, -2.8730,\n",
      "         -7.1451, -2.3019]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.681336879730225\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7245, -4.3261, -5.0831, -0.7368, -6.7572, -1.3242, -7.2782, -3.3658,\n",
      "         -6.6000, -2.0205]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.757224082946777\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5015, -4.5514, -4.8918, -0.7192, -5.0387, -1.3928, -7.2236, -3.6790,\n",
      "         -5.9541, -1.7080]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.89180326461792\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0460, -4.5850, -3.8144, -0.9065, -3.3188, -1.4687, -6.9979, -3.8023,\n",
      "         -5.1973, -1.3818]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.3188390731811523\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6995, -4.7732, -3.0107, -1.5405, -1.2192, -1.8647, -6.9456, -4.0801,\n",
      "         -4.6701, -1.4219]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.0106916427612305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0889, -5.7435, -2.3881, -3.0730, -0.3401, -3.1351, -7.6937, -5.1370,\n",
      "         -4.9966, -2.4286]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.3401144742965698\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.1105, -7.3884, -2.6634, -5.2578, -0.1065, -5.0813, -9.1364, -6.8618,\n",
      "         -6.0642, -4.1683]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.388362884521484\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.4700, -7.6589, -2.5013, -6.7682, -0.0968, -6.3775, -9.9744, -7.9547,\n",
      "         -6.5662, -5.2850]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.5013389587402344\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.2793,  -7.4881,  -1.2732,  -7.7142,  -0.3371,  -7.1312, -10.3143,\n",
      "          -8.5241,  -6.6044,  -5.8795]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.131228923797607\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.0436,  -7.3701,  -0.4076,  -8.6019,  -1.1084,  -7.0750, -10.6558,\n",
      "          -9.0725,  -6.6752,  -6.4523]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.4523210525512695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.7572,  -7.2897,  -0.1406,  -9.4268,  -2.0683,  -7.0503, -10.9887,\n",
      "          -9.5917,  -6.7653,  -6.2640]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  10.988689422607422\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.9534,  -6.7715,  -0.0875,  -9.7232,  -2.5783,  -6.5825, -10.1031,\n",
      "          -9.6130,  -6.4009,  -5.6496]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.578320264816284\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.6212,  -5.7969,  -0.1950,  -9.4814,  -1.8558,  -5.6534,  -8.7969,\n",
      "          -9.1234,  -5.5651,  -4.5900]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.589959144592285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.0455,  -4.6449,  -0.6089,  -8.9870,  -1.0420,  -4.5429,  -7.3442,\n",
      "          -8.4059,  -4.5387,  -2.6402]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.644933223724365\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.8112,  -3.1516,  -1.6577,  -8.8261,  -0.8495,  -3.8353,  -6.3207,\n",
      "          -8.0441,  -3.9064,  -1.2206]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.320672988891602\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.0294,  -2.2681,  -3.1691,  -9.1105,  -1.4156,  -3.6439,  -5.0942,\n",
      "          -8.1478,  -3.7808,  -0.5867]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.169052839279175\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.3091,  -1.6333,  -3.9170,  -9.4498,  -2.1846,  -3.5749,  -4.0775,\n",
      "          -8.3245,  -3.7675,  -0.5044]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.916987895965576\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.4384,  -1.0856,  -3.7609,  -9.6328,  -2.8362,  -3.4119,  -3.0519,\n",
      "          -8.3613,  -3.6498,  -0.7469]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.632811546325684\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.4905,  -0.7814,  -3.5728,  -8.9499,  -3.4013,  -3.2263,  -2.0991,\n",
      "          -8.3302,  -3.4985,  -1.2451]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.7813745141029358\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.9081,  -0.4722,  -3.7943,  -8.7057,  -4.3050,  -3.4605,  -1.7023,\n",
      "          -8.6731,  -3.7549,  -2.2733]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.705689430236816\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.1210,  -0.4981,  -3.8468,  -7.5454,  -4.9655,  -3.5326,  -1.3168,\n",
      "          -8.8189,  -3.8399,  -3.1110]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.49805641174316406\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.4946,  -0.4098,  -4.0914,  -6.6828,  -5.7471,  -3.8019,  -1.3496,\n",
      "          -9.1321,  -4.1139,  -4.0795]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  12.494575500488281\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.7388,  -0.4697,  -3.9667,  -5.5502,  -6.0964,  -3.7049,  -1.2140,\n",
      "          -9.0573,  -4.0157,  -4.6071]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.607078552246094\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.7477,  -0.6792,  -3.5576,  -4.2228,  -6.1020,  -3.3260,  -1.0010,\n",
      "          -8.6796,  -3.6299,  -4.0511]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.679567337036133\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.6721, -1.0619, -3.0265, -2.8558, -5.9255, -2.8294, -0.8976, -7.4170,\n",
      "         -3.1187, -3.3798]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.925486087799072\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.7132, -1.6735, -2.5929, -1.6794, -5.0501, -2.4377, -1.1150, -6.2902,\n",
      "         -2.7003, -2.8097]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.700317144393921\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.1128, -2.6269, -2.5194, -1.0290, -4.5295, -2.4156, -1.8158, -5.5398,\n",
      "         -1.9056, -2.6030]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.8158166408538818\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.7746, -3.7415, -2.7137, -0.9251, -4.2708, -2.6673, -2.0293, -5.0693,\n",
      "         -1.5009, -2.6730]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.069326400756836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.3696, -4.6621, -2.8357, -1.0408, -3.9472, -2.8471, -2.2177, -3.8138,\n",
      "         -1.1985, -2.6855]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.369636535644531\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1717, -5.3978, -2.8875, -1.3205, -3.5695, -2.9537, -2.3672, -2.5991,\n",
      "         -1.0460, -2.6460]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.953652858734131\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1280, -6.0966, -3.0078, -1.8138, -3.2830, -2.3480, -2.6043, -1.5935,\n",
      "         -1.1987, -2.6949]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.128020763397217\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5852, -6.8492, -3.2733, -2.5071, -3.1739, -1.9983, -2.9939, -0.9596,\n",
      "         -1.6777, -2.9098]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.1738991737365723\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3411, -7.6524, -3.6647, -3.3200, -2.5050, -1.9132, -3.5065, -0.7969,\n",
      "         -2.3703, -3.2678]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.341123104095459\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8666, -8.6777, -4.3373, -4.3819, -2.2637, -2.2527, -4.2920, -1.2850,\n",
      "         -3.3640, -3.9197]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.2849798202514648\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3797, -10.1338,  -5.4851,  -5.8805,  -2.6547,  -3.1726,  -5.5421,\n",
      "          -1.7240,  -4.8167,  -5.0538]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.0538153648376465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2475, -11.2499,  -6.3267,  -7.0371,  -2.8629,  -3.8384,  -6.4757,\n",
      "          -2.0558,  -5.9357,  -5.1571]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.862889051437378\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3375, -11.8941,  -6.7249,  -7.7184,  -2.0071,  -4.0937,  -6.9565,\n",
      "          -2.0881,  -6.5843,  -4.8934]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.718430995941162\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7019, -12.2386,  -6.8489,  -7.3142,  -1.0986,  -4.1011,  -7.1548,\n",
      "          -1.9732,  -6.9340,  -4.4260]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.7018557786941528\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9138, -12.7995,  -7.2118,  -7.2013,  -0.7733,  -4.3712,  -7.5844,\n",
      "          -2.2229,  -7.5001,  -4.2644]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.2229273319244385\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2734, -13.1820,  -7.4167,  -6.9778,  -0.6930,  -4.5018,  -7.8492,\n",
      "          -1.6688,  -7.8878,  -4.0066]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.273378849029541\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0946, -13.5466,  -7.6218,  -6.7974,  -1.0035,  -4.6481,  -8.1081,\n",
      "          -1.3288,  -8.2573,  -3.8079]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.25727653503418\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0181, -13.7167,  -7.6485,  -6.4775,  -1.3903,  -4.6290,  -8.1831,\n",
      "          -1.0595,  -7.6999,  -3.4868]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.648533344268799\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0375, -13.6961,  -6.7738,  -6.0171,  -1.7455,  -4.4458,  -8.0772,\n",
      "          -0.8988,  -7.0247,  -3.0464]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.8987768292427063\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4934, -13.8592,  -6.1686,  -5.7859,  -2.3733,  -4.4715,  -8.1637,\n",
      "          -0.4992,  -6.5989,  -2.8660]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  13.859152793884277\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8652, -13.0544,  -5.4237,  -5.3787,  -2.8049,  -4.3021,  -8.0403,\n",
      "          -0.3846,  -6.0150,  -2.5438]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.543792247772217\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1344, -12.1518,  -4.5782,  -4.8376,  -3.0594,  -3.9821,  -7.7514,\n",
      "          -0.6029,  -5.3131,  -1.4052]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.0593533515930176\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5595, -11.4360,  -3.9213,  -4.4537,  -2.6936,  -3.8055,  -7.5886,\n",
      "          -1.2972,  -4.7816,  -0.6556]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.781649589538574\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0599, -10.8528,  -3.4055,  -4.1784,  -2.4745,  -3.7252,  -7.5037,\n",
      "          -2.1839,  -3.6413,  -0.4202]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  10.852843284606934\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3756, -9.4128, -2.7962, -3.7736, -2.1694, -3.5028, -7.2588, -2.8960,\n",
      "         -2.4647, -0.5169]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.8960347175598145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6622, -8.0936, -2.2695, -3.4046, -1.9548, -3.3035, -7.0162, -2.8201,\n",
      "         -1.4449, -1.0138]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.303485631942749\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1256, -7.0927, -2.0572, -3.2851, -2.0510, -2.5607, -6.9851, -2.9820,\n",
      "         -0.8858, -1.9111]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.560715436935425\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7503, -6.3876, -2.1548, -3.4027, -2.4266, -1.3742, -7.1535, -3.3606,\n",
      "         -0.8798, -3.0220]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.4026598930358887\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4877, -5.9227, -2.4957, -2.9201, -2.9974, -0.6710, -7.4743, -3.8956,\n",
      "         -1.3462, -4.2263]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.9974498748779297\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1635, -5.5147, -2.8715, -2.5365, -2.8319, -0.4439, -7.7724, -4.4009,\n",
      "         -1.9651, -5.3301]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.9651415348052979\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6171, -4.9939, -3.0947, -2.0967, -2.5689, -0.5803, -7.8846, -4.7084,\n",
      "         -1.7380, -6.1711]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.737974762916565\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0532, -4.5569, -3.3555, -1.8238, -2.4145, -1.1626, -8.0127, -5.0188,\n",
      "         -0.9614, -6.9567]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.3554844856262207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5266, -4.2512, -2.9679, -1.7848, -2.4201, -2.0087, -8.2083, -5.3831,\n",
      "         -0.6207, -7.7447]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.78477144241333\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.0110, -4.0443, -2.7139, -1.1569, -2.5474, -2.9319, -8.4423, -5.7722,\n",
      "         -0.7629, -8.5123]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.713939666748047\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.4478, -3.8716, -1.8098, -0.8383, -2.7192, -3.8049, -8.6536, -6.1253,\n",
      "         -1.2304, -9.2041]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.125295162200928\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.8264, -3.7169, -1.0997, -0.8751, -2.9069, -4.5934, -8.8292, -5.6970,\n",
      "         -1.8487, -9.8122]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.8751120567321777\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.4248,  -3.8534,  -0.9597,  -0.7103,  -3.3730,  -5.5687,  -9.2448,\n",
      "          -5.5712,  -2.7774, -10.6173]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.568706035614014\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.7295,  -3.7579,  -0.8777,  -0.7119,  -3.5833,  -5.4414,  -9.3849,\n",
      "          -5.2265,  -3.4246, -11.1080]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.226504325866699\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.7169,  -3.4025,  -0.8185,  -0.8093,  -3.5059,  -5.0432,  -9.2240,\n",
      "          -3.9042,  -3.7440, -11.2628]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.9041876792907715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.5593,  -2.9613,  -0.9388,  -1.0977,  -3.3117,  -4.5432,  -8.9330,\n",
      "          -1.8578,  -3.9026, -11.2559]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.543216705322266\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.8304,  -3.0159,  -1.7435,  -2.0303,  -3.5763,  -3.7455,  -9.0840,\n",
      "          -0.5420,  -4.4731, -11.6627]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.745455265045166\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.5095,  -3.5370,  -3.0299,  -3.4073,  -4.2699,  -2.7171,  -9.6549,\n",
      "          -0.2170,  -5.4300, -12.4640]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.0298550128936768\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.9288,  -3.8360,  -3.3053,  -4.4810,  -4.7124,  -1.6497,  -9.9770,\n",
      "          -0.3188,  -6.1027, -12.9933]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  12.993276596069336\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.1791,  -3.9942,  -3.4525,  -5.3293,  -4.9901,  -0.7088, -10.1396,\n",
      "          -0.8106,  -6.5827, -12.6125]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.5827460289001465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.4492,  -4.1953,  -3.6528,  -6.1417,  -5.2899,  -0.2848, -10.3309,\n",
      "          -1.6202,  -6.3325, -12.3144]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  10.330892562866211\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.3945,  -4.0898,  -3.5539,  -6.5769,  -5.2655,  -0.1820,  -9.4553,\n",
      "          -2.1946,  -5.8104, -11.7480]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  11.74797534942627\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.8432,  -3.5055,  -2.9836,  -6.4679,  -4.7453,  -0.2236,  -8.1649,\n",
      "          -2.2905,  -4.8405, -10.0101]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  10.01010513305664\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.9506, -2.6058, -2.1106, -5.9747, -3.8871, -0.4720, -6.6070, -2.0542,\n",
      "         -3.5767, -7.3283]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.6058366298675537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.3115, -1.2619, -1.5769, -5.6973, -3.2939, -1.3328, -5.3697, -2.0990,\n",
      "         -2.6237, -5.0784]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.5769140720367432\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.3551, -0.8845, -1.1406, -6.0690, -3.4058, -2.9271, -4.8782, -2.8473,\n",
      "         -2.4374, -3.6761]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.069037914276123\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.4626, -0.9243, -1.0475, -5.6921, -3.5990, -4.4717, -4.5094, -3.6315,\n",
      "         -2.4015, -2.4999]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  9.462574005126953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.7730, -1.2064, -1.1650, -5.3025, -3.7402, -5.8184, -4.1329, -4.3040,\n",
      "         -2.3826, -1.4477]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.206445336341858\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.3947, -1.1753, -1.7392, -5.1981, -4.1274, -7.2759, -4.0485, -5.1621,\n",
      "         -2.6755, -0.9138]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.7391905784606934\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.0696, -1.3951, -1.6752, -5.1239, -4.5032, -8.6042, -4.0011, -5.9543,\n",
      "         -3.0050, -0.7403]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.604228019714355\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5622, -1.5646, -1.5381, -4.8468, -4.6347, -8.8219, -3.7572, -6.4546,\n",
      "         -3.1230, -0.7157]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.8468098640441895\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8964, -1.6654, -1.3606, -3.6167, -4.5511, -8.8088, -3.3460, -6.6970,\n",
      "         -3.0521, -0.8391]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.808838844299316\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1640, -1.7649, -1.2527, -2.3963, -4.3498, -7.9060, -2.8685, -6.7824,\n",
      "         -2.8891, -1.1299]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.8685402870178223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6062, -2.0836, -1.4622, -1.4685, -4.2782, -7.1934, -1.8305, -6.9603,\n",
      "         -2.8832, -1.7260]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.193413734436035\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3076, -2.6654, -2.0198, -1.0140, -4.4254, -6.0012, -1.2175, -7.3225,\n",
      "         -3.1199, -2.5934]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.307645320892334\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3130, -3.2164, -2.7153, -0.9436, -4.7638, -4.8757, -0.8899, -7.7107,\n",
      "         -3.3474, -3.5536]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.875654697418213\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3297, -3.6500, -3.2278, -1.0497, -4.8605, -3.0566, -0.8017, -7.9209,\n",
      "         -3.4834, -4.2603]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.4833834171295166\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4896, -4.0878, -3.7079, -1.4207, -4.9126, -1.4906, -1.0789, -8.1114,\n",
      "         -2.9226, -4.8883]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.111366271972656\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1431, -4.8437, -4.5070, -2.2919, -5.3138, -0.5992, -1.9328, -7.9031,\n",
      "         -2.8060, -5.8083]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.1431405544281006\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4462, -5.7902, -5.4944, -3.4150, -5.9386, -0.4707, -3.0703, -7.9757,\n",
      "         -3.0051, -6.8987]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.0702710151672363\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8863, -6.5396, -6.2813, -4.3468, -6.3980, -0.7198, -3.2729, -7.9362,\n",
      "         -3.1154, -7.7762]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.346779823303223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5329, -7.0637, -6.8394, -4.2648, -6.6611, -1.1577, -3.3319, -7.7490,\n",
      "         -3.0954, -8.4148]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.749030590057373\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4066, -7.2979, -7.1044, -3.9635, -6.6605, -1.5494, -3.1734, -6.6171,\n",
      "         -2.8722, -8.7517]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.6605377197265625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4667, -7.1962, -7.0305, -3.3939, -5.6133, -1.7483, -2.7490, -5.2858,\n",
      "         -2.3995, -8.7420]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.4666544497013092\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4386, -7.2959, -7.1553, -3.0978, -4.8637, -2.2488, -2.6056, -4.2813,\n",
      "         -2.2311, -8.9241]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.43862876296043396\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.3541, -7.5865, -7.4686, -3.0667, -4.3948, -2.9791, -2.7323, -3.5873,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -2.3586, -9.2885]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  9.288476943969727\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4750, -7.5330, -7.4355, -2.7594, -3.6660, -3.3593, -2.5797, -2.6669,\n",
      "         -2.2271, -8.5726]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.7593774795532227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9821, -7.4307, -7.3517, -1.7012, -2.9741, -3.6732, -2.4447, -1.8342,\n",
      "         -2.1334, -7.8737]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.444727897644043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9869, -7.6145, -7.5520, -1.1657, -2.6641, -4.2505, -1.9137, -1.4764,\n",
      "         -2.4113, -7.5200]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.552043437957764\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0776, -7.8663, -7.0922, -1.0117, -2.5223, -4.8670, -1.6322, -1.4067,\n",
      "         -2.8135, -7.2879]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.813511371612549\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0349, -8.0349, -6.6203, -1.0971, -2.3953, -5.3695, -1.4670, -1.4642,\n",
      "         -2.4279, -7.0210]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.02103328704834\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7783, -8.0555, -6.0647, -1.3016, -2.2166, -5.6940, -1.3597, -1.5531,\n",
      "         -2.0137, -5.9246]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.055459976196289\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3441, -7.2068, -5.4566, -1.5873, -2.0264, -5.8790, -1.3461, -1.6779,\n",
      "         -1.6290, -4.8297]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.5873048305511475\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9277, -6.5137, -4.9826, -1.2976, -2.0229, -6.1183, -1.5997, -1.9970,\n",
      "         -1.4970, -3.9201]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.9825944900512695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3756, -5.8112, -3.7576, -1.1689, -2.0380, -6.2559, -1.9001, -2.3040,\n",
      "         -1.4627, -3.0359]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.81119441986084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7307, -4.3782, -2.6219, -1.2442, -2.0981, -6.3317, -2.2334, -2.6038,\n",
      "         -1.5523, -2.2252]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.098139524459839\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.2150, -3.2612, -1.8158, -1.6990, -1.6692, -6.5651, -2.7777, -3.0916,\n",
      "         -1.9520, -1.7376]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.2611513137817383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.8799, -1.7635, -1.4364, -2.4786, -1.6501, -7.0046, -3.5429, -3.7923,\n",
      "         -2.6444, -1.6551]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.4785799980163574\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.7849, -0.8502, -1.5736, -2.7766, -2.0804, -7.7070, -4.5596, -4.7458,\n",
      "         -3.6261, -2.0260]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.8501975536346436\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.2306,  -0.2293,  -2.4783,  -3.7237,  -3.1906,  -8.9704,  -6.1136,\n",
      "          -6.2412,  -5.1602,  -3.0867]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.160160064697266\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.3617,  -0.1008,  -3.1834,  -4.4247,  -4.0500,  -9.9376,  -7.3440,\n",
      "          -7.4187,  -5.6412,  -3.9045]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.05003547668457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.8197,  -0.1041,  -3.2877,  -4.5044,  -3.5407, -10.2479,  -7.8918,\n",
      "          -7.9188,  -5.5163,  -4.0950]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  10.247907638549805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.6618,  -0.2099,  -2.8386,  -4.0146,  -2.5332,  -9.2020,  -7.8150,\n",
      "          -7.7991,  -4.8365,  -3.7084]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.20990243554115295\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.6986,  -0.3427,  -2.6558,  -3.7665,  -1.8634,  -8.4392,  -7.9252,\n",
      "          -7.8706,  -4.4092,  -3.5572]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.870569229125977\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.4865,  -0.7456,  -2.2971,  -3.3158,  -1.1293,  -7.5074,  -7.7796,\n",
      "          -6.9582,  -3.7882,  -3.1967]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.1293319463729858\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.7279,  -1.8935,  -2.4797,  -3.3704,  -0.4037,  -7.1010,  -8.0810,\n",
      "          -6.5696,  -3.6779,  -3.3343]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.569647789001465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.9407,  -3.0346,  -2.7006,  -3.4417,  -0.2372,  -6.7311,  -8.3481,\n",
      "          -5.4891,  -3.5926,  -3.4797]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  11.940707206726074\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.0138,  -3.7131,  -2.5636,  -3.1458,  -0.2808,  -6.0141,  -8.2039,\n",
      "          -4.1343,  -3.1511,  -3.2483]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.134340286254883\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.9455, -4.1087, -2.2628, -2.6793, -0.6380, -5.1367, -7.8407, -1.9695,\n",
      "         -2.5515, -2.8347]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.840651512145996\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.4568, -4.9503, -2.5411, -2.7856, -1.8179, -4.8243, -7.2332, -0.5948,\n",
      "         -2.5421, -2.9785]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.8178911209106445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.4996, -6.1962, -3.3319, -3.4121, -2.7493, -5.0318, -7.1695, -0.2419,\n",
      "         -3.0743, -3.6281]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  9.499576568603516\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.4804, -6.9918, -3.7424, -3.6740, -3.3068, -4.8958, -6.7850, -0.1672,\n",
      "         -3.2597, -3.9046]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.904639959335327\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0890, -7.2350, -3.6554, -3.4558, -3.3618, -4.3052, -5.9657, -0.2384,\n",
      "         -2.9811, -2.9631]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.3618080615997314\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5636, -7.1816, -3.3230, -3.0108, -2.4345, -3.5106, -4.9569, -0.5970,\n",
      "         -2.4947, -1.8801]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.5970155000686646\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5537, -7.4948, -3.4108, -3.0093, -2.0240, -3.1785, -4.4147, -0.9557,\n",
      "         -2.4783, -1.3773]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.3772727251052856\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9348, -8.0599, -3.7968, -3.3291, -2.0334, -3.1939, -4.2182, -1.8385,\n",
      "         -2.8081, -0.6619]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.0334091186523438\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5374, -8.7147, -4.3064, -3.7905, -1.5564, -3.3844, -4.1981, -2.8937,\n",
      "         -3.2952, -0.5405]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.8937132358551025\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0676, -9.1710, -4.6418, -4.0903, -1.1469, -3.4484, -4.0579, -3.0282,\n",
      "         -3.6278, -0.7230]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.057891368865967\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5431, -9.4464, -4.8152, -4.2377, -0.8735, -3.3947, -3.0566, -3.0486,\n",
      "         -3.8113, -1.1052]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.1052414178848267\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2459, -9.8117, -5.0947, -4.4991, -1.0481, -3.4891, -2.3078, -3.2185,\n",
      "         -4.1103, -1.0793]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.307812213897705\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1528, -10.2375,  -5.4477,  -4.8399,  -1.5567,  -3.6942,  -1.0562,\n",
      "          -3.4970,  -4.4884,  -1.4000]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.0561597347259521\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9393, -11.4059,  -6.5535,  -5.9378,  -2.9528,  -4.6827,  -0.2269,\n",
      "          -4.5546,  -5.6222,  -2.6533]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.9378252029418945\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6812, -12.4527,  -7.5451,  -6.1442,  -4.2425,  -5.5746,  -0.0760,\n",
      "          -5.5092,  -6.6404,  -3.8278]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  6.144179344177246\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7923, -12.8199,  -7.8629,  -4.9835,  -4.8389,  -5.8052,  -0.0596,\n",
      "          -5.7963,  -6.9828,  -4.3257]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.05964275449514389\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9638, -13.2054,  -8.2043,  -3.9986,  -5.4365,  -6.0700,  -0.0566,\n",
      "          -6.1119,  -7.3468,  -4.8387]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.9638452529907227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8145, -12.9683,  -7.9277,  -2.5419,  -5.3937,  -5.7260,  -0.1738,\n",
      "          -5.8135,  -7.0908,  -4.7222]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.8134565353393555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6851, -12.6163,  -7.5403,  -1.1527,  -5.2199,  -5.2802,  -0.7634,\n",
      "          -4.6880,  -6.7223,  -4.4852]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.6850979328155518\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7870, -13.0133,  -7.9058,  -0.8613,  -5.7812,  -5.5967,  -2.3533,\n",
      "          -4.3952,  -7.1054,  -4.9940]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.596651077270508\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4757, -13.5340,  -8.3985,  -1.0905,  -6.4522,  -5.2863,  -4.0187,\n",
      "          -4.3036,  -7.6141,  -5.6203]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  13.534002304077148\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3774, -12.9781,  -8.5688,  -1.2844,  -6.7840,  -4.7373,  -5.2582,\n",
      "          -3.9575,  -7.7991,  -5.9135]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.2581892013549805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4166, -12.1043,  -8.3489,  -1.3004,  -6.7103,  -3.8763,  -5.2603,\n",
      "          -3.2862,  -7.5927,  -5.8061]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.4165895879268646\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3473, -11.4617,  -8.2955,  -1.6706,  -6.7892,  -3.2611,  -5.4104,\n",
      "          -2.8531,  -7.5515,  -5.8559]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.2610764503479004\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5697, -10.6528,  -8.0172,  -1.9197,  -6.6307,  -1.7482,  -5.3185,\n",
      "          -2.2744,  -7.2845,  -5.6725]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.5696778297424316\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8643, -10.3357,  -8.1782,  -2.6691,  -6.9003,  -0.9297,  -5.6507,\n",
      "          -2.2390,  -7.4559,  -5.9212]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.650670528411865\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4295, -10.0432,  -8.3163,  -3.3908,  -7.1367,  -0.4860,  -5.2059,\n",
      "          -2.2770,  -7.6036,  -6.1401]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.4294962882995605\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3282, -9.7240, -8.3850, -4.0110, -7.2943, -0.4981, -4.7535, -2.3297,\n",
      "         -7.6811, -6.2829]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.282934188842773\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1192, -9.1259, -8.1363, -4.2728, -7.1260, -0.6588, -4.0419, -2.1367,\n",
      "         -7.4405, -5.3712]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.272784233093262\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9600, -8.3789, -7.7040, -3.5336, -6.7665, -0.9866, -3.2056, -1.8399,\n",
      "         -7.0158, -4.3451]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.20556902885437\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0903, -7.7016, -7.3103, -2.8858, -6.4388, -1.5587, -1.7415, -1.6828,\n",
      "         -6.6292, -3.4258]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.885802745819092\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7811, -7.4211, -7.2853, -1.9028, -6.4740, -2.5622, -0.8816, -2.0050,\n",
      "         -6.6111, -2.9509]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.9028156995773315\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0192, -7.6626, -7.7570, -0.8585, -7.0004, -4.0178, -0.9068, -2.8862,\n",
      "         -7.0895, -3.0551]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.00035285949707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3211, -8.0318, -8.3334, -0.3971, -6.8951, -5.4937, -1.3790, -3.8717,\n",
      "         -7.6723, -3.3350]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.493682861328125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2630, -8.1244, -8.6125, -0.2604, -6.5610, -5.8266, -1.7497, -4.5340,\n",
      "         -7.9573, -3.3729]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.3728976249694824\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.7165, -7.8097, -8.4657, -0.3314, -5.8628, -5.7302, -1.8135, -4.7398,\n",
      "         -7.8159, -2.3042]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.46566390991211\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8891, -7.2884, -7.3555, -0.7065, -4.9980, -5.4076, -1.7530, -4.6933,\n",
      "         -7.4505, -1.1766]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.450534343719482\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1585, -6.9315, -6.4684, -1.5333, -4.3362, -5.2327, -1.9384, -4.7701,\n",
      "         -6.4882, -0.4989]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.488211154937744\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3673, -6.5755, -5.6353, -2.4075, -3.7145, -5.0437, -2.1763, -4.8099,\n",
      "         -4.8471, -0.2971]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.367257595062256\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5328, -5.9616, -4.5934, -2.9692, -2.8782, -4.5840, -2.1799, -4.5574,\n",
      "         -3.0808, -0.3623]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.5840373039245605\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7287, -5.3551, -3.6070, -3.4587, -2.1107, -3.3675, -2.2110, -4.2819,\n",
      "         -1.4688, -0.8708]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.7286529541015625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7507, -5.2768, -3.2032, -4.3877, -1.9728, -2.7623, -2.7843, -4.5082,\n",
      "         -0.6530, -2.0969]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.096853256225586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0916, -5.4146, -3.0742, -5.4383, -2.1551, -2.4695, -3.5507, -4.9244,\n",
      "         -0.5107, -2.7653]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.074190378189087\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3947, -5.4056, -2.1173, -6.2512, -2.2680, -2.1333, -4.1256, -5.1680,\n",
      "         -0.6922, -3.2765]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.168012619018555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8278, -5.3953, -1.3392, -6.9790, -2.4401, -1.9146, -4.6496, -4.6590,\n",
      "         -1.2215, -3.7587]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.9145548343658447\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6749, -5.6301, -1.0734, -7.8758, -2.8998, -1.3162, -5.3692, -4.4483,\n",
      "         -2.1574, -4.4504]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.8998327255249023\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7168, -5.8876, -1.1305, -8.7269, -2.6639, -1.0232, -6.0639, -4.3104,\n",
      "         -3.1294, -5.1251]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.716827154159546\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1925, -6.1541, -1.4535, -9.5260, -2.5351, -1.0632, -6.7237, -4.2284,\n",
      "         -4.0696, -5.7695]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.0695953369140625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8497,  -6.3045,  -1.8262, -10.1543,  -2.3860,  -1.2685,  -7.2276,\n",
      "          -4.0741,  -4.0948,  -6.2608]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.2684727907180786\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9169,  -6.5068,  -2.3465, -10.7856,  -2.3848,  -0.9777,  -7.7472,\n",
      "          -4.0129,  -4.1952,  -6.7700]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.9777156114578247\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4816,  -6.9042,  -3.1000, -11.5682,  -2.6655,  -0.4619,  -8.4297,\n",
      "          -4.1852,  -4.5111,  -7.4435]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.6654765605926514\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0393,  -7.1472,  -3.6962, -12.1572,  -2.1218,  -0.3563,  -8.9286,\n",
      "          -4.2357,  -4.6879,  -7.9348]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.687893390655518\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3498,  -7.0804,  -3.9654, -12.4015,  -1.4339,  -0.5007,  -9.0920,\n",
      "          -4.0056,  -3.8292,  -8.0913]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.080440044403076\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5509,  -6.1136,  -4.0741, -12.4737,  -0.8415,  -0.9366,  -9.0913,\n",
      "          -3.6639,  -2.9242,  -8.0846]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.11358118057251\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7606,  -4.4630,  -4.1566, -12.5108,  -0.5961,  -1.5943,  -9.0628,\n",
      "          -3.3470,  -2.1210,  -8.0508]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.462967395782471\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9945,  -2.2360,  -4.2415, -12.5431,  -0.7774,  -2.3374,  -9.0362,\n",
      "          -3.0863,  -1.4856,  -8.0197]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.994471311569214\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9516,  -0.7477,  -4.7650, -13.0086,  -1.7129,  -3.5152,  -9.4487,\n",
      "          -3.3213,  -1.5174,  -8.4282]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.7649712562561035\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4302,  -0.2453,  -4.9805, -13.9070,  -3.1665,  -5.0774, -10.2995,\n",
      "          -4.0385,  -2.1877,  -9.2755]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.4302005767822266\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9482,  -0.1700,  -4.9652, -14.5014,  -4.2918,  -6.2741, -10.8510,\n",
      "          -4.4827,  -2.6599,  -9.8240]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.291758060455322\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0830,  -0.2674,  -4.4874, -14.5676,  -4.1137,  -6.8841, -10.8786,\n",
      "          -4.4219,  -2.6678,  -9.8488]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.2674410045146942\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5755,  -0.3605,  -4.2470, -14.8086,  -4.1467,  -7.6156, -11.0849,\n",
      "          -4.5573,  -2.9079, -10.0526]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.5754859447479248\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5897,  -1.0092,  -4.0835, -15.0680,  -4.2303,  -8.3169, -11.3130,\n",
      "          -4.7293,  -3.2068, -10.2785]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.0091962814331055\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3653,  -1.3789,  -4.2107, -15.5635,  -4.5782,  -9.2106, -11.7803,\n",
      "          -5.1525,  -3.7681, -10.7439]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.3652583956718445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.1632,  -2.1209,  -4.5569, -16.2302,  -5.1195, -10.2360, -12.4218,\n",
      "          -5.7585,  -4.5112, -11.3836]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.120918035507202\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2223,  -1.7593,  -4.5041, -16.4583,  -5.2390, -10.7870, -12.6271,\n",
      "          -5.9342,  -4.8161, -11.5873]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.816137313842773\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4475,  -1.1589,  -4.0614, -16.2604,  -4.9472, -10.8798, -12.4086,\n",
      "          -5.6910,  -3.9525, -11.3674]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  11.36743450164795\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9295,  -0.6741,  -3.4969, -15.9034,  -4.5109, -10.7847, -12.0331,\n",
      "          -5.2957,  -3.0104, -10.2591]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  12.033124923706055\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5578,  -0.5296,  -2.9228, -15.4936,  -4.0378, -10.6107, -10.8603,\n",
      "          -4.8551,  -2.1101,  -9.1727]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.855132579803467\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1935,  -0.7572,  -2.3648, -15.0436,  -3.5436, -10.3731,  -9.7232,\n",
      "          -3.6510,  -1.3084,  -8.1135]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.113483428955078\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8938,  -1.3588,  -1.9802, -14.6861,  -3.1676, -10.2069,  -8.7472,\n",
      "          -2.6335,  -0.8348,  -6.4802]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.9802147150039673\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7782,  -2.3059,  -1.2075, -14.5783,  -3.0740, -10.2713,  -8.0824,\n",
      "          -1.9840,  -0.9441,  -5.2247]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.9840483665466309\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8705,  -3.5127,  -1.0136, -14.7608,  -3.3033, -10.6089,  -7.7637,\n",
      "          -1.0498,  -1.6103,  -4.3777]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.870543479919434\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.2577,  -4.7391,  -1.2264, -15.0428,  -3.6543, -11.0306,  -7.5946,\n",
      "          -0.5825,  -2.4759,  -3.7417]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.4759135246276855\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5081,  -5.7481,  -1.5342, -15.1948,  -3.8875, -11.3084,  -7.3408,\n",
      "          -0.4684,  -2.4744,  -3.0845]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.468413770198822\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.9447,  -6.8673,  -2.1798, -15.5399,  -4.3208, -11.7668,  -7.3211,\n",
      "          -0.3010,  -2.7436,  -2.7345]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.734537124633789\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.1101,  -7.6462,  -2.6156, -15.6210,  -4.4911, -11.9499,  -7.0741,\n",
      "          -0.4610,  -2.8039,  -1.5100]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.074131488800049\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.2871,  -8.3744,  -3.0888, -15.7205,  -4.6792, -12.1413,  -6.1336,\n",
      "          -1.0907,  -2.9296,  -0.5951]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.5951379537582397\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.1311,  -9.7135,  -4.2321, -16.4933,  -5.5386, -12.9968,  -5.9716,\n",
      "          -2.5853,  -3.7655,  -0.1283]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.765526294708252\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.6109, -10.6386,  -4.9917, -16.9085,  -6.0346, -13.4865,  -5.5469,\n",
      "          -3.7053,  -3.5162,  -0.0703]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  10.638640403747559\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.4545, -10.1353,  -5.0920, -16.6936,  -5.8944, -13.3387,  -4.5786,\n",
      "          -4.1431,  -2.7250,  -0.1067]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.894354343414307\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8515,  -9.2193,  -4.7242, -16.0375,  -4.5726, -12.7429,  -3.2518,\n",
      "          -4.0861,  -1.5982,  -0.3259]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.598218560218811\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.7447,  -8.8300,  -4.8351, -15.8820,  -3.8254, -12.6419,  -2.5214,\n",
      "          -4.4825,  -0.4320,  -1.4782]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.744664192199707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.2848,  -8.8324,  -5.2937, -16.0949,  -3.5215, -12.9037,  -2.2767,\n",
      "          -5.2005,  -0.2143,  -3.0331]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  12.903712272644043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5425,  -8.5051,  -5.3807, -15.9570,  -2.9399, -12.0533,  -1.8036,\n",
      "          -5.5215,  -0.2827,  -4.1384]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.505117416381836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5730,  -7.1629,  -5.1587, -15.5289,  -2.1513, -10.9837,  -1.1972,\n",
      "          -5.5096,  -0.5927,  -4.8413]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  10.983744621276855\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6610,  -5.9084,  -4.9166, -15.0970,  -1.4804,  -9.2228,  -0.8311,\n",
      "          -5.4553,  -1.2297,  -5.4335]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.455284118652344\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8675,  -4.7901,  -4.7134, -14.7173,  -1.0531,  -7.6466,  -0.8369,\n",
      "          -4.6889,  -2.0265,  -5.9791]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.8369321227073669\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4408,  -4.0362,  -4.7840, -14.6224,  -1.1723,  -6.4746,  -0.6643,\n",
      "          -4.2524,  -3.0875,  -6.7193]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.719258785247803\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9405,  -3.1919,  -4.6752, -14.3582,  -1.3289,  -5.2417,  -0.7151,\n",
      "          -3.6910,  -3.8977,  -6.4833]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.1918628215789795\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5670,  -1.6943,  -4.5578, -14.0940,  -1.6385,  -4.1091,  -1.0999,\n",
      "          -3.1773,  -4.6157,  -6.2457]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.557796001434326\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6590,  -0.7608,  -3.9913, -14.1342,  -2.3384,  -3.3798,  -1.9731,\n",
      "          -3.0234,  -5.5476,  -6.3111]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.3384194374084473\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0828,  -0.4722,  -3.6988, -14.3742,  -2.5066,  -2.9527,  -3.0672,\n",
      "          -3.1241,  -6.5934,  -6.5753]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.698824644088745\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3913,  -0.5134,  -2.5491, -14.4275,  -2.5552,  -2.4449,  -3.9244,\n",
      "          -3.0842,  -7.3734,  -6.6513]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.549079418182373\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8520,  -1.1114,  -0.9510, -14.5925,  -2.7731,  -2.1702,  -4.8280,\n",
      "          -3.1986,  -8.1931,  -6.8377]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.8377180099487305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7992,  -2.3846,  -0.2902, -15.2319,  -3.5060,  -2.5001,  -6.1384,\n",
      "          -3.8223,  -9.4223,  -6.7762]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.776180744171143\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5653,  -3.4964,  -0.1487, -15.7046,  -4.0851,  -2.7563,  -7.2170,\n",
      "          -4.2970, -10.4261,  -5.9027]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.2969794273376465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7778,  -4.0352,  -0.1743, -15.6453,  -4.1340,  -2.5503,  -7.7039,\n",
      "          -3.5200, -10.8451,  -4.6333]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.6332597732543945\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5953,  -4.1536,  -0.4360, -15.2121,  -3.8100,  -2.0441,  -7.7628,\n",
      "          -2.4622, -10.8426,  -2.4052]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.40516996383667\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1535,  -4.9871,  -1.8614, -15.5373,  -4.2498,  -2.4018,  -8.5314,\n",
      "          -2.2872, -11.5556,  -0.4694]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8], device='cuda:0')\n",
      "Loss:  11.555604934692383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.5793,  -6.6616,  -4.1782, -16.7490,  -5.5753,  -3.7115, -10.1425,\n",
      "          -3.1227, -12.3804,  -0.0946]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.09464924037456512\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.1940,  -8.5004,  -6.6055, -18.1700,  -7.1015,  -5.2393, -11.9232,\n",
      "          -4.2371, -13.4530,  -0.0227]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  18.170026779174805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.0032e+00, -9.5111e+00, -8.1471e+00, -1.8018e+01, -7.8314e+00,\n",
      "         -5.9740e+00, -1.2882e+01, -4.6061e+00, -1.3774e+01, -1.3513e-02]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  18.017818450927734\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.0423,  -9.7318,  -8.8459, -16.4111,  -7.7993,  -5.9479, -13.0550,\n",
      "          -4.2560, -13.3731,  -0.0177]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.256041526794434\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4464,  -9.2993,  -8.8440, -14.3331,  -7.1396,  -5.2952, -12.5800,\n",
      "          -2.5919, -12.3811,  -0.0846]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.295224189758301\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.6770,  -8.6769,  -8.6095, -12.2289,  -6.3130,  -3.7204, -11.9192,\n",
      "          -0.9150, -11.2548,  -0.5575]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.313048362731934\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.5216,  -8.6537,  -8.9355, -10.8714,  -5.3701,  -2.8579, -11.8614,\n",
      "          -0.2347, -10.7778,  -1.9225]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.935477256774902\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.3720,  -8.6229,  -8.4814,  -9.6389,  -4.5143,  -2.1147, -11.7992,\n",
      "          -0.1884, -10.3382,  -3.2445]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.338188171386719\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.9162,  -8.2738,  -7.7512,  -8.2077,  -3.4303,  -1.2155, -11.4217,\n",
      "          -0.4261,  -8.8869,  -4.1408]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  11.421692848205566\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4615,  -7.9146,  -7.0489,  -6.8741,  -2.4331,  -0.5859, -10.2850,\n",
      "          -1.0674,  -7.5352,  -4.9142]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.048949241638184\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0642, -7.6024, -5.6953, -5.6850, -1.6109, -0.4520, -9.2724, -1.9048,\n",
      "         -6.3294, -5.6266]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.45195892453193665\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0464, -7.6600, -4.8172, -4.9554, -1.3565, -0.3940, -8.6990, -3.1051,\n",
      "         -5.5834, -6.6091]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.69904613494873\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.7466, -7.4266, -3.7469, -4.0183, -1.0322, -0.5665, -7.1501, -3.9328,\n",
      "         -4.6287, -7.2092]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.0321729183197021\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6830, -7.4209, -3.0045, -3.3927, -0.4690, -1.3543, -5.9600, -4.8963,\n",
      "         -3.9803, -7.9540]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.954020023345947\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5853, -7.3735, -2.3296, -2.8130, -0.3809, -2.2159, -4.8475, -5.7266,\n",
      "         -3.3675, -7.8744]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.2158799171447754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3894, -7.2205, -1.6827, -2.2277, -0.6936, -2.2059, -3.7409, -6.3658,\n",
      "         -2.7302, -7.6922]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.740922451019287\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2863, -7.1532, -1.3070, -1.8555, -1.4122, -2.3500, -2.0878, -7.0127,\n",
      "         -2.2746, -7.5985]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.012684345245361\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4905, -7.3867, -1.4613, -1.9372, -2.5318, -2.8452, -0.9855, -7.1615,\n",
      "         -2.2335, -7.8078]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.4613051414489746\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0184, -7.9383, -1.3771, -2.4655, -3.9394, -3.6759, -0.6136, -7.6370,\n",
      "         -2.6167, -8.3376]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.939394950866699\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3379, -8.2777, -1.3292, -2.8506, -4.3266, -4.2854, -0.5266, -7.9080,\n",
      "         -2.8580, -8.6572]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.907990455627441\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3271, -8.2836, -1.1808, -2.9432, -4.3851, -4.5449, -0.5898, -7.1294,\n",
      "         -2.8179, -8.6452]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.1807808876037598\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3764, -8.3469, -0.5967, -3.1260, -4.5048, -4.8443, -1.1178, -6.4867,\n",
      "         -2.8837, -8.6924]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.126033067703247\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3509, -8.3330, -0.4039, -2.4662, -4.5495, -5.0487, -1.7659, -5.8379,\n",
      "         -2.9132, -8.6638]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.837925434112549\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0986, -8.0900, -0.4887, -1.7082, -4.3669, -5.0070, -2.2463, -4.3061,\n",
      "         -2.7493, -8.4076]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.098609924316406\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0269, -7.7541, -0.8959, -1.0513, -4.0945, -4.8572, -2.6405, -2.8191,\n",
      "         -2.5318, -8.0597]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.0512583255767822\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5781, -7.9633, -2.0719, -0.4598, -4.3728, -5.2396, -3.5602, -2.0346,\n",
      "         -2.9062, -8.2580]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.258041381835938\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1954, -8.1660, -3.2369, -0.4385, -4.6467, -5.6019, -4.4234, -1.4367,\n",
      "         -3.2978, -7.7443]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.646713733673096\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6675, -8.1544, -4.1203, -0.7314, -3.9721, -5.7367, -5.0155, -0.8759,\n",
      "         -3.4835, -7.0878]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.4835376739501953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1139, -8.0472, -4.8308, -1.2752, -3.2815, -5.7635, -5.4566, -0.5751,\n",
      "         -2.8368, -6.4002]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.456586837768555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5256, -7.8288, -5.3542, -1.8614, -2.5651, -5.6679, -4.9874, -0.5884,\n",
      "         -2.1756, -5.6601]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.5884143114089966\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3305, -7.9084, -6.1051, -2.7873, -2.2525, -5.8605, -4.8460, -0.5553,\n",
      "         -1.9403, -5.2722]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.90839147567749\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0435, -7.0459, -6.6005, -3.4869, -1.8661, -5.8537, -4.5422, -0.7570,\n",
      "         -1.6524, -4.7442]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.600468158721924\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7667, -6.1566, -6.2013, -4.0277, -1.5186, -5.7366, -4.1634, -1.1632,\n",
      "         -1.4217, -4.1617]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.7365593910217285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5844, -5.2994, -5.7852, -4.4706, -1.3088, -4.8174, -3.7758, -1.6959,\n",
      "         -1.3346, -3.5901]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.775848627090454\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5326, -4.4936, -5.3750, -4.8406, -1.2809, -3.9582, -2.6625, -2.2700,\n",
      "         -1.4133, -3.0573]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.5326368808746338\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1035, -3.9671, -5.1999, -5.3707, -1.6508, -3.3897, -1.9027, -3.0522,\n",
      "         -1.8551, -2.8016]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.9670944213867188\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0402, -2.8388, -5.1268, -5.9324, -2.2058, -2.9840, -1.4103, -3.8713,\n",
      "         -2.4495, -2.6951]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.0401654243469238\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8034, -2.1587, -5.3573, -6.7322, -3.0785, -2.9491, -1.4408, -4.9158,\n",
      "         -3.3406, -2.9391]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.357323169708252\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8425, -1.5583, -4.7638, -7.3785, -3.8235, -2.8826, -1.5700, -5.7869,\n",
      "         -4.0945, -3.1217]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.12168550491333\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1267, -1.1109, -4.1705, -7.8958, -4.4452, -2.8001, -1.7761, -6.5082,\n",
      "         -4.7204, -2.5437]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.8000969886779785\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6226, -0.9595, -3.6511, -8.3655, -5.0173, -2.0189, -2.0917, -7.1625,\n",
      "         -5.2944, -2.0826]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  5.017339706420898\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2042, -1.1023, -3.1935, -8.7798, -4.7919, -1.4073, -2.4590, -7.7433,\n",
      "         -5.8060, -1.7469]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.7468535900115967\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9850, -1.6573, -2.9881, -9.3295, -4.7716, -1.2189, -3.0302, -8.4432,\n",
      "         -6.4456, -1.0379]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.6572726964950562\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8509, -1.6750, -2.9659, -9.9504, -4.8854, -1.3992, -3.7064, -9.1994,\n",
      "         -7.1485, -0.7764]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.706397533416748\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4831,  -1.6685,  -2.8205, -10.3465,  -4.8304,  -1.5856,  -3.4253,\n",
      "          -9.7174,  -7.6190,  -0.7039]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.717401504516602\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8449,  -1.5885,  -2.5176, -10.4876,  -4.5711,  -1.6931,  -2.9808,\n",
      "          -9.2448,  -7.8273,  -0.7729]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.5176148414611816\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1207,  -1.6142,  -1.5184, -10.5589,  -4.2895,  -1.8738,  -2.5626,\n",
      "          -8.7636,  -7.9595,  -1.1056]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.763554573059082\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4372,  -1.8504,  -0.8426, -10.6869,  -4.1098,  -2.2166,  -2.3073,\n",
      "          -7.6753,  -8.1425,  -1.7027]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.7027325630187988\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8152,  -2.2711,  -0.6388, -10.8919,  -4.0499,  -2.6979,  -2.2414,\n",
      "          -6.7856,  -8.3974,  -1.7518]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.697916269302368\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.0061,  -2.5757,  -0.6893, -10.9249,  -3.8571,  -2.2724,  -2.1096,\n",
      "          -5.8336,  -8.4753,  -1.7668]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  8.475343704223633\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.9999,  -2.7274,  -0.9209, -10.7748,  -3.5193,  -1.7874,  -1.9017,\n",
      "          -4.7986,  -7.6220,  -1.7210]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.9209132790565491\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.1558,  -3.0727,  -0.8497, -10.7992,  -3.3966,  -1.6371,  -1.9855,\n",
      "          -4.0322,  -7.0136,  -1.9657]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.9854605197906494\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.2750,  -3.3959,  -1.0745, -10.7985,  -3.2881,  -1.6264,  -1.3954,\n",
      "          -3.3321,  -6.4438,  -2.2623]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.3954131603240967\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6712,  -3.9996,  -1.8130, -11.0854,  -3.5055,  -2.0533,  -0.5936,\n",
      "          -3.0151,  -6.2193,  -2.8905]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.50551176071167\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0918,  -4.6199,  -2.6599, -11.4066,  -3.0494,  -2.5979,  -0.3458,\n",
      "          -2.8280,  -6.0816,  -3.5583]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  11.406617164611816\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.1929,  -4.9077,  -3.1953, -10.6268,  -2.3955,  -2.8665,  -0.3701,\n",
      "          -2.4240,  -5.6811,  -3.9017]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.195283889770508\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0589, -4.9467, -2.7524, -9.6989, -1.6482, -2.9259, -0.6773, -1.8987,\n",
      "         -5.0973, -3.9995]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.0588788986206055\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1885, -4.9700, -2.3828, -8.8462, -1.1000, -3.0028, -1.3120, -1.5167,\n",
      "         -4.5590, -4.0832]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.969989776611328\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4374, -4.2743, -2.1482, -8.1097, -0.8833, -3.1409, -2.1136, -1.3628,\n",
      "         -4.1131, -4.2017]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.1131486892700195\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6988, -3.5929, -1.9565, -7.3812, -0.9277, -3.2327, -2.8594, -1.3440,\n",
      "         -2.9158, -4.2536]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.381198406219482\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9941, -2.9537, -1.8405, -5.8926, -1.2128, -3.2990, -3.5270, -1.4695,\n",
      "         -1.8317, -4.2640]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.2127853631973267\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6292, -2.6735, -2.1078, -4.8105, -1.2072, -3.6428, -4.4060, -2.0052,\n",
      "         -1.2308, -4.5395]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.642845630645752\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3235, -2.4767, -2.4405, -3.8460, -1.4258, -3.2165, -5.2100, -2.5885,\n",
      "         -0.9107, -4.7986]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.5885486602783203\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0413, -2.3293, -2.7702, -2.9610, -1.7663, -2.8296, -5.9047, -2.4104,\n",
      "         -0.8886, -5.0044]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.7662962675094604\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8653, -2.3130, -3.1557, -2.2479, -1.5055, -2.5690, -6.5751, -2.3578,\n",
      "         -1.2175, -5.2374]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.575074672698975\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7243, -2.3487, -3.5097, -1.6651, -1.4096, -2.3682, -6.4136, -2.3546,\n",
      "         -1.7095, -5.4266]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.426626205444336\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6259, -2.4331, -3.8305, -1.2702, -1.4831, -2.2387, -6.2497, -2.4006,\n",
      "         -2.2673, -4.8708]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.238668203353882\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6465, -2.6312, -4.1911, -1.1928, -1.7721, -1.5018, -6.1594, -2.5636,\n",
      "         -2.9027, -4.4316]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.1927995681762695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9726, -3.1194, -4.7822, -0.8286, -2.4128, -1.2625, -6.3350, -3.0215,\n",
      "         -3.7710, -4.3000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.8285830020904541\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6419, -3.9304, -5.6586, -0.3951, -3.3936, -1.5995, -6.8324, -3.8070,\n",
      "         -4.9080, -4.5291]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.641915798187256\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2921, -4.4383, -6.2132, -0.3001, -4.0644, -1.8190, -7.0440, -4.2934,\n",
      "         -5.7002, -4.5059]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.213155746459961\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5876, -4.4878, -5.5669, -0.3808, -4.2642, -1.7227, -6.8183, -4.3244,\n",
      "         -5.9992, -4.0760]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.566898822784424\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7251, -4.2575, -3.9794, -0.7058, -4.1711, -1.4880, -6.3325, -4.0786,\n",
      "         -5.9869, -3.4176]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.171070098876953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1170, -4.0983, -2.6011, -1.4223, -3.4001, -1.4854, -5.9339, -3.9070,\n",
      "         -6.0152, -2.8856]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.015222072601318\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9812, -4.1385, -1.5849, -2.4272, -2.9014, -1.8258, -5.7479, -3.9380,\n",
      "         -5.4680, -2.6172]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.4272477626800537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2794, -4.3317, -0.9640, -2.7605, -2.6376, -2.3994, -5.7276, -4.1250,\n",
      "         -5.1233, -2.5724]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.727623462677002\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7267, -4.4897, -0.6570, -3.0841, -2.4269, -2.9590, -4.9457, -4.2793,\n",
      "         -4.7915, -2.5606]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.945680141448975\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1240, -4.5044, -0.6216, -3.2752, -2.1660, -3.3660, -3.3757, -4.2921,\n",
      "         -4.3626, -2.4689]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.3756697177886963\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6217, -4.5779, -1.0319, -3.5288, -2.0674, -3.8108, -1.3087, -4.3656,\n",
      "         -4.0380, -2.4986]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.621671676635742\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0752, -5.3397, -2.3478, -4.4678, -2.7596, -4.9158, -0.3344, -5.1287,\n",
      "         -4.4465, -3.2718]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.339679718017578\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6537, -5.4081, -3.7383, -5.4585, -3.5657, -6.0525, -0.1219, -5.9562,\n",
      "         -4.9592, -4.1311]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.5657269954681396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7292, -5.0088, -4.5434, -5.8896, -3.1129, -6.6136, -0.1171, -6.2390,\n",
      "         -4.9619, -4.4521]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.7292470932006836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5909, -4.1620, -4.7839, -5.7877, -2.2457, -6.6276, -0.2707, -6.0029,\n",
      "         -4.4773, -4.2573]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.6275954246521\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4883, -3.2790, -4.8741, -5.5659, -1.4102, -5.7486, -0.8316, -5.6596,\n",
      "         -3.9169, -3.9595]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.4883019924163818\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5501, -3.1314, -5.5799, -5.9883, -1.4566, -5.5786, -2.2723, -5.9721,\n",
      "         -4.0464, -4.3241]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.046381950378418\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.3055, -3.2093, -6.3958, -6.5482, -1.8475, -5.6060, -3.8223, -6.4329,\n",
      "         -3.6087, -4.8395]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.8474845886230469\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4424, -3.1287, -6.9504, -6.8722, -1.3997, -5.4521, -5.0526, -6.6677,\n",
      "         -3.0534, -5.1278]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.667686462402344\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8097, -2.8655, -7.2265, -6.9407, -0.9538, -5.0929, -5.9412, -5.9276,\n",
      "         -2.3647, -5.1679]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.9538342952728271\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7921, -2.9997, -7.8037, -7.3312, -0.4299, -5.1020, -7.0712, -5.5911,\n",
      "         -2.1427, -5.5359]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.4299068748950958\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2657, -3.6262, -8.7915, -8.1512, -0.1700, -5.5827, -8.5571, -5.7586,\n",
      "         -2.4982, -6.3380]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.557141304016113\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2061, -3.7962, -9.2667, -8.4753, -0.1414, -5.6040, -8.7501, -5.4974,\n",
      "         -2.4654, -6.6471]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.14142180979251862\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1577, -4.0603, -9.7886, -8.8614, -0.1131, -5.7200, -9.0179, -5.3591,\n",
      "         -2.5933, -7.0203]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.020310401916504\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4488, -3.7413, -9.6886, -8.6391, -0.1705, -5.2569, -8.6891, -4.6680,\n",
      "         -2.1944, -6.0714]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.689071655273438\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2775, -3.0356, -9.1622, -8.0026, -0.3989, -4.4075, -7.2306, -3.6161,\n",
      "         -1.4821, -4.7821]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.035621404647827\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1435, -1.6941, -8.7046, -7.4461, -1.1075, -3.6683, -5.9342, -2.7050,\n",
      "         -1.0270, -3.6435]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.1075116395950317\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4413, -1.0399, -8.7070, -7.3598, -1.6713, -3.4364, -5.1831, -2.3478,\n",
      "         -1.2994, -3.0513]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.3477694988250732\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8492, -0.8561, -8.8458, -7.4191, -2.4520, -3.3887, -4.6473, -1.5038,\n",
      "         -1.8851, -2.6886]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.419090270996094\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2483, -1.0427, -9.0005, -6.7158, -3.2472, -3.4012, -4.2015, -0.9358,\n",
      "         -2.5557, -2.4403]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.5557146072387695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5917, -1.4609, -9.1226, -6.0661, -3.9742, -3.4207, -3.7937, -0.6934,\n",
      "         -2.4518, -2.2619]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.4609242677688599\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8992, -1.2522, -9.2300, -5.4802, -4.6398, -3.4605, -3.4402, -0.8370,\n",
      "         -2.4200, -2.1734]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.440187931060791\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0560, -1.1601, -9.2059, -4.8351, -5.1254, -3.3995, -2.2995, -1.1609,\n",
      "         -2.3368, -2.0546]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.2995285987854004\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.4375, -1.5542, -9.4239, -4.5001, -5.8066, -3.6098, -0.8637, -1.9203,\n",
      "         -2.5738, -2.2793]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.80656623840332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.1871,  -2.4748, -10.0259,  -4.6129,  -6.0999,  -4.2256,  -0.2826,\n",
      "          -3.1165,  -3.2499,  -2.9608]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  8.18709945678711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.9708,  -3.2074, -10.4078,  -4.5621,  -6.2055,  -4.6311,  -0.1461,\n",
      "          -4.0658,  -3.7274,  -3.4516]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.1461091786623001\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.9250,  -4.0467, -10.9006,  -4.6734,  -6.4508,  -5.1525,  -0.0738,\n",
      "          -5.0820,  -4.3243,  -4.0651]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.324329853057861\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.2987,  -4.2302, -10.7589,  -4.1956,  -6.0875,  -5.0410,  -0.0943,\n",
      "          -5.4161,  -3.5399,  -4.0445]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.298691272735596\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4822,  -3.8806, -10.1054,  -3.2514,  -5.2361,  -4.4197,  -0.2403,\n",
      "          -5.1942,  -2.3293,  -3.5127]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  10.105390548706055\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7280, -3.4599, -8.6613, -2.3102, -4.3517, -3.7479, -0.8125, -4.8770,\n",
      "         -1.1904, -2.9337]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.1903860569000244\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9350, -3.8740, -8.1301, -2.3102, -4.3338, -3.9301, -2.4141, -5.3659,\n",
      "         -0.4159, -3.2197]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.310215950012207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4528, -4.4557, -7.8450, -1.7936, -4.5203, -4.3024, -4.1135, -6.0027,\n",
      "         -0.4041, -3.6992]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.113473892211914\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8806, -4.7876, -7.3878, -1.2589, -4.4954, -4.4472, -4.7345, -6.3771,\n",
      "         -0.6893, -3.9480]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.495378017425537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3991, -5.0151, -6.8989, -0.9238, -3.6772, -4.5089, -5.2223, -6.6377,\n",
      "         -1.2410, -4.1082]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.898900508880615\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0859, -5.1649, -5.6682, -0.8753, -2.8988, -4.5128, -5.6053, -6.8133,\n",
      "         -1.8923, -4.2043]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.813281536102295\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9332, -5.1867, -4.4450, -1.0425, -2.1205, -4.4074, -5.8354, -6.1236,\n",
      "         -2.4733, -4.1842]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.835407733917236\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9939, -5.1216, -3.2632, -1.3818, -1.4180, -4.2328, -5.2403, -5.4152,\n",
      "         -2.9701, -4.0880]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.1215620040893555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3254, -4.3139, -2.2338, -1.8918, -0.9683, -4.0934, -4.7148, -4.7872,\n",
      "         -3.4623, -4.0202]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.2337985038757324\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0890, -3.8678, -0.9267, -2.7408, -1.1108, -4.2518, -4.5191, -4.4989,\n",
      "         -4.1998, -4.2432]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.9267047047615051\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7411, -4.3561, -0.1840, -4.4304, -2.3528, -5.2796, -5.2248, -5.1215,\n",
      "         -5.7492, -5.3285]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.121520519256592\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1852, -4.7447, -0.0653, -5.9002, -3.4795, -6.1480, -5.8032, -4.8976,\n",
      "         -7.0858, -6.2484]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.479475736618042\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9271, -4.5387, -0.0801, -6.6634, -3.2271, -6.3692, -5.7636, -4.1390,\n",
      "         -7.7275, -6.5156]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.927077770233154\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3002, -3.7958, -0.1976, -6.7861, -2.4631, -6.0041, -5.1647, -2.9020,\n",
      "         -7.7401, -6.1917]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.9019851684570312\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7075, -3.1120, -0.8639, -6.8655, -1.8051, -5.6454, -4.5976, -1.0712,\n",
      "         -7.7198, -5.8696]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.8639480471611023\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9341, -3.2840, -1.7981, -7.6916, -2.0859, -6.0788, -4.8479, -0.4263,\n",
      "         -8.4557, -6.3354]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.934116840362549\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3430, -3.3939, -2.6854, -8.3623, -2.3554, -6.3973, -5.0053, -0.2479,\n",
      "         -9.0448, -6.6826]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.00532865524292\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4407, -3.1389, -3.1543, -8.5869, -2.2876, -6.3059, -4.0580, -0.2748,\n",
      "         -9.1960, -6.6166]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.616569995880127\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3284, -2.6192, -3.2841, -8.4661, -1.9772, -5.9018, -2.8942, -0.5254,\n",
      "         -9.0089, -5.5104]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.3283941745758057\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9303, -2.4638, -3.6851, -8.6143, -2.0553, -5.7970, -2.1427, -1.4347,\n",
      "         -9.0975, -4.7742]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.4637811183929443\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4804, -2.1494, -4.5863, -9.2699, -2.7408, -6.2269, -2.0720, -2.9476,\n",
      "         -9.6992, -4.6393]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.48039644956588745\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2370,  -2.3933,  -5.8433, -10.2986,  -3.8433,  -7.0537,  -2.5367,\n",
      "          -4.7860, -10.6794,  -4.9631]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.679364204406738\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2162,  -2.3070,  -6.6018, -10.8493,  -4.4761,  -7.4234,  -2.6363,\n",
      "          -6.0719, -10.4396,  -4.8842]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.423357963562012\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3295,  -1.8541,  -6.8347, -10.8940,  -4.6031,  -6.5321,  -2.3262,\n",
      "          -6.7803,  -9.7726,  -4.3675]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.32948604226112366\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3759,  -1.7131,  -7.1925, -11.0818,  -4.8722,  -5.8780,  -2.2645,\n",
      "          -7.5665,  -9.3194,  -4.0588]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.0588297843933105\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6121,  -1.4223,  -7.2140, -10.9496,  -4.8188,  -4.9900,  -1.9821,\n",
      "          -7.9735,  -8.6102,  -2.7693]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.422347068786621\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4241,  -0.7915,  -7.4425, -11.0391,  -4.9852,  -4.4042,  -2.0353,\n",
      "          -8.5488,  -8.1802,  -1.8621]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.4241249561309814\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8069,  -0.7690,  -7.8489, -11.3200,  -5.3403,  -4.0865,  -2.3773,\n",
      "          -9.2672,  -7.9936,  -1.3582]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.993557929992676\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1215,  -0.9531,  -8.0669, -11.4247,  -5.5152,  -3.6651,  -2.6036,\n",
      "          -9.7659,  -6.9336,  -0.9426]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.066850662231445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3333,  -1.2540,  -7.3795, -11.3610,  -5.5178,  -3.1476,  -2.7026,\n",
      "         -10.0571,  -5.8220,  -0.6931]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  11.361028671264648\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3998,  -1.5478,  -6.5670, -10.3160,  -5.3290,  -2.5209,  -2.6459,\n",
      "         -10.1252,  -4.6291,  -0.6365]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.328972339630127\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3576,  -1.8064,  -5.6687,  -9.2074,  -4.2650,  -1.8514,  -2.4783,\n",
      "         -10.0190,  -3.3946,  -0.8008]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.8063688278198242\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4897,  -1.5049,  -4.9643,  -8.3112,  -3.4191,  -1.4723,  -2.4895,\n",
      "         -10.0252,  -2.4100,  -1.3749]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  10.025238037109375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7404, -1.4737, -4.4068, -7.5761, -2.7532, -1.3811, -2.6312, -9.3762,\n",
      "         -1.6623, -2.1466]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.3810917139053345\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2776, -1.8844, -4.1786, -7.1795, -2.4649, -0.9830, -3.0755, -9.0567,\n",
      "         -1.3957, -3.1909]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.178601264953613\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7552, -2.3361, -3.2273, -6.7895, -2.2339, -0.8813, -3.4754, -8.7356,\n",
      "         -1.3073, -4.1275]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.8813422322273254\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4418, -3.0560, -2.6391, -6.6789, -2.3440, -0.5761, -4.0975, -8.6863,\n",
      "         -1.6698, -5.2224]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.6391308307647705\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0249, -3.6964, -1.3974, -6.5367, -2.4696, -0.6932, -4.6260, -8.5984,\n",
      "         -2.0933, -6.1684]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.168443202972412\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6619, -4.3990, -0.5655, -6.5169, -2.7518, -1.2924, -5.2160, -8.6264,\n",
      "         -2.6739, -6.4035]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.398991584777832\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2711, -4.3147, -0.2611, -6.5334, -3.0857, -2.0773, -5.7844, -8.6850,\n",
      "         -3.2816, -6.6495]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.784387111663818\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4819, -3.9098, -0.2044, -6.2103, -3.0807, -2.5418, -5.2385, -8.3987,\n",
      "         -3.5177, -6.5329]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.90978741645813\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2709, -2.4042, -0.3377, -5.5190, -2.7079, -2.6190, -4.3488, -7.7391,\n",
      "         -3.3506, -6.0269]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.348807334899902\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0541, -1.0886, -0.9410, -4.8715, -2.3929, -2.7168, -2.8125, -7.1173,\n",
      "         -3.1983, -5.5449]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.088578701019287\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7584, -0.3027, -2.6618, -5.1925, -3.0742, -3.7539, -2.3701, -7.4559,\n",
      "         -3.9896, -6.0115]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.661799430847168\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.4566, -0.2174, -3.6044, -5.5490, -3.7846, -4.7691, -2.1020, -7.8243,\n",
      "         -4.7791, -6.4966]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.604416847229004\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.6752, -0.3364, -3.3468, -5.4628, -4.0307, -5.2793, -1.5381, -7.7459,\n",
      "         -5.0859, -6.5241]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.74587345123291\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5900, -0.6968, -2.8575, -5.1061, -3.9827, -5.4603, -0.9024, -6.6665,\n",
      "         -5.0844, -6.2674]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.106087684631348\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.4349, -1.3156, -2.3793, -3.9153, -3.8746, -5.5477, -0.5430, -5.6167,\n",
      "         -5.0089, -5.9590]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.91530704498291\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.2558, -2.0340, -1.9749, -2.0298, -3.7525, -5.5897, -0.5969, -4.6342,\n",
      "         -4.9061, -5.6432]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.255799293518066\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6393, -3.0488, -1.9801, -0.7063, -3.9299, -5.9003, -1.3102, -4.0265,\n",
      "         -5.0890, -5.6314]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.631402492523193\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4366, -4.3497, -2.4350, -0.2585, -4.4555, -6.5336, -2.4974, -3.8438,\n",
      "         -5.6099, -5.2506]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.4349701404571533\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0481, -5.3235, -1.9859, -0.2608, -4.7301, -6.8977, -3.4183, -3.4876,\n",
      "         -5.8744, -4.7043]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.730067253112793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3396, -5.8438, -1.3193, -0.5107, -3.8891, -6.8661, -3.9108, -2.8289,\n",
      "         -5.7544, -3.8586]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.858628034591675\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6709, -6.2802, -0.8758, -1.1735, -3.1126, -6.8042, -4.3344, -2.2447,\n",
      "         -5.6145, -2.3576]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.3575856685638428\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5326, -7.1316, -1.2309, -2.4708, -2.9031, -7.2064, -5.1823, -2.2530,\n",
      "         -5.9483, -0.8142]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.9031386375427246\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9662, -8.4492, -2.3095, -4.2558, -2.5741, -8.1194, -6.5001, -2.8875,\n",
      "         -6.8011, -0.2951]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.255804061889648\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2202, -9.4942, -3.2102, -4.9432, -2.1922, -8.8002, -7.5463, -3.3581,\n",
      "         -7.4284, -0.2240]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.22402283549308777\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6166, -10.5990,  -4.2138,  -5.7315,  -2.0940,  -9.5771,  -8.6525,\n",
      "          -3.9710,  -8.1574,  -0.1795]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.731532096862793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5022, -11.1200,  -4.6541,  -5.1870,  -1.6219,  -9.8029,  -9.1748,\n",
      "          -4.0627,  -8.3402,  -0.2670]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.502226829528809\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3359, -11.2479,  -4.7162,  -4.3598,  -1.0006,  -9.6649,  -9.3039,\n",
      "          -3.8167,  -8.1637,  -0.5532]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.000630259513855\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6430, -11.7109,  -5.1264,  -3.9728,  -0.3263,  -9.8887,  -9.7682,\n",
      "          -3.9592,  -8.3529,  -1.5700]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.888665199279785\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9836, -12.0733,  -5.4455,  -3.5846,  -0.1939,  -9.2571, -10.1317,\n",
      "          -4.0470,  -8.4689,  -2.5799]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  10.131714820861816\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0466, -12.0196,  -5.3559,  -2.8768,  -0.2963,  -8.3084,  -9.3585,\n",
      "          -3.7587,  -8.1935,  -3.1634]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  12.019612312316895\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1109, -11.0319,  -5.0926,  -2.0976,  -0.7434,  -7.2684,  -8.4764,\n",
      "          -3.3303,  -7.7597,  -3.5333]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  11.031882286071777\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6338, -9.5207, -4.9858, -1.6181, -1.6173, -6.4582, -7.8081, -3.0966,\n",
      "         -7.4953, -4.0130]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.6181294918060303\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8386, -8.4085, -5.1429, -0.8078, -2.7971, -5.9784, -7.4551, -3.1679,\n",
      "         -7.5061, -4.7065]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.797058343887329\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3474, -7.4176, -5.2991, -0.4381, -3.1840, -5.5588, -7.1481, -3.2734,\n",
      "         -7.5267, -5.3479]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.417620658874512\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7182, -5.5058, -5.1671, -0.3336, -3.2862, -4.9078, -6.5959, -3.1199,\n",
      "         -7.2693, -5.6526]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.269339561462402\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8177, -3.4227, -4.6876, -0.4331, -3.0408, -3.9626, -5.7350, -2.6496,\n",
      "         -5.9172, -5.5648]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.4330587387084961\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3315, -1.8776, -4.5686, -0.5543, -3.1607, -3.4325, -5.2683, -2.5841,\n",
      "         -5.0078, -5.7946]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.79461145401001\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9938, -0.7297, -4.5979, -1.2394, -3.4285, -3.1093, -4.9807, -2.7096,\n",
      "         -4.3229, -5.4143]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.99379301071167\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1701, -0.3293, -4.9031, -2.3531, -3.9648, -3.1249, -4.9983, -3.1433,\n",
      "         -3.9878, -5.3467]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.1700832843780518\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4495, -0.3208, -4.9967, -3.2436, -4.2751, -2.9868, -4.8325, -3.3790,\n",
      "         -3.5137, -5.1028]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.5136830806732178\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6497, -0.6406, -4.8725, -3.8625, -4.3512, -2.6885, -4.4756, -3.4030,\n",
      "         -2.1425, -4.6740]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.6405829191207886\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4420, -0.9489, -5.1396, -4.8095, -4.8024, -2.8465, -4.5359, -3.8225,\n",
      "         -1.3699, -4.6681]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.8224661350250244\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4185, -1.5073, -5.3766, -5.6608, -5.2071, -3.0266, -4.5901, -3.4729,\n",
      "         -0.8587, -4.6617]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.02657151222229\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5369, -2.1392, -5.5574, -6.3943, -5.5396, -2.4098, -4.6105, -3.1451,\n",
      "         -0.6830, -4.6269]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.5368869304656982\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1102, -2.8302, -5.7572, -7.0902, -5.8760, -1.9588, -4.6702, -2.9158,\n",
      "         -0.9405, -4.6368]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.8301570415496826\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9160, -2.7026, -5.8910, -7.6692, -6.1326, -1.6146, -4.6824, -2.7008,\n",
      "         -1.4186, -4.6043]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.6146146059036255\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1847, -2.7918, -6.1678, -8.3450, -6.5195, -0.8356, -4.8543, -2.7108,\n",
      "         -2.1859, -4.7364]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.345048904418945\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6493, -2.9194, -6.4201, -8.1746, -6.8706, -0.4744, -5.0164, -2.7705,\n",
      "         -2.9634, -4.8634]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.9633584022521973\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9968, -2.8646, -6.4386, -7.8115, -6.9776, -0.4244, -4.9573, -2.6605,\n",
      "         -2.7377, -4.7734]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.996828317642212\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4901, -2.6626, -6.2614, -7.2897, -6.8795, -0.6925, -4.7141, -2.4179,\n",
      "         -2.3881, -4.5034]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.388087749481201\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2263, -2.5625, -6.1330, -6.8503, -6.8218, -1.3518, -4.5315, -2.2950,\n",
      "         -1.4217, -4.2980]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.2263460159301758\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8406, -2.8906, -6.3797, -6.8161, -7.1315, -2.5070, -4.7356, -2.6195,\n",
      "         -1.0936, -4.4837]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.1314697265625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7383, -3.1614, -6.5369, -6.7201, -6.6140, -3.5443, -4.8597, -2.8992,\n",
      "         -0.9838, -4.5929]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.9838465452194214\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1183, -3.5646, -6.8074, -6.7624, -6.2769, -4.6286, -5.1049, -3.3196,\n",
      "         -0.5435, -4.8264]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.2768778800964355\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4816, -3.7346, -6.8375, -6.5873, -5.0345, -5.3985, -5.1159, -3.5108,\n",
      "         -0.3689, -4.8282]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.587252140045166\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6250, -3.5583, -6.5182, -5.3055, -3.5732, -5.7479, -4.7829, -3.3576,\n",
      "         -0.3820, -4.4884]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.6250464916229248\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1079, -3.3529, -6.1638, -4.0874, -2.2100, -5.9971, -4.4212, -3.1776,\n",
      "         -0.8352, -4.1226]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.8351917862892151\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2039, -3.5183, -6.1704, -3.3277, -1.3867, -6.5476, -4.4285, -3.3705,\n",
      "         -1.1437, -4.1291]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.547623634338379\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5089, -3.6923, -6.1808, -2.6746, -0.8307, -6.2692, -4.4467, -3.5726,\n",
      "         -1.6622, -4.1496]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.446732521057129\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9168, -3.8418, -6.1658, -2.1145, -0.6223, -5.9941, -3.7182, -3.7496,\n",
      "         -2.2449, -4.1536]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.165788650512695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2580, -3.8607, -5.2970, -1.5725, -0.6940, -5.6166, -2.9481, -3.7946,\n",
      "         -2.7168, -4.0368]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.25799298286438\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8995, -3.8719, -4.4966, -1.2249, -1.1006, -5.2578, -2.2712, -3.8301,\n",
      "         -3.1695, -3.9228]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.2248576879501343\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9907, -4.2040, -4.0905, -0.6685, -2.0152, -5.2453, -2.0433, -4.1847,\n",
      "         -3.9151, -4.1410]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.203979969024658\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1355, -3.7312, -3.7016, -0.5318, -2.9004, -5.2026, -1.8972, -4.4798,\n",
      "         -4.5659, -4.3136]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.313576698303223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1363, -3.1090, -3.1548, -0.6516, -3.5231, -4.9541, -1.6605, -4.5395,\n",
      "         -4.9453, -3.5404]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.108978509902954\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1698, -1.7868, -2.6414, -1.1121, -4.0532, -4.6836, -1.5340, -4.5491,\n",
      "         -5.2401, -2.8130]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2.1698355674743652\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8458, -1.0027, -2.5123, -2.0636, -4.8247, -4.7288, -1.8588, -4.8471,\n",
      "         -5.7910, -2.4830]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.482987880706787\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8746, -0.7777, -2.6624, -3.2264, -5.7326, -4.9837, -2.4724, -5.3286,\n",
      "         -6.4967, -1.7326]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.983659267425537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9837, -0.8907, -2.8214, -4.2773, -6.5254, -4.4156, -3.0595, -5.7388,\n",
      "         -7.1063, -1.1578]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.277297019958496\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0942, -1.2115, -2.9213, -4.3698, -7.1539, -3.8269, -3.5359, -6.0240,\n",
      "         -7.5692, -0.7810]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.153903007507324\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1305, -1.5705, -2.8990, -4.3114, -6.8389, -3.1622, -3.8346, -6.1310,\n",
      "         -7.8349, -0.6214]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.899016857147217\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1155, -1.9155, -2.0596, -4.1361, -6.4229, -2.4635, -3.9863, -6.0959,\n",
      "         -7.9414, -0.7325]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.136104106903076\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1627, -2.3098, -1.3704, -3.1921, -6.0235, -1.8745, -4.1105, -6.0400,\n",
      "         -8.0115, -1.1532]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.8745206594467163\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5857, -3.0367, -1.2324, -2.6718, -5.9636, -0.9868, -4.5322, -6.2893,\n",
      "         -8.3728, -2.0575]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.671804904937744\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2436, -3.9498, -1.5429, -1.7113, -6.1341, -0.6998, -5.1425, -6.7378,\n",
      "         -8.9209, -3.1866]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.134127140045166\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8648, -4.7871, -1.9787, -0.9865, -5.5637, -0.8278, -5.6971, -7.1434,\n",
      "         -9.4154, -4.2340]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.864812135696411\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6606, -5.4873, -2.4116, -0.5618, -4.9927, -1.2216, -6.1389, -7.4492,\n",
      "         -9.8007, -5.1276]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.127583980560303\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2859, -5.9114, -2.6573, -0.4097, -4.2742, -1.5952, -6.3289, -7.5155,\n",
      "         -9.9383, -5.0045]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.328887462615967\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6530, -5.9731, -2.6074, -0.4610, -3.3151, -1.7665, -5.4474, -7.2535,\n",
      "         -9.7399, -4.5763]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.653010368347168\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3422, -5.9544, -2.5399, -0.9145, -2.4017, -1.9770, -4.5806, -6.9418,\n",
      "         -9.4852, -4.1219]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.914541482925415\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7893, -6.3795, -2.9767, -1.3023, -2.0854, -2.7140, -4.2477, -7.1019,\n",
      "         -9.6960, -4.1645]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.101948261260986\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5640, -6.7104, -3.3540, -1.8067, -1.8380, -3.3758, -3.9052, -6.4475,\n",
      "         -9.8326, -4.1609]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.837953805923462\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7793, -7.0201, -3.7300, -2.3976, -1.0150, -4.0091, -3.6223, -5.8702,\n",
      "         -9.9664, -4.1797]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.729973793029785\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3063,  -7.3045,  -3.3627,  -3.0044,  -0.5430,  -4.5984,  -3.3921,\n",
      "          -5.3574, -10.0919,  -4.2126]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.5984015464782715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8364,  -7.4232,  -2.9192,  -3.4508,  -0.4029,  -4.2230,  -3.0715,\n",
      "          -4.7612, -10.0670,  -4.1150]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.450824737548828\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1918, -7.2944, -2.3232, -2.8740, -0.5260, -3.6603, -2.5808, -3.9947,\n",
      "         -9.8085, -3.8028]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.5807743072509766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5977, -7.1849, -1.8637, -2.4037, -1.0709, -3.1795, -1.4694, -3.3242,\n",
      "         -9.5818, -3.5439]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.5438599586486816\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2637, -7.3341, -1.8102, -2.2967, -2.0569, -3.0259, -0.8844, -2.9946,\n",
      "         -9.6248, -2.8574]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.8101569414138794\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0934, -7.6714, -1.3567, -2.4799, -3.2400, -3.1278, -0.8625, -2.9378,\n",
      "         -9.8662, -2.4833]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.127768039703369\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8246,  -7.9476,  -1.1079,  -2.6812,  -4.3059,  -2.4535,  -1.1237,\n",
      "          -2.8984, -10.0556,  -2.1788]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.89839506149292\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4803,  -8.1883,  -1.1158,  -2.9066,  -5.2671,  -1.9044,  -1.5882,\n",
      "          -2.1500, -10.2179,  -1.9780]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.115761637687683\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.3131,  -8.6445,  -0.8742,  -3.3908,  -6.3757,  -1.7645,  -2.3952,\n",
      "          -1.8024, -10.6034,  -2.1365]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.3952369689941406\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0182,  -9.0093,  -0.9138,  -3.8066,  -7.3290,  -1.7249,  -2.4115,\n",
      "          -1.5666, -10.9044,  -2.3184]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.018189907073975\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.7714,  -9.1729,  -1.0756,  -4.0330,  -8.0230,  -1.6621,  -2.3265,\n",
      "          -1.3453, -11.0105,  -2.3885]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.662128210067749\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6097,  -9.3800,  -1.5286,  -4.3103,  -8.7078,  -1.0405,  -2.3811,\n",
      "          -1.4006, -11.1657,  -2.5777]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  11.165745735168457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.4072,  -9.5088,  -2.0361,  -4.5125,  -9.2668,  -0.6959,  -2.4400,\n",
      "          -1.5768, -10.4906,  -2.7452]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  9.508772850036621\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0405, -8.6880, -2.4022, -4.5174, -9.5846, -0.5849, -2.3711, -1.7044,\n",
      "         -9.6971, -2.7570]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  9.697114944458008\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4517, -7.6888, -2.5374, -4.2699, -9.6105, -0.6540, -2.1170, -1.6950,\n",
      "         -7.9705, -2.5533]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.5373950004577637\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7967, -6.6615, -1.8624, -3.9300, -9.5060, -0.9881, -1.8484, -1.6961,\n",
      "         -6.2881, -2.2984]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.848440408706665\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3638, -5.8884, -1.5181, -3.7900, -9.5630, -1.7261, -1.1422, -1.9852,\n",
      "         -4.9255, -2.2926]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.9852063655853271\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1508, -5.3620, -1.5346, -3.8489, -9.7819, -2.6951, -0.9070, -1.7675,\n",
      "         -3.8717, -2.5284]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.848938465118408\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9148, -4.8360, -1.6503, -3.0946, -9.9236, -3.5642, -0.9344, -1.6435,\n",
      "         -2.8831, -2.7431]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.564244270324707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6731,  -4.3247,  -1.8502,  -2.4065, -10.0076,  -3.5536,  -1.2020,\n",
      "          -1.6327,  -1.9916,  -2.9395]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.8502225875854492\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6185,  -4.0192,  -1.5640,  -2.0010, -10.2281,  -3.7108,  -1.8069,\n",
      "          -1.9139,  -1.4370,  -3.2997]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.228139877319336\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6086, -3.7776, -1.4779, -1.7599, -9.7174, -3.8912, -2.4915, -2.2973,\n",
      "         -1.1376, -3.6708]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.7598668336868286\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7497, -3.7077, -1.6960, -1.0389, -9.3880, -4.1997, -3.2988, -2.8481,\n",
      "         -1.2412, -4.1539]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.0389392375946045\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3455, -4.1152, -2.4772, -0.3482, -9.5433, -4.9409, -4.5045, -3.8394,\n",
      "         -2.0053, -5.0522]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.543327331542969\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7886, -4.3917, -3.1387, -0.1658, -8.8554, -5.5111, -5.4956, -4.6453,\n",
      "         -2.6924, -5.7630]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  4.7886247634887695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9837, -4.1586, -3.2745, -0.1579, -7.7446, -5.5362, -5.8996, -4.8869,\n",
      "         -2.8711, -5.9140]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.1579185575246811\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3788, -4.0671, -3.5307, -0.1459, -6.8513, -5.6685, -6.3720, -5.2166,\n",
      "         -3.1815, -6.1584]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.216586589813232\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3450, -3.4840, -3.2690, -0.2789, -5.5340, -5.2765, -6.2848, -4.2558,\n",
      "         -2.9788, -5.8664]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.284842491149902\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2883, -2.7873, -2.8662, -0.7768, -4.1559, -4.7327, -5.2819, -3.2065,\n",
      "         -2.6401, -5.4107]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.2882978916168213\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4465, -2.8360, -3.1742, -2.2025, -3.5558, -4.8792, -5.0118, -2.9212,\n",
      "         -3.0185, -5.6329]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.4465385377407074\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.1465, -3.6405, -4.1983, -4.2864, -3.7525, -5.7332, -5.4898, -3.4209,\n",
      "         -4.1128, -6.5520]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.11277961730957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.1205, -4.0071, -4.7536, -5.7955, -3.5690, -6.1270, -5.5455, -3.5176,\n",
      "         -3.9747, -7.0029]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.002881050109863\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.1982, -3.8177, -4.7265, -6.6235, -2.8910, -5.9500, -5.0651, -3.0936,\n",
      "         -3.3312, -6.1476]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.0935778617858887\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5971, -3.4083, -4.4532, -7.1145, -2.0656, -5.5371, -4.3818, -1.7445,\n",
      "         -2.5235, -5.1236]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.453189849853516\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6076, -3.3247, -3.7490, -7.8173, -1.6749, -5.4284, -4.0355, -0.9203,\n",
      "         -2.1168, -4.4658]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.465794563293457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8713, -3.4878, -3.3429, -8.6613, -1.6709, -5.5448, -3.9477, -0.6868,\n",
      "         -2.0530, -3.3682]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.0529634952545166\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1087, -3.7171, -3.0622, -9.4808, -1.8640, -5.7119, -3.9420, -0.9114,\n",
      "         -1.3960, -2.4642]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.3960037231445312\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5946,  -4.3019,  -3.2033, -10.5786,  -2.5112,  -6.2249,  -4.3110,\n",
      "          -1.7732,  -0.5982,  -2.0719]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.511195182800293\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0480,  -4.9516,  -3.4727, -11.6799,  -2.5363,  -6.8011,  -4.7658,\n",
      "          -2.7886,  -0.4086,  -1.9231]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.95159387588501\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.0867,  -4.5133,  -3.4672, -12.4009,  -2.3459,  -7.0501,  -4.9110,\n",
      "          -3.4782,  -0.4689,  -1.6248]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.6248173713684082\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.0296,  -4.1344,  -3.4923, -13.0575,  -2.2518,  -7.2823,  -5.0544,\n",
      "          -4.1295,  -1.0012,  -0.7817]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.134379863739014\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.9472,  -3.1209,  -3.6056, -13.7172,  -2.3124,  -7.5605,  -5.2568,\n",
      "          -4.7966,  -1.8252,  -0.4239]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.825246810913086\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.7036,  -2.1717,  -3.6575, -14.2415,  -2.3694,  -7.7416,  -5.3730,\n",
      "          -5.3335,  -1.8666,  -0.5073]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.17171049118042\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.5060,  -0.7743,  -3.8444, -14.8347,  -2.6103,  -8.0262,  -5.6023,\n",
      "          -5.9418,  -2.1411,  -1.1398]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.026168823242188\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.6013,  -0.2372,  -4.4010, -15.7417,  -3.2537,  -7.8816,  -6.1843,\n",
      "          -6.8644,  -2.8493,  -2.3137]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.3137285709381104\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.4027,  -0.1641,  -4.7263, -16.3736,  -3.6766,  -7.5668,  -6.5250,\n",
      "          -7.5110,  -3.3456,  -2.5333]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  16.37359619140625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.5940,  -0.2050,  -4.4954, -15.6492,  -3.5455,  -6.7535,  -6.3025,\n",
      "          -7.5633,  -3.2887,  -2.2581]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.753494739532471\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.3248,  -0.4088,  -3.8541, -14.5554,  -3.0070,  -4.8116,  -5.6620,\n",
      "          -7.1694,  -2.8240,  -1.6443]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.0070462226867676\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.0489,  -1.0534,  -3.2586, -13.5370,  -1.7947,  -3.0357,  -5.0544,\n",
      "          -6.7817,  -2.4167,  -1.1979]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.054384231567383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.1294,  -2.2226,  -3.0795, -12.9490,  -1.1534,  -1.8028,  -4.1066,\n",
      "          -6.7624,  -2.4460,  -1.3432]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  13.129375457763672\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.7336,  -3.6046,  -3.2003, -12.6679,  -1.0549,  -1.0684,  -3.5136,\n",
      "          -6.9944,  -2.7861,  -1.9112]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.2002837657928467\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.4355,  -4.9277,  -2.6676, -12.4731,  -1.2789,  -0.7312,  -3.0599,\n",
      "          -7.2622,  -3.1971,  -2.5880]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.1970858573913574\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.0722,  -6.0297,  -2.1438, -12.2028,  -1.5889,  -0.7047,  -2.5910,\n",
      "          -7.4090,  -2.7512,  -3.1570]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.5909628868103027\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.7382,  -7.0169,  -1.7509, -11.9526,  -2.0103,  -1.0554,  -1.4851,\n",
      "          -7.5349,  -2.3908,  -3.6933]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.4851007461547852\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.9719,  -8.4409,  -2.0582, -12.2617,  -3.0220,  -2.1739,  -0.4601,\n",
      "          -8.1830,  -2.6695,  -4.7287]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.4600537419319153\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.0061, -10.5471,  -3.2521, -13.3639,  -4.7925,  -4.0927,  -0.0918,\n",
      "          -9.5906,  -3.7964,  -6.4912]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.590591430664062\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.5454, -12.0516,  -3.9634, -13.9643,  -6.0007,  -5.4412,  -0.0389,\n",
      "          -9.7161,  -4.4359,  -7.6874]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.000732421875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.3760, -12.7514,  -3.9628, -13.8500,  -5.7050,  -6.0040,  -0.0387,\n",
      "          -9.1742,  -4.3657,  -8.1098]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  12.75143814086914\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.5645, -11.9734,  -3.3171, -13.0880,  -4.7821,  -5.8536,  -0.0770,\n",
      "          -8.0274,  -3.6531,  -7.8314]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  12.564464569091797\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.5977, -10.7522,  -2.2418, -11.8814,  -3.4366,  -5.1999,  -0.2583,\n",
      "          -6.4744,  -2.5104,  -7.0605]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.060510635375977\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.8015,  -9.6273,  -1.3259, -10.7695,  -2.2232,  -4.5901,  -0.9508,\n",
      "          -5.0517,  -1.5173,  -5.6162]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.616236686706543\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.5743,  -9.0046,  -1.0858, -10.1585,  -1.5999,  -4.4391,  -2.2423,\n",
      "          -4.1657,  -1.1786,  -3.9884]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  10.158477783203125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5857, -8.5600, -1.2329, -8.9602, -1.3022, -4.4283, -3.5980, -3.4956,\n",
      "         -1.2215, -2.6520]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.232923984527588\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9187, -8.3820, -1.0685, -8.1035, -1.4551, -4.6501, -5.0607, -3.1373,\n",
      "         -1.7046, -1.7219]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.382003784179688\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3402, -7.4967, -1.1920, -7.3525, -1.7836, -4.8774, -6.4026, -2.8675,\n",
      "         -2.2969, -1.0338]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.867495059967041\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8791, -6.7563, -1.5814, -6.7330, -2.2584, -5.1443, -7.6683, -1.9741,\n",
      "         -2.9623, -0.7278]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.756254196166992\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4352, -5.3157, -2.0484, -6.1420, -2.7284, -5.3549, -8.7743, -1.2398,\n",
      "         -3.5665, -0.7673]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.0483720302581787\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0751, -4.0532, -1.8628, -5.6425, -3.2303, -5.5794, -9.8013, -0.8271,\n",
      "         -4.1628, -1.1692]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.8271203637123108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1150,  -3.2813,  -2.1611,  -5.5475,  -4.0633,  -6.1364, -11.0782,\n",
      "          -0.3861,  -5.0635,  -2.1072]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.1072208881378174\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0479,  -2.4994,  -2.3991,  -5.3501,  -4.7112,  -6.5249, -12.1131,\n",
      "          -0.3845,  -5.7647,  -2.2027]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  12.113146781921387\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7253,  -1.5818,  -2.4049,  -4.9012,  -5.0264,  -6.6010, -12.0455,\n",
      "          -0.6177,  -6.1235,  -2.0935]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.404909372329712\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4957,  -0.9524,  -1.7905,  -4.5463,  -5.3585,  -6.7141, -12.0281,\n",
      "          -1.2736,  -6.4918,  -2.1276]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  12.028116226196289\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3646,  -0.7273,  -1.4128,  -4.2886,  -5.7149,  -6.8708, -11.3466,\n",
      "          -2.1270,  -6.8785,  -2.2980]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.3646016120910645\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4797,  -0.8109,  -1.1766,  -3.9935,  -5.9645,  -6.9390, -10.6592,\n",
      "          -2.9109,  -7.1537,  -2.4503]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.4503488540649414\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7169,  -1.1907,  -1.1625,  -3.7157,  -6.1649,  -6.9748, -10.0140,\n",
      "          -3.6310,  -7.3759,  -1.9029]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.974849224090576\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1651, -1.7647, -1.3838, -3.4901, -6.3527, -6.2372, -9.4389, -4.3052,\n",
      "         -7.5823, -1.5234]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.383805274963379\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0462, -2.5625, -1.1903, -3.4639, -6.6766, -5.7280, -9.0745, -5.0758,\n",
      "         -7.9219, -1.4920]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.4920004606246948\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2632, -3.4096, -1.3089, -3.5357, -7.0404, -5.3433, -8.8179, -5.8458,\n",
      "         -8.2994, -0.9782]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.8457536697387695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5536, -4.0887, -1.5041, -3.5145, -7.2604, -4.8922, -8.4785, -5.6842,\n",
      "         -8.5311, -0.6778]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.8921990394592285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7786, -4.5241, -1.6531, -3.3298, -7.2703, -3.5311, -7.9844, -5.3527,\n",
      "         -8.5513, -0.5838]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.2703142166137695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9151, -4.7365, -1.7391, -3.0033, -6.3577, -2.1405, -7.3521, -4.8700,\n",
      "         -8.3819, -0.7119]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.73906672000885\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3139, -5.1041, -1.3859, -2.9175, -5.7070, -1.1493, -6.9530, -4.6109,\n",
      "         -8.3994, -1.3488]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.149251937866211\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3662, -6.0618, -1.8719, -3.5041, -5.7456, -0.3520, -7.2164, -5.0071,\n",
      "         -9.0373, -2.7305]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  9.03732681274414\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3205, -6.9076, -2.4032, -4.0373, -5.7645, -0.1616, -7.4359, -5.3507,\n",
      "         -8.8350, -4.0032]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.435935974121094\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6889, -7.1695, -2.4469, -4.0305, -5.2833, -0.1467, -6.4131, -5.1630,\n",
      "         -8.1524, -4.6619]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.661888122558594\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4890, -6.8677, -2.0112, -3.4999, -4.3155, -0.2580, -4.9551, -4.4602,\n",
      "         -6.9998, -4.0048]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.999820709228516\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0249, -6.3045, -1.4241, -2.7534, -3.1617, -0.6562, -3.3551, -3.5438,\n",
      "         -4.9165, -3.1339]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.133941411972046\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8793, -6.0581, -1.3302, -2.3898, -2.4133, -1.6700, -2.1989, -2.9996,\n",
      "         -3.3054, -1.9260]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.3053886890411377\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2890, -6.3638, -1.9641, -2.6592, -2.3312, -3.2527, -1.7639, -3.0728,\n",
      "         -1.6584, -1.4683]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.2527194023132324\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0987, -7.0713, -3.0681, -3.3870, -2.7599, -4.3695, -1.9270, -3.6044,\n",
      "         -0.7502, -1.6518]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.9269917011260986\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0328, -7.9096, -4.2968, -4.2692, -3.3931, -5.5854, -1.6592, -4.3041,\n",
      "         -0.4901, -2.1548]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.154844284057617\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7432, -8.5322, -5.2805, -4.9419, -3.8556, -6.5505, -1.4229, -4.8118,\n",
      "         -0.5858, -1.8450]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.8117804527282715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.1665, -8.8758, -5.9529, -5.3360, -4.0705, -7.2035, -1.1671, -4.3092,\n",
      "         -0.8739, -1.4617]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.4617185592651367\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.6916, -9.3287, -6.7036, -5.8380, -4.4200, -7.9355, -1.3048, -4.0101,\n",
      "         -1.5904, -0.7139]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.7139078974723816\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.6974, -10.2692,  -7.9131,  -6.8249,  -5.2762,  -9.1274,  -2.1573,\n",
      "          -4.2870,  -2.9215,  -0.2109]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.824874401092529\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.3720, -10.8849,  -8.7712,  -6.7086,  -5.8197,  -9.9696,  -2.7772,\n",
      "          -4.3153,  -3.9294,  -0.1051]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  10.884867668151855\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.4355, -10.1457,  -9.0000,  -6.0609,  -5.7673, -10.1840,  -2.8363,\n",
      "          -3.8069,  -4.3077,  -0.1054]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.0608930587768555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.9586, -8.9461, -8.6721, -4.1766, -5.1884, -9.8430, -2.3979, -2.8317,\n",
      "         -4.1245, -0.2075]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.12447452545166\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.3229, -7.6596, -8.1705, -2.2852, -4.4648, -9.3295, -1.8624, -1.7914,\n",
      "         -3.0129, -0.6646]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.17047119140625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.1613, -6.9122, -7.3988, -1.0714, -4.2324, -9.2779, -1.9033, -1.3905,\n",
      "         -2.4597, -1.8485]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.277938842773438\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.3605, -6.5844, -7.0488, -0.5877, -4.3784, -8.8110, -2.3924, -1.5610,\n",
      "         -2.3701, -3.3699]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  8.360465049743652\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.6936, -6.1688, -6.6128, -0.4598, -4.3976, -8.2693, -2.7775, -1.7508,\n",
      "         -2.2383, -4.6427]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.397624969482422\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8075, -5.5103, -5.9353, -0.5451, -3.3991, -7.4957, -2.8834, -1.7662,\n",
      "         -1.9139, -5.5097]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.495733261108398\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8080, -4.7178, -5.1248, -0.8650, -2.3223, -5.8372, -2.8169, -1.7062,\n",
      "         -1.5303, -6.0907]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.5302578210830688\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1724, -4.2732, -4.6614, -1.7385, -1.6873, -4.6081, -3.0626, -2.0509,\n",
      "         -0.8586, -6.8778]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.273229598999023\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7353, -3.2661, -4.3822, -2.7911, -1.3836, -3.6401, -3.4488, -2.5890,\n",
      "         -0.7032, -7.7182]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.71823263168335\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2833, -2.3231, -4.0753, -3.7216, -1.2310, -2.7238, -3.7549, -3.0655,\n",
      "         -0.8701, -7.7029]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.7549185752868652\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8936, -1.5547, -3.8185, -4.5852, -1.3169, -1.9560, -3.3299, -3.5368,\n",
      "         -1.3415, -7.6966]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.554673194885254\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9551, -0.6717, -4.0011, -5.7683, -1.9902, -1.7703, -3.3706, -4.3808,\n",
      "         -2.3595, -8.0889]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  4.001073837280273\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1549, -0.3905, -3.5791, -6.9666, -2.8282, -1.8638, -3.5627, -5.2806,\n",
      "         -3.4776, -8.5729]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.4775938987731934\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0988, -0.3965, -2.9721, -7.7989, -3.3791, -1.8191, -3.5089, -5.8474,\n",
      "         -3.5098, -8.7614]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.5088753700256348\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7997, -0.6432, -2.2023, -8.2880, -3.6398, -1.6421, -2.4997, -6.0992,\n",
      "         -3.3005, -8.6706]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.4997148513793945\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7058, -1.4157, -1.7492, -8.8877, -4.0531, -1.7899, -1.0916, -6.4867,\n",
      "         -3.2987, -8.7480]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.747998237609863\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0255, -2.6785, -1.8548, -9.8141, -4.8244, -2.4371, -0.4524, -7.2231,\n",
      "         -3.7110, -8.4994]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.4370946884155273\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3212,  -3.8616,  -2.0594, -10.6432,  -5.5198,  -2.3179,  -0.3308,\n",
      "          -7.8816,  -4.0955,  -8.2705]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.321169853210449\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5401,  -4.6121,  -2.0066, -11.0592,  -5.8184,  -1.9553,  -0.4077,\n",
      "          -8.1443,  -4.1236,  -7.7341]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.144338607788086\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5971,  -5.0346,  -1.7968, -11.1731,  -5.8287,  -1.4760,  -0.6934,\n",
      "          -7.3660,  -3.9004,  -6.9906]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.6933737993240356\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0060,  -5.6237,  -1.9334, -11.4795,  -6.0441,  -1.4229,  -0.7953,\n",
      "          -6.8695,  -3.9184,  -6.5257]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.623741626739502\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4216,  -5.2602,  -2.0123, -11.6053,  -6.0896,  -1.4089,  -1.0605,\n",
      "          -6.2731,  -3.7994,  -5.9579]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.089591026306152\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9849,  -4.8505,  -2.0953, -11.6324,  -5.3041,  -1.4969,  -1.4612,\n",
      "          -5.6512,  -3.6228,  -5.3623]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.9849185347557068\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4396,  -4.7906,  -2.5635, -11.9599,  -4.9036,  -2.0502,  -2.2914,\n",
      "          -5.3971,  -3.7871,  -5.1325]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.7906036376953125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2929,  -3.8765,  -2.9171, -12.1304,  -4.4240,  -2.5222,  -2.9870,\n",
      "          -5.0472,  -3.8275,  -4.8052]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.9869794845581055\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4025,  -2.7693,  -2.9758, -11.9843,  -3.7014,  -2.7091,  -2.6322,\n",
      "          -4.4374,  -3.5808,  -4.2167]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.769298553466797\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0167,  -1.1130,  -3.0982, -11.8848,  -3.1013,  -2.9604,  -2.3962,\n",
      "          -3.9294,  -3.4116,  -3.7293]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.729306697845459\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3653,  -0.3992,  -3.7754, -12.3291,  -3.1281,  -3.7603,  -2.7828,\n",
      "          -4.0206,  -3.8180,  -3.1360]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  12.329129219055176\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6588,  -0.2655,  -4.4134, -11.9663,  -3.1961,  -4.5095,  -3.1865,\n",
      "          -4.1276,  -4.2118,  -2.6437]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.127615451812744\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5173,  -0.3868,  -4.6718, -11.3145,  -2.9628,  -4.8677,  -3.2546,\n",
      "          -3.1578,  -4.2525,  -1.9257]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.3867880403995514\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5209,  -0.4819,  -5.1341, -10.9504,  -3.0139,  -5.4187,  -3.5663,\n",
      "          -2.5392,  -4.5226,  -1.6050]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.013864755630493\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.2702,  -0.8656,  -5.3974, -10.4652,  -2.1976,  -5.7610,  -3.7099,\n",
      "          -1.8846,  -4.6167,  -1.3010]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.761035919189453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.9572,  -1.5319,  -5.6487, -10.0392,  -1.5559,  -5.3170,  -3.8677,\n",
      "          -1.4207,  -4.7198,  -1.2308]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.2307779788970947\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.8216, -2.5361, -6.1227, -9.9007, -1.3799, -5.1661, -4.2700, -1.4306,\n",
      "         -5.0644, -0.9127]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.122661113739014\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.4938, -3.3924, -5.7085, -9.6697, -1.3020, -4.9281, -4.5358, -1.5138,\n",
      "         -5.2731, -0.8038]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.5138473510742188\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.1068, -4.1957, -5.3456, -9.4692, -1.4413, -4.7269, -4.7904, -1.0085,\n",
      "         -5.4725, -1.0294]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.472491264343262\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.5273, -4.7988, -4.8908, -9.1573, -1.6110, -4.4210, -4.8941, -0.6972,\n",
      "         -4.7701, -1.3532]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  9.527338027954102\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.9762, -5.1445, -4.2836, -8.6732, -1.7089, -3.9515, -4.7895, -0.5889,\n",
      "         -3.9407, -1.6239]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.673189163208008\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.2435, -5.2236, -3.5103, -7.2279, -1.6949, -3.3068, -4.4648, -0.6724,\n",
      "         -2.9719, -1.7703]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.223551273345947\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.4632, -4.4397, -2.7154, -5.8064, -1.6982, -2.6338, -4.0601, -1.0104,\n",
      "         -2.0175, -1.9018]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.439703941345215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8621, -3.1106, -2.1494, -4.6297, -1.9383, -2.1838, -3.8090, -1.6891,\n",
      "         -1.3596, -2.2267]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.3595787286758423\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7984, -2.4235, -2.2027, -4.0547, -2.7384, -2.3420, -4.0759, -2.9160,\n",
      "         -0.6848, -3.0724]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.4235081672668457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.9557, -1.3539, -2.5460, -3.7641, -3.7208, -2.7720, -4.5422, -4.2753,\n",
      "         -0.6713, -4.0805]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.772028923034668\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.2034, -0.6855, -3.0185, -3.6258, -4.7288, -2.5470, -5.0752, -5.6151,\n",
      "         -1.1494, -5.1056]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.075158596038818\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.3903, -0.4168, -3.4432, -3.4853, -5.6063, -2.3676, -4.8031, -6.7876,\n",
      "         -1.7815, -5.9963]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.41675078868865967\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.8465, -0.2131, -4.1369, -3.6700, -6.6867, -2.5654, -4.8516, -8.1317,\n",
      "         -2.7649, -7.0875]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.0875444412231445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.8435, -0.2077, -4.3593, -3.4421, -7.2465, -2.3883, -4.4868, -8.9282,\n",
      "         -3.2838, -6.9485]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.246480464935303\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.3970, -0.3509, -4.1247, -2.8176, -6.5619, -1.8551, -3.7222, -9.2014,\n",
      "         -3.3350, -6.3798]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.3509388566017151\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.1767, -0.4454, -4.1069, -2.4831, -6.1279, -1.6763, -3.2325, -9.6287,\n",
      "         -3.5894, -6.0502]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.6762645244598389\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.9679,  -0.9856,  -4.0921,  -2.2359,  -5.7278,  -0.8825,  -2.8091,\n",
      "         -10.0026,  -3.8283,  -5.7442]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.8825387954711914\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.3394,  -2.3021,  -4.6499,  -2.6553,  -5.9287,  -0.2795,  -3.0301,\n",
      "         -10.8981,  -4.6186,  -6.0296]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.3020761013031006\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.5547,  -2.7120,  -5.0396,  -2.9681,  -5.9920,  -0.1959,  -3.1444,\n",
      "         -11.5849,  -5.2181,  -6.1688]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.968052625656128\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.3158,  -2.6962,  -4.9622,  -2.0803,  -5.6176,  -0.3140,  -2.8452,\n",
      "         -11.7701,  -5.3288,  -5.8624]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.0802693367004395\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.1805,  -2.8103,  -4.9770,  -0.6853,  -5.3626,  -1.0538,  -2.6971,\n",
      "         -12.0162,  -5.5114,  -5.6678]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.6852951049804688\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.1162,  -4.0138,  -6.0523,  -0.1039,  -6.1933,  -3.0411,  -3.6694,\n",
      "         -13.2947,  -6.7359,  -6.5520]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.041149139404297\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.7251,  -4.8767,  -6.7886,  -0.0465,  -6.7091,  -3.8728,  -4.3296,\n",
      "         -14.2122,  -7.6056,  -7.1154]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.605597496032715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.5892,  -4.9750,  -6.7681,  -0.0462,  -6.4902,  -3.9530,  -4.2492,\n",
      "         -14.3540,  -6.9504,  -6.9389]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.938909530639648\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.7866,  -4.3882,  -6.0701,  -0.0960,  -5.6137,  -3.3594,  -3.5068,\n",
      "         -13.8013,  -5.6807,  -5.3929]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.506801128387451\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6700,  -3.4745,  -5.0491,  -0.4369,  -4.4330,  -2.4569,  -1.7440,\n",
      "         -12.9094,  -4.1458,  -3.6097]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.669959545135498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3716,  -3.1105,  -4.5705,  -1.6697,  -3.8148,  -2.1454,  -0.7190,\n",
      "         -12.5423,  -3.2116,  -2.4593]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.110464096069336\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6556,  -2.5376,  -4.5969,  -3.3728,  -3.7243,  -2.4033,  -0.5977,\n",
      "         -12.6615,  -2.8506,  -1.9337]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.537625551223755\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0984,  -1.4369,  -4.7089,  -5.0131,  -3.7414,  -2.7847,  -0.9659,\n",
      "         -12.8494,  -2.6498,  -1.6436]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.013067245483398\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7475,  -0.7570,  -4.9552,  -5.8681,  -3.9134,  -3.3139,  -1.7104,\n",
      "         -13.1574,  -2.6611,  -1.6583]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.9551849365234375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4591,  -0.4954,  -4.4494,  -6.6504,  -4.0935,  -3.8282,  -2.5214,\n",
      "         -13.4449,  -2.7344,  -1.8169]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.734403133392334\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0799,  -0.5588,  -3.8600,  -7.2132,  -4.1256,  -4.1653,  -3.1671,\n",
      "         -13.5613,  -1.9535,  -1.9326]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.213221073150635\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6450,  -0.9024,  -3.2180,  -6.8340,  -4.0396,  -4.3536,  -3.6520,\n",
      "         -13.5390,  -1.2302,  -2.0125]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.012502670288086\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4170,  -1.6162,  -2.7812,  -6.6049,  -4.0869,  -4.6445,  -4.2188,\n",
      "         -13.6305,  -0.9111,  -1.5817]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  13.630525588989258\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2487,  -2.3742,  -2.4057,  -6.3713,  -4.1137,  -4.8854,  -4.7115,\n",
      "         -12.9253,  -0.8987,  -1.3113]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.885425567626953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0684,  -3.0179,  -2.0286,  -6.0562,  -4.0441,  -4.2426,  -5.0555,\n",
      "         -12.1842,  -1.0883,  -1.1527]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.088261604309082\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1299,  -3.7641,  -1.9182,  -5.9053,  -4.1256,  -3.8059,  -5.5010,\n",
      "         -11.6479,  -0.8904,  -1.3650]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.905273914337158\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1134,  -4.2937,  -1.7691,  -4.8570,  -4.0521,  -3.2703,  -5.7460,\n",
      "         -11.0060,  -0.8621,  -1.5780]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  11.005951881408691\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0310, -4.6242, -1.6058, -3.7627, -3.8428, -2.6607, -5.8127, -9.5165,\n",
      "         -0.9981, -1.7600]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.516511917114258\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9665, -4.8423, -1.5217, -2.7083, -3.5837, -2.0783, -5.7883, -7.3392,\n",
      "         -1.3109, -1.9593]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.5837416648864746\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0596, -5.0928, -1.6572, -1.8577, -2.6694, -1.6973, -5.8169, -5.4274,\n",
      "         -1.8436, -2.2871]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.816893577575684\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3490, -5.4347, -2.0333, -1.3219, -2.0101, -1.6055, -5.2333, -3.8212,\n",
      "         -2.5542, -2.7663]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.3490185737609863\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1011, -5.9014, -2.6254, -1.1973, -1.6726, -1.8312, -4.8673, -2.5471,\n",
      "         -3.4083, -3.3982]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.547110080718994\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2474, -6.6035, -3.4925, -1.5938, -1.7897, -2.4363, -4.8231, -0.9900,\n",
      "         -4.4821, -4.2708]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.9900498390197754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4991, -8.2791, -5.3385, -3.1472, -3.0630, -4.0901, -5.8317, -0.1606,\n",
      "         -6.5001, -6.1089]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.338461875915527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6330, -9.7728, -6.2424, -4.5632, -4.2293, -5.5767, -6.7265, -0.0433,\n",
      "         -8.3029, -7.7503]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.24235725402832\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0315, -10.4880,  -5.6872,  -5.2164,  -4.6607,  -6.2884,  -6.9035,\n",
      "          -0.0284,  -9.2967,  -8.5988]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.288398265838623\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7006, -10.4376,  -4.4953,  -5.1143,  -4.3619,  -5.4760,  -6.3691,\n",
      "          -0.0462,  -9.4972,  -8.6685]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.668546676635742\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7977, -9.7806, -2.8187, -4.4151, -3.4907, -4.1360, -5.2774, -0.1585,\n",
      "         -9.0660, -7.4084]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.277376651763916\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8844, -9.0723, -1.2367, -3.6782, -2.6125, -2.8249, -3.4597, -0.7722,\n",
      "         -8.5613, -6.1576]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.2367255687713623\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1686, -9.5000, -0.3524, -4.0991, -2.9424, -2.7547, -2.9110, -2.7310,\n",
      "         -9.1723, -6.0980]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.731022357940674\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6208, -10.0505,  -0.2442,  -4.6561,  -3.4445,  -2.9053,  -2.6217,\n",
      "          -3.9646,  -9.8878,  -6.2114]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.2442113161087036\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2301, -10.7287,  -0.1688,  -5.3473,  -4.1031,  -3.2649,  -2.5962,\n",
      "          -5.2719, -10.7146,  -6.4973]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.230067729949951\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5678, -10.8521,  -0.2394,  -5.4860,  -4.2213,  -3.1306,  -2.1399,\n",
      "          -5.9655, -10.9719,  -6.2686]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.130561113357544\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7029, -10.6739,  -0.5940,  -5.3248,  -4.0496,  -1.9952,  -1.5250,\n",
      "          -6.3027, -10.9142,  -5.7747]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.049633026123047\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0912, -10.6313,  -1.4372,  -5.3012,  -3.2733,  -1.1939,  -1.2468,\n",
      "          -6.7255, -10.9801,  -5.4499]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.4499125480651855\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7931, -10.7549,  -2.5333,  -5.4456,  -2.7646,  -0.8646,  -1.3665,\n",
      "          -7.2690, -11.2014,  -4.6129]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.533318519592285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6197, -10.8388,  -2.8130,  -5.5515,  -2.3267,  -0.8606,  -1.6317,\n",
      "          -7.7315, -11.3732,  -3.8388]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.8129687309265137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5210, -10.8261,  -2.2871,  -5.5617,  -1.9177,  -1.0896,  -1.9241,\n",
      "          -8.0601, -11.4398,  -3.0690]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.0896481275558472\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7689, -10.9908,  -2.0640,  -5.7498,  -1.8361,  -0.9685,  -2.4692,\n",
      "          -8.5322, -11.6758,  -2.5848]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.749842643737793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0085, -11.0298,  -1.8470,  -5.0514,  -1.7737,  -1.0380,  -2.9122,\n",
      "          -8.8483, -11.7790,  -2.0933]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.8469603061676025\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4075, -11.1495,  -1.1204,  -4.5119,  -1.9300,  -1.4532,  -3.4352,\n",
      "          -9.2175, -11.9566,  -1.8230]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.9300061464309692\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9717, -11.3959,  -0.8437,  -4.1730,  -1.5661,  -2.1428,  -4.0680,\n",
      "          -9.6886, -12.2550,  -1.8333]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  11.395858764648438\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4225, -10.7918,  -0.8145,  -3.7846,  -1.3007,  -2.7577,  -4.5554,\n",
      "         -10.0180, -12.4288,  -1.8615]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  12.42876148223877\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6791, -10.0744,  -0.9386,  -3.2787,  -1.0933,  -3.1860,  -4.8283,\n",
      "         -10.1410, -11.6533,  -1.8242]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.6790621280670166\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0390,  -9.2751,  -1.1828,  -2.6987,  -1.0054,  -3.4497,  -4.9266,\n",
      "         -10.0986, -10.8017,  -1.7524]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.0053884983062744\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6963,  -8.7537,  -1.8250,  -2.4260,  -0.6478,  -3.9096,  -5.2188,\n",
      "         -10.2587, -10.2332,  -2.0097]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.6477639079093933\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7881,  -8.6352,  -2.8719,  -2.5987,  -0.3187,  -4.6898,  -5.8366,\n",
      "         -10.7537, -10.0721,  -2.6878]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.072139739990234\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6193,  -8.2319,  -3.5593,  -2.5144,  -0.2722,  -5.1025,  -6.0983,\n",
      "         -10.9028,  -8.8761,  -3.0503]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  10.902776718139648\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1150, -7.4630, -3.7931, -2.0942, -0.3946, -5.0728, -5.9296, -9.8888,\n",
      "         -7.3931, -3.0045]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.004472494125366\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5699, -6.5911, -3.8402, -1.6302, -0.8277, -4.8709, -5.5997, -8.7960,\n",
      "         -5.8784, -2.1053]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.840188980102539\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3121, -5.8867, -3.2458, -1.4417, -1.6231, -4.7746, -5.3850, -7.8917,\n",
      "         -4.5963, -1.4621]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.891722679138184\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3406, -5.3167, -2.8013, -1.5151, -2.5489, -4.7566, -5.2573, -6.4022,\n",
      "         -3.5117, -1.1104]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.257336616516113\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5319, -4.7799, -2.4183, -1.7221, -3.4138, -4.7197, -4.3909, -5.0350,\n",
      "         -2.5305, -1.0014]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.413780689239502\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8620, -4.3011, -2.1369, -2.0436, -3.4662, -4.6918, -3.6181, -3.8072,\n",
      "         -1.7058, -1.1634]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.0435967445373535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4202, -4.0264, -2.1163, -1.8135, -3.6831, -4.8200, -3.0882, -2.8645,\n",
      "         -1.2476, -1.6783]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.026368618011475\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0511, -3.1227, -2.2486, -1.7935, -3.9598, -5.0043, -2.7070, -2.1205,\n",
      "         -1.1157, -2.3376]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.7934590578079224\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8283, -2.5154, -2.6192, -1.3149, -4.3975, -5.3496, -2.5866, -1.7139,\n",
      "         -1.4199, -3.1744]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.586566925048828\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6429, -2.1266, -3.1049, -1.1873, -4.8994, -5.7628, -1.9056, -1.5800,\n",
      "         -1.9760, -4.0564]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.642926216125488\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6451, -1.8640, -3.5751, -1.3048, -5.3569, -6.1373, -1.4006, -1.6124,\n",
      "         -2.5819, -4.8630]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.3048089742660522\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8100, -1.8972, -4.1749, -1.0127, -5.9282, -6.6319, -1.2811, -1.9454,\n",
      "         -3.3409, -5.7506]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.340885639190674\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8520, -1.9248, -4.6138, -0.9135, -6.3321, -6.9659, -1.2631, -2.2388,\n",
      "         -3.1799, -6.4396]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.965861797332764\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7031, -1.8643, -4.8238, -0.9369, -6.5047, -6.3124, -1.2603, -2.3898,\n",
      "         -2.8740, -6.8687]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.9368682503700256\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7192, -2.0674, -5.1623, -0.6397, -6.8048, -5.8689, -1.6076, -2.7374,\n",
      "         -2.7849, -7.3995]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.7374086380004883\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5911, -2.1940, -5.3221, -0.6235, -6.9266, -5.3225, -1.9169, -2.2076,\n",
      "         -2.6023, -7.7285]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.322513103485107\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3012, -2.2079, -5.2875, -0.8331, -6.8550, -3.8944, -2.1204, -1.6299,\n",
      "         -2.3120, -7.8431]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.3119707107543945\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1331, -2.3843, -5.3430, -1.4340, -6.8742, -2.7070, -2.4741, -1.3381,\n",
      "         -1.4524, -8.0295]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.029485702514648\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1439, -2.7613, -5.5468, -2.3059, -7.0426, -1.8388, -3.0041, -1.4202,\n",
      "         -1.0059, -7.6325]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.305867910385132\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2541, -3.2360, -5.8220, -2.4967, -7.2836, -1.2668, -3.6064, -1.7621,\n",
      "         -0.9695, -7.3643]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.2360246181488037\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2963, -2.8895, -6.0044, -2.6633, -7.4337, -0.8989, -4.1009, -2.1299,\n",
      "         -1.1561, -7.0556]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.1561347246170044\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4374, -2.7114, -6.2635, -2.9590, -7.6622, -0.9704, -4.6514, -2.6423,\n",
      "         -0.8995, -6.8713]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.6513519287109375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3793, -2.4058, -6.3043, -3.0706, -7.6744, -1.1292, -4.2311, -2.9625,\n",
      "         -0.7818, -6.5121]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.674421310424805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1220, -1.9827, -6.1280, -2.9920, -6.7224, -1.3036, -3.6490, -3.0750,\n",
      "         -0.8069, -5.9754]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.075049638748169\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7878, -1.5887, -5.8565, -2.8447, -5.7517, -1.5528, -3.0293, -2.3542,\n",
      "         -1.0516, -5.3796]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.35420560836792\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6509, -1.5311, -5.7612, -2.9033, -5.0271, -2.0851, -2.6537, -1.1849,\n",
      "         -1.6823, -4.9935]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.653663158416748\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8490, -1.9407, -5.9800, -3.2998, -4.6818, -2.9613, -1.9430, -0.6604,\n",
      "         -2.6926, -4.9529]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.6925954818725586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0843, -2.4563, -6.2198, -3.7259, -4.4187, -3.8307, -1.4483, -0.6112,\n",
      "         -2.9391, -4.9624]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.7259016036987305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1599, -2.8349, -6.2885, -3.2222, -4.0422, -4.4813, -1.0250, -0.8187,\n",
      "         -3.0522, -4.8273]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.827301979064941\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1073, -3.0869, -6.2195, -2.6665, -3.5841, -4.9435, -0.7726, -1.1983,\n",
      "         -3.0574, -3.8641]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.5841073989868164\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0048, -3.2801, -6.0915, -2.1513, -2.3779, -5.2978, -0.8136, -1.6951,\n",
      "         -3.0300, -2.9444]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.151313304901123\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1483, -3.7040, -6.2001, -1.2440, -1.5834, -5.8429, -1.3945, -2.5000,\n",
      "         -3.2641, -2.3763]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.3762564659118652\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6289, -4.4435, -6.6390, -0.9844, -1.3616, -6.6755, -2.4373, -3.6250,\n",
      "         -3.8433, -1.5582]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.3615565299987793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3669, -5.4160, -7.3331, -1.3308, -0.9050, -7.7241, -3.7377, -4.9555,\n",
      "         -4.6789, -1.2700]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.415994644165039\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9595, -5.4826, -7.8832, -1.7669, -0.7216, -8.5933, -4.8506, -6.0835,\n",
      "         -5.3629, -1.1361]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.083512783050537\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2726, -5.3232, -8.1565, -2.0662, -0.6977, -9.1538, -5.6360, -6.1400,\n",
      "         -5.7601, -1.0229]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.760060787200928\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2844, -4.9117, -8.1312, -2.1598, -0.7765, -9.3870, -6.0743, -5.9210,\n",
      "         -5.0955, -0.9065]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.920952320098877\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0345, -4.2846, -7.8467, -2.0693, -0.9287, -9.3350, -6.2086, -4.7303,\n",
      "         -4.2397, -0.8284]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.8284012079238892\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9662, -3.8851, -7.7458, -2.2382, -1.5152, -9.4433, -6.4860, -3.8197,\n",
      "         -3.6349, -0.5106]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.443288803100586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.7349, -3.3688, -7.4835, -2.2992, -2.0355, -8.6053, -6.5652, -2.8442,\n",
      "         -2.9385, -0.4811]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.483458518981934\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3793, -2.7796, -6.3570, -2.2803, -2.4518, -7.7011, -6.4878, -1.8587,\n",
      "         -2.2016, -0.7450]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.4518160820007324\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1850, -2.4172, -5.4664, -2.4630, -2.2661, -7.0096, -6.5416, -1.2085,\n",
      "         -1.7439, -1.4428]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.2084715366363525\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4530, -2.5956, -5.1064, -3.1309, -2.6149, -6.8265, -7.0299, -0.5476,\n",
      "         -1.9026, -2.6781]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.5475729703903198\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2356, -3.3495, -5.3248, -4.3035, -3.5216, -7.2006, -8.0084, -0.1816,\n",
      "         -2.6961, -4.3775]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.18164853751659393\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.2668, -4.3794, -5.8501, -5.6946, -4.6851, -7.8630, -9.2147, -0.0553,\n",
      "         -3.7866, -6.2417]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.850142955780029\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5990, -4.7190, -4.9905, -6.3529, -5.1428, -7.8629, -9.7041, -0.0409,\n",
      "         -4.1888, -7.3248]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.0409046933054924\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.9367,  -5.0697,  -4.2596,  -6.9852,  -5.5974,  -7.9012, -10.1830,\n",
      "          -0.0368,  -4.6006,  -8.3387]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.9851603507995605\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5889, -4.7380, -2.9599, -6.1459, -5.3576, -7.2840, -9.9622, -0.0856,\n",
      "         -4.3269, -8.5999]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.145925045013428\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8572, -4.0269, -1.4090, -4.2216, -4.7261, -6.3097, -9.3444, -0.3774,\n",
      "         -3.6715, -8.4162]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.37742626667022705\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7118, -3.9125, -0.7064, -3.0126, -4.6767, -5.9465, -9.3009, -0.9236,\n",
      "         -3.6133, -8.7636]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.946534156799316\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6168, -3.8592, -0.4746, -1.9960, -4.6743, -4.8935, -9.2968, -1.7391,\n",
      "         -3.6163, -9.1115]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.6163132190704346\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5039, -3.7986, -0.6979, -1.1547, -4.6507, -3.9227, -9.2648, -2.5728,\n",
      "         -2.8558, -9.3965]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.798611640930176\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4634, -3.0809, -1.3267, -0.6953, -4.6967, -3.1237, -9.2961, -3.4392,\n",
      "         -2.2744, -9.7133]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.0808634757995605\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.5154,  -1.8208,  -2.1761,  -0.7452,  -4.8322,  -2.5252,  -9.4116,\n",
      "          -4.3299,  -1.9160, -10.0859]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.8207728862762451\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.0461,  -0.5560,  -3.5077,  -1.6306,  -5.4430,  -2.5303,  -9.9985,\n",
      "          -5.6244,  -2.1873, -10.9042]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.443038463592529\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.8753,  -0.1913,  -5.0795,  -2.9260,  -5.6000,  -2.9466, -10.8777,\n",
      "          -7.1433,  -2.8670, -11.9916]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  11.991642951965332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.2791,  -0.1282,  -6.1564,  -3.7897,  -5.4010,  -3.0185, -11.3262,\n",
      "          -8.1685,  -3.1791, -11.9119]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.156437873840332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.1000,  -0.1727,  -5.8442,  -4.0415,  -4.6822,  -2.5777, -11.1871,\n",
      "          -8.5488,  -2.9485, -11.2971]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.6821794509887695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.5256,  -0.4126,  -5.1520,  -3.8683,  -2.8860,  -1.8258, -10.6486,\n",
      "          -8.4782,  -2.3674, -10.3303]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.4126325249671936\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.3567,  -0.7296,  -4.8808,  -4.0759,  -1.6580,  -1.6202, -10.5116,\n",
      "          -8.7625,  -2.2629,  -9.8075]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.07588005065918\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.3048,  -1.4658,  -4.7420,  -3.6215,  -0.7941,  -1.6866, -10.4880,\n",
      "          -9.1185,  -2.3475,  -9.4366]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.3047709465026855\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.5902,  -2.3808,  -4.7072,  -3.3164,  -0.4374,  -1.9723, -10.5506,\n",
      "          -9.5229,  -2.5800,  -9.1865]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.707235336303711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.7391,  -3.0634,  -3.7374,  -2.8602,  -0.3884,  -2.1277, -10.3982,\n",
      "          -9.6784,  -2.6380,  -8.7527]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.8602142333984375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8125,  -3.5495,  -2.7189,  -1.5800,  -0.6852,  -2.1963, -10.0984,\n",
      "          -9.6558,  -2.5819,  -8.1994]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.7189083099365234\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2915,  -4.3154,  -1.4250,  -0.8894,  -1.6333,  -2.6509, -10.1357,\n",
      "          -9.9427,  -2.8960,  -8.0088]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.8893870115280151\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5360,  -5.7182,  -1.1402,  -0.5299,  -3.3353,  -3.8178, -10.8726,\n",
      "         -10.9044,  -3.9242,  -8.5406]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.540611267089844\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6383,  -6.8579,  -0.9934,  -0.5228,  -4.7684,  -4.7596, -11.4103,\n",
      "         -11.6446,  -4.7391,  -8.1787]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.5228294134140015\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8781,  -8.0253,  -1.2740,  -0.3521,  -6.2055,  -5.7546, -12.0349,\n",
      "         -12.4514,  -5.6199,  -7.9934]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.993373394012451\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7012,  -8.6780,  -1.3338,  -0.3273,  -7.1024,  -6.2543, -12.1986,\n",
      "         -12.7793,  -6.0172,  -6.7172]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  12.19863510131836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1236,  -8.8407,  -1.1563,  -0.4184,  -7.4855,  -6.2806, -11.1837,\n",
      "         -12.6493,  -5.9516,  -5.1438]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.840723991394043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2878,  -7.9282,  -0.8999,  -0.6627,  -7.5030,  -5.9779,  -9.9420,\n",
      "         -12.2044,  -5.5667,  -3.4033]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.2878050804138184\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8025,  -7.0981,  -0.9590,  -1.2572,  -7.5103,  -5.6984,  -8.8151,\n",
      "         -11.7951,  -5.2141,  -1.8511]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.510329246520996\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.0255,  -6.7872,  -1.7297,  -2.4404,  -7.2092,  -5.8855,  -8.2367,\n",
      "         -11.8625,  -5.3370,  -1.0018]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.236669540405273\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8379,  -6.7497,  -2.7957,  -3.8122,  -7.1801,  -6.2976,  -7.2240,\n",
      "         -12.1649,  -5.6928,  -0.7417]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.223955154418945\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8159,  -6.5378,  -3.6215,  -4.8850,  -6.9755,  -6.4912,  -5.4051,\n",
      "         -12.2581,  -5.8368,  -0.6692]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.83679723739624\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8420,  -6.0611,  -4.0977,  -5.5696,  -6.5050,  -6.3796,  -3.4836,\n",
      "         -12.0551,  -4.9209,  -0.6828]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.6828060150146484\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3894,  -5.8335,  -4.7388,  -6.3890,  -6.2824,  -6.4805,  -1.9760,\n",
      "         -12.0723,  -4.3018,  -0.5416]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.738798141479492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1567,  -5.7176,  -4.6729,  -7.2149,  -6.1703,  -6.6594,  -0.8071,\n",
      "         -12.1747,  -3.8415,  -0.9164]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.170285224914551\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1497,  -5.8307,  -4.8354,  -8.1742,  -5.5451,  -7.0366,  -0.2979,\n",
      "         -12.4820,  -3.6584,  -1.7542]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.174227714538574\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8735,  -5.7321,  -4.7850,  -8.0880,  -4.7824,  -7.1742,  -0.1820,\n",
      "         -12.5560,  -3.3105,  -2.4294]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.73211145401001\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0959,  -4.4708,  -4.3007,  -7.5657,  -3.6569,  -6.8538,  -0.2422,\n",
      "         -12.1777,  -2.5801,  -2.6552]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.6568779945373535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1226,  -3.1572,  -3.6885,  -6.9095,  -1.7392,  -6.3799,  -0.6815,\n",
      "         -11.6508,  -1.7940,  -2.7226]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.688467502593994\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6909,  -2.5376,  -2.9548,  -6.8515,  -0.6747,  -6.4866,  -1.9769,\n",
      "         -11.7085,  -1.7451,  -3.3623]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.486567497253418\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5209,  -2.3489,  -2.6437,  -7.1114,  -0.4051,  -6.1224,  -3.5557,\n",
      "         -12.0718,  -2.1457,  -4.2744]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  12.071840286254883\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.0568,  -2.0342,  -2.2011,  -7.1314,  -0.4412,  -5.5816,  -4.7835,\n",
      "         -11.4471,  -2.3811,  -4.8911]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.7834792137146\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.2993,  -1.6049,  -1.6422,  -6.9084,  -0.7065,  -4.8558,  -4.9223,\n",
      "         -10.6428,  -2.4219,  -5.2101]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.922295093536377\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4336, -1.2800, -1.1955, -6.6227, -1.2231, -4.1228, -4.2414, -9.8331,\n",
      "         -2.4410, -5.4157]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.622742652893066\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5159, -1.1513, -0.9759, -5.5823, -1.8654, -3.4356, -3.5990, -9.0643,\n",
      "         -2.4850, -5.5643]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.599001884460449\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5439, -1.2198, -1.0074, -4.6009, -2.5105, -2.7943, -2.2717, -8.3248,\n",
      "         -2.5410, -5.6536]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.543916702270508\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8729, -1.5553, -1.3616, -3.7824, -3.2090, -2.3221, -1.2089, -7.7168,\n",
      "         -2.7094, -5.7942]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.794186592102051\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4421, -2.1834, -2.0398, -3.2336, -4.0391, -2.1441, -0.6393, -7.3410,\n",
      "         -3.0833, -5.3783]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.6392765045166016\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5303, -3.3043, -3.2188, -3.2417, -5.2724, -2.5475, -0.2583, -7.4758,\n",
      "         -3.9279, -5.4799]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.9279112815856934\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3472, -4.0752, -4.0444, -3.0128, -6.1212, -2.7061, -0.2088, -7.3323,\n",
      "         -3.6736, -5.3090]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.20875032246112823\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3227, -4.9184, -4.9374, -2.9800, -7.0239, -3.0374, -0.1649, -7.3401,\n",
      "         -3.6006, -5.2953]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.16485236585140228\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4134, -5.7922, -5.8559, -3.0976, -7.9465, -3.4821, -0.1248, -7.4568,\n",
      "         -3.6649, -5.3957]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.456838130950928\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9525, -6.0353, -6.1392, -2.6913, -8.2315, -3.3604, -0.1795, -6.2791,\n",
      "         -3.1964, -4.9434]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.231542587280273\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1251, -5.8382, -5.9781, -1.9584, -7.3314, -2.8601, -0.4107, -4.8023,\n",
      "         -2.3881, -4.1235]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.4106981158256531\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6552, -5.9259, -6.0978, -1.6671, -6.7843, -2.7172, -0.6395, -3.7415,\n",
      "         -1.9934, -3.6597]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.6670564413070679\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3778, -6.1328, -6.3334, -0.9251, -6.4185, -2.7658, -1.3499, -2.9299,\n",
      "         -1.8683, -3.3867]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.8683243989944458\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3947, -6.5616, -6.7877, -0.7942, -6.3313, -3.0995, -2.4165, -2.4795,\n",
      "         -1.3512, -3.4060]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.099536895751953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4245, -6.9379, -7.1867, -1.0029, -6.2431, -2.6477, -3.4301, -2.1251,\n",
      "         -1.0725, -3.4364]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.072512149810791\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7271, -7.5286, -7.7976, -1.7156, -6.4163, -2.5470, -4.6172, -2.1454,\n",
      "         -0.5719, -3.7379]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.73793363571167\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9174, -7.9604, -8.2477, -2.3911, -6.4730, -2.4166, -5.5928, -2.1501,\n",
      "         -0.4516, -3.2098]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.247664451599121\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8382, -8.0838, -7.6504, -2.8021, -6.2596, -2.1029, -6.2083, -1.9749,\n",
      "         -0.5623, -2.4975]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.80208683013916\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6640, -8.0760, -6.9937, -2.3520, -5.9496, -1.7960, -6.6447, -1.8008,\n",
      "         -0.9756, -1.7960]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.075994491577148\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5312, -7.3377, -6.4075, -2.0222, -5.6768, -1.6532, -7.0432, -1.7710,\n",
      "         -1.6383, -1.2878]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.2878361940383911\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7475, -6.9870, -6.1946, -2.1375, -5.7475, -1.9872, -7.7163, -2.1841,\n",
      "         -2.6963, -0.6259]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.747511386871338\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9352, -6.6469, -5.9794, -2.3042, -5.0503, -2.3695, -8.2977, -2.6146,\n",
      "         -3.6752, -0.3885]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.050348281860352\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8468, -6.0694, -5.5152, -2.2565, -3.4222, -2.5142, -8.5491, -2.7843,\n",
      "         -4.3037, -0.3878]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.7843496799468994\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6453, -5.4129, -4.9620, -2.1535, -1.8421, -2.5694, -8.6375, -2.1034,\n",
      "         -4.7418, -0.7332]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.7332462072372437\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9173, -5.2586, -4.9027, -2.5810, -0.9696, -3.1123, -9.1507, -2.0143,\n",
      "         -5.5764, -1.1064]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.90267276763916\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2366, -5.1827, -4.1786, -3.0816, -0.5230, -3.6950, -9.6722, -2.0920,\n",
      "         -6.3900, -1.7376]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.5229893326759338\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.9256,  -5.5090,  -3.9285,  -3.9572,  -0.2119,  -4.6296, -10.5323,\n",
      "          -2.6440,  -7.5145,  -2.8220]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.925622940063477\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4358,  -5.4500,  -3.3619,  -4.4041,  -0.1726,  -5.1230, -10.9510,\n",
      "          -2.8380,  -8.1716,  -3.4852]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.361924648284912\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6264,  -5.0228,  -1.7681,  -4.4384,  -0.3771,  -5.1946, -10.9507,\n",
      "          -2.6788,  -8.3863,  -3.7270]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  10.950706481933594\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0598,  -4.7849,  -0.6005,  -4.6201,  -1.2045,  -5.4054, -10.3705,\n",
      "          -2.7284,  -8.7217,  -4.1038]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.2044978141784668\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9603,  -4.9518,  -0.3279,  -5.1660,  -1.8112,  -5.9737, -10.2231,\n",
      "          -3.1965,  -9.3988,  -4.8300]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  9.398771286010742\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5847, -4.7820, -0.2863, -5.3365, -2.1516, -6.1620, -9.7650, -3.3230,\n",
      "         -8.9209, -5.1642]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.162012100219727\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9213, -4.2528, -0.4157, -5.1110, -2.1606, -5.1712, -8.9699, -3.0812,\n",
      "         -8.1081, -5.0866]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.111022472381592\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2379, -3.5890, -0.8158, -3.9675, -2.0553, -4.0858, -8.0564, -2.6999,\n",
      "         -7.1788, -4.8235]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.699878692626953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9651, -3.1334, -1.6201, -3.0736, -2.1758, -3.2432, -7.3557, -1.7859,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -6.4642, -4.7139]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.1334173679351807\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1969, -2.2045, -2.6761, -2.4905, -2.5548, -2.7022, -6.9125, -1.2747,\n",
      "         -6.0092, -4.8091]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.2747254371643066\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0474, -1.8613, -4.0889, -2.4392, -3.3647, -2.6791, -6.9259, -0.6933,\n",
      "         -6.0132, -5.3123]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.6933028697967529\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4084, -2.1640, -5.8702, -2.9550, -4.6161, -3.2086, -7.4355, -0.2972,\n",
      "         -6.5153, -6.2657]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.870186805725098\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3894, -2.2519, -6.4739, -3.1889, -5.4805, -3.4474, -7.6251, -0.2221,\n",
      "         -6.6990, -6.8560]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.480502128601074\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8261, -1.9526, -6.5624, -2.9741, -5.0732, -3.2310, -7.3400, -0.2897,\n",
      "         -6.4092, -6.9321]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.339976787567139\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8689, -1.4317, -6.2867, -2.4625, -4.3545, -2.7106, -6.0056, -0.5444,\n",
      "         -5.7930, -6.6448]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.005629062652588\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8154, -1.0416, -5.9418, -1.9678, -3.6188, -2.1961, -3.9913, -1.1015,\n",
      "         -5.1425, -6.2891]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.815429210662842\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1062, -1.0467, -5.7285, -1.7224, -3.0712, -1.9151, -2.2861, -1.9424,\n",
      "         -4.6565, -6.0655]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.2860538959503174\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0201, -1.8511, -6.0789, -2.1755, -3.1522, -2.3174, -0.6493, -3.3449,\n",
      "         -4.7662, -6.4058]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.175462007522583\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6089, -3.3443, -7.0487, -2.5724, -3.9091, -3.4095, -0.2049, -5.2865,\n",
      "         -5.5242, -7.3661]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.57236647605896\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9515, -4.5198, -7.7274, -2.0473, -4.4102, -4.2235, -0.1962, -6.8433,\n",
      "         -6.0146, -8.0361]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.014623641967773\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8730, -5.1939, -7.9464, -1.2784, -4.4778, -4.5755, -0.3847, -7.8534,\n",
      "         -5.3027, -8.2472]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.946380615234375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6396, -5.6366, -7.2458, -0.6256, -4.3786, -4.7321, -0.8718, -8.5948,\n",
      "         -4.4970, -8.2689]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.268935203552246\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3382, -5.9393, -6.5170, -0.3387, -4.1999, -4.7815, -1.5100, -9.1640,\n",
      "         -3.6814, -7.4708]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.33873558044433594\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3765, -6.5134, -6.1613, -0.1658, -4.3496, -5.1321, -2.5418, -9.9762,\n",
      "         -3.2659, -7.0522]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.16579005122184753\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6237,  -7.2346,  -6.0458,  -0.0993,  -4.6971,  -5.6556,  -3.7304,\n",
      "         -10.9107,  -3.1241,  -6.8790]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.623687744140625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5410,  -7.3323,  -5.3913,  -0.1620,  -4.4645,  -5.5776,  -4.2655,\n",
      "         -11.2000,  -2.4779,  -6.1717]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.265522003173828\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2206,  -7.0533,  -4.4378,  -0.4810,  -3.8959,  -5.1427,  -3.6749,\n",
      "         -11.0930,  -1.5927,  -5.1686]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.437752723693848\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.2669,  -6.9552,  -3.0131,  -1.3777,  -3.5515,  -4.9083,  -3.3137,\n",
      "         -11.1492,  -1.1039,  -4.4221]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.1039165258407593\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1994,  -7.4440,  -2.3425,  -2.9481,  -3.8388,  -5.2794,  -3.5908,\n",
      "         -11.7762,  -0.7294,  -4.3350]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.279439926147461\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3249,  -7.8413,  -1.7654,  -4.3577,  -4.0701,  -4.7901,  -3.8166,\n",
      "         -12.2975,  -0.7178,  -4.2227]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.8166160583496094\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5010,  -8.0597,  -1.2311,  -5.4969,  -4.1514,  -4.2164,  -3.1848,\n",
      "         -12.6273,  -0.9407,  -3.9925]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.5009732246398926\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1603,  -8.3487,  -1.0552,  -6.6178,  -4.3282,  -3.8035,  -2.7373,\n",
      "         -13.0163,  -1.5313,  -3.8907]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.1602888107299805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5946,  -8.8706,  -1.4125,  -7.8897,  -4.7587,  -3.7107,  -2.6420,\n",
      "         -13.6282,  -2.4897,  -4.0752]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.870560646057129\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4044,  -8.4965,  -1.8114,  -8.9346,  -5.0521,  -3.5457,  -2.5063,\n",
      "         -14.0785,  -3.3156,  -4.1532]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.052134037017822\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4385,  -7.8590,  -1.9890,  -9.5748,  -4.2844,  -3.1191,  -2.1415,\n",
      "         -14.1832,  -3.7862,  -3.9339]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.1415047645568848\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8775,  -7.2059,  -2.1695, -10.0719,  -3.5238,  -2.6902,  -1.1070,\n",
      "         -14.1981,  -4.1478,  -3.6712]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.1070194244384766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1954,  -7.2268,  -3.0240, -11.1281,  -3.4692,  -2.9659,  -0.3102,\n",
      "         -14.8200,  -5.0941,  -4.0616]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.061555862426758\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5084,  -7.2884,  -3.8711, -12.1214,  -3.4851,  -3.2969,  -0.1569,\n",
      "         -15.4222,  -5.9931,  -3.7463]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.5084145069122314\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5298,  -6.9179,  -4.2227, -12.5893,  -3.0956,  -3.1977,  -0.1984,\n",
      "         -15.5380,  -6.3780,  -3.0529]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  15.538032531738281\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1779,  -6.1917,  -4.1567, -12.6173,  -2.3849,  -2.7471,  -0.4210,\n",
      "         -14.5079,  -6.3326,  -2.0694]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.3849005699157715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0121,  -5.6590,  -4.2285, -12.7622,  -1.1980,  -2.5116,  -1.2030,\n",
      "         -13.7000,  -6.4128,  -1.3948]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.0121374130249023\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5092,  -5.5436,  -4.6654, -13.2544,  -0.7132,  -2.7252,  -2.4801,\n",
      "         -13.3343,  -6.8479,  -1.3283]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  13.334257125854492\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0859,  -5.4111,  -5.0342, -13.6660,  -0.6058,  -2.9376,  -3.6576,\n",
      "         -12.2366,  -7.2090,  -1.4284]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.2089667320251465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5923,  -5.0890,  -5.1650, -13.8306,  -0.7041,  -2.9647,  -4.5300,\n",
      "         -11.0422,  -6.5629,  -1.4859]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.5300211906433105\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1310,  -4.6336,  -5.1169, -13.8088,  -0.9854,  -2.8598,  -4.4464,\n",
      "          -9.7967,  -5.8122,  -1.5314]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.1310255527496338\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4773,  -4.5013,  -5.3486, -14.0597,  -1.7829,  -3.0810,  -4.6498,\n",
      "          -8.9457,  -5.4090,  -1.9992]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.50132417678833\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2880,  -3.5787,  -5.4931, -14.2180,  -2.5569,  -3.2489,  -4.7722,\n",
      "          -8.1119,  -4.9818,  -2.4509]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.2489278316497803\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3959,  -2.4848,  -5.3422, -14.0765,  -3.0268,  -2.3587,  -4.6043,\n",
      "          -7.0775,  -4.3184,  -2.6362]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.4847793579101562\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1238,  -0.9489,  -5.3375, -14.0768,  -3.6132,  -1.7592,  -4.5879,\n",
      "          -6.2742,  -3.8589,  -2.9825]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.982473373413086\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5451,  -0.3771,  -5.8598, -14.6000,  -4.6839,  -1.8780,  -5.1032,\n",
      "          -6.0752,  -3.9842,  -3.1297]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.8779921531677246\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9247,  -0.4136,  -6.3732, -15.1122,  -5.6959,  -1.3613,  -5.6125,\n",
      "          -5.9388,  -4.1524,  -3.3349]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.373176574707031\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.9360,  -0.6912,  -5.8573, -15.3276,  -6.3640,  -0.8521,  -5.8280,\n",
      "          -5.5722,  -4.0702,  -3.2998]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  6.36398458480835\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6586,  -1.1182,  -5.2013, -15.3282,  -6.0376,  -0.5354,  -5.8306,\n",
      "          -5.0514,  -3.8158,  -3.1014]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.5354375243186951\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.6193,  -2.0520,  -4.9222, -15.6361,  -6.0530,  -0.2324,  -6.1425,\n",
      "          -4.8947,  -3.9111,  -3.2627]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.922183990478516\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.1172,  -2.6197,  -3.5783, -15.5452,  -5.7004,  -0.2136,  -6.0567,\n",
      "          -4.3910,  -3.6442,  -3.0676]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.056718349456787\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.1895,  -2.8083,  -2.0121, -15.0867,  -5.0086,  -0.4506,  -4.8994,\n",
      "          -3.5700,  -3.0473,  -2.5489]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.0120532512664795\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.7730,  -3.5406,  -0.4901, -15.1917,  -4.9086,  -1.6777,  -4.3805,\n",
      "          -3.3695,  -3.0642,  -2.6564]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.6563944816589355\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.9115,  -4.8342,  -0.1811, -15.8989,  -5.4366,  -3.5410,  -4.5347,\n",
      "          -3.8272,  -3.7281,  -2.6935]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.436557292938232\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.5960,  -5.6643,  -0.1716, -16.1951,  -4.8422,  -4.9008,  -4.3405,\n",
      "          -3.9150,  -4.0037,  -2.4353]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  9.596025466918945\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.9985,  -5.9511,  -0.3118, -15.9986,  -3.8496,  -5.6678,  -3.7116,\n",
      "          -3.5457,  -3.8028,  -1.8029]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.802905559539795\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.5326,  -6.2835,  -1.0400, -15.8938,  -3.0436,  -6.4334,  -3.2347,\n",
      "          -3.3068,  -3.7113,  -0.7037]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.2834930419921875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.3765,  -6.1054,  -2.2146, -16.0627,  -2.6159,  -7.3871,  -3.0964,\n",
      "          -3.3822,  -3.9109,  -0.3349]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.382183313369751\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.0924,  -5.8030,  -3.2077, -16.0710,  -2.1409,  -8.1028,  -2.8601,\n",
      "          -2.5887,  -3.9624,  -0.3755]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  8.092434883117676\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8938,  -5.3364,  -3.9347, -15.8820,  -1.6029,  -8.5508,  -2.4912,\n",
      "          -1.7335,  -3.8269,  -0.7095]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.8268685340881348\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8675,  -4.9721,  -4.6557, -15.7640,  -1.3187,  -9.0067,  -2.2700,\n",
      "          -1.1472,  -3.0041,  -1.4159]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.4158802032470703\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1022,  -4.8058,  -5.4685, -15.8144,  -1.4161,  -9.5739,  -2.3006,\n",
      "          -1.0122,  -2.4581,  -1.6631]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.573884010314941\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2863,  -4.5309,  -6.0723, -15.7285,  -1.5509,  -9.1708,  -2.2679,\n",
      "          -1.0297,  -1.9012,  -1.8907]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.286308765411377\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7508,  -4.2235,  -6.5497, -15.5834,  -1.7603,  -8.7401,  -2.2440,\n",
      "          -1.2432,  -1.4469,  -2.1361]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.750840187072754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9612,  -4.2420,  -7.2651, -15.7371,  -2.3598,  -8.6368,  -2.5821,\n",
      "          -1.9344,  -1.5037,  -2.7264]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.582069158554077\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2758,  -4.9101,  -8.5505, -16.5163,  -3.6098,  -9.1846,  -2.8729,\n",
      "          -3.3049,  -2.3670,  -3.9458]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.872889518737793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.1764,  -5.4687,  -9.6597, -17.1694,  -4.7069,  -9.6296,  -2.4224,\n",
      "          -4.5179,  -3.1681,  -5.0092]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.4223990440368652\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4554,  -5.7209, -10.4045, -17.5036,  -5.4475,  -9.7763,  -1.1250,\n",
      "          -5.3643,  -3.6681,  -5.7176]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.668095588684082\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3431,  -6.1180, -11.2428, -17.9721,  -6.2851, -10.0761,  -0.3532,\n",
      "          -6.2976,  -3.5361,  -6.5255]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.297562599182129\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3265,  -6.4684, -11.9888, -18.3851,  -7.0318, -10.3372,  -0.1449,\n",
      "          -6.3861,  -3.4308,  -7.2451]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.430816173553467\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9041,  -6.4049, -12.2805, -18.3769,  -7.3248, -10.1923,  -0.1851,\n",
      "          -6.0870,  -2.2164,  -7.5136]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.2164320945739746\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5829,  -6.4672, -12.6613, -18.4877,  -7.7072, -10.1800,  -0.9205,\n",
      "          -5.9374,  -0.5642,  -7.8738]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  18.48765754699707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8042,  -7.1139, -13.5936, -18.4208,  -8.6415, -10.7584,  -2.4504,\n",
      "          -6.3943,  -0.1024,  -8.7880]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.78800106048584\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5688,  -7.3556, -14.0920, -18.0195,  -9.1416, -10.9381,  -3.5472,\n",
      "          -6.4657,  -0.0358,  -8.5501]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.03576647490262985\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3250e+00, -7.6386e+00, -1.4606e+01, -1.7723e+01, -9.6569e+00,\n",
      "         -1.1165e+01, -4.6198e+00, -6.5960e+00, -1.3893e-02, -8.4008e+00]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  11.164688110351562\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2775e+00, -7.1641e+00, -1.4338e+01, -1.6726e+01, -9.3912e+00,\n",
      "         -9.8576e+00, -4.8628e+00, -5.9846e+00, -1.3661e-02, -7.5369e+00]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  16.72611427307129\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5108,  -6.0121, -13.3724, -14.3512,  -8.4267,  -7.9554,  -4.3617,\n",
      "          -4.7107,  -0.0317,  -6.0340]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.012136459350586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2144,  -3.6232, -11.8936, -11.6036,  -6.9494,  -5.6337,  -3.3105,\n",
      "          -2.9613,  -0.1640,  -4.0734]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.6232337951660156\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3812,  -1.0759, -10.8851,  -9.4526,  -5.9429,  -3.8691,  -2.7125,\n",
      "          -1.7477,  -1.2387,  -2.6434]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.452601432800293\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9644,  -0.3440, -11.2852,  -8.0758,  -6.3468,  -3.6047,  -3.5289,\n",
      "          -2.0931,  -3.7315,  -2.7153]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.3439571261405945\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1482,  -0.1138, -12.2901,  -7.4808,  -7.3564,  -4.0325,  -4.9292,\n",
      "          -3.1407,  -6.6386,  -3.4723]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.480803966522217\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.7329,  -0.0847, -12.7094,  -5.7160,  -7.7803,  -3.9461,  -5.7096,\n",
      "          -3.6308,  -8.7718,  -3.6908]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.732880592346191\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.9360,  -0.1537, -12.5033,  -3.5457,  -7.5788,  -3.2998,  -5.8310,\n",
      "          -3.5083, -10.1092,  -3.3220]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.109158515930176\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9909,  -0.6129, -12.0848,  -1.3802,  -7.1648,  -2.5139,  -5.7094,\n",
      "          -3.1874, -10.3249,  -2.7831]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.3801584243774414\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4559,  -2.7261, -13.0103,  -0.1755,  -8.0948,  -3.1721,  -6.9047,\n",
      "          -4.2317, -11.8216,  -3.6448]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  11.821556091308594\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.2024,  -4.9962, -14.1629,  -0.0424,  -9.2518,  -4.1170,  -8.3009,\n",
      "          -5.5021, -12.7391,  -4.7589]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.0424494706094265\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0006e+00, -7.1672e+00, -1.5323e+01, -1.3427e-02, -1.0415e+01,\n",
      "         -5.1025e+00, -9.6801e+00, -6.7710e+00, -1.3687e+01, -5.8901e+00]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.890148639678955\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0076e+00, -8.4092e+00, -1.5653e+01, -1.2844e-02, -1.0750e+01,\n",
      "         -5.2811e+00, -1.0209e+01, -7.2008e+00, -1.3827e+01, -5.4758e+00]],\n",
      "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.20083475112915\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.2988,  -8.8107, -15.2342,  -0.0291, -10.3340,  -4.7290,  -9.9674,\n",
      "          -6.1247, -13.2366,  -4.3888]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.33398151397705\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0296,  -8.5376, -14.2221,  -0.1257,  -8.5829,  -3.6041,  -9.1156,\n",
      "          -4.5225, -12.0700,  -2.7842]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.7842042446136475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0066,  -8.3985, -13.4174,  -0.9665,  -7.1128,  -2.7192,  -8.4554,\n",
      "          -3.1947, -11.1261,  -0.7723]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.112837791442871\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0614,  -9.2126, -13.6319,  -2.9424,  -5.9918,  -2.9136,  -8.8001,\n",
      "          -2.9688, -11.2154,  -0.2332]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.061427116394043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3395,  -9.8813, -13.7607,  -4.6961,  -4.9199,  -3.0670,  -9.0463,\n",
      "          -2.7394, -11.2314,  -0.2538]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  9.881328582763672\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4658,  -9.4506, -13.5814,  -5.9867,  -3.6647,  -2.9466,  -8.9728,\n",
      "          -2.2859, -10.9506,  -0.5335]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  9.45055103302002\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8544,  -8.3344, -13.4237,  -7.1545,  -2.5573,  -2.8834,  -8.9104,\n",
      "          -1.9574, -10.7015,  -1.2087]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.334381103515625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7125,  -6.6950, -13.3742,  -8.2990,  -1.7100,  -2.9631,  -8.9468,\n",
      "          -1.8598, -10.5696,  -2.1227]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.7124848961830139\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5459,  -5.5590, -13.6687,  -9.6689,  -1.4203,  -3.4148,  -9.3188,\n",
      "          -2.2278, -10.7900,  -3.3707]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.4148306846618652\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6515,  -4.3644, -13.7596, -10.7281,  -1.1644,  -2.8855,  -9.4795,\n",
      "          -2.4655, -10.8142,  -4.3448]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  10.728109359741211\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9425,  -3.1078, -13.6511, -10.7509,  -0.9752,  -2.2625,  -9.4340,\n",
      "          -2.5530, -10.6457,  -5.0409]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.645659446716309\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4272,  -1.9434, -13.4878, -10.7058,  -1.0188,  -1.7179,  -9.3274,\n",
      "          -2.6244,  -9.6795,  -5.6066]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.6244430541992188\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1867,  -1.1451, -13.4860, -10.8105,  -1.4709,  -1.5143,  -9.3767,\n",
      "          -2.1397,  -8.9549,  -6.2641]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.264063358306885\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0396,  -0.7453, -13.5703, -10.9906,  -2.1341,  -1.5901,  -9.5071,\n",
      "          -1.8772,  -8.3884,  -6.2251]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  13.570296287536621\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7366,  -0.6267, -12.8016, -11.0463,  -2.7126,  -1.7128,  -9.5181,\n",
      "          -1.6489,  -7.7720,  -6.0850]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.7125630378723145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2094,  -0.7382, -11.9370, -10.9240,  -2.3684,  -1.7929,  -9.3555,\n",
      "          -1.4147,  -7.0447,  -5.7879]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.0446600914001465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4505,  -0.9989, -10.9724, -10.6117,  -1.9358,  -1.8066,  -9.0211,\n",
      "          -1.1967,  -5.4447,  -5.3288]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.9357837438583374\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7137,  -1.6026, -10.2412, -10.3106,  -0.9955,  -2.0431,  -8.8333,\n",
      "          -1.3267,  -4.0153,  -4.9785]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  10.241207122802734\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1144,  -2.3867,  -8.9152, -10.2569,  -0.5454,  -2.4598,  -8.7506,\n",
      "          -1.7393,  -2.9404,  -4.8080]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.7393360137939453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5156,  -3.1960,  -7.7574, -10.2446,  -0.6038,  -2.9385,  -8.7123,\n",
      "          -1.5295,  -2.0480,  -4.6963]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.712285995483398\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.7717,  -3.8464,  -6.6069, -10.1253,  -0.9510,  -3.3032,  -7.8602,\n",
      "          -1.3942,  -1.2330,  -4.4941]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.771718978881836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.2558,  -4.4417,  -5.5658, -10.0118,  -1.5418,  -3.6545,  -7.0872,\n",
      "          -1.4518,  -0.7115,  -4.3140]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.5657958984375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6992, -4.8904, -3.8036, -9.8138, -2.1355, -3.8955, -6.2958, -1.5829,\n",
      "         -0.5140, -4.0655]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.890409469604492\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0428, -4.4054, -2.0712, -9.4736, -2.5952, -3.9665, -5.4226, -1.6925,\n",
      "         -0.6214, -3.6921]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.692129611968994\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6575, -4.1703, -0.7969, -9.3600, -3.2569, -4.2383, -4.8321, -2.1216,\n",
      "         -1.3119, -2.8495]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.7968571186065674\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2599,  -4.9001,  -0.1771, -10.1880,  -4.8114,  -5.4246,  -5.2363,\n",
      "          -3.5279,  -3.0650,  -3.0624]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.17705538868904114\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3569,  -6.1067,  -0.0438, -11.4777,  -6.7612,  -7.0404,  -6.1481,\n",
      "          -5.3603,  -5.2225,  -3.8318]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  11.477662086486816\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.7481,  -6.5947,  -0.0300, -11.2984,  -7.9175,  -7.8959,  -6.3705,\n",
      "          -6.4136,  -6.5690,  -3.9400]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.594744682312012\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4233,  -5.6270,  -0.0490, -10.4576,  -8.2797,  -7.9871,  -5.8926,\n",
      "          -6.6840,  -7.1033,  -3.3720]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.04896698519587517\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1790, -4.8030, -0.0761, -9.7455, -8.6509, -8.1144, -5.5091, -6.9732,\n",
      "         -7.6298, -2.9302]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.803020000457764\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4298, -2.8093, -0.2419, -8.5708, -8.4519, -7.6959, -4.6333, -6.7010,\n",
      "         -7.5709, -2.0373]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.700969219207764\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8080, -1.1018, -1.0044, -7.5572, -8.3168, -7.3633, -3.8956, -5.7514,\n",
      "         -7.5622, -1.3711]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.1017802953720093\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4027, -0.2192, -3.0947, -7.7829, -9.3333, -8.2024, -4.3838, -6.0368,\n",
      "         -8.6927, -2.0919]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.202374458312988\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0180,  -0.0808,  -5.0806,  -8.0571, -10.3194,  -8.2363,  -4.9030,\n",
      "          -6.3663,  -9.7815,  -2.9005]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.366250991821289\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0207,  -0.0689,  -6.3170,  -7.7480, -10.6510,  -7.7108,  -4.8196,\n",
      "          -5.3633, -10.2057,  -3.1120]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.747988700866699\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4235,  -0.1265,  -6.8271,  -6.1266, -10.3452,  -6.6334,  -4.1457,\n",
      "          -3.8593,  -9.9832,  -2.7300]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.633433818817139\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5091, -0.4241, -6.9016, -4.2825, -9.6841, -4.4916, -3.1645, -2.1350,\n",
      "         -9.3972, -2.0473]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.684100151062012\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0138, -1.4659, -7.2752, -2.9380, -8.6544, -2.8777, -2.6170, -0.9765,\n",
      "         -9.1754, -1.8315]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.938000202178955\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2099, -3.1748, -8.2174, -1.6361, -8.3327, -2.0742, -2.7816, -0.8203,\n",
      "         -9.5810, -2.3581]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.17480206489563\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6798,  -4.2858,  -9.3292,  -0.8711,  -8.3064,  -1.7133,  -3.2374,\n",
      "          -1.2717, -10.2096,  -3.1637]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.209553718566895\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1667,  -5.3409, -10.3752,  -0.5369,  -8.3278,  -1.5758,  -3.7208,\n",
      "          -1.9324, -10.0695,  -3.9645]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.9324116706848145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5102,  -6.1879, -11.2107,  -0.5618,  -8.2407,  -1.5091,  -4.0669,\n",
      "          -1.7832,  -9.8369,  -4.5929]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  11.210698127746582\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5536,  -6.6779, -10.9588,  -0.7308,  -7.8883,  -1.3499,  -4.1167,\n",
      "          -1.5000,  -9.3534,  -4.8918]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  10.958768844604492\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3903, -6.9097, -9.7969, -1.0273, -7.3609, -1.2013, -3.9629, -1.2009,\n",
      "         -8.7077, -4.9561]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  1.0272510051727295\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3206, -7.1873, -8.8189, -0.8890, -6.9547, -1.3736, -3.9062, -1.2241,\n",
      "         -8.1945, -5.0872]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.8889608383178711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4247, -7.5947, -8.0952, -0.4882, -6.7464, -1.8859, -4.0264, -1.6209,\n",
      "         -7.8895, -5.3666]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.594655513763428\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3021, -7.0195, -7.2184, -0.3534, -6.3344, -2.2419, -3.9222, -1.9003,\n",
      "         -7.3898, -5.3962]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.9002749919891357\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9927, -6.2931, -6.2203, -0.5379, -5.7556, -2.4374, -3.6334, -1.3088,\n",
      "         -6.7312, -5.2170]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.755629062652588\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5691, -5.4814, -5.1642, -0.9725, -4.3382, -2.5238, -3.2335, -0.8183,\n",
      "         -5.9802, -4.9008]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.9007568359375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1555, -4.7002, -4.1639, -1.5870, -3.0182, -2.6118, -2.8484, -0.6514,\n",
      "         -5.2524, -3.8445]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.700188636779785\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8246, -3.2994, -3.2841, -2.2996, -1.8754, -2.7587, -2.5529, -0.8977,\n",
      "         -4.6106, -2.9184]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.8754191398620605\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0787, -2.5717, -3.0266, -3.5222, -0.7296, -3.4487, -2.8503, -1.9292,\n",
      "         -4.5476, -2.6309]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.0786917209625244\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9558, -2.3354, -3.1942, -5.0090, -0.4194, -4.4594, -3.5239, -3.3302,\n",
      "         -4.8630, -2.7884]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.863020896911621\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6998, -2.0074, -3.1906, -6.1683, -0.4420, -5.1943, -3.9673, -4.4339,\n",
      "         -4.2172, -2.7903]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.190615177154541\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3267, -1.6151, -2.2982, -7.0205, -0.7434, -5.6674, -4.1872, -5.2435,\n",
      "         -3.4537, -2.6435]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.4537136554718018\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1229, -1.4632, -1.6266, -7.8475, -1.4237, -6.1550, -4.4550, -6.0353,\n",
      "         -2.1021, -2.6217]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.847541332244873\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2415, -1.7044, -1.3771, -8.0696, -2.4258, -6.8079, -4.9167, -6.9622,\n",
      "         -1.1889, -2.8670]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.8669724464416504\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5772, -2.2010, -1.4851, -8.4189, -3.5423, -7.5457, -5.4868, -7.9466,\n",
      "         -0.7445, -2.5550]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.545693874359131\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8310, -2.6218, -1.6417, -8.6279, -4.4634, -7.3109, -5.8975, -8.7276,\n",
      "         -0.5954, -2.2247]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.6416683197021484\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0565, -3.0054, -1.1499, -8.7688, -5.2539, -7.0526, -6.2219, -9.3836,\n",
      "         -0.8271, -1.9581]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.8271136283874512\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4525,  -3.5440,  -1.0949,  -9.0534,  -6.1273,  -6.9783,  -6.6731,\n",
      "         -10.1320,  -0.7723,  -1.9779]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.4525387287139893\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8698,  -3.8368,  -1.0757,  -9.0970,  -6.7024,  -6.6993,  -6.8674,\n",
      "         -10.5931,  -0.8559,  -1.8831]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.075681447982788\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4886,  -4.2170,  -0.6815,  -9.2373,  -7.3222,  -6.5500,  -7.1441,\n",
      "         -11.1093,  -1.3499,  -2.0090]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.349869728088379\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2279,  -4.5901,  -0.7140,  -9.3838,  -7.9009,  -6.4370,  -7.4140,\n",
      "         -11.5943,  -1.2613,  -2.2398]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.900936126708984\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8478,  -4.7070,  -0.8720,  -9.2896,  -7.4577,  -6.1101,  -7.4312,\n",
      "         -11.8047,  -1.1668,  -2.2985]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  11.804680824279785\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4435,  -4.6384,  -1.1366,  -9.0243,  -6.8785,  -5.6371,  -7.2667,\n",
      "         -11.0675,  -1.1337,  -2.2438]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.878542423248291\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1167,  -4.4433,  -1.4669,  -8.6453,  -5.4842,  -5.0738,  -6.9788,\n",
      "         -10.2636,  -1.2040,  -2.1312]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.645309448242188\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9346, -4.1422, -1.7975, -7.4370, -4.0979, -4.4376, -6.5863, -9.4058,\n",
      "         -1.3572, -1.9822]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.9821879863739014\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1005, -3.9176, -2.2503, -6.3845, -2.8968, -3.9093, -6.2690, -8.6684,\n",
      "         -1.7222, -1.2575]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.384511470794678\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5664, -3.7963, -2.8011, -4.7761, -1.9226, -3.5162, -6.0513, -8.0713,\n",
      "         -2.2511, -0.8778]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.8011138439178467\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2423, -3.8028, -2.7147, -3.4334, -1.2525, -3.2853, -5.9564, -7.6333,\n",
      "         -2.9054, -0.9366]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.905391216278076\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9909, -3.8849, -2.7449, -2.3083, -0.9198, -3.1676, -5.9331, -7.2995,\n",
      "         -2.8478, -1.3336]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.744922161102295\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7812, -4.0521, -2.1752, -1.4464, -0.9922, -3.1736, -5.9925, -7.0779,\n",
      "         -2.9175, -1.9603]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.992537498474121\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5708, -4.2761, -1.8050, -0.9037, -1.3910, -3.2732, -5.3830, -6.9398,\n",
      "         -3.0815, -2.6874]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.8050119876861572\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4591, -4.6572, -1.0405, -0.8815, -2.1027, -3.5627, -5.0070, -6.9856,\n",
      "         -3.4328, -3.5610]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.985620498657227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.2547, -4.9999, -0.5996, -1.1574, -2.8260, -3.8385, -4.6658, -6.2752,\n",
      "         -3.7659, -4.3608]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.665799617767334\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8091, -5.1498, -0.4349, -1.4724, -3.3574, -3.9407, -3.4801, -5.4734,\n",
      "         -3.9196, -4.9268]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.149798393249512\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0665, -4.3251, -0.5094, -1.6813, -3.6190, -3.8055, -2.1921, -4.5119,\n",
      "         -3.8301, -5.1990]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.8300938606262207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.2794, -3.5726, -0.9883, -1.9863, -3.8548, -3.6821, -1.0938, -3.6348,\n",
      "         -3.0011, -5.4286]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.572624683380127\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.7365, -2.4632, -1.9513, -2.6263, -4.3477, -3.8561, -0.6128, -3.1297,\n",
      "         -2.5566, -5.9035]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.90354585647583\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.2255, -1.6024, -2.9975, -3.3327, -4.8780, -4.1067, -0.6494, -2.7845,\n",
      "         -2.2912, -5.6842]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.87801456451416\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.6542, -0.9606, -3.9637, -3.9832, -4.6123, -4.3338, -1.0487, -2.5082,\n",
      "         -2.1159, -5.4774]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.333835124969482\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.0344, -0.6524, -4.8413, -4.5766, -4.3744, -3.7441, -1.6556, -2.3143,\n",
      "         -2.0420, -5.2882]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  4.374443054199219\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.2618, -0.6345, -5.5222, -5.0034, -3.3222, -3.1168, -2.2252, -2.0986,\n",
      "         -1.9572, -5.0064]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.003370761871338\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.3469, -0.8795, -6.0185, -4.5394, -2.2813, -2.4676, -2.6966, -1.8765,\n",
      "         -1.8666, -4.6378]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.539413928985596\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.4606, -1.4351, -6.5041, -3.4384, -1.4562, -1.9880, -3.2069, -1.8283,\n",
      "         -1.9376, -4.3500]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.8283008337020874\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.8148, -2.3580, -7.1942, -2.7221, -1.1363, -1.9173, -3.9475, -1.4092,\n",
      "         -2.3609, -4.3519]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.358044385910034\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.1879,  -2.5923,  -7.8704,  -2.1794,  -1.1384,  -2.0256,  -4.6826,\n",
      "          -1.2689,  -2.8667,  -4.4172]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.5923283100128174\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.4799,  -2.0981,  -8.4354,  -1.7292,  -1.3315,  -2.1846,  -5.3071,\n",
      "          -1.3087,  -3.3207,  -4.4408]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.440761566162109\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.6851,  -1.6830,  -8.8867,  -1.3959,  -1.6417,  -2.3601,  -5.8154,\n",
      "          -1.4889,  -3.6989,  -3.6883]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.360149621963501\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.9074,  -1.4797,  -9.3305,  -1.3142,  -2.1007,  -1.8326,  -6.3127,\n",
      "          -1.8574,  -4.0953,  -3.0662]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.3141705989837646\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.3038,  -1.6559,  -9.9266,  -0.9037,  -2.8003,  -1.6817,  -6.9581,\n",
      "          -2.5023,  -4.6611,  -2.7363]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.6558537483215332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.7317,  -1.3080, -10.5342,  -0.9009,  -3.5458,  -1.7654,  -7.6108,\n",
      "          -3.2151,  -5.2485,  -2.5571]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  11.731705665588379\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.2208,  -1.0493, -10.9426,  -1.0561,  -4.0996,  -1.8387,  -8.0601,\n",
      "          -3.7483,  -5.6426,  -2.3133]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.060140609741211\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.6004,  -0.9062, -11.1501,  -1.2891,  -4.4502,  -1.8715,  -7.5788,\n",
      "          -4.0858,  -5.8399,  -2.0054]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.8714631795883179\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.0472,  -1.0713, -11.3423,  -1.7053,  -4.7798,  -1.2320,  -7.1511,\n",
      "          -4.4077,  -6.0251,  -1.8314]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  11.342297554016113\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.4840,  -1.3994, -10.7282,  -2.1474,  -5.0177,  -0.8238,  -6.7015,\n",
      "          -4.6416,  -6.1285,  -1.7262]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.3994178771972656\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.9987,  -1.1789, -10.1970,  -2.6526,  -5.2586,  -0.8278,  -6.3192,\n",
      "          -4.8811,  -6.2451,  -1.7826]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.319242477416992\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.3513, -0.9892, -9.5082, -2.9484, -5.2689, -0.9688, -5.0437, -4.8921,\n",
      "         -6.1410, -1.7454]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.948406219482422\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.6182, -0.9332, -8.7377, -2.3728, -5.1316, -1.2473, -3.7495, -4.7573,\n",
      "         -5.8986, -1.6887]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.9331574440002441\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.1629, -0.6546, -8.2485, -2.1267, -5.2168, -1.9310, -2.8056, -4.8468,\n",
      "         -5.8868, -1.9765]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.216761589050293\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6719, -0.6921, -7.7264, -1.9104, -4.4791, -2.5803, -1.9177, -4.8516,\n",
      "         -5.7966, -2.2550]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.671852111816406\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4205, -1.0277, -7.2026, -1.7695, -3.7691, -3.1713, -1.1708, -4.8077,\n",
      "         -5.6636, -2.5281]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.202611923217773\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3122, -1.5995, -6.0266, -1.7820, -3.1620, -3.7520, -0.7383, -4.7895,\n",
      "         -5.5616, -2.8474]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.1620025634765625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3335, -2.2670, -4.9785, -1.9251, -1.9226, -4.3027, -0.7044, -4.7884,\n",
      "         -5.4817, -3.1862]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.788416385650635\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5621, -3.0247, -4.1225, -2.2433, -0.9970, -4.8923, -1.1147, -4.1255,\n",
      "         -5.4958, -3.6044]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.892258644104004\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0787, -3.8942, -3.5161, -2.7600, -0.5876, -4.7843, -1.8742, -3.6935,\n",
      "         -5.6642, -4.1535]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.7599799633026123\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7129, -4.6662, -2.9661, -2.5164, -0.6019, -4.6683, -2.6438, -3.2976,\n",
      "         -5.7930, -4.6339]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.516376495361328\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4868, -5.3343, -2.4743, -1.5968, -0.9827, -4.5375, -3.3545, -2.9352,\n",
      "         -5.8775, -5.0398]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.3545169830322266\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5395, -6.0240, -2.1769, -1.0006, -1.6845, -4.5129, -3.3794, -2.7333,\n",
      "         -6.0404, -5.4946]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.040350914001465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7539, -6.6506, -1.9952, -0.7351, -2.4565, -4.5034, -3.4304, -2.6045,\n",
      "         -5.4394, -5.9112]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.7350884079933167\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.3626, -7.4999, -2.2141, -0.4026, -3.4985, -4.7877, -3.7838, -2.8282,\n",
      "         -5.1857, -6.5723]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.4985079765319824\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7459, -8.0287, -2.2540, -0.3526, -3.4888, -4.8141, -3.8821, -2.8378,\n",
      "         -4.7251, -6.9323]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.028701782226562\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7913, -7.4428, -2.0174, -0.4680, -3.1539, -4.4956, -3.6370, -2.5420,\n",
      "         -3.9684, -6.9086]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.791347026824951\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9770, -6.7732, -1.7583, -0.8816, -2.7411, -4.0754, -3.2929, -2.1925,\n",
      "         -3.1589, -6.7456]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.2928929328918457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4512, -6.2733, -1.7522, -1.6553, -2.5189, -3.8128, -2.3899, -2.0642,\n",
      "         -2.5643, -6.7019]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.064223051071167\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3931, -6.0622, -2.1101, -2.7275, -2.6155, -3.8316, -1.8807, -1.5295,\n",
      "         -2.3247, -6.9011]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.831634283065796\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5885, -5.9331, -2.5796, -3.7996, -2.8154, -3.1298, -1.5917, -1.2704,\n",
      "         -2.2421, -7.1405]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.2420926094055176\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9892, -5.8884, -3.1271, -4.8509, -3.1090, -2.6023, -1.5484, -1.3181,\n",
      "         -1.5646, -7.4263]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.1270737648010254\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4730, -5.8692, -2.9459, -5.8223, -3.4253, -2.2055, -1.6824, -1.5815,\n",
      "         -1.1315, -7.7033]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.473036289215088\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2123, -5.8520, -2.8187, -6.6971, -3.7320, -1.9340, -1.9354, -1.9715,\n",
      "         -0.9827, -7.9510]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.95095682144165\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9467, -5.7247, -2.6336, -7.3719, -3.9119, -1.6908, -2.1540, -2.3137,\n",
      "         -1.0172, -7.3270]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.9466872215270996\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1273, -5.6789, -2.5856, -8.0465, -4.1551, -1.6854, -2.5013, -2.7628,\n",
      "         -1.3872, -6.8322]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.832189083099365\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6640, -5.6697, -2.6265, -8.6838, -4.4152, -1.8579, -2.9030, -3.2443,\n",
      "         -1.9382, -5.6883]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.6697258949279785\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5076, -4.8224, -2.5874, -9.1293, -4.5299, -2.0092, -3.1760, -3.5789,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -2.4144, -4.5324]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.532358169555664\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6157, -3.8601, -2.4017, -9.3254, -4.4360, -2.0473, -3.2470, -3.6961,\n",
      "         -2.7055, -2.5696]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.6960947513580322\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2649, -3.1538, -2.4453, -9.6472, -4.5053, -2.3299, -3.4843, -3.2124,\n",
      "         -3.1633, -1.0032]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.505343437194824\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5543,  -3.0407,  -3.0400, -10.4294,  -4.3337,  -3.1543,  -4.2126,\n",
      "          -3.2994,  -4.0997,  -0.3531]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.299438714981079\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7495,  -2.9485,  -3.5858, -11.1093,  -4.1644,  -3.9063,  -4.8547,\n",
      "          -2.6327,  -4.9310,  -0.2565]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.930974006652832\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5201,  -2.5796,  -3.7740, -11.3981,  -3.6999,  -4.2761,  -5.1152,\n",
      "          -1.7630,  -4.6071,  -0.4092]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.2761054039001465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.1045,  -2.1840,  -3.8425, -11.5405,  -3.1822,  -3.7048,  -5.2364,\n",
      "          -0.9908,  -4.2052,  -0.9106]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.842522144317627\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.7101,  -1.9833,  -3.2688, -11.7436,  -2.8214,  -3.2849,  -5.4243,\n",
      "          -0.6493,  -3.9295,  -1.7285]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.2849080562591553\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.2508,  -1.8938,  -2.7725, -11.9193,  -2.5330,  -2.1374,  -5.5894,\n",
      "          -0.7264,  -3.6888,  -2.5864]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.7725319862365723\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8519,  -2.0340,  -1.7619, -12.1903,  -2.4448,  -1.3108,  -5.8538,\n",
      "          -1.2710,  -3.6038,  -3.5264]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  12.190332412719727\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.5856,  -2.4456,  -1.1678, -11.8986,  -2.6208,  -0.9723,  -6.2854,\n",
      "          -2.1631,  -3.7394,  -4.5859]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.620771884918213\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.3011,  -2.9327,  -0.9126, -11.6903,  -2.1531,  -1.0225,  -6.7299,\n",
      "          -3.1069,  -3.9338,  -5.6016]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.729893684387207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.8057,  -3.2698,  -0.8340, -11.3629,  -1.6775,  -1.2134,  -6.2644,\n",
      "          -3.8505,  -3.9839,  -6.3792]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.3792033195495605\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.0958,  -3.4361,  -0.9130, -10.9037,  -1.2222,  -1.4568,  -5.6821,\n",
      "          -4.3716,  -3.8786,  -6.1892]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.37158203125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.2142,  -3.4661,  -1.1315, -10.3474,  -0.8860,  -1.7179,  -5.0175,\n",
      "          -3.9576,  -3.6566,  -5.8768]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.466137409210205\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.1930, -2.6711, -1.4336, -9.7186, -0.7585, -1.9676, -4.2960, -3.4713,\n",
      "         -3.3484, -5.4696]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.6710991859436035\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.1980, -1.3162, -1.9020, -9.1764, -1.0115, -2.3275, -3.6801, -3.0805,\n",
      "         -3.1213, -5.1300]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.176369667053223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.4585, -0.5439, -2.6878, -8.2189, -1.7622, -2.9849, -3.3999, -3.0191,\n",
      "         -3.2063, -5.0844]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.084393501281738\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.7383, -0.3086, -3.4896, -7.4020, -2.6093, -3.6622, -3.2170, -3.0454,\n",
      "         -3.3585, -4.3697]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.2170238494873047\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.7579, -0.3882, -4.0015, -6.4346, -3.1938, -4.0602, -2.1239, -2.8725,\n",
      "         -3.2897, -3.5030]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.001474857330322\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.6837, -0.8500, -3.6591, -5.4727, -3.6584, -4.3403, -1.1345, -2.6672,\n",
      "         -3.1640, -2.6524]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.6583948135375977\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.7882, -1.7407, -3.5407, -4.7809, -3.5314, -4.7743, -0.6488, -2.7058,\n",
      "         -3.2542, -2.1089]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.5406851768493652\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.9007, -2.6858, -2.7533, -4.1825, -3.4569, -5.1901, -0.6098, -2.8091,\n",
      "         -3.3831, -1.7258]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.3830831050872803\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.9292, -3.5124, -2.0173, -3.5818, -3.3401, -5.4961, -0.8961, -2.8744,\n",
      "         -2.6950, -1.4372]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.896069347858429\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.1786,  -4.5018,  -1.6744,  -3.2851,  -3.4847,  -5.9987,  -0.9482,\n",
      "          -3.1995,  -2.3504,  -1.5735]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.6744102239608765\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.5210,  -5.5182,  -0.8998,  -3.1628,  -3.7551,  -6.5709,  -1.3936,\n",
      "          -3.6405,  -2.2299,  -1.9643]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.7551209926605225\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.8787,  -6.4859,  -0.5449,  -3.1331,  -3.3332,  -7.1368,  -2.0242,\n",
      "          -4.1068,  -2.2523,  -2.4675]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.136765480041504\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.0339,  -7.1913,  -0.4759,  -2.9712,  -2.8124,  -6.6837,  -2.5207,\n",
      "          -4.3722,  -2.1853,  -2.8153]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.971212148666382\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.0058,  -7.6591,  -0.6921,  -1.9678,  -2.2195,  -6.1089,  -2.8583,\n",
      "          -4.4527,  -2.0422,  -3.0040]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.452663421630859\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.9923,  -8.0925,  -1.2576,  -1.1780,  -1.7772,  -5.6049,  -3.2157,\n",
      "          -3.7950,  -2.0237,  -3.2218]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.604878902435303\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.0730,  -8.5759,  -2.0636,  -0.7842,  -1.5959,  -4.4563,  -3.6596,\n",
      "          -3.3126,  -2.2002,  -3.5399]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  11.073046684265137\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.3237,  -8.9504,  -2.8195,  -0.7011,  -1.5204,  -3.3704,  -4.0171,\n",
      "          -2.8446,  -2.3823,  -3.7864]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.017121315002441\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.5351, -9.1738, -3.4291, -0.8734, -1.4989, -2.3059, -3.5124, -2.3529,\n",
      "         -2.5024, -3.9110]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.502382278442383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.8878, -9.4377, -4.0641, -1.3947, -1.7063, -1.4892, -3.1423, -2.0445,\n",
      "         -1.9774, -4.1006]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  8.887767791748047\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.6366, -9.7635, -4.7363, -2.1324, -2.1143, -1.0211, -2.9284, -1.9521,\n",
      "         -1.6975, -4.3714]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.928445339202881\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.5430, -10.0895,  -5.3805,  -2.9156,  -2.6030,  -0.9183,  -2.0850,\n",
      "          -2.0083,  -1.6170,  -4.6570]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.9183241724967957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8454, -10.6692,  -6.2499,  -3.9463,  -3.3836,  -0.6359,  -1.7016,\n",
      "          -2.4461,  -1.9810,  -5.2073]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  10.669212341308594\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0594, -10.3162,  -6.8742,  -4.7285,  -3.9513,  -0.6416,  -1.3284,\n",
      "          -2.7454,  -2.2533,  -5.5467]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.546720504760742\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1446, -9.7865, -7.2251, -5.2273, -4.2648, -0.8516, -0.9722, -2.8514,\n",
      "         -2.3662, -4.9152]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.8515739440917969\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4680, -9.4446, -7.6768, -5.8155, -4.6925, -0.7222, -1.0604, -3.1255,\n",
      "         -2.6743, -4.4870]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.0603699684143066\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9297, -9.1841, -8.1310, -6.3945, -5.1316, -1.0368, -0.7146, -3.4526,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -3.0512, -4.1568]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.036804437637329\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5613, -9.0252, -8.6159, -6.9927, -5.6070, -0.8862, -0.8327, -3.8466,\n",
      "         -3.5022, -3.9465]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.606955051422119\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0542, -8.6479, -8.8183, -7.2978, -5.0682, -0.8416, -1.0189, -3.9834,\n",
      "         -3.6969, -3.5370]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.647909164428711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5057, -7.4064, -8.8113, -7.3836, -4.3981, -0.9518, -1.2577, -3.9310,\n",
      "         -3.7016, -3.0000]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.5057260990142822\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6427, -6.5107, -9.0268, -7.6830, -4.0256, -1.5768, -1.8997, -4.1205,\n",
      "         -3.9464, -2.7746]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.7745883464813232\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4058, -5.8450, -9.3608, -8.0928, -3.8431, -2.4421, -2.7256, -4.4432,\n",
      "         -4.3214, -2.0301]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.030062437057495\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7884, -5.3372, -9.7511, -8.5515, -3.7840, -3.3795, -3.6062, -4.8322,\n",
      "         -4.7586, -0.8213]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.606167793273926\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7073,  -5.1132, -10.3324,  -9.1945,  -3.9774,  -4.4802,  -3.9256,\n",
      "          -5.4183,  -5.3887,  -0.2828]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.194524765014648\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4787,  -4.7221, -10.6622,  -8.8494,  -3.9717,  -5.2866,  -4.0338,\n",
      "          -5.7558,  -5.7659,  -0.1518]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.4786624908447266\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0591,  -3.9571, -10.5399,  -8.1196,  -3.5612,  -5.5975,  -3.7247,\n",
      "          -5.6428,  -5.6886,  -0.2359]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.688642501831055\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4323,  -2.9364, -10.0843,  -7.1170,  -2.8669,  -5.5349,  -3.1183,\n",
      "          -5.1982,  -4.5157,  -0.5348]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  10.084319114685059\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0424, -2.0492, -8.9451, -6.2087, -2.2776, -5.4754, -2.5981, -4.7959,\n",
      "         -3.4617, -1.2186]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.0491814613342285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3092, -0.9797, -8.2704, -5.7434, -2.1736, -5.7763, -2.5344, -4.7910,\n",
      "         -2.8875, -2.3979]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.5343785285949707\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0447, -0.5764, -7.9540, -5.6176, -2.4548, -6.3405, -2.1046, -5.0838,\n",
      "         -2.7038, -3.8163]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.617617607116699\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7257, -0.5359, -7.5901, -4.7000, -2.6923, -6.7708, -1.7263, -5.2729,\n",
      "         -2.5101, -5.0301]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.6999831199646\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2225, -0.7509, -7.0967, -2.9914, -2.7901, -6.9931, -1.3478, -5.2810,\n",
      "         -2.2315, -5.9617]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.9913570880889893\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9289, -1.5099, -6.8821, -0.9992, -3.1525, -7.4229, -1.4235, -5.5212,\n",
      "         -2.2915, -7.0315]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.4234812259674072\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4180, -3.1887, -7.5274, -0.3110, -4.3484, -8.6484, -1.7832, -6.5784,\n",
      "         -3.2605, -8.8333]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.417958736419678\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.9416,  -4.6669,  -8.0460,  -0.1613,  -5.3719,  -9.6891,  -2.1654,\n",
      "          -7.4686,  -4.0994, -10.3929]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.689108848571777\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.9288,  -5.5184,  -8.0269,  -0.1564,  -5.8106,  -9.3488,  -2.1058,\n",
      "          -7.7842,  -4.3811, -11.3110]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.348769187927246\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4063,  -5.7749,  -7.4969,  -0.2550,  -5.6949,  -7.7450,  -1.6269,\n",
      "          -7.5557,  -4.1313, -11.6246]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.131288051605225\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.6225,  -5.6914,  -6.7034,  -0.5828,  -5.2764,  -5.9846,  -1.0207,\n",
      "          -7.0336,  -2.8411, -11.5904]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.984563827514648\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.9223,  -5.6169,  -5.9879,  -1.2759,  -4.9016,  -3.6205,  -0.7328,\n",
      "          -6.5624,  -1.7220, -11.5577]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.922295570373535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8228,  -5.8220,  -5.6152,  -2.3697,  -4.8393,  -1.7825,  -1.0894,\n",
      "          -6.4088,  -1.1201, -11.7980]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.821987152099609\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3516,  -5.7682,  -5.7561,  -3.8957,  -5.2630,  -0.7335,  -2.1267,\n",
      "          -6.7458,  -1.3006, -12.4883]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  12.488314628601074\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2049,  -5.9277,  -6.0911,  -5.4901,  -5.8541,  -0.3726,  -3.3524,\n",
      "          -7.2558,  -1.8762, -12.5920]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.37260928750038147\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5151,  -6.4322,  -6.7533,  -7.2877,  -6.7475,  -0.1630,  -4.8403,\n",
      "          -8.0745,  -2.8701, -13.0444]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.074506759643555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3627,  -6.3948,  -6.8576,  -8.4140,  -7.0599,  -0.1487,  -5.6929,\n",
      "          -7.5581,  -3.3154, -12.9589]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.414026260375977\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7444,  -5.8100,  -6.4000,  -8.1561,  -6.7897,  -0.2563,  -5.9108,\n",
      "          -6.5413,  -3.1919, -12.3296]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.541269302368164\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9860,  -4.9517,  -5.6553,  -7.5902,  -6.2132,  -0.6201,  -5.7751,\n",
      "          -4.5371,  -2.7781, -11.4291]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.6553425788879395\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5853,  -4.1840,  -4.2613,  -7.0811,  -5.6958,  -1.3647,  -5.6552,\n",
      "          -2.7407,  -2.4530, -10.6184]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  10.618386268615723\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7754, -3.6339, -3.1465, -6.7535, -5.3626, -2.3637, -5.6801, -1.3024,\n",
      "         -2.3563, -9.2979]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.6339335441589355\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.6483, -2.7989, -2.5284, -6.8138, -5.4205, -3.6907, -6.0594, -0.5684,\n",
      "         -2.6959, -8.4634]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.420521259307861\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6844, -2.1953, -2.1347, -6.9737, -4.8381, -5.0100, -6.5075, -0.4428,\n",
      "         -3.1582, -7.8170]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.009958744049072\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5023, -1.5648, -1.6997, -6.9518, -4.1530, -5.2564, -6.7454, -0.6500,\n",
      "         -3.4403, -7.0685]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.068527698516846\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1813, -1.0663, -1.3610, -6.8525, -3.4675, -5.4021, -6.8803, -1.1513,\n",
      "         -3.6387, -5.5973]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.181327819824219\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0318, -0.8476, -1.2268, -6.7481, -2.8576, -5.5210, -6.9867, -1.8259,\n",
      "         -3.8216, -4.2594]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.259402275085449\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8735, -0.9196, -1.2826, -6.6178, -2.3141, -5.5940, -7.0460, -2.5182,\n",
      "         -3.9659, -2.3137]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.9659268856048584\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9956, -1.5181, -1.7837, -6.7504, -2.1473, -5.9117, -7.3492, -3.4517,\n",
      "         -3.5953, -0.8819]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.911745548248291\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5361, -2.6300, -2.7740, -7.2873, -2.5007, -5.8421, -8.0392, -4.7328,\n",
      "         -3.6991, -0.3075]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.699141502380371\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9170, -3.5689, -3.5974, -7.6575, -2.7661, -5.6678, -8.5469, -5.7793,\n",
      "         -2.9387, -0.2057]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.7661423683166504\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9555, -4.1245, -4.0487, -7.6810, -1.9995, -5.2035, -8.6942, -6.4139,\n",
      "         -1.9841, -0.3876]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.1244683265686035\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9329, -3.8591, -4.4053, -7.6400, -1.3473, -4.7271, -8.7644, -6.9240,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -1.1668, -0.9736]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.727087020874023\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0501, -3.7672, -4.8674, -7.7355, -1.0854, -3.6671, -8.9598, -7.5162,\n",
      "         -0.8002, -1.9030]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.959770202636719\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0944, -3.6349, -5.2231, -7.7558, -1.0346, -2.6662, -8.3442, -7.9837,\n",
      "         -0.7462, -2.7802]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.6662042140960693\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.1865, -3.5822, -5.5948, -7.8218, -1.3005, -1.1001, -7.8377, -8.4525,\n",
      "         -1.1058, -3.6621]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.186491012573242\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.9051, -3.9402, -6.3179, -8.2673, -2.1280, -0.3325, -7.7675, -9.2605,\n",
      "         -2.0668, -4.8602]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.90509033203125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8696, -4.2374, -6.9312, -8.6295, -2.9224, -0.1553, -7.6655, -9.9490,\n",
      "         -2.9893, -5.9055]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.922433853149414\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5375,  -4.1000,  -7.0689,  -8.5405,  -2.5198,  -0.2377,  -7.1587,\n",
      "         -10.1537,  -3.4430,  -6.4334]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.540462493896484\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1742,  -3.7648,  -6.9701,  -7.5155,  -1.9935,  -0.6905,  -6.4796,\n",
      "         -10.1146,  -3.6525,  -6.6865]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  10.114627838134766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4565, -3.7565, -7.1589, -6.8700, -1.8978, -1.7574, -6.1462, -9.5965,\n",
      "         -4.1379, -7.1924]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.45648443698883057\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.1422, -4.3732, -7.9368, -6.8968, -2.5301, -3.4570, -6.4549, -9.7374,\n",
      "         -5.1945, -8.2557]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.1422480195760727\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.0468,  -5.2247,  -8.9248,  -7.2089,  -3.4459,  -5.2987,  -7.0213,\n",
      "         -10.1515,  -6.4373,  -9.5006]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.445871353149414\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.0645,  -5.3801,  -9.1993,  -6.8753,  -2.9387,  -6.3458,  -6.9167,\n",
      "          -9.9092,  -6.9426, -10.0065]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  10.006512641906738\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.1764, -4.9185, -8.8416, -5.9708, -1.9162, -6.6850, -6.2183, -9.0862,\n",
      "         -6.7933, -9.1401]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.918458461761475\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6425, -3.5353, -8.2617, -4.9001, -0.8466, -6.7334, -5.3329, -8.0872,\n",
      "         -6.4017, -8.1019]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.8465722799301147\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1864, -3.0442, -8.4732, -4.6750, -0.1948, -7.5115, -5.2727, -7.9214,\n",
      "         -6.7840, -7.9009]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.044159412384033\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6552, -1.9200, -8.6589, -4.4740, -0.2125, -8.2076, -5.2173, -7.7674,\n",
      "         -7.1240, -7.7152]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.715249061584473\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8113, -0.8265, -8.6403, -4.1155, -0.6383, -8.6487, -4.9856, -7.4433,\n",
      "         -7.2451, -6.6491]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.4432878494262695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9897, -0.2860, -8.7552, -3.9359, -1.5414, -9.1775, -4.9133, -6.5251,\n",
      "         -7.4860, -5.8214]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.541373610496521\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.9761, -0.2585, -8.7821, -3.7118, -1.6986, -9.5771, -4.7770, -5.6228,\n",
      "         -7.6268, -5.0016]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.626754283905029\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.4474, -0.3647, -8.3889, -3.1101, -1.5570, -9.5194, -4.2427, -4.3955,\n",
      "         -6.5727, -3.8507]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.388879776000977\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.6351, -0.7150, -7.0633, -2.3635, -1.3473, -9.2303, -3.5351, -3.0626,\n",
      "         -5.3875, -2.5924]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.3472785949707031\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.1453, -1.7175, -6.2113, -2.1006, -0.9553, -9.3110, -3.2601, -2.2388,\n",
      "         -4.6647, -1.8538]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.8538247346878052\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.9774, -3.1198, -5.8179, -2.3251, -1.2572, -9.7561, -3.4130, -1.9506,\n",
      "         -4.3934, -0.9598]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.756122589111328\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.8463, -4.5334, -5.5855, -2.7180, -1.8572, -9.5095, -3.6944, -1.9189,\n",
      "         -4.2782, -0.5486]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.585507869720459\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.4787,  -5.6639,  -4.4979,  -2.9698,  -2.3621,  -9.1374,  -3.8160,\n",
      "          -1.8521,  -4.0350,  -0.4414]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  10.47872257232666\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.0292,  -6.4133,  -3.2558,  -2.9628,  -2.6149,  -8.5315,  -3.6706,\n",
      "          -1.6405,  -3.5585,  -0.5329]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  10.029210090637207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.7208, -6.9277, -2.0041, -2.8326, -2.7347, -7.8245, -3.3968, -1.4362,\n",
      "         -2.9897, -0.8716]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.0041017532348633\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.9431, -7.7920, -0.6469, -3.1587, -3.2908, -7.5885, -3.5753, -1.8339,\n",
      "         -2.9165, -1.8746]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.791985034942627\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.6473, -8.2632, -0.2134, -3.8875, -4.2231, -7.7807, -4.1608, -2.7180,\n",
      "         -3.2963, -3.2912]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.263216972351074\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0960, -7.6958, -0.1293, -4.2733, -4.7880, -7.6687, -4.4141, -3.2791,\n",
      "         -3.3813, -4.3080]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.279127836227417\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1059, -6.6910, -0.1993, -4.1366, -4.8085, -7.0740, -4.1568, -2.5570,\n",
      "         -2.9896, -4.7388]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.136622428894043\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8791, -5.4501, -0.5193, -2.9602, -4.4961, -6.2021, -3.5997, -1.6289,\n",
      "         -2.3386, -4.7961]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.8791093826293945\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1502, -4.4461, -1.3481, -2.0490, -4.3333, -5.5290, -3.2285, -1.0528,\n",
      "         -1.9368, -4.9639]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.5289692878723145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9024, -3.8275, -2.5597, -1.5994, -4.4736, -4.4375, -3.2006, -1.0767,\n",
      "         -1.9628, -5.3972]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.200624942779541\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1077, -3.5038, -3.9247, -1.5596, -4.8262, -3.6816, -2.6889, -1.5752,\n",
      "         -2.3121, -6.0084]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.312089443206787\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8001, -3.3959, -5.3304, -1.8392, -5.3119, -3.1825, -2.4403, -2.3438,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -2.0979, -6.7229]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.33035945892334\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7765, -3.2417, -5.7909, -2.1260, -5.6721, -2.6842, -2.1996, -3.0282,\n",
      "         -1.9183, -7.2863]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.0281734466552734\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9954, -3.0292, -6.1063, -2.3698, -5.8975, -2.1865, -1.9630, -2.8190,\n",
      "         -1.7677, -7.6926]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.029207944869995\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4447, -2.1433, -6.3698, -2.6353, -6.0804, -1.8024, -1.8311, -2.6537,\n",
      "         -1.7409, -8.0367]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.369812965393066\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0542, -1.4585, -5.9153, -2.9567, -6.2767, -1.6134, -1.8601, -2.5884,\n",
      "         -1.8813, -8.3767]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  6.276655197143555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7086, -1.0170, -5.5183, -3.2943, -5.7275, -1.6066, -2.0111, -2.5969,\n",
      "         -2.1350, -8.6933]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.518291473388672\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.2749, -0.8033, -4.3729, -3.5531, -5.1630, -1.6824, -2.1733, -2.5889,\n",
      "         -2.3818, -8.9062]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.163044452667236\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6805, -0.7954, -3.2181, -3.6745, -3.7936, -1.7611, -2.2705, -2.5063,\n",
      "         -2.5425, -8.9655]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.270533800125122\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0900, -1.1330, -2.2327, -3.8279, -2.6026, -1.9897, -1.7242, -2.5195,\n",
      "         -2.7732, -9.0444]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.8279061317443848\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6237, -1.8173, -1.5752, -3.4047, -1.7371, -2.4533, -1.5158, -2.7451,\n",
      "         -3.1814, -9.2681]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.8172937631607056\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3168, -2.0458, -1.3378, -3.2531, -1.2927, -3.1423, -1.6950, -3.2025,\n",
      "         -3.7862, -9.6749]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.142261505126953\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.9135,  -2.3118,  -1.2823,  -3.1137,  -1.0636,  -2.9956,  -1.9601,\n",
      "          -3.6142,  -4.3172, -10.0101]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.1136717796325684\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.3740,  -2.5425,  -1.3538,  -2.2156,  -1.0327,  -2.8230,  -2.2237,\n",
      "          -3.9267,  -4.7267, -10.2332]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.373997688293457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.9813,  -2.7414,  -1.5401,  -1.4219,  -1.2026,  -2.6489,  -2.4762,\n",
      "          -4.1586,  -5.0379, -10.3696]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.037881851196289\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.6246,  -2.9612,  -1.8576,  -0.8779,  -1.5715,  -2.5415,  -2.7604,\n",
      "          -4.3745,  -4.5495, -10.4875]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.624598503112793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.5052,  -3.1339,  -2.1944,  -0.6290,  -1.9949,  -2.4436,  -3.0012,\n",
      "          -4.5166,  -4.0560, -10.5319]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.1338930130004883\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3769,  -2.4853,  -2.4496,  -0.6642,  -2.3477,  -2.2937,  -3.1262,\n",
      "          -4.5245,  -3.4964, -10.4434]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.485281467437744\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4247,  -1.3006,  -2.7914,  -1.1255,  -2.7718,  -2.3120,  -3.3499,\n",
      "          -4.6125,  -3.0650, -10.4170]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.7914178371429443\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8965,  -0.7068,  -2.7203,  -2.0913,  -3.4447,  -2.7946,  -3.9777,\n",
      "          -5.0785,  -3.0108, -10.7039]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  10.70388412475586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6023,  -0.5710,  -2.7289,  -3.0506,  -4.1544,  -3.1964,  -4.4638,\n",
      "          -5.4350,  -3.0268, -10.2529]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  10.25290298461914\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2988, -0.6583, -2.5957, -3.7608, -4.6169, -3.4017, -4.7220, -5.5713,\n",
      "         -2.8904, -8.9443]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.571283340454102\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0364, -0.9089, -2.3379, -4.2254, -4.8489, -3.4205, -4.7692, -4.7421,\n",
      "         -2.6186, -7.5743]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.574293613433838\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9199, -1.2740, -2.0319, -4.5110, -4.9201, -3.3191, -4.6746, -3.8586,\n",
      "         -2.2866, -5.4869]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.2739691734313965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1915, -1.1769, -1.9319, -4.8570, -5.0704, -3.3366, -4.6771, -3.1600,\n",
      "         -2.1468, -3.6911]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.160034418106079\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.7263, -1.3708, -2.0115, -5.2391, -5.2754, -3.4448, -4.7512, -1.8695,\n",
      "         -2.1760, -2.1569]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.1759557723999023\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7539, -2.1375, -2.5940, -6.0012, -5.8779, -3.9809, -5.2384, -1.2389,\n",
      "         -1.9343, -1.2724]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.980895757675171\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9337, -3.1179, -3.3797, -6.8963, -6.6295, -3.9146, -5.8882, -1.0989,\n",
      "         -2.0350, -0.8839]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.9337079524993896\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1721, -3.9361, -4.0161, -7.6073, -7.2116, -3.7745, -6.3795, -1.1310,\n",
      "         -2.1305, -0.7346]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.211611747741699\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1664, -4.4548, -4.3705, -8.0162, -6.7658, -3.4343, -6.5916, -1.1740,\n",
      "         -2.0763, -0.7122]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.5915937423706055\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9319, -4.6891, -4.4577, -8.1437, -6.1243, -2.9119, -5.8034, -1.2069,\n",
      "         -1.8830, -0.8019]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.9318692684173584\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8394, -4.7490, -4.3872, -8.1011, -5.3907, -2.3259, -4.9383, -1.3066,\n",
      "         -1.6687, -1.0456]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.0455682277679443\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0790, -4.9890, -4.5127, -8.2430, -4.9135, -2.0536, -4.3446, -1.7824,\n",
      "         -1.8009, -0.9810]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.24301528930664\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4385, -5.1617, -4.5854, -7.5931, -4.4411, -1.8592, -3.7714, -2.2907,\n",
      "         -1.9991, -1.1425]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.859223484992981\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1873, -5.4714, -4.8085, -7.1583, -4.1744, -1.1846, -3.4225, -2.9755,\n",
      "         -2.4321, -1.6657]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.158334732055664\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1959, -5.7623, -5.0243, -6.0515, -3.9548, -0.8219, -3.1415, -3.6401,\n",
      "         -2.8989, -2.2809]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.954822301864624\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3150, -5.9142, -5.1112, -4.9445, -2.9224, -0.7218, -2.8083, -4.1464,\n",
      "         -3.2495, -2.7957]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.944452285766602\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5088, -5.9409, -5.0819, -3.1199, -1.9205, -0.8933, -2.4410, -4.5024,\n",
      "         -3.4832, -3.1910]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.081850051879883\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9854, -6.1055, -4.4734, -1.6476, -1.2651, -1.5009, -2.3134, -4.9700,\n",
      "         -3.8559, -3.7149]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.9699811935424805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8507, -6.5897, -4.2683, -0.7960, -1.2180, -2.5537, -2.6064, -4.9683,\n",
      "         -4.5424, -4.5385]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.9683122634887695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7663, -7.1203, -4.1875, -0.4509, -1.4878, -3.6554, -3.0187, -4.3094,\n",
      "         -5.2625, -5.3816]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  1.487840175628662\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5653, -7.5562, -4.0832, -0.5598, -1.1179, -4.6246, -3.3837, -3.6837,\n",
      "         -5.8723, -6.1014]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.624621868133545\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0735, -7.7300, -3.7824, -0.8524, -0.8071, -4.5163, -3.5185, -2.9203,\n",
      "         -6.2045, -6.5322]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.073483467102051\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6289, -7.7202, -3.3616, -1.2575, -0.6896, -4.2606, -3.4954, -2.1072,\n",
      "         -6.3387, -6.7545]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.361616611480713\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1780, -7.6539, -2.2270, -1.7701, -0.8954, -3.9834, -3.4394, -1.4096,\n",
      "         -6.4031, -6.8978]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.4096388816833496\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1993, -8.0106, -1.6995, -2.7709, -1.7973, -4.1641, -3.8288, -0.6262,\n",
      "         -6.8784, -7.4435]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.6994856595993042\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5548, -8.6572, -0.9609, -4.0426, -3.0566, -4.6639, -4.5209, -0.6518,\n",
      "         -7.6324, -8.2605]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.632431983947754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8284, -9.1853, -0.5188, -5.1461, -4.1709, -5.0670, -5.0978, -1.0153,\n",
      "         -7.4839, -8.9422]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.828422546386719\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1259, -9.4429, -0.3335, -5.9260, -4.9676, -5.2167, -5.4039, -1.3987,\n",
      "         -7.1325, -9.3380]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  9.337967872619629\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1398, -9.3094, -0.3184, -6.2646, -5.3247, -4.9903, -5.3174, -1.5653,\n",
      "         -6.4513, -8.6116]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  9.309365272521973\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9475, -8.1450, -0.4917, -6.2347, -5.3136, -4.4553, -4.9068, -1.5371,\n",
      "         -5.5028, -7.6213]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.145014762878418\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9270, -6.3413, -1.0343, -6.1568, -5.2548, -3.9302, -4.4903, -1.6220,\n",
      "         -4.5995, -6.6776]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.49031925201416\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4611, -4.8789, -1.9386, -6.2488, -5.3663, -3.6331, -3.5402, -2.0086,\n",
      "         -3.9546, -5.9894]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.248810768127441\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4241, -3.4848, -2.7736, -5.5252, -5.3875, -3.3033, -2.6234, -2.3756,\n",
      "         -3.3060, -5.2887]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.773643970489502\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8039, -2.1827, -2.7810, -4.8081, -5.3416, -2.9662, -1.7836, -2.7081,\n",
      "         -2.6820, -4.5931]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.1827468872070312\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9127, -0.8254, -3.2699, -4.6061, -5.7416, -3.1403, -1.5904, -3.4958,\n",
      "         -2.6110, -4.4118]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.495840549468994\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4525, -0.3454, -4.1701, -4.8642, -6.5369, -3.7632, -2.0011, -3.9026,\n",
      "         -3.0369, -4.6900]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.9026169776916504\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6979, -0.2485, -4.8274, -4.9378, -7.0896, -4.1776, -2.3071, -3.3671,\n",
      "         -3.2931, -4.7827]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.2931416034698486\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4850, -0.3688, -5.0839, -4.6682, -7.2469, -4.2215, -2.3159, -2.5699,\n",
      "         -2.4380, -4.5311]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.531100273132324\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0441, -0.8091, -5.1667, -4.2795, -7.2363, -4.1197, -2.2447, -1.7570,\n",
      "         -1.5829, -3.4426]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.279480457305908\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.7023, -1.6704, -5.3983, -3.3696, -7.3803, -4.1936, -2.4126, -1.3082,\n",
      "         -1.1251, -2.6385]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.6385185718536377\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5112, -2.7932, -5.8254, -2.7906, -7.7258, -4.4871, -2.8461, -1.3234,\n",
      "         -1.1797, -1.4674]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.51116943359375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.6637, -4.0090, -6.3740, -2.4755, -8.1990, -4.9221, -3.4416, -1.6997,\n",
      "         -1.6288, -0.7401]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  7.663706302642822\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0832, -5.1309, -6.8836, -2.2671, -8.6397, -5.3337, -4.0161, -2.1908,\n",
      "         -2.1995, -0.4418]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.267129421234131\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.4716, -6.0557, -7.2536, -1.3437, -8.9471, -5.6184, -4.4573, -2.6278,\n",
      "         -2.7097, -0.5441]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.3436505794525146\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3069, -7.2750, -7.9722, -0.3661, -9.6090, -6.2627, -5.2483, -3.4608,\n",
      "         -3.6057, -1.4360]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.4608168601989746\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.3005,  -8.5140,  -8.7601,  -0.1285, -10.3456,  -6.9848,  -6.1049,\n",
      "          -3.6216,  -4.5741,  -2.5495]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.6215620040893555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8813,  -9.2150,  -9.0549,  -0.1340, -10.5940,  -7.2209,  -6.4632,\n",
      "          -2.6234,  -5.0392,  -3.1931]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.881289482116699\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3761,  -9.4463,  -8.9205,  -0.3664, -10.4178,  -7.0342,  -6.3871,\n",
      "          -1.3793,  -5.0633,  -3.4022]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.063255310058594\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1006,  -9.7254,  -8.8702,  -1.1417, -10.3299,  -6.9375,  -6.3904,\n",
      "          -0.5188,  -4.3859,  -3.6850]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  9.725369453430176\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1114,  -9.3996,  -8.9514,  -2.1944, -10.3771,  -6.9775,  -6.5211,\n",
      "          -0.3174,  -3.9119,  -4.0839]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.377095222473145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1588, -8.9555, -8.8740, -3.0713, -9.5260, -6.8635, -6.4891, -0.5306,\n",
      "         -3.3499, -4.3045]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.955521583557129\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5235, -7.8487, -8.7964, -3.8863, -8.7518, -6.7538, -6.4536, -1.1538,\n",
      "         -2.8631, -4.5049]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.5234825015068054\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.1628, -7.3621, -9.2365, -5.1446, -8.5646, -7.1657, -6.9326, -2.4604,\n",
      "         -2.9789, -5.2031]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.932584285736084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.1148, -6.5780, -9.2863, -5.9354, -8.0496, -7.1907, -6.2694, -3.3542,\n",
      "         -2.7760, -5.4892]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.190713405609131\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.1861, -5.3371, -8.7956, -6.1137, -7.0505, -5.9019, -5.1379, -3.6495,\n",
      "         -2.1060, -5.2142]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.113681793212891\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4975, -3.8679, -7.9985, -5.2028, -5.7962, -4.3881, -3.7682, -3.5796,\n",
      "         -1.2419, -4.6151]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.579596996307373\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3159, -2.6573, -7.3786, -4.4841, -4.7667, -3.1324, -2.6498, -2.8862,\n",
      "         -0.7856, -4.1804]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.3786468505859375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4852, -1.8542, -6.3355, -4.0828, -4.0837, -2.2733, -1.9335, -2.5412,\n",
      "         -0.9659, -4.0378]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  0.9659417867660522\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.9863, -1.6286, -5.7850, -4.1211, -3.8689, -1.9675, -1.7846, -2.6770,\n",
      "         -1.0352, -4.3096]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.628629207611084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4722, -0.9833, -5.4123, -4.2880, -3.8118, -1.9216, -1.8972, -2.9714,\n",
      "         -1.4934, -4.6847]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.288012981414795\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8082, -0.6598, -5.0748, -3.7288, -3.7718, -1.9891, -2.1062, -3.2697,\n",
      "         -2.0750, -5.0241]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  5.024118423461914\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.8680, -0.5873, -4.6316, -3.0984, -3.6090, -2.0126, -2.2418, -3.4228,\n",
      "         -2.5520, -4.4724]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.5873252153396606\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.0305, -0.4187, -4.4474, -2.7710, -3.6906, -2.3456, -2.6517, -3.7930,\n",
      "         -3.2499, -4.1916]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.4474101066589355\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.8310, -0.4815, -3.3225, -2.2746, -3.5363, -2.4738, -2.8274, -3.8968,\n",
      "         -3.6621, -3.7032]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.7032296657562256\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.4342,  -0.8522,  -2.2181,  -1.7836,  -3.3016,  -2.5373,  -2.9124,\n",
      "          -3.8879,  -3.9355,  -2.4490]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.2180886268615723\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.3598,  -1.8662,  -0.9661,  -1.8442,  -3.5001,  -3.0385,  -3.4123,\n",
      "          -4.2775,  -4.5792,  -1.7639]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.5001094341278076\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.5853,  -3.2794,  -0.5059,  -2.4040,  -3.3478,  -3.9192,  -4.2793,\n",
      "          -5.0308,  -5.5589,  -1.6619]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.404003381729126\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.6332,  -4.5227,  -0.4715,  -2.2029,  -3.1814,  -4.6722,  -5.0148,\n",
      "          -5.6585,  -6.3885,  -1.6506]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.2029130458831787\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.4599,  -5.5331,  -0.7735,  -1.2732,  -2.9458,  -5.2408,  -5.5653,\n",
      "          -6.1095,  -7.0200,  -1.6614]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.273153305053711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-15.6522,  -6.8934,  -1.8249,  -0.3737,  -3.2206,  -6.2046,  -6.5116,\n",
      "          -6.9650,  -8.0371,  -2.2551]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.204603672027588\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-16.8142,  -8.2074,  -2.9761,  -0.1438,  -3.5863,  -6.3831,  -7.4533,\n",
      "          -7.8245,  -9.0415,  -2.9533]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.383139610290527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.4182,  -8.9484,  -3.6071,  -0.1109,  -3.4940,  -5.3301,  -7.8593,\n",
      "          -8.1564,  -9.5039,  -3.1772]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.6071317195892334\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.4490,  -9.1028,  -2.9629,  -0.2017,  -2.9206,  -3.8725,  -7.7122,\n",
      "          -7.9425,  -9.4071,  -2.8957]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.8957273960113525\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.2739,  -9.0391,  -2.2170,  -0.6565,  -2.2418,  -2.3734,  -7.3773,\n",
      "          -7.5473,  -9.1173,  -1.7628]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.656459391117096\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.5981,  -9.4635,  -2.1054,  -1.2075,  -2.1918,  -1.5777,  -7.5579,\n",
      "          -7.6736,  -9.3382,  -1.3473]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.577665090560913\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-18.2770, -10.2328,  -2.4795,  -2.3015,  -2.6176,  -0.6358,  -8.1080,\n",
      "          -8.1747,  -9.9242,  -1.5467]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.546685814857483\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-19.1277, -11.1650,  -3.1160,  -3.5966,  -3.2951,  -0.4384,  -8.8430,\n",
      "          -8.8656, -10.6913,  -1.4031]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.4031345844268799\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-19.8921, -12.0027,  -3.7194,  -4.7805,  -3.9312,  -0.7590,  -9.5033,\n",
      "          -9.4861, -11.3804,  -0.7352]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.719372034072876\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-20.4830, -12.6596,  -3.4656,  -5.7550,  -4.4214,  -1.3120, -10.0004,\n",
      "          -9.9476, -11.9035,  -0.3795]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.421369552612305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-20.7496, -12.9856,  -2.9940,  -6.3693,  -3.8586,  -1.7525, -10.1827,\n",
      "         -10.0976, -12.1091,  -0.2828]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  12.985595703125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-20.6216, -12.2088,  -2.2373,  -6.5556,  -2.9996,  -1.9151,  -9.9788,\n",
      "          -9.8647, -11.9262,  -0.3644]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  20.621604919433594\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-19.5604, -11.2966,  -1.4200,  -6.5118,  -2.0508,  -1.9627,  -9.5826,\n",
      "          -9.4424, -11.5488,  -0.7184]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  11.296636581420898\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-18.6745,  -9.8467,  -0.9273,  -6.5429,  -1.3624,  -2.1838,  -9.2955,\n",
      "          -9.1318, -11.2787,  -1.4525]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  9.295482635498047\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.9216,  -8.5860,  -0.8126,  -6.6169,  -0.9790,  -2.5149,  -8.3257,\n",
      "          -8.8971, -11.0803,  -2.3244]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.897074699401855\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-17.0918,  -7.2990,  -0.8759,  -6.5325,  -0.7632,  -2.7237,  -7.3007,\n",
      "          -7.7805, -10.7497,  -3.0271]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.780487060546875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-16.0907,  -5.8868,  -0.9777,  -6.2037,  -0.6636,  -2.7086,  -6.1244,\n",
      "          -5.7739, -10.1982,  -3.4404]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  10.198241233825684\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.9269,  -4.3548,  -1.0766,  -5.6468,  -0.6961,  -2.4844,  -4.8046,\n",
      "          -3.7070,  -8.6577,  -3.5731]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.646759986877441\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.8202,  -2.9254,  -1.3511,  -4.3811,  -1.0382,  -2.2883,  -3.5635,\n",
      "          -1.8055,  -7.2118,  -3.6538]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.2882771492004395\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.3848,  -2.2371,  -2.3450,  -3.8114,  -2.1715,  -1.9764,  -3.0286,\n",
      "          -0.7781,  -6.4716,  -4.3060]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.028555393218994\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.3645,  -2.0642,  -3.6806,  -3.6859,  -3.6490,  -2.1745,  -2.2013,\n",
      "          -0.5705,  -6.1781,  -5.2746]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.0641677379608154\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.4108,  -1.3625,  -4.9660,  -3.6552,  -5.0634,  -2.5055,  -1.6047,\n",
      "          -0.8729,  -5.9801,  -6.2152]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.215151786804199\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.4743,  -0.9320,  -6.1502,  -3.6677,  -6.3635,  -2.8884,  -1.2413,\n",
      "          -1.4805,  -5.8255,  -6.3722]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.150163650512695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.4726,  -0.7617,  -6.4393,  -3.6381,  -7.4765,  -3.2174,  -1.0738,\n",
      "          -2.1393,  -5.6296,  -6.4559]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.476497173309326\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.2744,  -0.7390,  -6.5042,  -3.4335,  -7.5331,  -3.3480,  -0.9848,\n",
      "          -2.6243,  -5.2595,  -6.3358]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.335782527923584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.8472,  -0.8043,  -6.3151,  -3.0234,  -7.3359,  -3.2442,  -0.9384,\n",
      "          -2.8669,  -4.6816,  -5.2714]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.681601047515869\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.2585,  -0.9720,  -5.9420,  -2.4847,  -6.9547,  -2.9769,  -0.9881,\n",
      "          -2.9239,  -3.1843,  -4.1126]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.4846763610839844\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.8184,  -1.4774,  -5.6979,  -1.4409,  -6.7020,  -2.8657,  -1.4038,\n",
      "          -3.1056,  -1.9583,  -3.1707]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.4774094820022583\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.8143,  -1.7838,  -5.8727,  -1.0610,  -6.8677,  -3.2020,  -2.3559,\n",
      "          -3.6951,  -1.3571,  -2.7446]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  11.814310073852539\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.1052,  -2.2073,  -6.0623,  -0.9943,  -7.0478,  -3.5665,  -3.3150,\n",
      "          -4.2748,  -1.0474,  -2.4367]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.0473710298538208\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.7254,  -2.9243,  -6.4934,  -1.4551,  -7.4694,  -4.1755,  -4.4649,\n",
      "          -5.0660,  -0.5210,  -2.4804]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.924292802810669\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.2532,  -2.7786,  -6.7524,  -1.9050,  -7.7191,  -4.6054,  -5.3787,\n",
      "          -5.6529,  -0.3814,  -2.4490]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.652913570404053\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.4851, -2.3480, -6.6436, -2.0728, -7.6015, -4.6575, -5.8622, -5.0891,\n",
      "         -0.4455, -2.1394]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.0727620124816895\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.6502, -1.8834, -6.4032, -1.4616, -7.3525, -4.5684, -6.1563, -4.4426,\n",
      "         -0.8576, -1.8009]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.568388938903809\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.9070, -1.5800, -6.1964, -1.0838, -7.1374, -3.7290, -6.4313, -3.8778,\n",
      "         -1.5666, -1.6223]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.8778271675109863\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.2686, -1.4811, -6.0423, -1.0134, -6.9748, -3.0222, -6.7107, -2.6678,\n",
      "         -2.3977, -1.6327]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.022216320037842\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8015, -1.6582, -6.0123, -1.3139, -6.9362, -1.7599, -7.0703, -1.7373,\n",
      "         -3.3240, -1.8884]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.801513671875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8849, -2.1885, -6.2248, -2.0121, -7.1400, -0.9941, -7.6325, -1.2692,\n",
      "         -4.4238, -2.4642]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.884941101074219\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4256, -2.8375, -6.5108, -2.8286, -7.4172, -0.6842, -8.2323, -1.1517,\n",
      "         -5.5166, -3.1366]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.516621112823486\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9686, -3.3113, -6.6177, -3.4540, -7.5156, -0.6437, -8.6209, -1.1313,\n",
      "         -5.5729, -3.6213]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.454031467437744\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5736, -3.6426, -6.5942, -3.2112, -7.4839, -0.8920, -8.8502, -1.2341,\n",
      "         -5.5057, -3.9561]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.5735938549041748\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.3483, -4.5678, -7.1824, -3.6294, -8.0641, -2.0400, -9.6652, -2.1532,\n",
      "         -6.0568, -4.8797]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  9.66520881652832\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.0878, -5.7313, -8.0359, -4.3479, -8.9101, -3.4972, -9.9635, -3.3911,\n",
      "         -6.8781, -6.0400]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.878116607666016\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.0474, -6.3042, -8.3275, -4.5269, -9.1949, -4.3557, -9.7551, -4.0539,\n",
      "         -6.3675, -6.6094]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.053915500640869\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.0777, -6.1936, -7.9625, -4.0681, -8.8236, -4.5109, -8.9397, -3.2869,\n",
      "         -5.2814, -6.4953]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.495320796966553\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.2444, -5.5655, -7.1042, -3.1371, -7.9595, -4.1292, -7.6757, -2.0942,\n",
      "         -3.7774, -5.1498]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.565524101257324\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.9137, -4.2571, -6.2868, -2.2843, -7.1365, -3.7528, -6.4927, -1.0674,\n",
      "         -2.3956, -3.8973]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  6.492661952972412\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2030, -3.4862, -5.9495, -1.9860, -6.7935, -3.8294, -5.0709, -0.7976,\n",
      "         -1.6196, -3.1813]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.070896148681641\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5886, -2.9582, -5.7924, -1.9594, -6.6302, -4.0599, -3.1906, -1.0363,\n",
      "         -1.2191, -2.7110]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.959377408027649\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0732, -2.7362, -5.8702, -1.5447, -6.7011, -4.4979, -1.7456, -1.7334,\n",
      "         -1.3048, -2.5520]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.073202133178711\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9425, -2.8362, -6.1968, -1.5769, -7.0205, -5.1554, -0.8308, -2.7479,\n",
      "         -1.8469, -2.7191]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.8308023810386658\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.3757, -3.6159, -7.1409, -2.4005, -7.9572, -6.4004, -0.2318, -4.3577,\n",
      "         -3.1059, -3.5652]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.140865325927734\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.4820, -4.1522, -7.0827, -3.0216, -8.6163, -7.3382, -0.1078, -5.6323,\n",
      "         -4.0898, -4.1626]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.616302490234375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.9086, -4.0766, -6.4613, -3.0458, -7.8867, -7.6134, -0.1021, -6.2130,\n",
      "         -4.4190, -4.1421]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.0765700340271\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.7365, -2.7643, -5.3464, -2.5448, -6.6736, -7.3052, -0.2155, -6.1810,\n",
      "         -4.1684, -3.5786]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.3463873863220215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.3721, -1.4173, -3.4161, -1.9398, -5.3726, -6.8187, -0.7077, -5.9442,\n",
      "         -3.7453, -2.8816]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.9442219734191895\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.4307, -0.7608, -2.0882, -1.8836, -4.5913, -6.7680, -1.9037, -5.3704,\n",
      "         -3.7692, -2.6808]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.0882420539855957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.0114, -1.0249, -0.7917, -2.4685, -4.4231, -7.2510, -3.6194, -5.3848,\n",
      "         -4.3365, -3.0768]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  9.011385917663574\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.1338, -1.8360, -0.2740, -3.3773, -4.6028, -8.0085, -5.5063, -5.7233,\n",
      "         -5.1795, -3.7885]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.6028032302856445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.0442, -2.4782, -0.1572, -4.0199, -3.8212, -8.4910, -7.0086, -5.8307,\n",
      "         -5.7431, -4.2458]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.8212220668792725\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.5692, -2.7208, -0.2721, -4.2170, -1.9937, -8.5312, -7.9676, -5.5351,\n",
      "         -5.8586, -4.2734]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.535137176513672\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.2601, -3.1039, -1.0394, -4.5234, -0.5688, -8.6860, -8.9497, -4.6450,\n",
      "         -6.0834, -4.4267]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  8.260085105895996\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.6978,  -3.9151,  -2.4182,  -5.2418,  -0.1468,  -9.2603, -10.2691,\n",
      "          -4.2855,  -6.7223,  -5.0082]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.260299682617188\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8648,  -4.3326,  -3.3966,  -5.5655,  -0.0880,  -8.6737, -11.1302,\n",
      "          -3.6452,  -6.9717,  -5.2096]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.332619667053223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.5630,  -3.4646,  -3.7492,  -5.3072,  -0.1655,  -7.5932, -11.3531,\n",
      "          -2.5356,  -6.6445,  -4.8424]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.842437744140625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1087,  -2.4199,  -3.7986,  -4.7932,  -0.5790,  -6.3357, -11.2688,\n",
      "          -1.3107,  -6.0659,  -3.5149]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.108702182769775\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4282,  -1.8751,  -4.1927,  -4.6699,  -1.6999,  -5.5384, -11.5266,\n",
      "          -0.7432,  -5.8803,  -2.6745]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.669925689697266\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.3130,  -1.8265,  -4.8931,  -4.1893,  -3.1794,  -5.1580, -12.0933,\n",
      "          -0.9224,  -6.0500,  -2.3018]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  6.0500030517578125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6741,  -2.0671,  -5.7005,  -3.9387,  -4.7139,  -4.9914, -12.7749,\n",
      "          -1.5522,  -5.5964,  -2.2095]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.991418361663818\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4499,  -2.3563,  -6.4138,  -3.7108,  -6.0862,  -4.0569, -13.3727,\n",
      "          -2.2615,  -5.1748,  -2.1892]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.174798488616943\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4913,  -2.4679,  -6.8420,  -3.3076,  -7.1083,  -3.0135, -13.6955,\n",
      "          -2.7627,  -3.8103,  -2.0361]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.467893362045288\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9140,  -1.8741,  -7.1748,  -2.9172,  -7.9758,  -2.0587, -13.9328,\n",
      "          -3.2078,  -2.5454,  -1.9387]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.9387049674987793\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8716,  -1.7364,  -7.7646,  -2.8937,  -9.0467,  -1.5876, -14.4360,\n",
      "          -3.9284,  -1.7569,  -1.5262]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.5261989831924438\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1976,  -2.0892,  -8.6495,  -3.2654, -10.3646,  -1.6757, -15.2425,\n",
      "          -4.9454,  -1.5346,  -0.9490]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.649480819702148\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4104,  -2.4831,  -8.7166,  -3.6167, -11.5406,  -1.8898, -15.9582,\n",
      "          -5.8559,  -1.4917,  -0.6964]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.616694450378418\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3421,  -2.7272,  -8.6081,  -3.0730, -12.4306,  -2.0311, -16.4335,\n",
      "          -6.5089,  -1.4590,  -0.6574]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.342094898223877\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.2466,  -2.7734,  -8.2910,  -2.3969, -13.0124,  -2.0408, -16.6421,\n",
      "          -6.8785,  -1.3911,  -0.7738]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.291047096252441\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.0069,  -2.7013,  -7.1332,  -1.6953, -13.3789,  -1.9932, -16.6723,\n",
      "          -7.0546,  -1.3661,  -1.0509]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.9931519031524658\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8789,  -2.7666,  -6.1743,  -1.2773, -13.7920,  -1.3631, -16.7827,\n",
      "          -7.2969,  -1.6252,  -1.6335]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.633479356765747\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8762,  -2.9766,  -5.4194,  -1.2064, -14.2709,  -1.1015, -16.9891,\n",
      "          -7.6226,  -2.1188,  -1.6892]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.976569175720215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7801,  -2.4015,  -4.6437,  -1.2565, -14.6031,  -1.0248, -17.0759,\n",
      "          -7.8171,  -2.5577,  -1.7721]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.2564587593078613\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7983,  -2.0459,  -4.0508,  -0.8918, -15.0010,  -1.3328, -17.2527,\n",
      "          -8.0913,  -3.1121,  -2.0669]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.091322898864746\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7191,  -1.7148,  -3.4280,  -0.7534, -15.2577,  -1.7132, -17.3105,\n",
      "          -7.4870,  -3.5444,  -2.3213]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.7148194313049316\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.7321,  -0.9216,  -2.9683,  -1.0411, -15.5668,  -2.2734, -17.4403,\n",
      "          -7.0211,  -4.0342,  -2.6985]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.968313455581665\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8496,  -0.5855,  -1.9760,  -1.6503, -15.9445,  -2.9573, -17.6567,\n",
      "          -6.7017,  -4.5884,  -3.1856]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.1855881214141846\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.9694,  -0.6811,  -1.1904,  -2.3436, -16.2931,  -3.6218, -17.8600,\n",
      "          -6.4235,  -5.1038,  -2.9479]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.969433784484863\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3305,  -1.0858,  -0.6662,  -3.0012, -16.5720,  -4.2061, -18.0081,\n",
      "          -6.1392,  -5.5377,  -2.7363]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.139196872711182\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6557,  -1.5770,  -0.4537,  -3.5197, -16.7142,  -4.6348, -18.0325,\n",
      "          -5.0294,  -5.8226,  -2.4831]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.029406547546387\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8590,  -1.9561,  -0.5095,  -3.8001, -16.6347,  -4.8208, -17.8469,\n",
      "          -3.0863,  -5.8738,  -2.1072]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.80007004737854\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2127,  -2.4262,  -1.0188,  -3.3873, -16.5929,  -5.0245, -17.7096,\n",
      "          -1.4006,  -5.9520,  -1.8855]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.0187876224517822\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2709,  -3.4729,  -1.5816,  -3.6011, -17.1169,  -5.7745, -18.1476,\n",
      "          -0.6283,  -6.5860,  -2.3558]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.6010828018188477\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4295,  -4.4691,  -2.2674,  -3.1381, -17.6208,  -6.4843, -18.5740,\n",
      "          -0.3638,  -7.1901,  -2.8792]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.484339714050293\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3521,  -5.0906,  -2.6753,  -2.4683, -17.7909,  -6.0639, -18.6744,\n",
      "          -0.3604,  -7.4510,  -3.1071]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.107137441635132\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1057,  -5.4095,  -2.8467,  -1.6801, -17.6990,  -5.4419, -18.5197,\n",
      "          -0.6304,  -7.4413,  -2.3853]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  18.519689559936523\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9482,  -5.6764,  -3.0193,  -1.0792, -17.5929,  -4.8619, -17.6006,\n",
      "          -1.2449,  -7.4097,  -1.7777]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.409667015075684\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9645,  -5.9747,  -3.2652,  -0.8345, -17.5529,  -4.4012, -16.8285,\n",
      "          -2.0674,  -6.6554,  -1.4069]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  16.828474044799805\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9939,  -6.1588,  -3.4277,  -0.8356, -17.4307,  -3.9097, -15.2957,\n",
      "          -2.8157,  -5.8909,  -1.1617]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.8355599045753479\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2789,  -6.4865,  -3.7576,  -0.5957, -17.4810,  -3.6431, -14.0758,\n",
      "          -3.6943,  -5.3651,  -1.3248]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.486475467681885\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3823,  -5.8547,  -3.8445,  -0.5430, -17.2994,  -3.1964, -12.7505,\n",
      "          -4.2771,  -4.6684,  -1.4346]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.196422815322876\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3720,  -5.1178,  -3.7680,  -0.7358, -16.9657,  -1.8812, -11.3870,\n",
      "          -4.6420,  -3.8782,  -1.5336]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.371983528137207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8615,  -4.6104,  -3.8677,  -1.3995, -16.8173,  -0.9673, -10.3113,\n",
      "          -5.1298,  -3.3350,  -1.9289]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.12982177734375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6699,  -4.3168,  -4.1288,  -2.3276, -16.8400,  -0.5959,  -9.4990,\n",
      "          -4.9857,  -3.0300,  -2.5450]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.316769599914551\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.5230,  -3.2539,  -4.2654,  -3.1223, -16.7504,  -0.5789,  -8.6576,\n",
      "          -4.7509,  -2.6833,  -3.0459]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.045865058898926\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4107,  -2.1869,  -4.2616,  -3.7320, -16.5327,  -0.8605,  -7.7631,\n",
      "          -4.4090,  -2.2877,  -2.6786]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.1869006156921387\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7296,  -0.8535,  -4.5126,  -4.5423, -16.5810,  -1.6852,  -7.2023,\n",
      "          -4.3544,  -2.2554,  -2.6411]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.542300224304199\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5142,  -0.3203,  -5.1162,  -4.9410, -16.9942,  -2.9410,  -7.0676,\n",
      "          -4.6845,  -2.6784,  -3.0280]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.3202918469905853\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7286,  -0.0990,  -6.1137,  -5.7547, -17.8160,  -4.5624,  -7.3966,\n",
      "          -5.4383,  -3.5628,  -3.8606]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.860624313354492\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3854,  -0.0784,  -6.5594,  -6.0356, -18.1018,  -5.5763,  -7.2392,\n",
      "          -5.6662,  -3.9274,  -3.4590]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  6.035558700561523\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4242,  -0.1406,  -6.4001,  -5.0246, -17.7976,  -5.9307,  -6.5365,\n",
      "          -5.3124,  -3.7096,  -2.5583]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  17.797607421875\n",
      "torch.Size([1, 1, 40])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -4.0907,  -0.4200,  -5.8808,  -3.7418, -16.3908,  -5.8747,  -5.5276,\n",
      "          -4.6203,  -3.1556,  -1.4253]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.88077449798584\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8895,  -1.2116,  -4.7835,  -2.6904, -15.2112,  -5.9135,  -4.7093,\n",
      "          -4.0916,  -2.7773,  -0.6636]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  15.211198806762695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8813,  -2.2882,  -3.9596,  -1.9498, -13.5567,  -6.1087,  -4.1375,\n",
      "          -3.7861,  -2.6439,  -0.5032]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  13.556652069091797\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.8209,  -3.2598,  -3.1635,  -1.3153, -11.2538,  -6.2184,  -3.5668,\n",
      "          -3.4600,  -2.5118,  -0.7211]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.566779851913452\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8077, -4.1866, -2.5024, -0.9588, -9.2056, -6.3440, -2.3433, -3.2152,\n",
      "         -2.4822, -1.2882]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.2881734371185303\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0343, -5.2540, -2.1884, -1.1305, -7.5837, -6.6808, -1.5367, -3.2471,\n",
      "         -2.7436, -1.5050]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.2470521926879883\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.2866, -6.2543, -2.0219, -1.5483, -6.1591, -7.0205, -1.0090, -2.5961,\n",
      "         -3.0654, -1.8935]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.286569118499756\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7984, -7.1536, -1.9646, -2.0718, -4.8752, -7.3244, -0.8077, -2.0626,\n",
      "         -3.3891, -2.3476]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.3476078510284424\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3529, -7.9418, -1.9919, -2.6099, -3.7027, -7.5764, -0.9421, -1.6548,\n",
      "         -3.6851, -2.0917]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.702680826187134\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9963, -8.6710, -2.1341, -3.1656, -1.9394, -7.8230, -1.3775, -1.4493,\n",
      "         -3.9908, -1.9681]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.134122848510742\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.0848, -9.7012, -2.0013, -4.0693, -0.8330, -8.4188, -2.3340, -1.8126,\n",
      "         -4.6540, -2.3295]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.654027462005615\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4246, -10.8560,  -2.2060,  -5.1222,  -0.3909,  -9.1825,  -3.4958,\n",
      "          -2.4886,  -4.6976,  -2.9511]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.9511260986328125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5756, -11.7173,  -2.2911,  -5.8960,  -0.3222,  -9.6918,  -4.3863,\n",
      "          -2.9805,  -4.5654,  -2.6611]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.691792488098145\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.3689, -12.1299,  -2.0776,  -6.2316,  -0.4396,  -9.0094,  -4.8347,\n",
      "          -3.0984,  -4.0915,  -2.0864]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.0863988399505615\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2030, -12.4968,  -1.9709,  -6.5307,  -1.0211,  -8.3904,  -5.2398,\n",
      "          -3.2336,  -3.6734,  -0.9466]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.970890998840332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4136, -13.1576,  -1.5870,  -7.1315,  -2.1437,  -8.1638,  -5.9391,\n",
      "          -3.7152,  -3.6474,  -0.5256]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.939136981964111\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.5535, -13.6791,  -1.3148,  -7.5995,  -3.1685,  -7.8863,  -5.7392,\n",
      "          -4.0936,  -3.5711,  -0.4912]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.553513526916504\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7615, -13.9325,  -1.0467,  -7.8050,  -3.9064,  -7.4205,  -5.3453,\n",
      "          -4.2305,  -3.3082,  -0.6759]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.675910472869873\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2387, -14.3052,  -1.2024,  -8.1349,  -4.7305,  -7.1462,  -5.1389,\n",
      "          -4.5093,  -3.2451,  -0.6402]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  14.305188179016113\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6279, -13.7277,  -1.3415,  -8.2151,  -5.2620,  -6.6826,  -4.7402,\n",
      "          -4.5513,  -3.0018,  -0.7625]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.6278607845306396\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6699, -13.3788,  -1.8258,  -8.4584,  -5.9154,  -6.4371,  -4.5589,\n",
      "          -4.7681,  -2.9931,  -1.3721]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.6699471473693848\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.1539, -13.7625,  -3.0756,  -9.3756,  -7.2038,  -6.9152,  -5.1015,\n",
      "          -5.6676,  -3.7228,  -2.7976]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.7975821495056152\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.0857, -13.8842,  -4.0105,  -9.9778,  -8.1406,  -7.1228,  -5.3709,\n",
      "          -6.2563,  -4.1752,  -3.1954]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.08573316037654877\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.0483, -14.0769,  -4.9484, -10.6031,  -9.0675,  -7.3933,  -5.7001,\n",
      "          -6.8710,  -4.6779,  -3.6654]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.870986461639404\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.0580, -13.6082,  -5.1559, -10.5240,  -9.2600,  -6.9953,  -5.3569,\n",
      "          -6.0356,  -4.4956,  -3.4645]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.260039329528809\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.1324, -12.5772,  -4.7379,  -9.8438,  -8.0762,  -6.0286,  -4.4424,\n",
      "          -4.6761,  -3.7314,  -2.6966]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  12.577159881591797\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4543, -10.5865,  -3.9996,  -8.8632,  -6.6423,  -4.7918,  -3.2598,\n",
      "          -3.0908,  -2.6940,  -1.6845]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.2597815990448\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4951, -9.0943, -3.6483, -8.2805, -5.6523, -3.9849, -1.7670, -1.9975,\n",
      "         -2.1138, -1.2040]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.7669719457626343\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4109, -8.5696, -4.1697, -8.5749, -5.5824, -4.0917, -0.6173, -1.9335,\n",
      "         -2.5061, -1.8015]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.410916566848755\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7256, -8.3801, -4.9331, -9.1230, -5.8051, -4.4838, -0.2737, -2.2671,\n",
      "         -3.2070, -2.7387]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.483835697174072\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5980, -7.8919, -5.3080, -9.2989, -5.6902, -3.7480, -0.2216, -2.3273,\n",
      "         -3.5525, -3.3105]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.891902446746826\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.9435, -6.3177, -5.2065, -9.0145, -5.1465, -2.6611, -0.3348, -2.0119,\n",
      "         -3.4437, -3.4083]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.317735195159912\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.0470, -4.0042, -4.9096, -8.5492, -4.4518, -1.5275, -0.7634, -1.6187,\n",
      "         -3.1616, -3.3103]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.310323476791382\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3926, -2.1844, -4.8983, -8.3810, -4.0858, -0.9272, -1.7490, -1.6640,\n",
      "         -3.1921, -2.7934]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.748978614807129\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.1035, -1.0223, -5.2921, -8.6283, -4.1674, -1.0946, -2.4136, -2.2454,\n",
      "         -3.6508, -2.7697]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.2453725337982178\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.9948, -0.4761, -5.9009, -9.1016, -4.5030, -1.7573, -3.3295, -2.3494,\n",
      "         -4.3351, -3.0430]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.502967834472656\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.6937, -0.3115, -6.3471, -9.4240, -3.9622, -2.3848, -4.0772, -2.4106,\n",
      "         -4.8577, -3.2187]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  8.693720817565918\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.2796, -0.3392, -6.4194, -9.3835, -3.1586, -2.6911, -4.4324, -2.2021,\n",
      "         -5.0037, -3.0744]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.3391856551170349\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.0652, -0.3235, -6.6438, -9.5053, -2.6250, -3.1781, -4.9193, -2.2554,\n",
      "         -5.2988, -3.1352]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.91926908493042\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5572, -0.4940, -6.5319, -9.3000, -1.8839, -3.3342, -4.2995, -2.0669,\n",
      "         -5.2534, -2.9057]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.066892623901367\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.1226, -1.0901, -6.4545, -9.1376, -1.3527, -3.5251, -3.7739, -1.2667,\n",
      "         -5.2391, -2.7600]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  9.13762092590332\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.8331, -1.9597, -6.4872, -8.3777, -1.1696, -3.8213, -3.4191, -0.8582,\n",
      "         -5.3317, -2.7749]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.821267604827881\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5127, -2.7793, -6.4573, -7.6331, -1.1768, -3.2628, -3.0635, -0.7469,\n",
      "         -5.3585, -2.7717]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.063523292541504\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1206, -3.4555, -6.3268, -6.8583, -1.3097, -2.6852, -1.9286, -0.8959,\n",
      "         -5.2817, -2.7086]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.281708717346191\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.8018, -4.1190, -6.2434, -6.1941, -1.6643, -2.2512, -1.0480, -1.3676,\n",
      "         -4.4525, -2.7316]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.731560230255127\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6682, -4.8789, -6.3210, -5.7488, -2.2767, -2.0938, -0.6681, -2.1336,\n",
      "         -3.8664, -2.2433]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.866361618041992\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.5242, -5.5422, -6.3659, -5.3239, -2.8790, -2.0223, -0.6827, -2.8856,\n",
      "         -2.5381, -1.8525]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  6.365946292877197\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3876, -6.1325, -5.6716, -4.9350, -3.4537, -2.0517, -1.0625, -3.5948,\n",
      "         -1.3950, -1.6016]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.3875813484191895\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.6979, -6.8076, -5.1910, -4.7321, -4.1371, -2.3208, -1.8040, -4.3960,\n",
      "         -0.7049, -1.6602]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.3207504749298096\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1417, -7.4747, -4.8206, -4.6142, -4.8228, -1.9177, -2.6527, -5.1850,\n",
      "         -0.5348, -1.9057]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.141677379608154\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7672, -7.8989, -4.3162, -4.3382, -5.2695, -1.4926, -3.2927, -5.7229,\n",
      "         -0.6696, -2.0550]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.269487380981445\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5288, -8.2357, -3.8263, -4.0537, -4.8795, -1.2399, -3.8512, -6.1643,\n",
      "         -1.1507, -2.2347]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.5288487672805786\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4282, -9.1069, -3.9687, -4.3777, -5.1016, -1.8060, -4.9378, -7.1310,\n",
      "         -2.4020, -3.0399]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.8060047626495361\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2207, -10.2108,  -4.4301,  -4.9979,  -5.6257,  -1.9845,  -6.2409,\n",
      "          -8.3215,  -3.9198,  -4.1182]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  10.210846900939941\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2144, -10.1234,  -4.4653,  -5.1723,  -5.7113,  -1.8634,  -7.0268,\n",
      "          -9.0047,  -4.9134,  -4.7118]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  9.004682540893555\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.3327, -9.5981, -4.0589, -4.8868, -5.3444, -1.4288, -7.2886, -8.4245,\n",
      "         -5.3673, -4.8061]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  9.598145484924316\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6371, -8.1297, -3.3985, -4.3282, -4.7106, -0.9171, -7.2179, -7.5953,\n",
      "         -5.4728, -4.5898]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.472778797149658\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1339, -6.6584, -2.6790, -3.6856, -3.9974, -0.6185, -7.0055, -6.6998,\n",
      "         -4.6293, -4.2531]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.6790482997894287\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.8203, -5.3470, -1.3667, -3.1376, -3.3816, -0.7812, -6.8276, -5.9069,\n",
      "         -3.8901, -3.9726]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.1375503540039062\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8372, -4.4544, -0.6556, -2.2415, -3.1376, -1.5682, -6.9531, -5.4799,\n",
      "         -3.5255, -4.0182]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.241508960723877\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1147, -3.9791, -0.7138, -1.1164, -3.2709, -2.7593, -7.3872, -5.4190,\n",
      "         -3.5409, -4.3925]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.759319305419922\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4514, -3.7390, -1.2973, -0.5135, -3.5945, -3.2768, -7.9535, -5.5424,\n",
      "         -3.7528, -4.9133]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.5135292410850525\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.1318, -4.0129, -2.4950, -0.1569, -4.3802, -4.2457, -8.9374, -6.1301,\n",
      "         -4.4357, -5.8611]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.130061149597168\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.2895, -3.9161, -3.2775, -0.0941, -4.7411, -4.7733, -9.4674, -5.5583,\n",
      "         -4.7040, -6.3606]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.773313522338867\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.7778, -3.2884, -3.4554, -0.1337, -4.5185, -3.9268, -9.3905, -4.4921,\n",
      "         -4.3986, -6.2574]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.518479824066162\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.8030, -2.3344, -3.2238, -0.3764, -3.1604, -2.7651, -8.9066, -3.1257,\n",
      "         -3.7187, -5.7511]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.3764210343360901\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.2015, -1.9183, -3.4200, -0.7472, -2.3452, -2.1436, -8.8468, -2.3040,\n",
      "         -3.5015, -5.6732]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.4200263023376465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.6536, -1.7386, -2.9862, -1.5108, -1.7764, -1.7679, -8.8862, -1.7320,\n",
      "         -3.4230, -5.6988]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.5108368396759033\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.2460,  -1.8841,  -2.8174,  -1.8285,  -1.5767,  -1.7471,  -9.1070,\n",
      "          -1.5348,  -3.5635,  -5.9094]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  9.107003211975098\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.6818,  -2.0228,  -2.6112,  -2.1311,  -1.4548,  -1.7658,  -8.4581,\n",
      "          -1.4212,  -3.6149,  -6.0034]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.6148762702941895\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.9916,  -2.1569,  -2.3964,  -2.4052,  -1.4381,  -1.8325,  -7.7912,\n",
      "          -1.4171,  -2.8079,  -6.0071]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.007083892822266\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.1941,  -2.2816,  -2.1927,  -2.6397,  -1.5252,  -1.9402,  -7.1146,\n",
      "          -1.5187,  -2.0526,  -5.2238]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  11.194131851196289\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.6296,  -2.4260,  -2.0517,  -2.8629,  -1.7285,  -2.1098,  -6.4672,\n",
      "          -1.7356,  -1.4354,  -4.4835]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.109760046005249\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.1991,  -2.6952,  -2.0961,  -3.1822,  -2.1231,  -1.6596,  -5.9632,\n",
      "          -2.1408,  -1.1463,  -3.9027]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.902738571166992\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.7903, -2.9636, -2.2046, -3.4782, -2.5474, -1.3804, -5.4901, -2.5729,\n",
      "         -1.1168, -2.6646]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  5.490146636962891\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.4170, -3.2358, -2.3773, -3.7614, -2.9832, -1.3182, -4.3146, -3.0138,\n",
      "         -1.3444, -1.5939]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.3182320594787598\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.3861, -3.8135, -2.9058, -4.3383, -3.7190, -1.0019, -3.5713, -3.7530,\n",
      "         -2.0611, -1.0795]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.5712568759918213\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.4000, -4.3907, -3.4631, -4.9085, -4.4414, -1.0424, -2.2214, -4.4778,\n",
      "         -2.8490, -0.8997]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.390676975250244\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.4431, -4.2540, -4.0184, -5.4579, -5.1314, -1.3819, -1.1176, -5.1696,\n",
      "         -3.6350, -1.0576]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.6349704265594482\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.6157, -4.2747, -4.6653, -6.0895, -5.8910, -2.0153, -0.5023, -5.9306,\n",
      "         -3.7049, -1.5804]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.7048873901367188\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.6891, -4.2207, -5.1726, -6.5776, -6.4948, -2.6064, -0.3190, -6.5357,\n",
      "         -2.9190, -2.1153]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  6.535674095153809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.4475, -3.8747, -5.3258, -6.7104, -6.7321, -2.8880, -0.3887, -6.0227,\n",
      "         -1.9463, -2.3751]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.3886575996875763\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.4646, -3.8121, -5.7019, -7.0654, -7.1811, -3.4192, -0.4459, -5.7970,\n",
      "         -1.4174, -2.9097]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.8121421337127686\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.2635, -2.8615, -5.8265, -7.1692, -7.3696, -3.7064, -0.7575, -5.3797,\n",
      "         -0.9159, -3.2134]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.2133779525756836\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.0074, -1.9701, -5.8656, -7.1881, -7.4645, -3.9088, -1.3113, -4.9322,\n",
      "         -0.7047, -2.7293]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.865621566772461\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.7277, -1.2152, -5.1237, -7.1565, -7.5014, -4.0576, -1.9611, -4.4855,\n",
      "         -0.8547, -2.2906]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.057559967041016\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.4908, -0.7564, -4.4747, -7.1434, -7.5498, -3.4467, -2.6657, -4.1066,\n",
      "         -1.3390, -1.9823]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.446744203567505\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.2880, -0.6798, -3.9090, -7.1426, -7.6042, -2.1647, -3.3623, -3.7882,\n",
      "         -1.9917, -1.8130]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.7881996631622314\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.1711, -1.0281, -3.4799, -7.2080, -7.7191, -1.1642, -4.0809, -2.8353,\n",
      "         -2.7524, -1.8421]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  8.171146392822266\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.5081, -1.7416, -3.2679, -7.4193, -7.9748, -0.6556, -4.8925, -2.1731,\n",
      "         -3.6395, -2.1330]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.132974624633789\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.9639, -2.5582, -3.1573, -7.6625, -8.2578, -0.6498, -5.6814, -1.7148,\n",
      "         -4.5114, -1.8214]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.257771492004395\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3349, -3.2077, -2.9493, -7.7421, -7.6161, -0.9061, -6.2546, -1.2976,\n",
      "         -5.1656, -1.5161]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.2077267169952393\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.6864, -3.0425, -2.7169, -7.7307, -6.9552, -1.3635, -6.6888, -1.0437,\n",
      "         -5.6758, -1.3137]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.043679118156433\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.3417, -3.1636, -2.7929, -7.9577, -6.5978, -2.2086, -7.3175, -0.5666,\n",
      "         -6.3747, -1.5593]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  7.957701206207275\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8882, -3.1556, -2.7597, -7.2992, -6.1304, -2.9074, -7.7377, -0.4163,\n",
      "         -6.8589, -1.7833]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.737725734710693\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1731, -2.8657, -2.4641, -6.3945, -5.3991, -3.2664, -7.0582, -0.4622,\n",
      "         -6.9836, -1.7923]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.2664413452148438\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3190, -2.4230, -2.0391, -5.3599, -4.5228, -2.6294, -6.2258, -0.7525,\n",
      "         -6.8754, -1.6976]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.629397392272949\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6755, -2.1857, -1.8517, -4.5314, -3.8417, -1.4477, -5.5775, -1.4647,\n",
      "         -6.8786, -1.8423]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.1856865882873535\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4855, -1.6972, -2.1385, -4.1334, -3.5851, -0.9037, -5.3369, -2.6189,\n",
      "         -7.2226, -2.4256]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.618875026702881\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4474, -1.4578, -2.5568, -3.8601, -3.4486, -0.7969, -5.1974, -3.0376,\n",
      "         -7.6064, -3.0873]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.4578397274017334\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.5711, -0.8084, -3.0867, -3.7255, -3.4462, -1.1412, -5.1721, -3.5467,\n",
      "         -8.0488, -3.8119]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.0867486000061035\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7228, -0.5180, -2.8494, -3.6072, -3.4538, -1.6805, -5.1393, -4.0121,\n",
      "         -8.4329, -4.4658]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.722777843475342\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0619, -0.5369, -2.5462, -3.3883, -3.3529, -2.1764, -4.9822, -4.3129,\n",
      "         -8.6472, -4.9309]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.312938690185547\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4180, -0.8180, -2.1911, -3.0759, -3.1491, -2.5700, -4.7063, -3.7100,\n",
      "         -8.7006, -5.2152]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.7100114822387695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.0312, -1.3959, -1.9736, -2.8482, -3.0185, -3.0032, -4.4849, -2.4667,\n",
      "         -8.7692, -5.4955]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.0311893224716187\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6237, -2.4857, -2.2784, -3.0834, -3.3367, -3.8297, -4.6926, -1.8087,\n",
      "         -9.2296, -6.1493]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.692598342895508\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6199, -3.5055, -2.6089, -3.3092, -3.6313, -4.5716, -4.1223, -1.3187,\n",
      "         -9.6253, -6.7205]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.571573257446289\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8490, -4.2943, -2.8103, -3.3886, -3.7664, -4.3333, -3.4706, -0.9255,\n",
      "         -9.8313, -7.0854]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.085428237915039\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.2029, -4.8574, -2.8794, -3.3278, -3.7493, -3.9722, -2.7504, -0.7091,\n",
      "         -9.8603, -6.5448]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.709050714969635\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0034,  -5.6382,  -3.2511,  -3.5674,  -4.0201,  -3.9298,  -2.4180,\n",
      "          -0.4064, -10.1547,  -6.3273]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.417964458465576\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.7336,  -6.2572,  -3.5280,  -3.7170,  -4.1912,  -3.8201,  -1.3558,\n",
      "          -0.5409, -10.3335,  -6.0462]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.5408655405044556\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7538,  -7.1324,  -4.1153,  -4.1857,  -4.6732,  -4.0546,  -0.9080,\n",
      "          -0.6694, -10.8109,  -6.1113]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  4.054551124572754\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4978,  -7.7296,  -4.4647,  -4.4274,  -4.9231,  -3.3274,  -0.6141,\n",
      "          -0.9725, -11.0493,  -5.9801]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.497769832611084\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2335,  -8.0375,  -4.5576,  -4.4234,  -4.9234,  -2.4698,  -0.5222,\n",
      "          -1.2945, -11.0339,  -5.6335]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.4698293209075928\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0058,  -8.3149,  -4.6490,  -4.4285,  -4.9292,  -1.0058,  -0.8802,\n",
      "          -1.7870, -11.0200,  -5.3240]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.880244791507721\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3149,  -9.0659,  -5.2394,  -4.9428,  -5.4410,  -0.4667,  -1.2686,\n",
      "          -2.8552, -11.5085,  -5.5498]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.314864635467529\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7304,  -9.5780,  -5.6107,  -5.2467,  -5.7410,  -0.2935,  -1.6629,\n",
      "          -3.6954, -11.7842,  -5.5917]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.695405960083008\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8464,  -9.6645,  -5.5730,  -5.1496,  -5.6388,  -0.3276,  -1.7840,\n",
      "          -3.3561, -11.6577,  -5.2574]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.638824462890625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7825,  -9.4332,  -5.2327,  -4.7571,  -4.4767,  -0.5926,  -1.7087,\n",
      "          -2.7672, -11.2346,  -4.6509]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.650866508483887\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9761,  -9.2573,  -4.9625,  -4.4423,  -3.4712,  -1.2796,  -1.8077,\n",
      "          -2.3155, -10.8860,  -3.4308]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.442255020141602\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6990,  -9.2805,  -4.9060,  -3.6256,  -2.7711,  -2.2893,  -2.2003,\n",
      "          -2.1633, -10.7536,  -2.5369]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.7711398601531982\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.9402,  -9.4397,  -4.9988,  -3.0477,  -1.5669,  -3.4132,  -2.7745,\n",
      "          -2.2493, -10.7727,  -1.9267]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.5668927431106567\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0271, -10.1761,  -5.6803,  -3.1547,  -0.4772,  -5.0430,  -3.9309,\n",
      "          -2.9977, -11.3829,  -2.0743]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.0742931365966797\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4017, -11.1418,  -6.5990,  -3.5844,  -0.2720,  -6.8179,  -5.2893,\n",
      "          -4.0110, -12.2348,  -1.8877]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.817916393280029\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.3232, -11.6714,  -7.0874,  -3.6516,  -0.3268,  -7.3209,  -6.1764,\n",
      "          -4.5970, -12.6621,  -1.4878]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.65161395072937\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8559, -11.8418,  -7.2213,  -2.7034,  -0.6157,  -7.4678,  -6.6702,\n",
      "          -4.8256, -12.7403,  -0.9825]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.703439474105835\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3888, -12.0430,  -7.3901,  -1.2287,  -1.3315,  -7.6483,  -7.1635,\n",
      "          -5.0851, -12.8584,  -0.8425]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  12.04295825958252\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.1911, -11.8471,  -7.8617,  -0.4312,  -2.4946,  -8.1303,  -7.9274,\n",
      "          -5.6424, -13.2840,  -1.3428]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.494582414627075\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.9477, -11.7036,  -8.3194,  -0.2149,  -2.8810,  -8.5972,  -8.6483,\n",
      "          -6.1797, -13.6999,  -2.0123]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.597234725952148\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.2069, -11.1516,  -8.3090,  -0.1778,  -2.8485,  -7.8437,  -8.8748,\n",
      "          -6.2423, -13.6517,  -2.2878]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  8.308989524841309\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.9464, -10.1601,  -7.0653,  -0.2494,  -2.3685,  -6.6710,  -8.5845,\n",
      "          -5.8057, -13.1139,  -2.1139]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.67103385925293\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.3550,  -8.9099,  -5.5885,  -0.5120,  -1.6494,  -4.5122,  -7.9657,\n",
      "          -5.0572, -12.2721,  -1.6860]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.588537216186523\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8105,  -7.7709,  -3.5131,  -1.1619,  -1.1337,  -2.5632,  -7.3955,\n",
      "          -4.3748, -11.5008,  -1.4198]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.374795436859131\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.7040,  -7.1273,  -2.0478,  -2.3518,  -1.2937,  -1.2477,  -7.2642,\n",
      "          -3.4108, -11.1880,  -1.7344]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.351762294769287\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.1117,  -7.0496,  -1.3251,  -3.2756,  -2.1460,  -0.7800,  -7.6477,\n",
      "          -3.0685, -11.4076,  -2.6451]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.111746788024902\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.8412,  -7.0523,  -0.9428,  -4.2065,  -3.0738,  -0.7750,  -8.0655,\n",
      "          -2.8669, -11.6775,  -3.5880]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.052330017089844\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.4348,  -6.1951,  -0.7219,  -4.8905,  -3.7794,  -0.9510,  -8.2772,\n",
      "          -2.5627, -11.7557,  -4.2921]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.292099475860596\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8467,  -5.1994,  -0.6564,  -5.2866,  -4.2067,  -1.1734,  -8.2427,\n",
      "          -2.1206, -11.6009,  -3.9951]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  5.286560535430908\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1090,  -4.0929,  -0.7662,  -4.7201,  -4.3891,  -1.3915,  -7.9982,\n",
      "          -1.5979, -11.2478,  -3.5270]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.7661604881286621\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.6546,  -3.3063,  -0.6682,  -4.4144,  -4.7608,  -1.9722,  -7.9763,\n",
      "          -1.4754, -11.1279,  -3.3246]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.976309776306152\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1003,  -2.4601,  -0.7940,  -3.9842,  -4.9384,  -2.4358,  -7.0451,\n",
      "          -1.3714, -10.8564,  -3.0046]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.0046093463897705\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.6169,  -1.7414,  -1.2235,  -3.5938,  -5.0874,  -2.9024,  -6.1909,\n",
      "          -1.4497, -10.5957,  -2.0232]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.223465085029602\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4939,  -1.4769,  -1.3502,  -3.5220,  -5.4865,  -3.6240,  -5.6835,\n",
      "          -1.9546, -10.6210,  -1.4940]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.9546476602554321\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.4965,  -1.4526,  -1.7093,  -3.5328,  -5.9033,  -4.3481,  -5.2835,\n",
      "          -1.8265, -10.6983,  -1.2320]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.496508836746216\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8259,  -1.5742,  -2.1456,  -3.5432,  -6.2606,  -4.9898,  -4.9070,\n",
      "          -1.8102, -10.7478,  -1.1839]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.5741544961929321\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4372,  -1.2309,  -2.7250,  -3.6737,  -6.6842,  -5.6730,  -4.6739,\n",
      "          -2.0173, -10.8927,  -1.4593]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.2308595180511475\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4897,  -0.6626,  -3.5281,  -4.0424,  -7.2997,  -6.5240,  -4.7042,\n",
      "          -2.5356, -11.2564,  -2.1062]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.524041175842285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6243,  -0.4374,  -4.1996,  -4.3137,  -7.7813,  -6.4675,  -4.6650,\n",
      "          -2.9879, -11.5107,  -2.7023]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.199646472930908\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.6177,  -0.4160,  -3.8114,  -4.2993,  -7.9469,  -6.1494,  -4.3685,\n",
      "          -3.1642, -11.4714,  -3.0186]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.299318790435791\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4615,  -0.5635,  -3.1866,  -3.2920,  -7.8047,  -5.5730,  -3.8195,\n",
      "          -3.0628, -11.1444,  -3.0468]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.4615087509155273\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8634,  -1.1804,  -2.7437,  -2.5010,  -7.7664,  -5.1463,  -3.4311,\n",
      "          -3.0956, -10.9395,  -3.1955]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.146304607391357\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.6902,  -2.0140,  -2.4572,  -1.9122,  -7.7973,  -4.0851,  -3.1707,\n",
      "          -3.2239, -10.8199,  -3.4237]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.690170407295227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5006,  -3.1781,  -2.5832,  -1.8083,  -8.1464,  -3.4630,  -3.2887,\n",
      "          -3.6899, -11.0332,  -3.9735]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.5006344318389893\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3149,  -4.5200,  -3.0170,  -2.0965,  -8.7256,  -3.1910,  -3.6877,\n",
      "          -4.3928, -11.4900,  -4.7467]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.31485041975975037\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.1759,  -5.9562,  -3.6638,  -2.6640,  -9.4675,  -3.1971,  -4.2861,\n",
      "          -5.2552, -12.1216,  -5.6693]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.956169605255127\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.1854,  -6.0929,  -3.8027,  -2.7624,  -9.6732,  -2.7707,  -4.3729,\n",
      "          -5.5732, -12.2279,  -6.0402]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.770733118057251\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4742,  -5.9093,  -3.6360,  -2.5878,  -9.5503,  -1.3808,  -4.1523,\n",
      "          -5.5541, -12.0154,  -6.0676]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.3808469772338867\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.8579,  -6.4300,  -4.1894,  -3.1684, -10.1237,  -0.2582,  -4.6496,\n",
      "          -6.2239, -12.5080,  -6.7780]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.189410209655762\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.4636,  -7.1492,  -4.2131,  -3.9707, -10.8893,  -0.0745,  -5.3540,\n",
      "          -7.0778, -13.2010,  -7.6678]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  4.213144779205322\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.4181,  -7.2839,  -3.0020,  -4.1931, -11.0653,  -0.0864,  -5.4782,\n",
      "          -7.3339, -13.3115,  -7.9559]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.333866119384766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8181,  -6.9377,  -1.4798,  -3.9361, -10.7558,  -0.3071,  -5.1253,\n",
      "          -6.3527, -12.9430,  -7.7476]], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.755772590637207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.3270,  -6.7696,  -0.4192,  -3.8617,  -9.8581,  -1.1902,  -4.9550,\n",
      "          -5.6134, -12.7542,  -7.7033]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.8617093563079834\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.9956,  -6.8260,  -0.1537,  -3.3022,  -9.2567,  -2.4163,  -5.0139,\n",
      "          -5.1573, -12.7910,  -7.8706]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.825950622558594\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.2250,  -5.8095,  -0.1672,  -2.4502,  -8.3409,  -3.2117,  -4.6975,\n",
      "          -4.3766, -12.4498,  -7.6471]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.45023250579834\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.2983,  -4.7617,  -0.6599,  -0.8989,  -7.3817,  -3.8231,  -4.2848,\n",
      "          -3.5482, -12.0079,  -7.3116]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.284849166870117\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8344,  -4.2929,  -1.9478,  -0.2614,  -6.9873,  -4.8586,  -3.6383,\n",
      "          -3.2926, -12.0788,  -7.4788]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.261414498090744\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.8880,  -4.4504,  -3.7813,  -0.0937,  -7.2030,  -6.3668,  -3.6461,\n",
      "          -3.6602, -12.7127,  -8.1998]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.3667802810668945\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.3474,  -4.1107,  -4.9593,  -0.1025,  -6.9082,  -6.4969,  -3.1832,\n",
      "          -3.5209, -12.7940,  -8.3596]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.520902395248413\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.2984,  -3.3534,  -5.5623,  -0.2876,  -6.1807,  -6.1522,  -2.3348,\n",
      "          -2.2116, -12.4043,  -8.0409]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.040899276733398\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.2270,  -2.6684,  -6.0806,  -0.9565,  -5.4997,  -5.8160,  -1.6167,\n",
      "          -1.0868, -12.0260,  -7.0078]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.0867998600006104\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.9249,  -2.8617,  -7.3110,  -2.5921,  -5.6516,  -6.2775,  -1.8821,\n",
      "          -0.3447, -12.4473,  -6.8402]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.277453899383545\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.5451,  -3.0674,  -8.4111,  -4.1096,  -5.7828,  -5.9510,  -2.2279,\n",
      "          -0.1959, -12.8184,  -6.6818]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.109628200531006\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.6529,  -2.8343,  -8.9511,  -4.3274,  -5.4525,  -5.2082,  -2.1701,\n",
      "          -0.2211, -12.7018,  -6.0893]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.170111656188965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.4874,  -2.4027,  -9.1748,  -4.2703,  -4.8958,  -4.2807,  -1.1871,\n",
      "          -0.5728, -12.3342,  -5.2948]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.4027059078216553\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.5025,  -1.5461,  -9.5405,  -4.3927,  -4.5644,  -3.6199,  -0.6965,\n",
      "          -1.4689, -12.1673,  -4.7471]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.4688990116119385\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.6967,  -1.1036, -10.0503,  -4.6923,  -4.4544,  -3.2250,  -0.8112,\n",
      "          -1.8870, -12.1975,  -4.4407]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.692262649536133\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.7315,  -0.7959, -10.3693,  -4.1230,  -4.2243,  -2.7588,  -1.1092,\n",
      "          -2.2350, -12.0847,  -4.0332]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.2350406646728516\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.7058,  -0.7755, -10.5994,  -3.5646,  -3.9712,  -2.3285,  -1.5688,\n",
      "          -1.8338, -11.9260,  -3.6220]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.3285043239593506\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.7295,  -1.1239, -10.8535,  -3.1287,  -3.8046,  -1.3253,  -2.1865,\n",
      "          -1.6368, -11.8299,  -3.3178]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.6367710828781128\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.0451,  -1.9577, -11.3766,  -3.0613,  -3.9659,  -0.9118,  -3.1215,\n",
      "          -1.1631, -12.0376,  -3.3643]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.1631189584732056\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.6662,  -3.1434, -12.1844,  -3.3704,  -4.4625,  -1.1720,  -4.3335,\n",
      "          -0.5710, -12.5615,  -3.7680]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.7679812908172607\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.1366,  -4.1522, -12.8229,  -3.5842,  -4.8298,  -1.5452,  -5.3460,\n",
      "          -0.3638, -12.9443,  -3.3395]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.54522705078125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.4117,  -4.9231, -13.2495,  -3.6479,  -5.0182,  -1.1557,  -6.1128,\n",
      "          -0.5378, -13.1407,  -2.8308]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.018194198608398\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.4500,  -5.4129, -13.4241,  -3.5142,  -4.2167,  -0.8267,  -6.5955,\n",
      "          -0.9114, -13.1079,  -2.2057]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.5141868591308594\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.4009,  -5.7734, -13.4978,  -2.6267,  -3.4227,  -0.7680,  -6.9476,\n",
      "          -1.4575, -12.9949,  -1.6388]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  0.7680004835128784\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.6545,  -6.3980, -13.8618,  -2.1763,  -3.0306,  -0.6199,  -7.5631,\n",
      "          -2.4168, -13.1909,  -1.5662]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.5662281513214111\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.9486,  -7.0273, -14.2555,  -1.9167,  -2.7804,  -0.9468,  -8.1836,\n",
      "          -3.4116, -13.4332,  -0.9976]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.9976376295089722\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.5786,  -7.9598, -14.9751,  -2.1519,  -2.9680,  -1.8905,  -9.1076,\n",
      "          -4.6967, -14.0166,  -0.3979]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.696696758270264\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.0433,  -8.6971, -15.5204,  -2.3432,  -3.0737,  -2.7482,  -9.8372,\n",
      "          -5.0269, -14.4392,  -0.2397]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.0736985206604004\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.1212,  -9.0206, -15.6710,  -2.2427,  -2.0991,  -3.2269, -10.1536,\n",
      "          -4.9885, -14.4792,  -0.3221]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.2427175045013428\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.1070,  -9.2276, -15.7222,  -1.4385,  -1.2311,  -3.6028, -10.3542,\n",
      "          -4.8746, -14.4310,  -0.8307]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.2311069965362549\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.6470,  -9.9669, -16.3211,  -1.4345,  -0.4624,  -4.5140, -11.0877,\n",
      "          -5.3303, -14.9403,  -2.1530]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  16.321125030517578\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.1519, -10.6513, -16.1439,  -1.6176,  -0.2720,  -5.3612, -11.7667,\n",
      "          -5.7629, -15.4175,  -3.4454]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  16.143943786621094\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-14.1993, -10.8602, -14.8474,  -1.5151,  -0.2756,  -5.7202, -11.9710,\n",
      "          -5.7474, -15.4400,  -4.2247]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  10.860217094421387\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.8016,  -9.9098, -13.2396,  -1.1377,  -0.4162,  -5.6056, -11.7146,\n",
      "          -5.2955, -15.0199,  -4.4966]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.1376988887786865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.5386,  -9.1490, -11.8869,  -0.4140,  -1.1379,  -5.6002, -11.5787,\n",
      "          -4.9873, -14.7367,  -4.8445]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  14.736716270446777\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.2460,  -8.4082, -10.6131,  -0.1725,  -1.9752,  -5.5422, -11.4007,\n",
      "          -4.6590, -13.5990,  -5.1076]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  10.613126754760742\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.5673,  -7.3262,  -8.3238,  -0.1307,  -2.4192,  -5.0777, -10.8251,\n",
      "          -3.9551, -12.1592,  -4.9337]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.326171875\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.4588,  -5.1597,  -5.7652,  -0.2089,  -2.3893,  -4.1667,  -9.8095,\n",
      "          -2.8379, -10.3655,  -4.2849]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.2849016189575195\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.2720,  -3.0241,  -3.2749,  -0.6553,  -2.2434,  -3.1690,  -8.7063,\n",
      "          -1.6861,  -8.5616,  -2.8043]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.686134934425354\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.0322,  -1.9640,  -1.8891,  -2.2478,  -3.0217,  -3.1306,  -8.5421,\n",
      "          -0.8824,  -7.7664,  -2.3435]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.8823671340942383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.6655,  -1.9564,  -1.6012,  -4.6046,  -4.6086,  -3.9773,  -9.2433,\n",
      "          -0.5803,  -7.8998,  -2.8464]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.956371545791626\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.2551,  -1.3729,  -1.5091,  -6.7532,  -6.0646,  -4.7730,  -9.8943,\n",
      "          -0.7372,  -8.0396,  -3.3602]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.5090622901916504\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.8836,  -1.1216,  -0.9559,  -8.7862,  -7.4750,  -5.5932, -10.5780,\n",
      "          -1.3253,  -8.2633,  -3.9454]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.786212921142578\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.3931,  -1.0662,  -0.6831,  -9.8582,  -8.6890,  -6.2782, -11.1374,\n",
      "          -1.9924,  -8.4086,  -4.4298]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.429793357849121\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.6481,  -1.0523,  -0.6031, -10.6196,  -9.5784,  -6.6925, -11.4371,\n",
      "          -2.4886,  -8.3357,  -3.9554]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  3.955437660217285\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.6311,  -1.0365,  -0.6842, -11.0587, -10.1328,  -6.8199, -11.4606,\n",
      "          -2.7496,  -8.0238,  -2.5849]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.749567747116089\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.5672,  -1.2207,  -1.0766, -11.4055, -10.5834,  -6.8869, -11.4330,\n",
      "          -2.2537,  -7.6946,  -1.3560]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.0765962600708008\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.8409,  -1.9231,  -1.2800, -12.0489, -11.3204,  -7.2791, -11.7394,\n",
      "          -2.2147,  -7.7296,  -0.7647]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.279050827026367\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.0184,  -2.5885,  -1.5969, -12.5594, -11.9151,  -6.8260, -11.9464,\n",
      "          -2.1904,  -7.6927,  -0.4961]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.1904149055480957\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-13.0649,  -3.1267,  -1.9165, -12.9057, -12.3372,  -6.3054, -12.0195,\n",
      "          -1.4103,  -7.5465,  -0.5752]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.305428504943848\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.9964,  -3.5315,  -2.2012, -13.1072, -12.6070,  -4.9946, -11.9749,\n",
      "          -0.7751,  -7.3049,  -0.9366]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  13.107171058654785\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.8509,  -3.8327,  -2.4545, -12.5060, -12.7661,  -3.7355, -11.8510,\n",
      "          -0.4545,  -7.0041,  -1.4572]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  12.766136169433594\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.5122,  -3.9112,  -2.5375, -11.7568, -11.9377,  -2.4115, -11.5316,\n",
      "          -0.4189,  -6.5262,  -1.8838]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.8838163614273071\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.1846,  -3.9733,  -2.6474, -11.0598, -11.1692,  -1.2629, -11.2215,\n",
      "          -0.8408,  -6.0747,  -1.6410]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.647444009780884\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.0881,  -4.2409,  -2.2669, -10.6305, -10.6756,  -0.6355, -11.1407,\n",
      "          -1.7311,  -5.8684,  -1.7585]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.266934871673584\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.1252,  -4.6159,  -1.3983, -10.3680, -10.3552,  -0.5849, -11.1920,\n",
      "          -2.7851,  -5.8090,  -2.1109]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  10.36800765991211\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.1099,  -4.9117,  -0.7470,  -9.3868, -10.0180,  -0.9004, -11.1895,\n",
      "          -3.7302,  -5.7093,  -2.4655]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  11.189455032348633\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.9997,  -5.0869,  -0.4087,  -8.4070,  -9.6180,  -1.3867, -10.3251,\n",
      "          -4.5023,  -5.5260,  -2.7490]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  8.40696907043457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.6191,  -4.9675,  -0.3048,  -6.5510,  -8.9764,  -1.7267,  -9.2654,\n",
      "          -4.9241,  -5.0828,  -2.7684]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  4.967526435852051\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.9004,  -3.7900,  -0.3684,  -4.5048,  -8.0229,  -1.7877,  -7.9352,\n",
      "          -4.9332,  -4.3129,  -2.4546]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.022890090942383\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.0473,  -2.5395,  -0.7186,  -2.4641,  -6.1971,  -1.7598,  -6.5319,\n",
      "          -4.7408,  -3.4250,  -2.0273]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.5395495891571045\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.7762, -1.2701, -1.8821, -1.1828, -5.0516, -2.3582, -5.7663, -5.0708,\n",
      "         -3.1497, -2.2334]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  9.776206016540527\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-9.3761, -0.8951, -3.6119, -0.8150, -4.5972, -3.5389, -5.6515, -5.9447,\n",
      "         -3.5099, -3.0677]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  9.376133918762207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.2537, -0.8032, -5.1498, -0.7531, -4.1565, -4.5842, -5.5117, -6.6944,\n",
      "         -3.8202, -3.8128]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  0.7531406283378601\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.3715, -1.1611, -6.6672, -0.4580, -3.9000, -5.6614, -5.5172, -7.4987,\n",
      "         -4.2463, -4.6280]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.1610510349273682\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5197, -0.9475, -7.9764, -0.5748, -3.6266, -6.5759, -5.4673, -8.1653,\n",
      "         -4.5840, -5.3110]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.519650459289551\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.7549, -0.7462, -8.8767, -0.7923, -3.1218, -7.1216, -5.1468, -8.4869,\n",
      "         -4.6179, -5.6506]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  0.7462345957756042\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3713, -0.3988, -9.8868, -1.5017, -2.9003, -7.8127, -5.0619, -8.9759,\n",
      "         -4.8559, -6.1583]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.975879669189453\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.0131,  -0.4155, -10.6590,  -2.1579,  -2.6056,  -8.2981,  -4.8529,\n",
      "          -8.5510,  -4.9394,  -6.4795]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.479510307312012\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.8790,  -0.8804, -11.3464,  -2.8211,  -2.3889,  -8.7274,  -4.6629,\n",
      "          -8.1606,  -5.0127,  -6.0477]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.047738075256348\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3563,  -1.7832, -12.1622,  -3.6565,  -2.4609,  -9.3109,  -4.6959,\n",
      "          -8.0062,  -5.2812,  -5.1482]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.281191825866699\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.2420,  -2.5610, -12.7452,  -4.2751,  -2.4395,  -9.6847,  -4.5810,\n",
      "          -7.7157,  -4.5376,  -4.1906]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  12.745180130004883\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.3337,  -2.9422, -12.1718,  -4.4690,  -2.1144,  -9.6486,  -4.1127,\n",
      "          -7.0817,  -3.5043,  -2.9664]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.081689834594727\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.7558,  -3.1459, -11.4792,  -4.4754,  -1.7380,  -9.4399,  -3.5274,\n",
      "          -5.6105,  -2.4228,  -1.7244]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.610494613647461\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7096,  -3.5951, -11.0915,  -4.7249,  -1.7699,  -9.4880,  -3.2590,\n",
      "          -3.8046,  -1.7592,  -0.9691]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.724948883056641\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.9188,  -4.2386, -10.9623,  -4.4796,  -2.1494,  -9.7512,  -3.2669,\n",
      "          -2.4145,  -1.5262,  -0.7793]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  9.751226425170898\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.1058,  -4.8873, -10.9053,  -4.3258,  -2.6398,  -9.3081,  -3.3627,\n",
      "          -1.2868,  -1.5581,  -0.9944]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  1.2868139743804932\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.7678,  -6.0580, -11.4352,  -4.7779,  -3.7176,  -9.4904,  -4.0571,\n",
      "          -0.3318,  -2.3449,  -2.0327]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2.344949722290039\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.4322,  -7.2793, -12.0780,  -5.3563,  -4.8723,  -9.8202,  -4.8613,\n",
      "          -0.1583,  -2.4624,  -3.2264]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.861330986022949\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.4804,  -7.9286, -12.2058,  -5.4295,  -5.4671,  -9.6663,  -4.3696,\n",
      "          -0.1680,  -2.1885,  -3.8786]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.467063903808594\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.9584,  -8.0476, -11.8550,  -5.0325,  -4.7721,  -9.0618,  -3.4707,\n",
      "          -0.3186,  -1.5697,  -4.0147]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  0.3185534179210663\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.5606,  -8.3266, -11.7107,  -4.8512,  -4.3245,  -8.6892,  -2.8569,\n",
      "          -0.4297,  -1.3586,  -4.3218]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  4.324547290802002\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.8505,  -8.3256, -11.3284,  -4.4411,  -2.9171,  -8.1015,  -2.0962,\n",
      "          -0.7441,  -1.1314,  -4.3554]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.096160411834717\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.3344,  -8.5476, -11.2070,  -4.3027,  -1.9138,  -7.7952,  -0.9604,\n",
      "          -1.5903,  -1.4196,  -4.6176]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  11.20699691772461\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.0891,  -9.0667, -10.6919,  -4.5066,  -1.4423,  -7.8387,  -0.5518,\n",
      "          -2.8175,  -2.2005,  -5.1797]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.8174524307250977\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.7041,  -9.4695, -10.1634,  -4.6332,  -1.1339,  -7.8136,  -0.5629,\n",
      "          -3.1821,  -2.9319,  -5.6253]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.931861162185669\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.0316,  -9.6061,  -9.4613,  -4.5279,  -0.8763,  -7.5651,  -0.7843,\n",
      "          -3.3140,  -2.5720,  -5.8029]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.7842753529548645\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.4176,  -9.8202,  -8.9203,  -4.5316,  -1.0538,  -7.4327,  -0.6572,\n",
      "          -3.5498,  -2.4028,  -6.0560]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  7.432682037353516\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.4811,  -9.7290,  -8.1491,  -4.2584,  -1.1959,  -6.2905,  -0.6564,\n",
      "          -3.4987,  -2.0419,  -6.0015]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  9.728970527648926\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.2882,  -8.6986,  -7.2048,  -3.7722,  -1.3048,  -5.0133,  -0.8027,\n",
      "          -3.2242,  -1.5752,  -5.7041]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  7.204777240753174\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.9608,  -7.6173,  -5.4787,  -3.1968,  -1.4564,  -3.7144,  -1.1235,\n",
      "          -2.8519,  -1.1743,  -5.2850]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.4564237594604492\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.8038,  -6.7818,  -4.0652,  -2.8451,  -1.1438,  -2.7008,  -1.7988,\n",
      "          -2.6959,  -1.2092,  -5.0491]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.695892810821533\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.7521,  -6.1200,  -2.8946,  -2.6589,  -1.1952,  -1.9275,  -2.6233,\n",
      "          -1.9772,  -1.5796,  -4.9310]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.119964599609375\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.8324,  -4.9573,  -2.0075,  -2.6671,  -1.5991,  -1.4661,  -3.5482,\n",
      "          -1.5560,  -2.2121,  -4.9566]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.6670656204223633\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-12.0691,  -4.0797,  -1.4707,  -2.1880,  -2.2813,  -1.3863,  -4.5675,\n",
      "          -1.4923,  -3.0375,  -5.1491]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  12.069136619567871\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.5756,  -3.3207,  -1.1736,  -1.8546,  -2.9930,  -1.5194,  -5.5126,\n",
      "          -1.6154,  -3.8402,  -5.3461]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.8545719385147095\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.2566,  -2.7878,  -1.2562,  -1.0921,  -3.7977,  -1.9272,  -6.4923,\n",
      "          -1.9941,  -4.7065,  -5.6523]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.0920841693878174\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.4169,  -2.7986,  -1.9849,  -0.3913,  -4.9869,  -2.8500,  -7.8231,\n",
      "          -2.8803,  -5.9417,  -6.3781]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.8802878856658936\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.5537,  -2.8431,  -2.7333,  -0.2254,  -6.0553,  -3.7164,  -9.0141,\n",
      "          -2.9952,  -7.0485,  -7.0253]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  2.843146324157715\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.3578,  -1.9101,  -3.1353,  -0.3132,  -6.7001,  -4.1954,  -9.7676,\n",
      "          -2.8154,  -7.7267,  -7.2896]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.135345220565796\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-11.0250,  -1.0168,  -2.6473,  -0.7435,  -7.1254,  -4.4817, -10.2898,\n",
      "          -2.5400,  -8.1815,  -7.3717]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.647289752960205\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.8916,  -0.6309,  -1.7043,  -1.6266,  -7.6750,  -4.9141, -10.9262,\n",
      "          -2.5146,  -8.7574,  -7.6123]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  2.5146291255950928\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.8982,  -0.7812,  -1.1135,  -2.6849,  -8.2971,  -5.4356, -11.6261,\n",
      "          -1.9631,  -9.4029,  -7.9561]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.68489670753479\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.8979,  -1.2288,  -0.8129,  -2.9844,  -8.8512,  -5.9022, -12.2499,\n",
      "          -1.5605,  -9.9779,  -8.2596]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  9.97790813446045\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.7704,  -1.7084,  -0.7359,  -3.1619,  -9.2229,  -6.1972, -12.6845,\n",
      "          -1.2209,  -9.5309,  -8.4058]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  1.708379864692688\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.5857,  -1.5006,  -0.9428,  -3.2812,  -9.4879,  -6.3944, -13.0059,\n",
      "          -1.0561,  -9.0586,  -8.4678]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.9428433179855347\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.4983,  -1.5474,  -0.7673,  -3.4935,  -9.8054,  -6.6521, -13.3742,\n",
      "          -1.2351,  -8.7122,  -8.6026]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  13.374175071716309\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-10.1865,  -1.5043,  -0.7112,  -3.4727,  -9.8582,  -6.6520, -12.7030,\n",
      "          -1.3710,  -8.1674,  -8.4910]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  8.491005897521973\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -9.6587,  -1.3729,  -0.7675,  -3.2284,  -9.6587,  -6.4057, -11.8516,\n",
      "          -1.4276,  -7.4300,  -7.4234]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.405743598937988\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.9632,  -1.2105,  -0.9322,  -2.8156,  -9.2589,  -5.2205, -10.8647,\n",
      "          -1.4297,  -6.5462,  -6.2422]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  9.258892059326172\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.1695, -1.1040, -1.1963, -2.3180, -7.9647, -3.9897, -9.8085, -1.4352,\n",
      "         -5.5840, -5.0125]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  8.169526100158691\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.6349, -1.1464, -1.5595, -1.8462, -6.7076, -2.8031, -8.7654, -1.5182,\n",
      "         -4.6287, -3.8178]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  1.5595221519470215\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4093, -1.5607, -1.4714, -1.6864, -5.7317, -1.9351, -7.9815, -1.9049,\n",
      "         -3.9319, -2.9132]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.7317328453063965\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.3918, -2.1626, -1.6400, -1.7540, -4.1765, -1.3440, -7.3587, -2.4423,\n",
      "         -3.4038, -2.2207]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  7.358681678771973\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5807, -2.8808, -2.0275, -2.0314, -2.8840, -1.1023, -6.1278, -3.0846,\n",
      "         -3.0523, -1.7717]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.883986711502075\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1098, -3.8056, -2.7103, -2.6114, -1.2440, -1.3714, -5.2602, -3.9348,\n",
      "         -3.0146, -1.7292]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.7102880477905273\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1858, -5.1213, -3.1204, -3.6524, -0.4549, -2.2704, -4.9505, -5.1819,\n",
      "         -3.4894, -2.2868]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.286769151687622\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3471, -6.3729, -3.5840, -4.6705, -0.2918, -3.2196, -4.7397, -6.3716,\n",
      "         -4.0053, -2.2038]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.372934818267822\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1486, -6.4340, -3.6520, -5.2242, -0.3439, -3.7347, -4.1872, -7.0745,\n",
      "         -4.1156, -1.8392]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.651970386505127\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7136, -6.2024, -2.7277, -5.4389, -0.6407, -3.9286, -3.4136, -7.4204,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -3.9410, -1.3378]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  2.727719783782959\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.4720, -6.0970, -1.3318, -5.7369, -1.4082, -4.2196, -2.8441, -7.8340,\n",
      "         -3.9019, -1.1776]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  1.408167839050293\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.7211, -6.4084, -0.6685, -6.4123, -1.9311, -4.8974, -2.7809, -8.6114,\n",
      "         -4.2885, -1.6604]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  8.611429214477539\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9551, -6.6515, -0.3997, -6.9831, -2.4731, -5.4748, -2.7333, -8.5553,\n",
      "         -4.6097, -2.1938]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  0.39965131878852844\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4737, -7.1410, -0.1922, -7.7675, -3.2947, -6.2676, -3.0103, -8.7746,\n",
      "         -5.1770, -3.0244]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.177002429962158\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.5424, -7.1614, -0.1742, -8.0531, -3.6416, -6.5620, -2.8768, -8.5513,\n",
      "         -4.4315, -3.3864]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  6.561976909637451\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1577, -6.7125, -0.2878, -7.8427, -3.5060, -5.6134, -2.3322, -7.8825,\n",
      "         -3.3024, -3.2691]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.5060319900512695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6504, -6.1170, -0.7292, -7.4614, -2.4587, -4.5697, -1.7247, -7.0884,\n",
      "         -2.1244, -2.9988]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.458726406097412\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.6149, -5.9518, -1.8377, -7.4880, -1.1988, -4.0072, -1.6849, -6.7435,\n",
      "         -1.5338, -3.1610]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.951786041259766\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9855, -5.4575, -3.2975, -7.8611, -0.6403, -3.8631, -2.1412, -6.7826,\n",
      "         -1.5324, -3.6865]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.141172409057617\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3679, -5.0270, -4.6497, -8.2088, -0.5461, -3.7606, -1.8828, -6.8301,\n",
      "         -1.7244, -4.1894]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.8827693462371826\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7142, -4.6206, -5.8509, -8.4989, -0.8734, -3.6624, -0.9766, -6.8503,\n",
      "         -2.0242, -4.6300]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  3.6623692512512207\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0957, -4.3131, -6.9861, -8.8118, -1.5332, -2.9004, -0.5022, -6.9210,\n",
      "         -2.4569, -5.0853]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.5022385120391846\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.8900, -4.4843, -8.4477, -9.5323, -2.7280, -2.6940, -0.2109, -7.4239,\n",
      "         -3.3574, -5.9385]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.357423782348633\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2727, -4.3081, -9.4257, -9.8430, -3.5148, -2.2204, -0.2334, -7.5391,\n",
      "         -3.0193, -6.3705]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  5.272667407989502\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.5002, -3.7724, -9.9200, -9.7364, -3.8593, -1.4885, -0.4731, -7.2568,\n",
      "         -2.3694, -6.3744]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  1.4885435104370117\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.0902,  -3.5836, -10.6426,  -9.9179,  -4.4627,  -0.5315,  -1.4415,\n",
      "          -7.2805,  -2.1402,  -6.6564]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.09017276763916\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1866,  -3.6161, -11.4764, -10.2645,  -5.1979,  -0.2917,  -2.6773,\n",
      "          -7.4855,  -2.2158,  -7.0946]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.6772513389587402\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1685,  -3.4295, -11.9925, -10.3419,  -5.6293,  -0.3968,  -2.8429,\n",
      "          -7.4357,  -2.1407,  -7.2549]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.629312038421631\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1617,  -3.1102, -12.2834, -10.2377,  -5.0948,  -0.8162,  -2.8626,\n",
      "          -7.2176,  -1.9982,  -7.2260]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  5.094836711883545\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5851,  -2.9545, -12.6458, -10.2445,  -3.9726,  -1.6217,  -3.0245,\n",
      "          -7.1222,  -2.0844,  -7.3010]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.12215518951416\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.4338,  -2.8104, -12.9318, -10.2102,  -2.9358,  -2.4531,  -3.1668,\n",
      "          -6.2766,  -2.2262,  -7.3287]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  7.328654766082764\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -0.5778,  -2.5293, -12.9958,  -9.9859,  -1.8484,  -3.0720,  -3.1336,\n",
      "          -5.3232,  -2.2512,  -6.4343]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  3.1335856914520264\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.1415,  -2.3566, -13.0780,  -9.8085,  -1.0118,  -3.6882,  -2.4004,\n",
      "          -4.4927,  -2.3870,  -5.6546]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  1.1414579153060913\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4071,  -2.5235, -13.4079,  -9.9047,  -0.7868,  -4.5176,  -2.0651,\n",
      "          -4.0089,  -2.8425,  -5.2110]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.8425345420837402\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7251,  -2.6302, -13.6051,  -9.8916,  -0.8252,  -5.1727,  -1.7599,\n",
      "          -3.4865,  -2.3613,  -4.7158]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  2.3612775802612305\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.1977,  -2.8331, -13.8391,  -9.9360,  -1.2438,  -5.8231,  -1.6723,\n",
      "          -3.0945,  -1.2291,  -4.3326]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.6722970008850098\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0169,  -3.3697, -14.3623, -10.2887,  -2.1488,  -6.7235,  -1.2896,\n",
      "          -3.0868,  -0.7672,  -4.3097]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.309713363647461\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.7454,  -3.8323, -14.7885, -10.5615,  -3.0060,  -7.4904,  -1.1095,\n",
      "          -3.0680,  -0.6949,  -3.5300]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  3.06801700592041\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.2599,  -4.1052, -15.0136, -10.6482,  -3.6562,  -8.0225,  -1.0391,\n",
      "          -2.2064,  -0.8880,  -2.6903]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.6903414726257324\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8042,  -4.4331, -15.2868, -10.7970,  -4.3316,  -8.5725,  -1.3150,\n",
      "          -1.5806,  -1.4755,  -1.3333]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  1.4755090475082397\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -5.7048,  -5.1414, -15.9375, -11.3356,  -5.3543,  -9.4725,  -2.1719,\n",
      "          -1.5702,  -1.7662,  -0.7071]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.1719415187835693\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.5286,  -5.7937, -16.5338, -11.8310,  -6.2891, -10.2933,  -2.2819,\n",
      "          -1.7212,  -2.1807,  -0.5113]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.5113247632980347\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.4962,  -6.6079, -17.2954, -12.5018,  -7.3569, -11.2572,  -2.6830,\n",
      "          -2.2110,  -2.8726,  -0.2706]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  12.501770973205566\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.9906,  -6.9647, -17.6039, -12.0218,  -7.9416, -11.7479,  -2.7188,\n",
      "          -2.3539,  -3.1656,  -0.2292]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  17.603919982910156\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.9840,  -6.8347, -16.7129, -11.1376,  -8.0164, -11.7377,  -2.3489,\n",
      "          -2.0990,  -3.0125,  -0.3133]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  16.712947845458984\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.6525,  -6.3925, -14.8730, -10.0156,  -7.7581, -11.4026,  -1.7625,\n",
      "          -1.6323,  -2.5898,  -0.5884]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  11.402619361877441\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.2620,  -5.9032, -13.1239,  -8.9131,  -7.4336, -10.2634,  -1.2725,\n",
      "          -1.2609,  -2.1795,  -1.1420]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.433599472045898\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.8961,  -5.4497, -11.5341,  -7.9054,  -6.3770,  -9.2227,  -1.0289,\n",
      "          -1.1164,  -1.8895,  -1.8546]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.8546361923217773\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -6.5384,  -5.0155, -10.0736,  -6.9695,  -5.3980,  -8.2568,  -1.0519,\n",
      "          -1.1939,  -1.7257,  -1.8593]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.0518798828125\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3397, -4.7515, -8.8809, -6.2497, -4.6421, -7.5095, -0.7006, -1.6048,\n",
      "         -1.8491, -2.0976]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  6.3396992683410645\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.2561, -4.3467, -7.6339, -5.4299, -3.7956, -6.6640, -0.5873, -1.9469,\n",
      "         -1.9186, -2.2271]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  3.7955551147460938\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1278, -3.8351, -6.3550, -4.5384, -2.1477, -5.7472, -0.7491, -2.2017,\n",
      "         -1.9474, -2.2647]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3], device='cuda:0')\n",
      "Loss:  4.538366317749023\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3010, -3.5670, -5.3819, -3.2142, -0.9284, -5.1013, -1.4292, -2.6884,\n",
      "         -2.2698, -2.5505]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  0.9284451603889465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.4581, -4.2202, -5.3837, -2.9250, -0.2548, -5.3990, -3.0973, -4.0506,\n",
      "         -3.5213, -3.7386]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  3.4581451416015625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.8587, -4.7845, -5.3543, -2.6683, -0.1943, -5.6360, -4.5992, -5.2555,\n",
      "         -4.6385, -4.7912]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.2555155754089355\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.9662, -4.9038, -4.9365, -2.0915, -0.3588, -5.4574, -5.5644, -5.2249,\n",
      "         -5.2579, -5.3503]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  5.224928379058838\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.1279, -4.8794, -4.4283, -1.5226, -0.8882, -5.1627, -6.2994, -4.3449,\n",
      "         -5.6829, -5.7200]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.1627020835876465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.7231, -4.9758, -4.0922, -1.2779, -1.7828, -4.2697, -7.0755, -3.6746,\n",
      "         -6.1814, -6.1682]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  6.168221950531006\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.6634, -5.0170, -3.7511, -1.2047, -2.6627, -3.4256, -7.7246, -3.0390,\n",
      "         -6.5815, -5.8035]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  0.6634026169776917\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.4837, -5.2873, -3.6893, -1.5799, -3.7353, -2.9183, -8.5379, -2.7296,\n",
      "         -7.1714, -5.7057]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  7.171438217163086\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.5451, -5.3068, -3.4242, -1.8363, -4.4914, -2.2744, -9.0429, -2.2706,\n",
      "         -6.6390, -5.3926]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  9.042863845825195\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-0.8567, -5.1613, -3.0424, -2.0137, -5.0139, -1.6048, -8.5723, -1.7652,\n",
      "         -5.9940, -4.9474]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  5.993978977203369\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4366, -5.0243, -2.7229, -2.2581, -5.4793, -1.1420, -8.1387, -1.4235,\n",
      "         -4.5758, -4.5415]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  8.138710975646973\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.1318, -4.9053, -2.4821, -2.5521, -5.9012, -0.9636, -6.9950, -1.2894,\n",
      "         -3.3070, -4.1833]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  3.3069891929626465\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9317, -4.8909, -2.4131, -2.9596, -6.3706, -1.1753, -6.0533, -1.4549,\n",
      "         -1.4587, -3.9593]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.9596409797668457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1652, -5.3576, -2.8897, -3.1276, -7.2688, -2.0709, -5.6814, -2.2467,\n",
      "         -0.4619, -4.2456]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  3.1276371479034424\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.4252, -5.9190, -3.4970, -2.7421, -8.2160, -3.1094, -5.4870, -3.1740,\n",
      "         -0.2259, -4.6516]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  4.651577949523926\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.1628, -6.0263, -3.6654, -2.0404, -8.6689, -3.6777, -4.9149, -3.6390,\n",
      "         -0.2735, -3.9059]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.914895057678223\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.5196, -5.8158, -3.5267, -1.1915, -8.7681, -3.8995, -3.3461, -3.7679,\n",
      "         -0.6334, -2.9400]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.9400217533111572\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-7.0551, -5.8414, -3.6362, -0.8552, -9.0705, -4.3274, -2.1730, -4.1137,\n",
      "         -1.6060, -1.6069]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.1729700565338135\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-8.1008, -6.4295, -4.3167, -1.4162, -9.9058, -5.2856, -1.0177, -4.9998,\n",
      "         -3.2096, -1.1134]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  8.100794792175293\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.5962,  -7.2453,  -5.2241,  -2.3779, -10.9431,  -6.4372,  -0.5346,\n",
      "          -6.0877,  -4.9717,  -1.1899]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  10.943059921264648\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.8832,  -7.8210,  -5.8859,  -3.1502, -10.9721,  -7.3161,  -0.3816,\n",
      "          -6.9096,  -6.4049,  -1.3178]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  8.883201599121094\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -8.0444,  -7.9690,  -6.1130,  -3.5052, -10.6275,  -7.7372,  -0.3857,\n",
      "          -7.2797,  -7.3260,  -1.2543]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.3856818377971649\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -7.4138,  -8.2268,  -6.4435,  -3.9704, -10.4415,  -8.2411,  -0.2740,\n",
      "          -7.7377,  -8.2803,  -1.5261]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  8.226840019226074\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-6.3953, -7.2946, -6.2911, -3.9517, -9.8231, -8.2440, -0.2916, -7.6995,\n",
      "         -8.6888, -1.4757]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  7.294641971588135\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-5.0548, -5.3225, -5.7307, -3.5239, -8.8417, -7.8222, -0.4398, -7.2408,\n",
      "         -8.6322, -1.1698]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.322460174560547\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6364, -2.6299, -5.0125, -2.9436, -7.7421, -7.2267, -0.8361, -6.6123,\n",
      "         -8.3654, -0.9011]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  0.8361324071884155\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9771, -0.8551, -4.9692, -3.0571, -7.3509, -7.2896, -1.3682, -6.6459,\n",
      "         -8.7239, -1.5488]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  1.5488256216049194\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.1299, -0.2689, -5.6446, -3.9020, -7.7085, -8.0562, -2.7461, -7.3866,\n",
      "         -9.7562, -2.2758]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  2.2757720947265625\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.2168,  -0.2015,  -6.1727,  -4.5945,  -7.9481,  -8.6640,  -3.9519,\n",
      "          -7.9712, -10.6032,  -2.2063]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  8.663999557495117\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8860,  -0.2812,  -6.2115,  -4.7870,  -7.7259,  -8.0227,  -4.6139,\n",
      "          -8.0597, -10.9276,  -1.7842]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.7259440422058105\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2991,  -0.5551,  -5.9180,  -4.6364,  -6.4518,  -7.1157,  -4.8874,\n",
      "          -7.8097, -10.8899,  -1.1944]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  4.887445449829102\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7461,  -1.1076,  -5.5578,  -4.4097,  -5.2078,  -6.2016,  -4.2959,\n",
      "          -7.4871, -10.7580,  -0.7821]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  0.7820615768432617\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7502,  -2.2120,  -5.6107,  -4.5888,  -4.4662,  -5.7546,  -4.1479,\n",
      "          -7.5714, -11.0138,  -0.3976]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  7.571392059326172\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.7013,  -3.1038,  -5.4814,  -4.5776,  -3.6273,  -5.1747,  -3.8466,\n",
      "          -6.7413, -11.0644,  -0.3518]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  11.064382553100586\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.4902, -3.6381, -5.0674, -4.2743, -2.5912, -4.3563, -3.2907, -5.6942,\n",
      "         -9.9838, -0.5112]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  2.5912458896636963\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5485, -4.2211, -4.7827, -4.0946, -1.0549, -3.7124, -2.9013, -4.8372,\n",
      "         -9.0943, -1.1645]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.9012913703918457\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.2504, -5.2503, -5.0263, -4.4385, -0.4252, -3.6449, -2.3432, -4.5652,\n",
      "         -8.7873, -2.4686]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([7], device='cuda:0')\n",
      "Loss:  4.565219879150391\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9623, -6.1835, -5.2531, -4.7593, -0.3482, -3.6064, -1.9147, -3.6071,\n",
      "         -8.5136, -3.7058]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  6.183472633361816\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3922, -6.0695, -5.2121, -4.8052, -0.5543, -3.3432, -1.3893, -2.5151,\n",
      "         -8.0183, -4.5883]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  4.805184841156006\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.7453, -5.9099, -5.1204, -4.0816, -1.1069, -3.0741, -1.0429, -1.5317,\n",
      "         -7.5139, -5.3316]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  5.909866809844971\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.1735, -5.1590, -5.1354, -3.5352, -1.9424, -2.9597, -1.0860, -0.8964,\n",
      "         -7.1532, -6.0973]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  4.17354679107666\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.8313, -4.4805, -5.1467, -3.0576, -2.7947, -2.8895, -1.3693, -0.6145,\n",
      "         -6.8227, -6.7821]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  5.146734714508057\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3782, -3.7168, -4.2715, -2.5002, -3.4468, -2.7074, -1.6526, -0.5924,\n",
      "         -6.3652, -7.2387]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.6525521278381348\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.9947, -3.0457, -3.4930, -2.0563, -4.0571, -2.5933, -1.3063, -0.9726,\n",
      "         -5.9542, -7.6499]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0], device='cuda:0')\n",
      "Loss:  2.9946627616882324\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-2.0138, -2.5317, -2.8712, -1.8048, -4.6763, -2.6040, -1.2524, -1.6456,\n",
      "         -5.6431, -8.0774]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.2523949146270752\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.5437, -2.4405, -2.6682, -2.0113, -5.5565, -2.9851, -0.9904, -2.7070,\n",
      "         -5.6816, -8.7781]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  2.011284351348877\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-1.3480, -2.4913, -2.6075, -1.6522, -6.4234, -3.4380, -1.1013, -3.7826,\n",
      "         -5.7905, -9.4807]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.6521801948547363\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.4945,  -2.7283,  -2.7398,  -0.8890,  -7.3383,  -4.0031,  -1.5805,\n",
      "          -4.9007,  -6.0242, -10.2465]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.580507755279541\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -1.9199,  -3.1173,  -3.0355,  -0.6239,  -8.2920,  -4.6552,  -1.5543,\n",
      "          -6.0423,  -6.3660, -11.0655]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  8.291969299316406\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.2030,  -3.2917,  -3.1299,  -0.5593,  -8.2002,  -5.0426,  -1.4799,\n",
      "          -6.8649,  -6.4682, -11.5959]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.2916533946990967\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3114,  -2.5445,  -3.0196,  -0.6795,  -7.8904,  -5.1689,  -1.3540,\n",
      "          -7.3790,  -6.3342, -11.8461]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n",
      "Loss:  3.019578218460083\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.3778,  -1.8233,  -2.1231,  -1.0434,  -7.5081,  -5.1834,  -1.3280,\n",
      "          -7.7388,  -6.1113, -11.9678]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([4], device='cuda:0')\n",
      "Loss:  7.508070945739746\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.5392,  -1.3214,  -1.4369,  -1.6543,  -6.4590,  -5.2344,  -1.5343,\n",
      "          -8.0968,  -5.9462, -12.1111]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([3], device='cuda:0')\n",
      "Loss:  1.654320478439331\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -2.8762,  -1.1911,  -1.1265,  -1.7644,  -5.6494,  -5.4182,  -2.0135,\n",
      "          -8.5532,  -5.9335, -12.3740]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  12.374032974243164\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.0975,  -1.1644,  -0.9604,  -1.8614,  -4.7996,  -5.4636,  -2.4203,\n",
      "          -8.8410,  -5.8010, -11.7709]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  5.463647842407227\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1599,  -1.1901,  -0.9201,  -1.8888,  -3.8705,  -4.5810,  -2.6825,\n",
      "          -8.9302,  -5.5141, -11.0577]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.6824889183044434\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -3.1453,  -1.3256,  -1.0728,  -1.9189,  -2.9475,  -3.6921,  -2.1273,\n",
      "          -8.9088,  -5.1574, -10.3138]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  2.1272902488708496\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.3056, -1.7764, -1.6014, -2.1917, -2.2971, -3.0524, -1.1212, -9.0314,\n",
      "         -4.9827, -9.7857]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([8], device='cuda:0')\n",
      "Loss:  4.982693672180176\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-3.6767, -2.5013, -2.4243, -2.7163, -1.9859, -2.7120, -0.6554, -9.3417,\n",
      "         -4.2008, -9.5100]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([5], device='cuda:0')\n",
      "Loss:  2.7119646072387695\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.0801, -3.2626, -3.2807, -3.2865, -1.8584, -1.7527, -0.6694, -9.6720,\n",
      "         -3.5600, -9.3126]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([1], device='cuda:0')\n",
      "Loss:  3.2625958919525146\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[-4.4570, -3.2713, -4.0805, -3.8275, -1.8606, -1.0212, -1.0600, -9.9705,\n",
      "         -3.0078, -9.1361]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([9], device='cuda:0')\n",
      "Loss:  9.13609790802002\n",
      "torch.Size([1, 1, 40])\n",
      "tensor([[ -4.8062,  -3.3074,  -4.8154,  -4.3321,  -1.9801,  -0.6363,  -1.6684,\n",
      "         -10.2408,  -2.5533,  -8.2639]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6], device='cuda:0')\n",
      "Loss:  1.6683646440505981\n"
     ]
    }
   ],
   "source": [
    "n_steps = 75\n",
    "print_every = 15\n",
    "\n",
    "trained_rnn = train(rnn, n_steps, print_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model\n",
    "correct = 0\n",
    "total = 0\n",
    "hidden = None  \n",
    "print(len(test_loader))\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for X, y in test_loader:\n",
    "       \n",
    "        X = X.cuda()\n",
    "        y = y.cuda()\n",
    "        \n",
    "    \n",
    "    output,hidden = trained_rnn(X, hidden)\n",
    "\n",
    "    for idx, i in enumerate(output):\n",
    "        if torch.argmax(i) == y[idx]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Testing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
