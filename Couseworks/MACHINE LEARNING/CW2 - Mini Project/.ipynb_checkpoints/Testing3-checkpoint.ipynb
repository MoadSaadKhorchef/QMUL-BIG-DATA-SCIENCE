{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys, re, pickle, glob\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import soundfile\n",
    "\n",
    "\n",
    "#from IPython.display import Audio\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padArra(an_array):\n",
    "    np.array(an_array)\n",
    "    shape = np.shape(an_array)\n",
    "    print(shape)\n",
    "    if shape[0] < 129:\n",
    "    \n",
    "        padded_array = np.zeros((128))\n",
    "        padded_array[:shape[0]] = an_array\n",
    "        print(\"padded: \", padded_array.shape)\n",
    "        return(padded_array.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_chromagram(waveform, sample_rate):\n",
    "    # STFT computed here explicitly; mel spectrogram and MFCC functions do this under the hood\n",
    "    stft_spectrogram=np.abs(librosa.stft(waveform))\n",
    "    # Produce the chromagram for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
    "    chromagram=np.mean(librosa.feature.chroma_stft(S=stft_spectrogram, sr=sample_rate,hop_length=512,n_fft=2048).T,axis=0)\n",
    "    return chromagram\n",
    "\n",
    "def feature_melspectrogram(waveform, sample_rate):\n",
    "    # Produce the mel spectrogram for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
    "    # Using 8khz as upper frequency bound should be enough for most speech classification tasks\n",
    "    melspectrogram=np.mean(librosa.feature.melspectrogram(y=waveform, sr=sample_rate, n_mels=128, fmax=sample_rate, hop_length=512,n_fft=2048).T,axis=0) ###\n",
    "    return melspectrogram\n",
    "\n",
    "def feature_mfcc(waveform, sample_rate):\n",
    "    # Compute the MFCCs for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
    "    # 40 filterbanks = 40 coefficients\n",
    "    mfc_coefficients=np.mean(librosa.feature.mfcc(y=waveform, sr=sample_rate, n_mfcc=40).T, axis=0) \n",
    "    return mfc_coefficients\n",
    "\n",
    "\n",
    "\n",
    "def getPitch(x,fs,winLen=0.02):\n",
    "  #winLen = 0.02 \n",
    "    p = winLen*fs\n",
    "    frame_length = int(2**int(p-1).bit_length())\n",
    "    hop_length = frame_length//2\n",
    "    f0, voiced_flag, voiced_probs = librosa.pyin(y=x, fmin=80, fmax=450, sr=fs, frame_length=frame_length,hop_length=hop_length)\n",
    "    return f0,voiced_flag\n",
    "\n",
    "\n",
    "\n",
    "def get_features(file):\n",
    "    # load an individual soundfile\n",
    "     with soundfile.SoundFile(file) as audio:\n",
    "        waveform = audio.read(dtype=\"float32\")\n",
    "        sample_rate = audio.samplerate\n",
    "        # compute features of soundfile\n",
    "        chromagram = padArra(feature_chromagram(waveform, sample_rate))\n",
    "        melspectrogram = padArra(feature_melspectrogram(waveform, sample_rate))\n",
    "        mfc_coefficients = padArra(feature_mfcc(waveform, sample_rate))\n",
    "\n",
    "        # my added features\n",
    "        #######\n",
    "        y = waveform\n",
    "        sr = sample_rate\n",
    "        stft_=np.abs(librosa.stft(waveform))\n",
    "        #print(chromagram.shape)\n",
    "        cent = padArra(np.mean( librosa.feature.spectral_centroid(y=y, sr=sr,hop_length=512,n_fft=2048).T, axis=0))\n",
    "        \n",
    "        contrast = padArra(np.mean( librosa.feature.spectral_contrast(S=stft_, sr=sr,hop_length=512,n_fft=2048).T, axis=0))\n",
    "        #tonnetz = np.mean( librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sample_rate ,hop_length=512).T,axis=0)#\n",
    "        rms = padArra(np.mean( librosa.feature.rms(y=y,frame_length=2048 ,hop_length=512).T, axis=0))\n",
    "        spec_bw = padArra(np.mean( librosa.feature.spectral_bandwidth(y=y, sr=sr ,n_fft=2048, hop_length=512).T, axis=0))\n",
    "        rolloff = padArra(np.mean( librosa.feature.spectral_rolloff(y=y, sr=sr ,n_fft=2048, hop_length=512).T, axis=0))\n",
    "        zcr = padArra(np.mean( librosa.feature.zero_crossing_rate(y, frame_length=2048, hop_length=512).T, axis=0))\n",
    "        #######\n",
    "    \n",
    "        #feature_matrix=np.array([])\n",
    "        # use np.hstack to stack our feature arrays horizontally to create a feature matrix\n",
    "        feature_matrix = np.column_stack((chromagram, np.array(melspectrogram).reshape(-1,1), mfc_coefficients , cent, contrast, rms, spec_bw, rolloff, zcr))\n",
    "        \n",
    "        return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXy(files,labels_file,scale_audio=False, onlySingleDigit=False):\n",
    "    X,y =[],[]\n",
    "    for file in tqdm(files):\n",
    "        file = file.replace(\"\\\\\", \"/\")\n",
    "        fileID = file.split(\"/\")[-1]\n",
    "        #print(fileID)\n",
    "        yi = list(labels_file[labels_file['File ID']==fileID]['digit_label'])[0]\n",
    "        label = list(labels_file[labels_file['File ID']==fileID]['digit_label'])[0]\n",
    "        if onlySingleDigit and yi>9:\n",
    "            continue\n",
    "        else:\n",
    "            fs = None # if None, fs would be 22050\n",
    "            x, fs = librosa.load(file,sr=fs)\n",
    "            if scale_audio: x = x/np.max(np.abs(x))\n",
    "            f0, voiced_flag = getPitch(x,fs,winLen=0.02)\n",
    "\n",
    "            print( (np.sum(x**2)/len(x).type))\n",
    "\n",
    "            \n",
    "            power = np.sum(x**2)/len(x)\n",
    "            pitch_mean = np.nanmean(f0) if np.mean(np.isnan(f0))<1 else 0\n",
    "            pitch_std  = np.nanstd(f0) if np.mean(np.isnan(f0))<1 else 0\n",
    "            voiced_fr = np.mean(voiced_flag)\n",
    "\n",
    "            #added \n",
    "            #features = get_features(file)\n",
    "\n",
    "            #xi = [power,pitch_mean,pitch_std,voiced_fr]\n",
    "            print(features.shape)\n",
    "            \n",
    "            xi = np.column_stack((power,pitch_mean,pitch_std,voiced_fr,features))\n",
    "\n",
    "            X.append(xi)\n",
    "            y.append(label)\n",
    "    return np.array(X),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File ID</th>\n",
       "      <th>digit_label</th>\n",
       "      <th>participant</th>\n",
       "      <th>intonation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000000.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>S73</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000001.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>S88</td>\n",
       "      <td>excited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000002.wav</td>\n",
       "      <td>70</td>\n",
       "      <td>S5</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000003.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>S85</td>\n",
       "      <td>bored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000004.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>S30</td>\n",
       "      <td>excited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0019995.wav</td>\n",
       "      <td>90</td>\n",
       "      <td>S163</td>\n",
       "      <td>excited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0019996.wav</td>\n",
       "      <td>10</td>\n",
       "      <td>S99</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0019997.wav</td>\n",
       "      <td>90</td>\n",
       "      <td>S46</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0019998.wav</td>\n",
       "      <td>19</td>\n",
       "      <td>S13</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0019999.wav</td>\n",
       "      <td>20</td>\n",
       "      <td>S101</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           File ID  digit_label participant intonation\n",
       "0      0000000.wav            4         S73   question\n",
       "1      0000001.wav            2         S88    excited\n",
       "2      0000002.wav           70          S5    neutral\n",
       "3      0000003.wav            2         S85      bored\n",
       "4      0000004.wav            4         S30    excited\n",
       "...            ...          ...         ...        ...\n",
       "19995  0019995.wav           90        S163    excited\n",
       "19996  0019996.wav           10         S99   question\n",
       "19997  0019997.wav           90         S46   question\n",
       "19998  0019998.wav           19         S13    neutral\n",
       "19999  0019999.wav           20        S101    neutral\n",
       "\n",
       "[20000 rows x 4 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('./Data/MLEnd/trainingMLEnd.csv')\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"./Data/MLEnd/training/Training/*.wav\" )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-214-4bc2b2d591d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetXy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscale_audio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monlySingleDigit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#a,b = getXy(files[:1000],labels_file=labels,scale_audio=True, onlySingleDigit=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-211-8ca6b8b788e5>\u001b[0m in \u001b[0;36mgetXy\u001b[1;34m(files, labels_file, scale_audio, onlySingleDigit)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mf0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoiced_flag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetPitch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwinLen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.02\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "X,y = getXy(files[:1],labels_file=labels,scale_audio=True, onlySingleDigit=True)\n",
    "\n",
    "#a,b = getXy(files[:1000],labels_file=labels,scale_audio=True, onlySingleDigit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.01288382e-02, 2.08882834e+02, 1.18829623e+02, 2.15277778e-01]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
