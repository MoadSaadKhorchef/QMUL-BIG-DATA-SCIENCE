{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys, re, pickle, glob\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import soundfile\n",
    "\n",
    "\n",
    "#from IPython.display import Audio\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padArra(an_array):\n",
    "    np.array(an_array)\n",
    "    shape = np.shape(an_array)\n",
    "    #print(shape)\n",
    "    if shape[0] < 129:\n",
    "    \n",
    "        padded_array = np.zeros((128))\n",
    "        padded_array[:shape[0]] = an_array\n",
    "        #print(\"padded: \", padded_array.shape)\n",
    "        return(padded_array.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_chromagram(waveform, sample_rate):\n",
    "    # STFT computed here explicitly; mel spectrogram and MFCC functions do this under the hood\n",
    "    stft_spectrogram=np.abs(librosa.stft(waveform))\n",
    "    # Produce the chromagram for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
    "    chromagram=np.mean(librosa.feature.chroma_stft(S=stft_spectrogram, sr=sample_rate,hop_length=512,n_fft=2048).T,axis=0)\n",
    "    return chromagram\n",
    "\n",
    "def feature_melspectrogram(waveform, sample_rate):\n",
    "    # Produce the mel spectrogram for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
    "    # Using 8khz as upper frequency bound should be enough for most speech classification tasks\n",
    "    melspectrogram=np.mean(librosa.feature.melspectrogram(y=waveform, sr=sample_rate, n_mels=128, fmax=sample_rate, hop_length=512,n_fft=2048).T,axis=0) ###\n",
    "    return melspectrogram\n",
    "\n",
    "def feature_mfcc(waveform, sample_rate):\n",
    "    # Compute the MFCCs for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
    "    # 40 filterbanks = 40 coefficients\n",
    "    mfc_coefficients=np.mean(librosa.feature.mfcc(y=waveform, sr=sample_rate, n_mfcc=40).T, axis=0) \n",
    "    return mfc_coefficients\n",
    "\n",
    "\n",
    "\n",
    "def getPitch(x,fs,winLen=0.02):\n",
    "  #winLen = 0.02 \n",
    "    p = winLen*fs\n",
    "    frame_length = int(2**int(p-1).bit_length())\n",
    "    hop_length = frame_length//2\n",
    "    f0, voiced_flag, voiced_probs = librosa.pyin(y=x, fmin=80, fmax=450, sr=fs, frame_length=frame_length,hop_length=hop_length)\n",
    "    return f0,voiced_flag\n",
    "\n",
    "\n",
    "\n",
    "def get_features(file):\n",
    "    # load an individual soundfile\n",
    "     with soundfile.SoundFile(file) as audio:\n",
    "        waveform = audio.read(dtype=\"float32\")\n",
    "        sample_rate = audio.samplerate\n",
    "        # compute features of soundfile\n",
    "        chromagram = padArra(feature_chromagram(waveform, sample_rate))\n",
    "        melspectrogram = padArra(feature_melspectrogram(waveform, sample_rate))\n",
    "        mfc_coefficients = padArra(feature_mfcc(waveform, sample_rate))\n",
    "\n",
    "        # my added features\n",
    "        #######\n",
    "        y = waveform\n",
    "        sr = sample_rate\n",
    "        stft_=np.abs(librosa.stft(waveform))\n",
    "        #print(chromagram.shape)\n",
    "        cent = padArra(np.mean( librosa.feature.spectral_centroid(y=y, sr=sr,hop_length=512,n_fft=2048).T, axis=0))\n",
    "        \n",
    "        contrast = padArra(np.mean( librosa.feature.spectral_contrast(S=stft_, sr=sr,hop_length=512,n_fft=2048).T, axis=0))\n",
    "        #tonnetz = np.mean( librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sample_rate ,hop_length=512).T,axis=0)#\n",
    "        rms = padArra(np.mean( librosa.feature.rms(y=y,frame_length=2048 ,hop_length=512).T, axis=0))\n",
    "        spec_bw = padArra(np.mean( librosa.feature.spectral_bandwidth(y=y, sr=sr ,n_fft=2048, hop_length=512).T, axis=0))\n",
    "        rolloff = padArra(np.mean( librosa.feature.spectral_rolloff(y=y, sr=sr ,n_fft=2048, hop_length=512).T, axis=0))\n",
    "        zcr = padArra(np.mean( librosa.feature.zero_crossing_rate(y, frame_length=2048, hop_length=512).T, axis=0))\n",
    "        #######\n",
    "    \n",
    "        #feature_matrix=np.array([])\n",
    "        # use np.hstack to stack our feature arrays horizontally to create a feature matrix\n",
    "        feature_matrix = np.column_stack((chromagram, np.array(melspectrogram).reshape(-1,1), mfc_coefficients , cent, contrast, rms, spec_bw, rolloff, zcr))\n",
    "        \n",
    "        return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXy(files,labels_file,scale_audio=False, onlySingleDigit=False):\n",
    "    X,y =[],[]\n",
    "    for file in tqdm(files):\n",
    "        file = file.replace(\"\\\\\", \"/\")\n",
    "        fileID = file.split(\"/\")[-1]\n",
    "        #print(fileID)\n",
    "        yi = list(labels_file[labels_file['File ID']==fileID]['digit_label'])[0]\n",
    "        label = list(labels_file[labels_file['File ID']==fileID]['digit_label'])[0]\n",
    "        if onlySingleDigit and yi>9:\n",
    "            continue\n",
    "        else:\n",
    "            fs = None # if None, fs would be 22050\n",
    "            x, fs = librosa.load(file,sr=fs)\n",
    "            if scale_audio: x = x/np.max(np.abs(x))\n",
    "            f0, voiced_flag = getPitch(x,fs,winLen=0.02)\n",
    "\n",
    "            a = np.sum(x**2)/len(x)\n",
    "            b = np.array(( a )).reshape(-1,1)\n",
    "            #print( np.array(( a )).reshape(-1,1) )\n",
    "            #print( b.shape )\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            power =      padArra( np.array(( np.sum(x**2)/len(x) )) .reshape(-1,1))\n",
    "            pitch_mean = padArra( np.array(( np.nanmean(f0) if np.mean(np.isnan(f0))<1 else 0)).reshape(-1,1) )\n",
    "            pitch_std  = padArra( np.array(( np.nanstd(f0) if np.mean(np.isnan(f0))<1 else 0)).reshape(-1,1) )\n",
    "            voiced_fr =  padArra( np.array(( np.mean(voiced_flag) )) .reshape(-1,1))\n",
    "\n",
    "            \n",
    "            #print (power)\n",
    "\n",
    "            #added \n",
    "            features = get_features(file)\n",
    "\n",
    "            #xi = [power,pitch_mean,pitch_std,voiced_fr]\n",
    "            #print(features.shape)\n",
    "            \n",
    "            xi = np.column_stack((power,pitch_mean,pitch_std,voiced_fr,features))\n",
    "\n",
    "            X.append(xi)\n",
    "            y.append(label)\n",
    "    return np.array(X),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File ID</th>\n",
       "      <th>digit_label</th>\n",
       "      <th>participant</th>\n",
       "      <th>intonation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000000.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>S73</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000001.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>S88</td>\n",
       "      <td>excited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000002.wav</td>\n",
       "      <td>70</td>\n",
       "      <td>S5</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000003.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>S85</td>\n",
       "      <td>bored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000004.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>S30</td>\n",
       "      <td>excited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0019995.wav</td>\n",
       "      <td>90</td>\n",
       "      <td>S163</td>\n",
       "      <td>excited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0019996.wav</td>\n",
       "      <td>10</td>\n",
       "      <td>S99</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0019997.wav</td>\n",
       "      <td>90</td>\n",
       "      <td>S46</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0019998.wav</td>\n",
       "      <td>19</td>\n",
       "      <td>S13</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0019999.wav</td>\n",
       "      <td>20</td>\n",
       "      <td>S101</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           File ID  digit_label participant intonation\n",
       "0      0000000.wav            4         S73   question\n",
       "1      0000001.wav            2         S88    excited\n",
       "2      0000002.wav           70          S5    neutral\n",
       "3      0000003.wav            2         S85      bored\n",
       "4      0000004.wav            4         S30    excited\n",
       "...            ...          ...         ...        ...\n",
       "19995  0019995.wav           90        S163    excited\n",
       "19996  0019996.wav           10         S99   question\n",
       "19997  0019997.wav           90         S46   question\n",
       "19998  0019998.wav           19         S13    neutral\n",
       "19999  0019999.wav           20        S101    neutral\n",
       "\n",
       "[20000 rows x 4 columns]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('./Data/MLEnd/trainingMLEnd.csv')\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"./Data/MLEnd/training/Training/*.wav\" )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:16<00:00,  6.53it/s]\n"
     ]
    }
   ],
   "source": [
    "X,y = getXy(files[:500],labels_file=labels,scale_audio=True, onlySingleDigit=True)\n",
    "\n",
    "#a,b = getXy(files[:1000],labels_file=labels,scale_audio=True, onlySingleDigit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 128, 13)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166,)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 2, 4, 2, 1, 3, 6, 9, 9, 2, 5, 4, 7, 9, 1, 9, 9, 1, 9, 5, 4,\n",
       "       5, 6, 3, 9, 7, 3, 5, 0, 6, 4, 9, 9, 0, 9, 0, 7, 3, 9, 1, 7, 1, 6,\n",
       "       6, 3, 9, 9, 4, 7, 6, 8, 2, 8, 2, 3, 4, 1, 1, 0, 1, 3, 5, 5, 5, 1,\n",
       "       1, 0, 2, 0, 2, 8, 2, 4, 2, 4, 9, 3, 6, 2, 5, 0, 1, 5, 7, 4, 8, 8,\n",
       "       8, 6, 6, 0, 1, 4, 4, 6, 3, 3, 1, 8, 2, 5, 9, 3, 5, 6, 5, 0, 3, 6,\n",
       "       8, 3, 3, 6, 3, 1, 4, 1, 6, 6, 8, 4, 1, 4, 8, 3, 9, 4, 6, 5, 6, 9,\n",
       "       3, 8, 3, 4, 0, 2, 1, 3, 7, 9, 9, 9, 3, 4, 8, 7, 1, 7, 8, 0, 7, 1,\n",
       "       6, 1, 8, 3, 4, 3, 3, 6, 3, 3, 7, 6])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.01288382e-02, 2.08882834e+02, 1.18829623e+02, ...,\n",
       "         2.19799573e+03, 4.69393921e+03, 1.59003364e-01],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[3.53392653e-02, 1.57289085e+02, 3.17844155e+01, ...,\n",
       "         2.43435264e+03, 5.33570107e+03, 1.55646073e-01],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[1.36762273e-02, 1.34964540e+02, 4.52054700e+00, ...,\n",
       "         1.44683333e+03, 1.62786991e+03, 2.71657783e-02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[3.36793034e-02, 2.35043429e+02, 2.25806484e+01, ...,\n",
       "         1.53812060e+03, 2.15815430e+03, 4.65959821e-02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[7.20467988e-03, 1.28627693e+02, 4.76938792e+00, ...,\n",
       "         2.64076862e+03, 5.97712027e+03, 1.06079102e-01],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[3.25437063e-02, 2.02585930e+02, 1.16999204e+01, ...,\n",
       "         2.35636731e+03, 4.95368712e+03, 1.06826410e-01],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1400)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(4, 4)\n",
    "b = t.view(2, 8)\n",
    "t.storage().data_ptr() == b.storage().data_ptr()  # `t` and `b` share the same underlying data.\n",
    "True\n",
    "# Modifying view tensor changes base tensor as well.\n",
    "b[0][0] = 3.14\n",
    "t[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n",
      "Tensors A and B data match? True\n",
      "Tensors A and C data match? True\n",
      "Tensors B and C data match? True\n"
     ]
    }
   ],
   "source": [
    "# Create (2, 3, 4) shape data tensor filled with 0.\n",
    "a = torch.zeros(2, 3, 4)\n",
    "\n",
    "# Flatten 2nd and 3rd dimensions of the original data \n",
    "# tensor using `view` and `flatten` methods.\n",
    "b = a.view(2, 12)\n",
    "c = torch.flatten(a, start_dim=1)\n",
    "\n",
    "print(a)\n",
    "# Change a distinct value in each flattened tensor object.\n",
    "b[0, 2] = 1\n",
    "c[0, 4] = 2\n",
    "\n",
    "# Compare tensors objects data to each other to look for \n",
    "# any mismatches.\n",
    "print(\"Tensors A and B data match?\", all(a.view(-1) == b.view(-1)))\n",
    "print(\"Tensors A and C data match?\", all(a.view(-1) == c.view(-1)))\n",
    "print(\"Tensors B and C data match?\", all(b.view(-1) == c.view(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
